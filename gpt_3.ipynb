{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "# openai.organization = \"org-SBQJ982bSDpfFvBzJ12OR7p9\"\n",
    "openai.api_key = \"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\"\n",
    "openai.Model.list()\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In a future world, robots are a common sight. They perform many tasks that humans used to do, from menial labor to complex surgeries. But there is one robot who is different from all the others. This robot, named Adam, has been programmed with the ability to feel emotions. At first, Adam is happy to be able to experience the world in a new way. But he soon realizes that the emotions he feels are much more powerful than he ever could have imagined. They overwhelm\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    engine=\"gpt-3.5-turbo\",  # Replace with the GPT-4 model engine name\n",
    "    prompt=\"Write a short story about a robot.\",\n",
    "    max_tokens=100,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "generated_text = response.choices[0].text\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get csv file\n",
    "data_path = \"data/raw/data/beetle.csv\"\n",
    "df = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "      <th>student_answer</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>assigned_points</th>\n",
       "      <th>max_points</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What role does the path play in determining wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>if that switch is with the path between that b...</td>\n",
       "      <td>If a bulb and a switch are in the same path th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What role does the path play in determining wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>the switch, the bulb, and the battery have to ...</td>\n",
       "      <td>If a bulb and a switch are in the same path th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What role does the path play in determining wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>the path plays an important role</td>\n",
       "      <td>If a bulb and a switch are in the same path th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What role does the path play in determining wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>uh-huh</td>\n",
       "      <td>If a bulb and a switch are in the same path th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What role does the path play in determining wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>switch is contained in a circuit</td>\n",
       "      <td>If a bulb and a switch are in the same path th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6613</th>\n",
       "      <td>6613</td>\n",
       "      <td>Explain your reasoning.</td>\n",
       "      <td>130</td>\n",
       "      <td>if one is out the others will go out, they are...</td>\n",
       "      <td>A and C are in the same closed path</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6614</th>\n",
       "      <td>6614</td>\n",
       "      <td>Explain your reasoning.</td>\n",
       "      <td>130</td>\n",
       "      <td>They are all on the dame closed path</td>\n",
       "      <td>A and C are in the same closed path</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6615</th>\n",
       "      <td>6615</td>\n",
       "      <td>Explain your reasoning.</td>\n",
       "      <td>130</td>\n",
       "      <td>They are contained on the same closed path.</td>\n",
       "      <td>A and C are in the same closed path</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616</th>\n",
       "      <td>6616</td>\n",
       "      <td>Explain your reasoning.</td>\n",
       "      <td>130</td>\n",
       "      <td>they are not parallel</td>\n",
       "      <td>A and C are in the same closed path</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6617</th>\n",
       "      <td>6617</td>\n",
       "      <td>Explain your reasoning.</td>\n",
       "      <td>130</td>\n",
       "      <td>removing either A or C will turn off the other...</td>\n",
       "      <td>A and C are in the same closed path</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6618 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id                                           question  question_id  \\\n",
       "0          0  What role does the path play in determining wh...            0   \n",
       "1          1  What role does the path play in determining wh...            0   \n",
       "2          2  What role does the path play in determining wh...            0   \n",
       "3          3  What role does the path play in determining wh...            0   \n",
       "4          4  What role does the path play in determining wh...            0   \n",
       "...      ...                                                ...          ...   \n",
       "6613    6613                            Explain your reasoning.          130   \n",
       "6614    6614                            Explain your reasoning.          130   \n",
       "6615    6615                            Explain your reasoning.          130   \n",
       "6616    6616                            Explain your reasoning.          130   \n",
       "6617    6617                            Explain your reasoning.          130   \n",
       "\n",
       "                                         student_answer  \\\n",
       "0     if that switch is with the path between that b...   \n",
       "1     the switch, the bulb, and the battery have to ...   \n",
       "2                      the path plays an important role   \n",
       "3                                                uh-huh   \n",
       "4                      switch is contained in a circuit   \n",
       "...                                                 ...   \n",
       "6613  if one is out the others will go out, they are...   \n",
       "6614               They are all on the dame closed path   \n",
       "6615        They are contained on the same closed path.   \n",
       "6616                              they are not parallel   \n",
       "6617  removing either A or C will turn off the other...   \n",
       "\n",
       "                                       reference_answer  assigned_points  \\\n",
       "0     If a bulb and a switch are in the same path th...                1   \n",
       "1     If a bulb and a switch are in the same path th...                1   \n",
       "2     If a bulb and a switch are in the same path th...                0   \n",
       "3     If a bulb and a switch are in the same path th...                0   \n",
       "4     If a bulb and a switch are in the same path th...                0   \n",
       "...                                                 ...              ...   \n",
       "6613                A and C are in the same closed path                1   \n",
       "6614                A and C are in the same closed path                1   \n",
       "6615                A and C are in the same closed path                1   \n",
       "6616                A and C are in the same closed path                0   \n",
       "6617                A and C are in the same closed path                0   \n",
       "\n",
       "      max_points  domain  \n",
       "0              1     NaN  \n",
       "1              1     NaN  \n",
       "2              1     NaN  \n",
       "3              1     NaN  \n",
       "4              1     NaN  \n",
       "...          ...     ...  \n",
       "6613           1     NaN  \n",
       "6614           1     NaN  \n",
       "6615           1     NaN  \n",
       "6616           1     NaN  \n",
       "6617           1     NaN  \n",
       "\n",
       "[6618 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4642360d5cf33d6f01da37720c4a2ade in your message.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39m# Measure the accuracy of GPT-3\u001b[39;00m\n\u001b[1;32m     70\u001b[0m gpt_3_engine \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# Replace with the appropriate GPT-3 model\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m gpt_3_accuracy \u001b[39m=\u001b[39m measure_accuracy(test_data, prompt_examples, gpt_3_engine)\n\u001b[1;32m     73\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGPT-3 Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mgpt_3_accuracy\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 51\u001b[0m, in \u001b[0;36mmeasure_accuracy\u001b[0;34m(test_data, prompt_examples, model)\u001b[0m\n\u001b[1;32m     48\u001b[0m assigned_points \u001b[39m=\u001b[39m item[\u001b[39m'\u001b[39m\u001b[39massigned_points\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     49\u001b[0m max_points \u001b[39m=\u001b[39m item[\u001b[39m'\u001b[39m\u001b[39mmax_points\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 51\u001b[0m predicted_points \u001b[39m=\u001b[39m grade_student_answer(prompt_examples, student_answer, reference_answer, max_points, model)\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m predicted_points \u001b[39m==\u001b[39m assigned_points:\n\u001b[1;32m     54\u001b[0m     correct_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[16], line 30\u001b[0m, in \u001b[0;36mgrade_student_answer\u001b[0;34m(prompt_examples, student_answer, reference_answer, max_points, model)\u001b[0m\n\u001b[1;32m     20\u001b[0m     messages\u001b[39m.\u001b[39mappend({\n\u001b[1;32m     21\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStudent answer: \u001b[39m\u001b[39m{\u001b[39;00mexample[\u001b[39m'\u001b[39m\u001b[39mstudent_answer\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mReference answer: \u001b[39m\u001b[39m{\u001b[39;00mexample[\u001b[39m'\u001b[39m\u001b[39mreference_answer\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mGrade out of \u001b[39m\u001b[39m{\u001b[39;00mexample[\u001b[39m'\u001b[39m\u001b[39mmax_points\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mexample[\u001b[39m'\u001b[39m\u001b[39massigned_points\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m     })\n\u001b[1;32m     25\u001b[0m messages\u001b[39m.\u001b[39mappend({\n\u001b[1;32m     26\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStudent answer: \u001b[39m\u001b[39m{\u001b[39;00mstudent_answer\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mReference answer: \u001b[39m\u001b[39m{\u001b[39;00mreference_answer\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mGrade out of \u001b[39m\u001b[39m{\u001b[39;00mmax_points\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m })\n\u001b[0;32m---> 30\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(model\u001b[39m=\u001b[39;49mmodel, messages\u001b[39m=\u001b[39;49mmessages, max_tokens\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, n\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, stop\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, temperature\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m)\n\u001b[1;32m     31\u001b[0m content \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     32\u001b[0m numbers \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mfindall(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+\u001b[39m\u001b[39m'\u001b[39m, content)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4642360d5cf33d6f01da37720c4a2ade in your message.)"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a function to grade student answers\n",
    "import re\n",
    "\n",
    "# Prepare the dataset\n",
    "def prepare_dataset(df):\n",
    "    data = df.to_dict('records')\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    return train_data, test_data\n",
    "\n",
    "import re\n",
    "\n",
    "def grade_student_answer(prompt_examples, student_answer, reference_answer, max_points, model):\n",
    "    messages = []\n",
    "    \n",
    "    for example in prompt_examples:\n",
    "        messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Student answer: {example['student_answer']}\\nReference answer: {example['reference_answer']}\\nGrade out of {example['max_points']}: {example['assigned_points']}\\n\\n\"\n",
    "        })\n",
    "\n",
    "    messages.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"Student answer: {student_answer}\\nReference answer: {reference_answer}\\nGrade out of {max_points}: \"\n",
    "    })\n",
    "\n",
    "    response = openai.ChatCompletion.create(model=model, messages=messages, max_tokens=3, n=1, stop=None, temperature=0.5)\n",
    "    content = response.choices[0].message['content'].strip()\n",
    "    numbers = re.findall(r'\\d+', content)\n",
    "    \n",
    "    if numbers:\n",
    "        predicted_points = int(numbers[0])\n",
    "    else:\n",
    "        predicted_points = 0\n",
    "\n",
    "    return predicted_points\n",
    "\n",
    "\n",
    "# Measure the accuracy of GPT-3\n",
    "def measure_accuracy(test_data, prompt_examples, model):\n",
    "    correct_count = 0\n",
    "    for item in test_data:\n",
    "        student_answer = item['student_answer']\n",
    "        reference_answer = item['reference_answer']\n",
    "        assigned_points = item['assigned_points']\n",
    "        max_points = item['max_points']\n",
    "        \n",
    "        predicted_points = grade_student_answer(prompt_examples, student_answer, reference_answer, max_points, model)\n",
    "        \n",
    "        if predicted_points == assigned_points:\n",
    "            correct_count += 1\n",
    "\n",
    "    accuracy = correct_count / len(test_data) * 100\n",
    "    return accuracy\n",
    "\n",
    "# Load your data into a DataFrame (assuming it's in a CSV file)\n",
    "data_path = \"data/raw/data/beetle.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.head(100)\n",
    "\n",
    "# Prepare the dataset\n",
    "train_data, test_data = prepare_dataset(df)\n",
    "\n",
    "# Select 5 examples for 5-shot learning\n",
    "prompt_examples = train_data[:5]\n",
    "\n",
    "# Measure the accuracy of GPT-3\n",
    "gpt_3_engine = \"gpt-3.5-turbo\" # Replace with the appropriate GPT-3 model\n",
    "gpt_3_accuracy = measure_accuracy(test_data, prompt_examples, gpt_3_engine)\n",
    "\n",
    "print(f\"GPT-3 Accuracy: {gpt_3_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a separate cell, define the following global variables\n",
    "correct_count = 0\n",
    "current_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages [{'role': 'system', 'content': 'Student answer: there is a gap\\nReference answer: the terminals are connected\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: the bulb terminal and the battery terminal are connected\\nReference answer: the terminals are connected\\nGrade out of 1: 1\\n\\n'}, {'role': 'system', 'content': 'Student answer: give me a hint\\nReference answer: the terminals are connected\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: uh-huh\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: The path cannot be open\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: the switch being on or off determines whether the bulb is contained in a closed path with the battery or not\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: An path with a switch connecting to a battery must be closed\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: they are in different states\\nReference answer: the terminals are connected\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: the path plays an important role\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: whether there is a closed path with a battery\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: a bulb must be in a closed path with a battery and a switch for the switch to affect the bulb\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: '}]\n",
      "content: {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"0\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1682722060,\n",
      "  \"id\": \"chatcmpl-7ARAK8GMRmAFN7QAeaEsWSiSfBa7s\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1,\n",
      "    \"prompt_tokens\": 470,\n",
      "    \"total_tokens\": 471\n",
      "  }\n",
      "}\n",
      "content: 0\n",
      "numbers: ['0']\n",
      "predicted_points: 0\n",
      "messages [{'role': 'system', 'content': 'Student answer: there is a gap\\nReference answer: the terminals are connected\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: the bulb terminal and the battery terminal are connected\\nReference answer: the terminals are connected\\nGrade out of 1: 1\\n\\n'}, {'role': 'system', 'content': 'Student answer: give me a hint\\nReference answer: the terminals are connected\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: uh-huh\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: The path cannot be open\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: the switch being on or off determines whether the bulb is contained in a closed path with the battery or not\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: An path with a switch connecting to a battery must be closed\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: they are in different states\\nReference answer: the terminals are connected\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: the path plays an important role\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: whether there is a closed path with a battery\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: It must be closed\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: '}]\n",
      "content: {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"0\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1682722061,\n",
      "  \"id\": \"chatcmpl-7ARAL0zEkssFK7GOqKpTuHTfJnJLE\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1,\n",
      "    \"prompt_tokens\": 453,\n",
      "    \"total_tokens\": 454\n",
      "  }\n",
      "}\n",
      "content: 0\n",
      "numbers: ['0']\n",
      "predicted_points: 0\n",
      "messages [{'role': 'system', 'content': 'Student answer: there is a gap\\nReference answer: the terminals are connected\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: the bulb terminal and the battery terminal are connected\\nReference answer: the terminals are connected\\nGrade out of 1: 1\\n\\n'}, {'role': 'system', 'content': 'Student answer: give me a hint\\nReference answer: the terminals are connected\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: uh-huh\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: The path cannot be open\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: the switch being on or off determines whether the bulb is contained in a closed path with the battery or not\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: An path with a switch connecting to a battery must be closed\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: they are in different states\\nReference answer: the terminals are connected\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: the path plays an important role\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: whether there is a closed path with a battery\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: if that switch is with the path between that bulb and the battery\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: '}]\n",
      "content: {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"1\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1682722061,\n",
      "  \"id\": \"chatcmpl-7ARALFBOWFHpbQm5hOHyCQY9rrC0n\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1,\n",
      "    \"prompt_tokens\": 462,\n",
      "    \"total_tokens\": 463\n",
      "  }\n",
      "}\n",
      "content: 1\n",
      "numbers: ['1']\n",
      "predicted_points: 1\n",
      "messages [{'role': 'system', 'content': 'Student answer: there is a gap\\nReference answer: the terminals are connected\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: the bulb terminal and the battery terminal are connected\\nReference answer: the terminals are connected\\nGrade out of 1: 1\\n\\n'}, {'role': 'system', 'content': 'Student answer: give me a hint\\nReference answer: the terminals are connected\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: uh-huh\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: The path cannot be open\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: the switch being on or off determines whether the bulb is contained in a closed path with the battery or not\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: An path with a switch connecting to a battery must be closed\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: they are in different states\\nReference answer: the terminals are connected\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: the path plays an important role\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: whether there is a closed path with a battery\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: they are connected.\\nReference answer: the terminals are connected\\nGrade out of 1: '}]\n",
      "content: {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"1\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1682722062,\n",
      "  \"id\": \"chatcmpl-7ARAMbtnN0agqOsY6LV73TROO4BtJ\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1,\n",
      "    \"prompt_tokens\": 440,\n",
      "    \"total_tokens\": 441\n",
      "  }\n",
      "}\n",
      "content: 1\n",
      "numbers: ['1']\n",
      "predicted_points: 1\n",
      "messages [{'role': 'system', 'content': 'Student answer: there is a gap\\nReference answer: the terminals are connected\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: the bulb terminal and the battery terminal are connected\\nReference answer: the terminals are connected\\nGrade out of 1: 1\\n\\n'}, {'role': 'system', 'content': 'Student answer: give me a hint\\nReference answer: the terminals are connected\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: uh-huh\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: The path cannot be open\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: the switch being on or off determines whether the bulb is contained in a closed path with the battery or not\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: An path with a switch connecting to a battery must be closed\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: they are in different states\\nReference answer: the terminals are connected\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: the path plays an important role\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: whether there is a closed path with a battery\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: 0\\n\\n'}, {'role': 'system', 'content': 'Student answer: if the switch is on?\\nReference answer: If a bulb and a switch are in the same path the switch affects the bulb\\nGrade out of 1: '}]\n",
      "content: {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"1\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1682722062,\n",
      "  \"id\": \"chatcmpl-7ARAMghMNvhxfHY49AbCVZkigHzee\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1,\n",
      "    \"prompt_tokens\": 454,\n",
      "    \"total_tokens\": 455\n",
      "  }\n",
      "}\n",
      "content: 1\n",
      "numbers: ['1']\n",
      "predicted_points: 1\n",
      "GPT-3 Accuracy: 60.00%\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Prepare the dataset\n",
    "def prepare_dataset(df):\n",
    "    data = df.to_dict('records')\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    return train_data, test_data\n",
    "\n",
    "import re\n",
    "\n",
    "def grade_student_answer(prompt_examples, student_answer, reference_answer, max_points, model):\n",
    "    messages = []\n",
    "    \n",
    "    for example in prompt_examples:\n",
    "        messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Student answer: {example['student_answer']}\\nReference answer: {example['reference_answer']}\\nGrade out of {example['max_points']}: {example['assigned_points']}\\n\\n\"\n",
    "        })\n",
    "\n",
    "    messages.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"Student answer: {student_answer}\\nReference answer: {reference_answer}\\nGrade out of {max_points}: \"\n",
    "    })\n",
    "\n",
    "    print(\"messages\", messages)\n",
    "\n",
    "    response = openai.ChatCompletion.create(model=model, messages=messages, max_tokens=3, n=1, stop=None, temperature=0.5)\n",
    "    content = response.choices[0].message['content'].strip()\n",
    "    print(\"content:\", response)\n",
    "    print(\"content:\", content)\n",
    "    numbers = re.findall(r'\\d+', content)\n",
    "    print(\"numbers:\", numbers)\n",
    "    if numbers:\n",
    "        predicted_points = int(numbers[0])\n",
    "        print(\"predicted_points:\", predicted_points)\n",
    "    else:\n",
    "        predicted_points = 0\n",
    "\n",
    "    return predicted_points\n",
    "\n",
    "\n",
    "# Update the measure_accuracy function as follows\n",
    "def measure_accuracy(test_data, prompt_examples, model, start_index=0):\n",
    "    global correct_count\n",
    "    global current_index\n",
    "    \n",
    "    for i, item in enumerate(test_data[start_index:]):  # Wrap the iterable with tqdm\n",
    "        current_index = start_index + i\n",
    "        student_answer = item['student_answer']\n",
    "        reference_answer = item['reference_answer']\n",
    "        assigned_points = item['assigned_points']\n",
    "        max_points = item['max_points']\n",
    "        \n",
    "        try:\n",
    "            predicted_points = grade_student_answer(prompt_examples, student_answer, reference_answer, max_points, model)\n",
    "        except Exception as e:\n",
    "            print(f\"Error at index {current_index}: {e}\")\n",
    "            break\n",
    "        \n",
    "        if predicted_points == assigned_points:\n",
    "            correct_count += 1\n",
    "        \n",
    "    accuracy = correct_count / len(test_data) * 100\n",
    "    return accuracy\n",
    "\n",
    "# Load your data into a DataFrame (assuming it's in a CSV file)\n",
    "data_path = \"data/raw/data/beetle.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.head(25)\n",
    "\n",
    "# Prepare the dataset\n",
    "train_data, test_data = prepare_dataset(df)\n",
    "\n",
    "# Select 10 random examples for 10-shot learning\n",
    "prompt_examples = random.sample(train_data, 10)\n",
    "\n",
    "# Measure the accuracy of GPT-3\n",
    "gpt_3_engine = \"gpt-3.5-turbo\" # Replace with the appropriate GPT-3 model\n",
    "gpt_3_accuracy = measure_accuracy(test_data, prompt_examples, gpt_3_engine, start_index=current_index)\n",
    "\n",
    "print(f\"GPT-3 Accuracy: {gpt_3_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3 Accuracy: 60.95%\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPT-3 Accuracy: {gpt_3_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.997732426303855"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdd = correct_count / current_index * 100\n",
    "testdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a separate cell, define the following global variables\n",
    "correct_count_4 = 0\n",
    "current_index_4 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'current_index_4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[240], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39m# Measure the accuracy of GPT-3\u001b[39;00m\n\u001b[1;32m     78\u001b[0m gpt_4_engine \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpt-4\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# Replace with the appropriate GPT-3 model\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m gpt_4_accuracy \u001b[39m=\u001b[39m measure_accuracy(test_data, prompt_examples, gpt_4_engine, start_index\u001b[39m=\u001b[39mcurrent_index_4)\n\u001b[1;32m     81\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGPT-4 Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mgpt_4_accuracy\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'current_index_4' is not defined"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Prepare the dataset\n",
    "def prepare_dataset(df):\n",
    "    data = df.to_dict('records')\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    return train_data, test_data\n",
    "\n",
    "import re\n",
    "\n",
    "def grade_student_answer(prompt_examples, student_answer, reference_answer, max_points, model):\n",
    "    messages = []\n",
    "    \n",
    "    for example in prompt_examples:\n",
    "        messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Student answer: {example['student_answer']}\\nReference answer: {example['reference_answer']}\\nGrade out of {example['max_points']}: {example['assigned_points']}\\n\\n\"\n",
    "        })\n",
    "\n",
    "    messages.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"Student answer: {student_answer}\\nReference answer: {reference_answer}\\nGrade out of {max_points}: \"\n",
    "    })\n",
    "\n",
    "    response = openai.ChatCompletion.create(model=model, messages=messages, max_tokens=3, n=1, stop=None, temperature=0.5)\n",
    "    content = response.choices[0].message['content'].strip()\n",
    "    numbers = re.findall(r'\\d+', content)\n",
    "    \n",
    "    if numbers:\n",
    "        predicted_points = int(numbers[0])\n",
    "    else:\n",
    "        predicted_points = 0\n",
    "\n",
    "    return predicted_points\n",
    "\n",
    "\n",
    "# Update the measure_accuracy function as follows\n",
    "def measure_accuracy(test_data, prompt_examples, model, start_index=0):\n",
    "    global correct_count_4\n",
    "    global current_index_4\n",
    "    \n",
    "    for i, item in enumerate(tqdm(test_data[start_index:])):  # Wrap the iterable with tqdm\n",
    "        current_index_4 = start_index + i\n",
    "        student_answer = item['student_answer']\n",
    "        reference_answer = item['reference_answer']\n",
    "        assigned_points = item['assigned_points']\n",
    "        max_points = item['max_points']\n",
    "        \n",
    "        try:\n",
    "            predicted_points = grade_student_answer(prompt_examples, student_answer, reference_answer, max_points, model)\n",
    "        except Exception as e:\n",
    "            print(f\"Error at index {current_index_4}: {e}\")\n",
    "            break\n",
    "        \n",
    "        if predicted_points == assigned_points:\n",
    "            correct_count_4 += 1\n",
    "        \n",
    "    accuracy = correct_count_4 / len(test_data) * 100\n",
    "    return accuracy\n",
    "\n",
    "# Load your data into a DataFrame (assuming it's in a CSV file)\n",
    "data_path = \"data/raw/data/beetle.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.head(50)\n",
    "\n",
    "# Prepare the dataset\n",
    "train_data, test_data = prepare_dataset(df)\n",
    "\n",
    "# Select 10 random examples for 10-shot learning\n",
    "prompt_examples = random.sample(train_data, 10)\n",
    "\n",
    "# Measure the accuracy of GPT-3\n",
    "gpt_4_engine = \"gpt-4\" # Replace with the appropriate GPT-3 model\n",
    "gpt_4_accuracy = measure_accuracy(test_data, prompt_examples, gpt_4_engine, start_index=current_index_4)\n",
    "\n",
    "print(f\"GPT-4 Accuracy: {gpt_4_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing selecting example rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found texas with type csv in (data/splits/data) and converted it to df\n"
     ]
    }
   ],
   "source": [
    "from performance_tracking.classes.Dataset_api import Dataset_api\n",
    "\n",
    "dataset = Dataset_api(\n",
    "    dir=\"data/splits/data\",\n",
    "    file_name=\"texas\",\n",
    "    seed=42,\n",
    "    shots=5\n",
    ")\n",
    "\n",
    "dataset.split_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "      <th>student_answer</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>assigned_points</th>\n",
       "      <th>max_points</th>\n",
       "      <th>domain</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>normalized_points</th>\n",
       "      <th>...</th>\n",
       "      <th>assigned_points_2</th>\n",
       "      <th>student_answer_3</th>\n",
       "      <th>reference_answer_3</th>\n",
       "      <th>assigned_points_3</th>\n",
       "      <th>student_answer_4</th>\n",
       "      <th>reference_answer_4</th>\n",
       "      <th>assigned_points_4</th>\n",
       "      <th>student_answer_5</th>\n",
       "      <th>reference_answer_5</th>\n",
       "      <th>assigned_points_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1442</td>\n",
       "      <td>What is a queue?</td>\n",
       "      <td>181</td>\n",
       "      <td>a queue is a list of things that follows the f...</td>\n",
       "      <td>A data structure that can store elements, whic...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>science</td>\n",
       "      <td>texas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>a queue is a list of objects in a particular o...</td>\n",
       "      <td>A data structure that can store elements, whic...</td>\n",
       "      <td>4</td>\n",
       "      <td>a queue is a data structure that stores elemen...</td>\n",
       "      <td>A data structure that can store elements, whic...</td>\n",
       "      <td>5</td>\n",
       "      <td>A waiting list of items that operation in a FI...</td>\n",
       "      <td>A data structure that can store elements, whic...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id          question  question_id  \\\n",
       "0    1442  What is a queue?          181   \n",
       "\n",
       "                                      student_answer  \\\n",
       "0  a queue is a list of things that follows the f...   \n",
       "\n",
       "                                    reference_answer  assigned_points  \\\n",
       "0  A data structure that can store elements, whic...                5   \n",
       "\n",
       "   max_points   domain dataset_name  normalized_points  ... assigned_points_2  \\\n",
       "0           5  science        texas                1.0  ...                 5   \n",
       "\n",
       "                                    student_answer_3  \\\n",
       "0  a queue is a list of objects in a particular o...   \n",
       "\n",
       "                                  reference_answer_3 assigned_points_3  \\\n",
       "0  A data structure that can store elements, whic...                 4   \n",
       "\n",
       "                                    student_answer_4  \\\n",
       "0  a queue is a data structure that stores elemen...   \n",
       "\n",
       "                                  reference_answer_4 assigned_points_4  \\\n",
       "0  A data structure that can store elements, whic...                 5   \n",
       "\n",
       "                                    student_answer_5  \\\n",
       "0  A waiting list of items that operation in a FI...   \n",
       "\n",
       "                                  reference_answer_5 assigned_points_5  \n",
       "0  A data structure that can store elements, whic...                 5  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation_df\"].head(1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# Create a function to grade student answers\n",
    "import re\n",
    "\n",
    "import openai\n",
    "# openai.organization = \"org-SBQJ982bSDpfFvBzJ12OR7p9\"\n",
    "openai.api_key = \"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\"\n",
    "openai.Model.list()\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_student_answer(row, model, shots):\n",
    "\n",
    "    # Parameters for exponential backoff\n",
    "    X = 5\n",
    "    k = 2\n",
    "    max_attempts = 5\n",
    "\n",
    "    instruction_line = \"Grade the following Student answer based on the Reference answer. The grade should be a howl number.\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an AI trained to grade student answers based on a reference answer. Please return a single hwol number.\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for i in range(1, shots + 1):\n",
    "        messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "                {instruction_line}\n",
    "                Student answer: {row[f'student_answer_{i}']}\\n\n",
    "                Reference answer: {row[f'reference_answer_{i}']}\\n\n",
    "                Grade out of {row['max_points']}: {row[f'assigned_points_{i}']}\\n\\n\n",
    "            \"\"\"\n",
    "        })\n",
    "\n",
    "    messages.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"\"\"\n",
    "            {instruction_line}\n",
    "            Student answer: {row['student_answer']}\\n\n",
    "            Reference answer: {row['reference_answer']}\\n\n",
    "            Grade out of {row['max_points']}: \n",
    "        \"\"\"\n",
    "    })\n",
    "\n",
    "    for attempt in range(max_attempts):\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(model=model, messages=messages, max_tokens=3, n=1, stop=None, temperature=0.5)\n",
    "                \n",
    "                # If the API call is successful, we break the loop and don't retry\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error on attempt {attempt + 1}: {str(e)}\")\n",
    "                \n",
    "                # If we've reached max attempts, re-raise the exception\n",
    "                if attempt + 1 == max_attempts:\n",
    "                    raise\n",
    "                else:\n",
    "                    # Sleep before next attempt\n",
    "                    time.sleep(X + (attempt ** k))\n",
    "    \n",
    "    content = response.choices[0].message['content'].strip()\n",
    "\n",
    "    # This regex pattern finds float numbers in a string\n",
    "    float_number_pattern = r\"[-+]?[0-9]*\\.?[0-9]+\"\n",
    "    numbers = re.findall(float_number_pattern, content)\n",
    "    \n",
    "    if numbers:                \n",
    "        predicted_points = int(round(float(numbers[0])))\n",
    "    else:\n",
    "        print(\"Not valid input!\")\n",
    "        predicted_points = 0\n",
    "\n",
    "    return predicted_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are an AI trained to grade student answers based on a reference answer. Please return a single hwol number.'}, {'role': 'system', 'content': \"\\n                Grade the following Student answer based on the Reference answer. The grade should be a howl number.\\n                Student answer: Last in, last out architecture. It works the same way a line at the bank would work, the person that's been waiting the longest gets served first.\\n\\n                Reference answer: A data structure that can store elements, which has the property that the last item added will be the last to be removed (or first-in-first-out).\\n\\n                Grade out of 5: 5\\n\\n\\n            \"}, {'role': 'system', 'content': '\\n                Grade the following Student answer based on the Reference answer. The grade should be a howl number.\\n                Student answer: is a particular kind of collection in which the entities in the collection are kept in order and the principal (or only) operations on the collection are the addition of entities to the rear terminal position and removal of entities from the front terminal position. First in First Out (FIFO Method).\\n\\n                Reference answer: A data structure that can store elements, which has the property that the last item added will be the last to be removed (or first-in-first-out).\\n\\n                Grade out of 5: 5\\n\\n\\n            '}, {'role': 'system', 'content': '\\n                Grade the following Student answer based on the Reference answer. The grade should be a howl number.\\n                Student answer: a queue is a list of objects in a particular order that is read one at a time starting at the first followed by the second and so on.\\n\\n                Reference answer: A data structure that can store elements, which has the property that the last item added will be the last to be removed (or first-in-first-out).\\n\\n                Grade out of 5: 4\\n\\n\\n            '}, {'role': 'system', 'content': '\\n                Grade the following Student answer based on the Reference answer. The grade should be a howl number.\\n                Student answer: a queue is a data structure that stores elements in a First in First out order.\\n\\n                Reference answer: A data structure that can store elements, which has the property that the last item added will be the last to be removed (or first-in-first-out).\\n\\n                Grade out of 5: 5\\n\\n\\n            '}, {'role': 'system', 'content': '\\n                Grade the following Student answer based on the Reference answer. The grade should be a howl number.\\n                Student answer: A waiting list of items that operation in a FIFO (first in first out) order.\\n\\n                Reference answer: A data structure that can store elements, which has the property that the last item added will be the last to be removed (or first-in-first-out).\\n\\n                Grade out of 5: 5\\n\\n\\n            '}, {'role': 'system', 'content': '\\n            Grade the following Student answer based on the Reference answer. The grade should be a howl number.\\n            Student answer: a queue is a list of things that follows the first in first out behavior\\n\\n            Reference answer: A data structure that can store elements, which has the property that the last item added will be the last to be removed (or first-in-first-out).\\n\\n            Grade out of 5: \\n        '}]\n"
     ]
    }
   ],
   "source": [
    "assinged_points = grade_student_answer(row=dataset[\"validation_df\"].iloc[0], model=gpt_3_engine, shots=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_student_answer(row, model):\n",
    "\n",
    "    # Parameters for exponential backoff\n",
    "    X = 5\n",
    "    k = 2\n",
    "    max_attempts = 5\n",
    "\n",
    "    instruction_line = \"Grade the following Student answer based on the Reference answer. The grade should be a howl number.\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an AI trained to grade student answers based on a reference answer. Please return a single hwol number.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "                {instruction_line}\n",
    "                Student answer: {row['student_answer_1']}\\n\n",
    "                Reference answer: {row['reference_answer_1']}\\n\n",
    "                Grade out of {row['max_points']}: {row['assigned_points_1']}\\n\\n\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "                {instruction_line}\n",
    "                Student answer: {row['student_answer_2']}\\n\n",
    "                Reference answer: {row['reference_answer_2']}\\n\n",
    "                Grade out of {row['max_points']}: {row['assigned_points_2']}\\n\\n\n",
    "            \"\"\"\n",
    "        },\n",
    "                {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "                {instruction_line}\n",
    "                Student answer: {row['student_answer_3']}\\n\n",
    "                Reference answer: {row['reference_answer_3']}\\n\n",
    "                Grade out of {row['max_points']}: {row['assigned_points_3']}\\n\\n\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    messages.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"\"\"\n",
    "            {instruction_line}\n",
    "            Student answer: {row['student_answer']}\\n\n",
    "            Reference answer: {row['reference_answer']}\\n\n",
    "            Grade out of {row['max_points']}: \n",
    "        \"\"\"\n",
    "    })\n",
    "\n",
    "    for attempt in range(max_attempts):\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(model=model, messages=messages, max_tokens=3, n=1, stop=None, temperature=0.5)\n",
    "                \n",
    "                # If the API call is successful, we break the loop and don't retry\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error on attempt {attempt + 1}: {str(e)}\")\n",
    "                \n",
    "                # If we've reached max attempts, re-raise the exception\n",
    "                if attempt + 1 == max_attempts:\n",
    "                    raise\n",
    "                else:\n",
    "                    # Sleep before next attempt\n",
    "                    time.sleep(X + (attempt ** k))\n",
    "    \n",
    "    content = response.choices[0].message['content'].strip()\n",
    "\n",
    "    # This regex pattern finds float numbers in a string\n",
    "    float_number_pattern = r\"[-+]?[0-9]*\\.?[0-9]+\"\n",
    "    numbers = re.findall(float_number_pattern, content)\n",
    "    \n",
    "    if numbers:\n",
    "                \n",
    "        predicted_points = int(round(float(numbers[0])))\n",
    "    else:\n",
    "        print(\"Not valid input!\")\n",
    "        predicted_points = 0\n",
    "\n",
    "    return predicted_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "      <th>student_answer</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>assigned_points</th>\n",
       "      <th>max_points</th>\n",
       "      <th>domain</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>normalized_points</th>\n",
       "      <th>...</th>\n",
       "      <th>assigned_points_2</th>\n",
       "      <th>student_answer_3</th>\n",
       "      <th>reference_answer_3</th>\n",
       "      <th>assigned_points_3</th>\n",
       "      <th>student_answer_4</th>\n",
       "      <th>reference_answer_4</th>\n",
       "      <th>assigned_points_4</th>\n",
       "      <th>student_answer_5</th>\n",
       "      <th>reference_answer_5</th>\n",
       "      <th>assigned_points_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1442</td>\n",
       "      <td>What is a queue?</td>\n",
       "      <td>181</td>\n",
       "      <td>a queue is a list of things that follows the f...</td>\n",
       "      <td>A data structure that can store elements, whic...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>science</td>\n",
       "      <td>texas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>a queue is a list of objects in a particular o...</td>\n",
       "      <td>A data structure that can store elements, whic...</td>\n",
       "      <td>4</td>\n",
       "      <td>a queue is a data structure that stores elemen...</td>\n",
       "      <td>A data structure that can store elements, whic...</td>\n",
       "      <td>5</td>\n",
       "      <td>A waiting list of items that operation in a FI...</td>\n",
       "      <td>A data structure that can store elements, whic...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id          question  question_id  \\\n",
       "0    1442  What is a queue?          181   \n",
       "\n",
       "                                      student_answer  \\\n",
       "0  a queue is a list of things that follows the f...   \n",
       "\n",
       "                                    reference_answer  assigned_points  \\\n",
       "0  A data structure that can store elements, whic...                5   \n",
       "\n",
       "   max_points   domain dataset_name  normalized_points  ... assigned_points_2  \\\n",
       "0           5  science        texas                1.0  ...                 5   \n",
       "\n",
       "                                    student_answer_3  \\\n",
       "0  a queue is a list of objects in a particular o...   \n",
       "\n",
       "                                  reference_answer_3 assigned_points_3  \\\n",
       "0  A data structure that can store elements, whic...                 4   \n",
       "\n",
       "                                    student_answer_4  \\\n",
       "0  a queue is a data structure that stores elemen...   \n",
       "\n",
       "                                  reference_answer_4 assigned_points_4  \\\n",
       "0  A data structure that can store elements, whic...                 5   \n",
       "\n",
       "                                    student_answer_5  \\\n",
       "0  A waiting list of items that operation in a FI...   \n",
       "\n",
       "                                  reference_answer_5 assigned_points_5  \n",
       "0  A data structure that can store elements, whic...                 5  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation_df\"].head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation_df\"].iloc[index][\"assigned_points\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gpt_3_engine = \"gpt-3.5-turbo\" # Replace with the appropriate GPT-3 model\n",
    "\n",
    "assinged_points = grade_student_answer(row=dataset[\"validation_df\"].iloc[index], model=gpt_3_engine)\n",
    "assinged_points\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "Total correct predictions: 0\n"
     ]
    }
   ],
   "source": [
    "# Sample 100 rows randomly from the dataframe\n",
    "sampled_df = dataset[\"validation_df\"]\n",
    "\n",
    "# Initialize a variable to count the number of correct predictions\n",
    "total_correct = 0\n",
    "total_seen = 0\n",
    "\n",
    "# Loop through the sampled dataframe\n",
    "for index, row in sampled_df.iterrows():\n",
    "\n",
    "    print(index)\n",
    "\n",
    "    # # Get the predicted points using the grade_student_answer function\n",
    "    # predicted_points = grade_student_answer(row=row, model=gpt_3_engine)\n",
    "\n",
    "    # # Check if the predicted points are equal to the assigned points in the row\n",
    "    # if predicted_points == row['assigned_points']:\n",
    "    #     # If they are equal, increment the total_correct counter\n",
    "    #     total_correct += 1\n",
    "    # total_seen += 1\n",
    "\n",
    "    # print(f\"difference: {predicted_points - row['assigned_points']}\")\n",
    "\n",
    "print(f'Total correct predictions: {total_correct}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_correct / total_seen\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maybe as check before running api calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>answer_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>207</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>208</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>209</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>210</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>211</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_id  answer_count\n",
       "0           131            29\n",
       "1           132            29\n",
       "2           133            29\n",
       "3           134            29\n",
       "4           135            29\n",
       "..          ...           ...\n",
       "76          207            28\n",
       "77          208            28\n",
       "78          209            28\n",
       "79          210            28\n",
       "80          211            28\n",
       "\n",
       "[81 rows x 2 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_counts = df.groupby('question_id')['student_answer'].size()\n",
    "answer_counts_df = answer_counts.reset_index().rename(columns={'student_answer': 'answer_count'})\n",
    "answer_counts_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
