{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.Dataset_Basic import Dataset_Basic\n",
    "from classes.Process_Stages import Process_Stages\n",
    "\n",
    "from classes.Dataset_Settings import Dataset_Settings\n",
    "\n",
    "from run_models.cosine_sililarity.classes.Dataset_Cosine import Dataset_Cosine\n",
    "from run_models.gensim.classes.Process_Stages_Gensim import Process_Stages_Gensim\n",
    "\n",
    "from run_models.embed_words.classes.Embed_Words import Embed_Words\n",
    "\n",
    "from run_models.gensim.services.gensim_services import gensim_download, gensim_save, gensim_load\n",
    "from word_embedding.models.classes.EmbeddingModel import EmbeddingModel\n",
    "\n",
    "name_dataset = \"conceptnet_cosine_similarity\"\n",
    "\n",
    "datasets = {}\n",
    "datasets[\"neural_course\"] = Dataset_Cosine(\n",
    "    df_name=\"neural_course\",\n",
    "    model_name=name_dataset, # used for dir name inside data_saved\n",
    "\n",
    "    language=\"english\",\n",
    "\n",
    "    datasets = {\n",
    "        \"emebed_words_conceptnet\": Dataset_Settings(\n",
    "            df=None,\n",
    "            may_run_now=False,\n",
    "            required=True,\n",
    "            parquet=True\n",
    "        ),\n",
    "        name_dataset: Dataset_Settings(\n",
    "            df=None,\n",
    "            may_run_now=True,\n",
    "            required=True,\n",
    "            parquet=True,\n",
    "            name_required_dataset=\"gensim\"\n",
    "        ),\n",
    "    },\n",
    "\n",
    "    columns_to_add = {name_dataset: {\"cosine_similarity\": []}},\n",
    "\n",
    ")\n",
    "\n",
    "# get dataset, process dataset, save dataset\n",
    "datasets[\"neural_course\"].get_dataset()\n",
    "datasets[\"neural_course\"].process_dataset()\n",
    "datasets[\"neural_course\"].add_columns()\n",
    "datasets[\"neural_course\"].save()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Initialize the tokenizer and the model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Your sentence\n",
    "sentence = \"This is a simple sentence.\"\n",
    "\n",
    "# Tokenize the sentence and encode it to IDs\n",
    "input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "\n",
    "# Create tensors\n",
    "input_ids = torch.tensor([input_ids])\n",
    "\n",
    "# Forward pass: compute the BERT embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "# Extract the last hidden states (the embeddings)\n",
    "last_hidden_states = outputs[0]\n",
    "\n",
    "# # Print the embeddings\n",
    "# for i, token_str in enumerate(tokenizer.convert_ids_to_tokens(input_ids[0])):\n",
    "#     print(token_str, last_hidden_states[0, i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(sentence):\n",
    "    # Tokenize the sentence and encode it to IDs\n",
    "    input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "\n",
    "    # Create tensors\n",
    "    input_ids = torch.tensor([input_ids])\n",
    "\n",
    "    # Forward pass: compute the BERT embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "\n",
    "    # Extract the last hidden states (the embeddings)\n",
    "    last_hidden_states = outputs[0]\n",
    "\n",
    "    return last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes\n",
    "from data.embed_words.BERT_embedding.classes.BERT_Embedding import BERT_Embedding\n",
    "from classes.Dataset_Settings import Dataset_Settings\n",
    "\n",
    "BERT_embed = BERT_Embedding(\n",
    "    df_name=\"neural_course\",\n",
    "    model_name=\"BERT\", # used for dir name inside data_saved\n",
    "\n",
    "    language=\"english\",\n",
    "\n",
    "    datasets = {\n",
    "        \"standardized_splits\": Dataset_Settings(\n",
    "            df=None,\n",
    "            df_name=\"splits\",\n",
    "            base_dir=\"data\",\n",
    "\n",
    "            may_run_now=False,\n",
    "            required=True,\n",
    "        ),\n",
    "        \"BERT\": Dataset_Settings(\n",
    "            df=None,\n",
    "            df_name=\"BERT\",\n",
    "            base_dir=\"data/embed_words/data\",\n",
    "\n",
    "            may_run_now=True,\n",
    "            required=True,\n",
    "            parquet=True,\n",
    "            name_required_dataset=\"standardized_splits\",\n",
    "            force_run=False\n",
    "        ),\n",
    "    },\n",
    "\n",
    "    pre_trained_BERT_model_name=\"bert-base-uncased\"\n",
    "\n",
    ")\n",
    "\n",
    "BERT_embed.run_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Marly is lief\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed a sentence in BERT_tokenized\n",
    "import pandas as pd\n",
    "\n",
    "df_BERT = pd.read_parquet(\"data/embed_words/data/BERT/data/neural_course.parquet\")\n",
    "df_2 = pd.read_csv(\"data/splits/data/neural_course.csv\")\n",
    "fast_text = pd.read_parquet(\"data/embed_words/data/fasttext/data/neural_course.parquet\")\n",
    "\n",
    "basic = pd.read_csv(\"data/basic_processed/data/neural_course.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.string_array import str_to_array\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "1 - cosine(str_to_array(df_BERT.iloc[0][\"student_answer\"])[0], str_to_array(df_BERT.iloc[0][\"student_answer\"])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create sample dataset\n",
    "sample = pd.read_csv(\"data/splits/data/beetle.csv\")\n",
    "sample = sample.sample(100, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the DataFrame into train (70%) and the remaining data (30%)\n",
    "train, temp_df = train_test_split(sample, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the remaining data further into test (20% of the original dataset) and validation (10% of the original dataset) sets\n",
    "test, validation = train_test_split(temp_df, test_size=1/3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.iloc[0:].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.save import save\n",
    "\n",
    "save(\n",
    "    dir=\"testing/data\", \n",
    "    file_name=\"sample\", \n",
    "    df=sample\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "      <th>student_answer</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>assigned_points</th>\n",
       "      <th>max_points</th>\n",
       "      <th>domain</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>normalized_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>Explain why you got a voltage reading of 1.5 f...</td>\n",
       "      <td>8</td>\n",
       "      <td>Terminal 1 is not connected to terminal 1</td>\n",
       "      <td>There is a gap between terminals 1 and 6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beetle</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id                                           question  question_id  \\\n",
       "96      96  Explain why you got a voltage reading of 1.5 f...            8   \n",
       "\n",
       "                               student_answer  \\\n",
       "96  Terminal 1 is not connected to terminal 1   \n",
       "\n",
       "                            reference_answer  assigned_points  max_points  \\\n",
       "96  There is a gap between terminals 1 and 6                0           1   \n",
       "\n",
       "    domain dataset_name  normalized_points  \n",
       "96     NaN       beetle                0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.query(\"question_id == 8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found sample with type csv in (testing/data) and converted it to df\n",
      "   row_id                                           question  question_id  \\\n",
      "0    1488  How does a damaged bulb compare to an open swi...           70   \n",
      "1    6348                            Explain your reasoning.          127   \n",
      "2    1321  Explain why you got a voltage reading of 1.5 f...           68   \n",
      "3    2927  When switch X was closed and switch Y was open...           86   \n",
      "4    4516      Explain why circuit 2 is not a short circuit.          106   \n",
      "5    3901          Explain why circuit 5 is a short circuit.           98   \n",
      "6    3749  What does a voltage reading of 1.5 tell you ab...           96   \n",
      "7    3090  Explain why you got a voltage reading of 1.5 f...           88   \n",
      "8    1536  What role does the path play in determining wh...           71   \n",
      "9    4882  Explain why you got a voltage reading of 1.5 f...          109   \n",
      "\n",
      "                                      student_answer  \\\n",
      "0                         it creates the same effect   \n",
      "1                        it will cut off the circuit   \n",
      "2  The positive battery terminal is separted by a...   \n",
      "3  It was still contained in a closed path with t...   \n",
      "4  Because the battery is out of the closed path ...   \n",
      "5          the bulb is not connected to the battery.   \n",
      "6                   the terminals form a closed path   \n",
      "7  I get a 1.5 V reading because the negative ter...   \n",
      "8    The path must be closed and contain the battery   \n",
      "9  the positive terminal is seperated by a gap fr...   \n",
      "\n",
      "                                    reference_answer  assigned_points  \\\n",
      "0  A damaged bulb and an open switch both create ...                1   \n",
      "1                               bulb B creates a gap                0   \n",
      "2  Terminal 2 and the positive terminal are separ...                1   \n",
      "3  Bulb A is still contained in a closed path wit...                1   \n",
      "4           The battery in 2 is not in a closed path                1   \n",
      "5  the battery is contained in a closed path in w...                0   \n",
      "6                    the terminals are not connected                0   \n",
      "7  Terminal 1 and the positive terminal are not c...                0   \n",
      "8  If a bulb and a switch are in the same path th...                0   \n",
      "9  Terminal 3 and the positive terminal are separ...                1   \n",
      "\n",
      "   max_points  domain dataset_name  normalized_points  ...  assigned_points_1  \\\n",
      "0           1     NaN       beetle                1.0  ...                0.0   \n",
      "1           1     NaN       beetle                0.0  ...                NaN   \n",
      "2           1     NaN       beetle                1.0  ...                0.0   \n",
      "3           1     NaN       beetle                1.0  ...                1.0   \n",
      "4           1     NaN       beetle                1.0  ...                0.0   \n",
      "5           1     NaN       beetle                0.0  ...                1.0   \n",
      "6           1     NaN       beetle                0.0  ...                NaN   \n",
      "7           1     NaN       beetle                0.0  ...                1.0   \n",
      "8           1     NaN       beetle                0.0  ...                0.0   \n",
      "9           1     NaN       beetle                1.0  ...                1.0   \n",
      "\n",
      "                                    student_answer_2  \\\n",
      "0                                    It is the same.   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "5              the battery alone is in a closed path   \n",
      "6                                                NaN   \n",
      "7                                    no damaged bulb   \n",
      "8  A switch affects a bulb when it is in a closed...   \n",
      "9                                                NaN   \n",
      "\n",
      "                                  reference_answer_2  assigned_points_2  \\\n",
      "0  A damaged bulb and an open switch both create ...                1.0   \n",
      "1                                                NaN                NaN   \n",
      "2                                                NaN                NaN   \n",
      "3                                                NaN                NaN   \n",
      "4                                                NaN                NaN   \n",
      "5  the battery is contained in a closed path in w...                1.0   \n",
      "6                                                NaN                NaN   \n",
      "7  Terminal 1 and the positive terminal are not c...                0.0   \n",
      "8  If a bulb and a switch are in the same path th...                0.0   \n",
      "9                                                NaN                NaN   \n",
      "\n",
      "                                    student_answer_0  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2              it has a closed path with the battery   \n",
      "3  the positive battery terminal and terminal 1 a...   \n",
      "4             same answer as i put for the other two   \n",
      "5                                                NaN   \n",
      "6                                                NaN   \n",
      "7                                                NaN   \n",
      "8                                                NaN   \n",
      "9  The bulb is not contained in a closed path wit...   \n",
      "\n",
      "                                  reference_answer_0  assigned_points_0  \\\n",
      "0                                                NaN                NaN   \n",
      "1                                                NaN                NaN   \n",
      "2  Bulb A is still contained in a closed path wit...                1.0   \n",
      "3  Terminal 1 and the positive terminal are not c...                1.0   \n",
      "4  Terminal 4 and the positive terminal are not c...                0.0   \n",
      "5                                                NaN                NaN   \n",
      "6                                                NaN                NaN   \n",
      "7                                                NaN                NaN   \n",
      "8                                                NaN                NaN   \n",
      "9  the battery is contained in a path in which th...                1.0   \n",
      "\n",
      "                                    student_answer_3  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "5  the batter is on a closed path without any oth...   \n",
      "6                                                NaN   \n",
      "7  the gap separates the positive battery termina...   \n",
      "8  If the switch is in front of the path of a lig...   \n",
      "9                                                NaN   \n",
      "\n",
      "                                  reference_answer_3  assigned_points_3  \n",
      "0                                                NaN                NaN  \n",
      "1                                                NaN                NaN  \n",
      "2                                                NaN                NaN  \n",
      "3                                                NaN                NaN  \n",
      "4                                                NaN                NaN  \n",
      "5  the battery is contained in a closed path in w...                1.0  \n",
      "6                                                NaN                NaN  \n",
      "7  Terminal 1 and the positive terminal are not c...                1.0  \n",
      "8  If a bulb and a switch are in the same path th...                0.0  \n",
      "9                                                NaN                NaN  \n",
      "\n",
      "[10 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "from performance_tracking.classes.Dataset_api import Dataset_api\n",
    "\n",
    "dataset = Dataset_api(\n",
    "    dir=\"testing/data\",\n",
    "    file_name=\"sample\",\n",
    "    seed=42,\n",
    "    shots=3 # DO NOT CHANGE UNTILL FINISHED WITH RUN THROUGH ALL DATASETS!\n",
    ")\n",
    "\n",
    "dataset.split_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"train\"].query(\"question_id == 70\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[\"validation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"validation\"].head(2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.read_csv(\"performance_tracking/tracking/performance_tracking.csv\")\n",
    "performance = performance.query(\"dataset_split == 'validation_df'\")\n",
    "performance = performance.query(\"dataset_name != 'concatenated_datasets'\")\n",
    "performance = performance.query(\"dataset_name != 'concatenated_domains'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped_column = \"embedding_model_name\"\n",
    "\n",
    "# embedding_model_name classification_model_name\n",
    "performance_embed_avg = performance.groupby(grouped_column).mean().reset_index()\n",
    "performance_embed_avg_classification = performance_embed_avg.loc[:, [grouped_column, \"accuracy\", \"precision_weighted\", \"recall_weighted\", \"f1_weighted\"]]\n",
    "performance_embed_avg_classification = performance_embed_avg_classification.round(2)\n",
    "\n",
    "performance_embed_avg_cont = performance_embed_avg.loc[:, [grouped_column, \"rmse\", \"pears_correlation\", \"p_value\"]]\n",
    "performance_embed_avg_cont = performance_embed_avg_cont.round(2)\n",
    "\n",
    "performance_embed_std = performance.groupby(grouped_column).std().reset_index()\n",
    "performance_embed_std_classification = performance_embed_std.loc[:, [grouped_column, \"accuracy\", \"precision_weighted\", \"recall_weighted\", \"f1_weighted\"]]\n",
    "performance_embed_std_classification = performance_embed_std_classification.round(2)\n",
    "\n",
    "performance_embed_std_cont = performance_embed_std.loc[:, [grouped_column, \"rmse\", \"pears_correlation\", \"p_value\"]]\n",
    "performance_embed_std_cont = performance_embed_std_cont.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(performance_embed_avg_classification.to_latex(index=False))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(performance_embed_avg_cont.to_latex(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(performance_embed_std_classification.to_latex(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(performance_embed_std_cont.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Load pre-trained model tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "# Load pre-trained model\n",
    "model = BertModel.from_pretrained('bert-large-uncased')\n",
    "\n",
    "# Sentence for which we want to create embeddings\n",
    "sentence = \"This is a sample sentence.\"\n",
    "\n",
    "# Tokenize the sentence and convert to input IDs.\n",
    "inputs = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "# Run the sentence through the model to get the embeddings.\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# We get a tuple as output. The first element of the tuple is the embeddings.\n",
    "embeddings = outputs[0]\n",
    "\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Load pre-trained model tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained model\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# A very long sentence\n",
    "sentence = \"This is a very long sentence...\" # Assume this is a very long sentence\n",
    "\n",
    "# Tokenize the sentence and get the tokens\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "\n",
    "# Define the maximum chunk size (max BERT length - 2 for [CLS] and [SEP])\n",
    "max_chunk_size = 510\n",
    "\n",
    "# Split the tokens into chunks\n",
    "chunks = [tokens[i:i + max_chunk_size] for i in range(0, len(tokens), max_chunk_size)]\n",
    "\n",
    "# For each chunk, add special tokens, convert to input IDs, feed to BERT, and get embeddings\n",
    "for chunk in chunks:\n",
    "    # Add special tokens\n",
    "    chunk = ['[CLS]'] + chunk + ['[SEP]']\n",
    "    # Convert to input IDs\n",
    "    inputs = tokenizer.convert_tokens_to_ids(chunk)\n",
    "    inputs = torch.tensor([inputs])  # Add batch dimension\n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    # The first element of outputs is the embeddings\n",
    "    embeddings = outputs[0]\n",
    "    print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from performance_tracking.classes.Performance_Row import Performance_Row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = Performance_Row(\n",
    "    # id what is being tracked\n",
    "    dataset_name=\"test\",\n",
    "    embedding_seperated=self.measurement_settings.embedding_seperated,\n",
    "    embedding_model_name = self.measurement_settings.embedding_model_name,\n",
    "    sentence_embedding_method = self.measurement_settings.sentence_embedding_method,\n",
    "    feature_engenearing_method = self.measurement_settings.feature_engenearing_method,\n",
    "    grading_model = self.measurement_settings.grading_model,\n",
    "    seed_data_split = self.measurement_settings.seed_data_split,\n",
    "    shots=self.shots,\n",
    "    epochs=self.epochs,\n",
    "\n",
    "    dataset_split=dataset_split,\n",
    "\n",
    "    # duplicates handeling\n",
    "    settings_performance_tracking=self.measurement_settings.settings_performance_tracking\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
