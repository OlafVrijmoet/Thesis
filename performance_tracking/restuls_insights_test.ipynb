{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.read_csv(\"data/beetle/past_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>126</th>\n",
       "      <th>...</th>\n",
       "      <th>884</th>\n",
       "      <th>918</th>\n",
       "      <th>919</th>\n",
       "      <th>920</th>\n",
       "      <th>954</th>\n",
       "      <th>955</th>\n",
       "      <th>956</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.520052</td>\n",
       "      <td>0.519600</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.520052</td>\n",
       "      <td>0.519600</td>\n",
       "      <td>0.596567</td>\n",
       "      <td>0.553753</td>\n",
       "      <td>0.553309</td>\n",
       "      <td>0.596567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582473</td>\n",
       "      <td>0.533679</td>\n",
       "      <td>0.584575</td>\n",
       "      <td>0.582474</td>\n",
       "      <td>0.596567</td>\n",
       "      <td>0.553753</td>\n",
       "      <td>0.553309</td>\n",
       "      <td>0.596567</td>\n",
       "      <td>0.553753</td>\n",
       "      <td>0.553308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171657</td>\n",
       "      <td>0.124502</td>\n",
       "      <td>0.125699</td>\n",
       "      <td>0.171657</td>\n",
       "      <td>0.124502</td>\n",
       "      <td>0.125699</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.087632</td>\n",
       "      <td>0.088647</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328165</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.327137</td>\n",
       "      <td>0.328165</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.087632</td>\n",
       "      <td>0.088647</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.087632</td>\n",
       "      <td>0.088647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.397566</td>\n",
       "      <td>0.397625</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.397566</td>\n",
       "      <td>0.397625</td>\n",
       "      <td>0.356287</td>\n",
       "      <td>0.389775</td>\n",
       "      <td>0.389843</td>\n",
       "      <td>0.356287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283544</td>\n",
       "      <td>0.275229</td>\n",
       "      <td>0.281967</td>\n",
       "      <td>0.283544</td>\n",
       "      <td>0.356287</td>\n",
       "      <td>0.389775</td>\n",
       "      <td>0.389843</td>\n",
       "      <td>0.356287</td>\n",
       "      <td>0.389775</td>\n",
       "      <td>0.389843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.418033</td>\n",
       "      <td>0.449433</td>\n",
       "      <td>0.449276</td>\n",
       "      <td>0.418033</td>\n",
       "      <td>0.449433</td>\n",
       "      <td>0.449276</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.430316</td>\n",
       "      <td>0.430258</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518595</td>\n",
       "      <td>0.497453</td>\n",
       "      <td>0.519910</td>\n",
       "      <td>0.518595</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.430316</td>\n",
       "      <td>0.430258</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.430316</td>\n",
       "      <td>0.430258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.418033</td>\n",
       "      <td>0.454836</td>\n",
       "      <td>0.454656</td>\n",
       "      <td>0.418033</td>\n",
       "      <td>0.454836</td>\n",
       "      <td>0.454656</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.441053</td>\n",
       "      <td>0.440961</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518762</td>\n",
       "      <td>0.497453</td>\n",
       "      <td>0.520080</td>\n",
       "      <td>0.518762</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.441053</td>\n",
       "      <td>0.440961</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.441053</td>\n",
       "      <td>0.440961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>0.625442</td>\n",
       "      <td>0.561158</td>\n",
       "      <td>0.560535</td>\n",
       "      <td>0.625442</td>\n",
       "      <td>0.561158</td>\n",
       "      <td>0.560535</td>\n",
       "      <td>0.596567</td>\n",
       "      <td>0.552895</td>\n",
       "      <td>0.552453</td>\n",
       "      <td>0.596567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412452</td>\n",
       "      <td>0.395604</td>\n",
       "      <td>0.412462</td>\n",
       "      <td>0.412452</td>\n",
       "      <td>0.596567</td>\n",
       "      <td>0.552895</td>\n",
       "      <td>0.552453</td>\n",
       "      <td>0.596567</td>\n",
       "      <td>0.552895</td>\n",
       "      <td>0.552453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.482931</td>\n",
       "      <td>0.482634</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.482931</td>\n",
       "      <td>0.482634</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.426775</td>\n",
       "      <td>0.426728</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505015</td>\n",
       "      <td>0.497453</td>\n",
       "      <td>0.506163</td>\n",
       "      <td>0.505015</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.426775</td>\n",
       "      <td>0.426728</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.426775</td>\n",
       "      <td>0.426728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>0.739464</td>\n",
       "      <td>0.642799</td>\n",
       "      <td>0.641835</td>\n",
       "      <td>0.739464</td>\n",
       "      <td>0.642799</td>\n",
       "      <td>0.641835</td>\n",
       "      <td>0.726681</td>\n",
       "      <td>0.677187</td>\n",
       "      <td>0.676355</td>\n",
       "      <td>0.726681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688590</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.691997</td>\n",
       "      <td>0.688590</td>\n",
       "      <td>0.726681</td>\n",
       "      <td>0.677187</td>\n",
       "      <td>0.676355</td>\n",
       "      <td>0.726681</td>\n",
       "      <td>0.677187</td>\n",
       "      <td>0.676355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.236028</td>\n",
       "      <td>0.236760</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.236028</td>\n",
       "      <td>0.236760</td>\n",
       "      <td>0.178899</td>\n",
       "      <td>0.194887</td>\n",
       "      <td>0.195566</td>\n",
       "      <td>0.178899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418461</td>\n",
       "      <td>0.395604</td>\n",
       "      <td>0.418544</td>\n",
       "      <td>0.418461</td>\n",
       "      <td>0.178899</td>\n",
       "      <td>0.194887</td>\n",
       "      <td>0.195566</td>\n",
       "      <td>0.178899</td>\n",
       "      <td>0.194887</td>\n",
       "      <td>0.195566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>0.171657</td>\n",
       "      <td>0.106870</td>\n",
       "      <td>0.108141</td>\n",
       "      <td>0.171657</td>\n",
       "      <td>0.106870</td>\n",
       "      <td>0.108141</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.131185</td>\n",
       "      <td>0.132063</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212113</td>\n",
       "      <td>0.174419</td>\n",
       "      <td>0.209657</td>\n",
       "      <td>0.212113</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.131185</td>\n",
       "      <td>0.132063</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.131185</td>\n",
       "      <td>0.132063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>662 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           18        19        20        54        55        56        90  \\\n",
       "0    0.437500  0.520052  0.519600  0.437500  0.520052  0.519600  0.596567   \n",
       "1    0.171657  0.124502  0.125699  0.171657  0.124502  0.125699  0.173333   \n",
       "2    0.303571  0.397566  0.397625  0.303571  0.397566  0.397625  0.356287   \n",
       "3    0.418033  0.449433  0.449276  0.418033  0.449433  0.449276  0.363636   \n",
       "4    0.418033  0.454836  0.454656  0.418033  0.454836  0.454656  0.396226   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "657  0.625442  0.561158  0.560535  0.625442  0.561158  0.560535  0.596567   \n",
       "658  0.421053  0.482931  0.482634  0.421053  0.482931  0.482634  0.363636   \n",
       "659  0.739464  0.642799  0.641835  0.739464  0.642799  0.641835  0.726681   \n",
       "660  0.171875  0.236028  0.236760  0.171875  0.236028  0.236760  0.178899   \n",
       "661  0.171657  0.106870  0.108141  0.171657  0.106870  0.108141  0.173333   \n",
       "\n",
       "           91        92       126  ...       884       918       919  \\\n",
       "0    0.553753  0.553309  0.596567  ...  0.582473  0.533679  0.584575   \n",
       "1    0.087632  0.088647  0.173333  ...  0.328165  0.285714  0.327137   \n",
       "2    0.389775  0.389843  0.356287  ...  0.283544  0.275229  0.281967   \n",
       "3    0.430316  0.430258  0.363636  ...  0.518595  0.497453  0.519910   \n",
       "4    0.441053  0.440961  0.396226  ...  0.518762  0.497453  0.520080   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "657  0.552895  0.552453  0.596567  ...  0.412452  0.395604  0.412462   \n",
       "658  0.426775  0.426728  0.363636  ...  0.505015  0.497453  0.506163   \n",
       "659  0.677187  0.676355  0.726681  ...  0.688590  0.857143  0.691997   \n",
       "660  0.194887  0.195566  0.178899  ...  0.418461  0.395604  0.418544   \n",
       "661  0.131185  0.132063  0.173333  ...  0.212113  0.174419  0.209657   \n",
       "\n",
       "          920       954       955       956       990       991       992  \n",
       "0    0.582474  0.596567  0.553753  0.553309  0.596567  0.553753  0.553308  \n",
       "1    0.328165  0.173333  0.087632  0.088647  0.173333  0.087632  0.088647  \n",
       "2    0.283544  0.356287  0.389775  0.389843  0.356287  0.389775  0.389843  \n",
       "3    0.518595  0.363636  0.430316  0.430258  0.363636  0.430316  0.430258  \n",
       "4    0.518762  0.396226  0.441053  0.440961  0.396226  0.441053  0.440961  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "657  0.412452  0.596567  0.552895  0.552453  0.596567  0.552895  0.552453  \n",
       "658  0.505015  0.363636  0.426775  0.426728  0.363636  0.426775  0.426728  \n",
       "659  0.688590  0.726681  0.677187  0.676355  0.726681  0.677187  0.676355  \n",
       "660  0.418461  0.178899  0.194887  0.195566  0.178899  0.194887  0.195566  \n",
       "661  0.212113  0.173333  0.131185  0.132063  0.173333  0.131185  0.132063  \n",
       "\n",
       "[662 rows x 84 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>embedding_seperated</th>\n",
       "      <th>embedding_model_name</th>\n",
       "      <th>sentence_embedding_method</th>\n",
       "      <th>feature_engenearing</th>\n",
       "      <th>grading_model</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>dataset_split</th>\n",
       "      <th>seed_data_split</th>\n",
       "      <th>shots</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>864</td>\n",
       "      <td>True</td>\n",
       "      <td>BERT</td>\n",
       "      <td>avg</td>\n",
       "      <td>cosine_similarity</td>\n",
       "      <td>Isotonic Regression</td>\n",
       "      <td>neural_course</td>\n",
       "      <td>validation</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.653633</td>\n",
       "      <td>0.397165</td>\n",
       "      <td>0.408882</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.565652</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.483795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>865</td>\n",
       "      <td>True</td>\n",
       "      <td>BERT</td>\n",
       "      <td>avg</td>\n",
       "      <td>cosine_similarity</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>neural_course</td>\n",
       "      <td>validation</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.316604</td>\n",
       "      <td>0.355499</td>\n",
       "      <td>0.332338</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.438651</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.453823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>866</td>\n",
       "      <td>True</td>\n",
       "      <td>BERT</td>\n",
       "      <td>avg</td>\n",
       "      <td>cosine_similarity</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>neural_course</td>\n",
       "      <td>validation</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.293651</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.303520</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.407619</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.412102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>867</td>\n",
       "      <td>True</td>\n",
       "      <td>BERT</td>\n",
       "      <td>avg</td>\n",
       "      <td>cosine_similarity</td>\n",
       "      <td>Isotonic Regression</td>\n",
       "      <td>concatenated_datasets</td>\n",
       "      <td>validation</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455925</td>\n",
       "      <td>0.471846</td>\n",
       "      <td>0.239574</td>\n",
       "      <td>0.253293</td>\n",
       "      <td>0.455925</td>\n",
       "      <td>0.455925</td>\n",
       "      <td>0.455925</td>\n",
       "      <td>0.488315</td>\n",
       "      <td>0.455925</td>\n",
       "      <td>0.452449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>868</td>\n",
       "      <td>True</td>\n",
       "      <td>BERT</td>\n",
       "      <td>avg</td>\n",
       "      <td>cosine_similarity</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>concatenated_datasets</td>\n",
       "      <td>validation</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459387</td>\n",
       "      <td>0.191821</td>\n",
       "      <td>0.197763</td>\n",
       "      <td>0.192313</td>\n",
       "      <td>0.459387</td>\n",
       "      <td>0.459387</td>\n",
       "      <td>0.459387</td>\n",
       "      <td>0.464153</td>\n",
       "      <td>0.459387</td>\n",
       "      <td>0.456558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>931</td>\n",
       "      <td>True</td>\n",
       "      <td>BERT</td>\n",
       "      <td>add</td>\n",
       "      <td>cosine_similarity</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>neural_networks</td>\n",
       "      <td>validation</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.316604</td>\n",
       "      <td>0.355499</td>\n",
       "      <td>0.332338</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.438651</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.453823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>932</td>\n",
       "      <td>True</td>\n",
       "      <td>BERT</td>\n",
       "      <td>add</td>\n",
       "      <td>cosine_similarity</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>neural_networks</td>\n",
       "      <td>validation</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.293651</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.303520</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.407619</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.412102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>933</td>\n",
       "      <td>True</td>\n",
       "      <td>BERT</td>\n",
       "      <td>add</td>\n",
       "      <td>cosine_similarity</td>\n",
       "      <td>Isotonic Regression</td>\n",
       "      <td>english_language_arts</td>\n",
       "      <td>validation</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517906</td>\n",
       "      <td>0.397258</td>\n",
       "      <td>0.428419</td>\n",
       "      <td>0.375445</td>\n",
       "      <td>0.517906</td>\n",
       "      <td>0.517906</td>\n",
       "      <td>0.517906</td>\n",
       "      <td>0.484152</td>\n",
       "      <td>0.517906</td>\n",
       "      <td>0.455708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>934</td>\n",
       "      <td>True</td>\n",
       "      <td>BERT</td>\n",
       "      <td>add</td>\n",
       "      <td>cosine_similarity</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>english_language_arts</td>\n",
       "      <td>validation</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476584</td>\n",
       "      <td>0.555363</td>\n",
       "      <td>0.298647</td>\n",
       "      <td>0.243315</td>\n",
       "      <td>0.476584</td>\n",
       "      <td>0.476584</td>\n",
       "      <td>0.476584</td>\n",
       "      <td>0.686648</td>\n",
       "      <td>0.476584</td>\n",
       "      <td>0.386593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>935</td>\n",
       "      <td>True</td>\n",
       "      <td>BERT</td>\n",
       "      <td>add</td>\n",
       "      <td>cosine_similarity</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>english_language_arts</td>\n",
       "      <td>validation</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.308108</td>\n",
       "      <td>0.285050</td>\n",
       "      <td>0.217554</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.501181</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.350667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id  embedding_seperated embedding_model_name  \\\n",
       "360     864                 True                 BERT   \n",
       "361     865                 True                 BERT   \n",
       "362     866                 True                 BERT   \n",
       "363     867                 True                 BERT   \n",
       "364     868                 True                 BERT   \n",
       "..      ...                  ...                  ...   \n",
       "427     931                 True                 BERT   \n",
       "428     932                 True                 BERT   \n",
       "429     933                 True                 BERT   \n",
       "430     934                 True                 BERT   \n",
       "431     935                 True                 BERT   \n",
       "\n",
       "    sentence_embedding_method feature_engenearing        grading_model  \\\n",
       "360                       avg   cosine_similarity  Isotonic Regression   \n",
       "361                       avg   cosine_similarity    Linear Regression   \n",
       "362                       avg   cosine_similarity     Ridge Regression   \n",
       "363                       avg   cosine_similarity  Isotonic Regression   \n",
       "364                       avg   cosine_similarity    Linear Regression   \n",
       "..                        ...                 ...                  ...   \n",
       "427                       add   cosine_similarity    Linear Regression   \n",
       "428                       add   cosine_similarity     Ridge Regression   \n",
       "429                       add   cosine_similarity  Isotonic Regression   \n",
       "430                       add   cosine_similarity    Linear Regression   \n",
       "431                       add   cosine_similarity     Ridge Regression   \n",
       "\n",
       "              dataset_name dataset_split  seed_data_split  shots  ...  \\\n",
       "360          neural_course    validation               42      0  ...   \n",
       "361          neural_course    validation               42      0  ...   \n",
       "362          neural_course    validation               42      0  ...   \n",
       "363  concatenated_datasets    validation               42      0  ...   \n",
       "364  concatenated_datasets    validation               42      0  ...   \n",
       "..                     ...           ...              ...    ...  ...   \n",
       "427        neural_networks    validation               42      0  ...   \n",
       "428        neural_networks    validation               42      0  ...   \n",
       "429  english_language_arts    validation               42      0  ...   \n",
       "430  english_language_arts    validation               42      0  ...   \n",
       "431  english_language_arts    validation               42      0  ...   \n",
       "\n",
       "     accuracy  precision_macro  recall_macro  f1_macro  precision_micro  \\\n",
       "360  0.492308         0.653633      0.397165  0.408882         0.492308   \n",
       "361  0.476923         0.316604      0.355499  0.332338         0.476923   \n",
       "362  0.430769         0.293651      0.326087  0.303520         0.430769   \n",
       "363  0.455925         0.471846      0.239574  0.253293         0.455925   \n",
       "364  0.459387         0.191821      0.197763  0.192313         0.459387   \n",
       "..        ...              ...           ...       ...              ...   \n",
       "427  0.476923         0.316604      0.355499  0.332338         0.476923   \n",
       "428  0.430769         0.293651      0.326087  0.303520         0.430769   \n",
       "429  0.517906         0.397258      0.428419  0.375445         0.517906   \n",
       "430  0.476584         0.555363      0.298647  0.243315         0.476584   \n",
       "431  0.457300         0.308108      0.285050  0.217554         0.457300   \n",
       "\n",
       "     recall_micro  f1_micro  precision_weighted  recall_weighted  f1_weighted  \n",
       "360      0.492308  0.492308            0.565652         0.492308     0.483795  \n",
       "361      0.476923  0.476923            0.438651         0.476923     0.453823  \n",
       "362      0.430769  0.430769            0.407619         0.430769     0.412102  \n",
       "363      0.455925  0.455925            0.488315         0.455925     0.452449  \n",
       "364      0.459387  0.459387            0.464153         0.459387     0.456558  \n",
       "..            ...       ...                 ...              ...          ...  \n",
       "427      0.476923  0.476923            0.438651         0.476923     0.453823  \n",
       "428      0.430769  0.430769            0.407619         0.430769     0.412102  \n",
       "429      0.517906  0.517906            0.484152         0.517906     0.455708  \n",
       "430      0.476584  0.476584            0.686648         0.476584     0.386593  \n",
       "431      0.457300  0.457300            0.501181         0.457300     0.350667  \n",
       "\n",
       "[72 rows x 27 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.query(\"embedding_model_name == 'BERT'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/qyl6p0kj7_s9q0djmp51j2jw0000gn/T/ipykernel_68761/1745069190.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  average_by_group = performance.groupby(\"dataset_name\").mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>embedding_seperated</th>\n",
       "      <th>seed_data_split</th>\n",
       "      <th>rmse</th>\n",
       "      <th>pears_correlation</th>\n",
       "      <th>p_value</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASAP_sas</th>\n",
       "      <td>5077.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.857769</td>\n",
       "      <td>0.430399</td>\n",
       "      <td>2.648754e-55</td>\n",
       "      <td>0.368587</td>\n",
       "      <td>0.300684</td>\n",
       "      <td>0.246250</td>\n",
       "      <td>0.206177</td>\n",
       "      <td>0.368587</td>\n",
       "      <td>0.368587</td>\n",
       "      <td>0.368587</td>\n",
       "      <td>0.527995</td>\n",
       "      <td>0.368587</td>\n",
       "      <td>0.328672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beetle</th>\n",
       "      <td>5068.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.460243</td>\n",
       "      <td>0.358530</td>\n",
       "      <td>1.360652e-18</td>\n",
       "      <td>0.672816</td>\n",
       "      <td>0.664643</td>\n",
       "      <td>0.648562</td>\n",
       "      <td>0.649226</td>\n",
       "      <td>0.672816</td>\n",
       "      <td>0.672816</td>\n",
       "      <td>0.672816</td>\n",
       "      <td>0.669626</td>\n",
       "      <td>0.672816</td>\n",
       "      <td>0.664357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biology</th>\n",
       "      <td>5086.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.598119</td>\n",
       "      <td>0.345959</td>\n",
       "      <td>4.318794e-09</td>\n",
       "      <td>0.779559</td>\n",
       "      <td>0.238103</td>\n",
       "      <td>0.258262</td>\n",
       "      <td>0.243585</td>\n",
       "      <td>0.779559</td>\n",
       "      <td>0.779559</td>\n",
       "      <td>0.779559</td>\n",
       "      <td>0.700358</td>\n",
       "      <td>0.779559</td>\n",
       "      <td>0.735421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenated_datasets</th>\n",
       "      <td>5023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.800607</td>\n",
       "      <td>0.326487</td>\n",
       "      <td>2.129917e-69</td>\n",
       "      <td>0.460072</td>\n",
       "      <td>0.217728</td>\n",
       "      <td>0.209709</td>\n",
       "      <td>0.204760</td>\n",
       "      <td>0.460072</td>\n",
       "      <td>0.460072</td>\n",
       "      <td>0.460072</td>\n",
       "      <td>0.470351</td>\n",
       "      <td>0.460072</td>\n",
       "      <td>0.453771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenated_domains</th>\n",
       "      <td>5032.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.012688</td>\n",
       "      <td>0.341081</td>\n",
       "      <td>5.385329e-43</td>\n",
       "      <td>0.299740</td>\n",
       "      <td>0.225156</td>\n",
       "      <td>0.178993</td>\n",
       "      <td>0.129724</td>\n",
       "      <td>0.299740</td>\n",
       "      <td>0.299740</td>\n",
       "      <td>0.299740</td>\n",
       "      <td>0.444775</td>\n",
       "      <td>0.299740</td>\n",
       "      <td>0.224327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english</th>\n",
       "      <td>5050.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.768669</td>\n",
       "      <td>0.441460</td>\n",
       "      <td>1.928315e-20</td>\n",
       "      <td>0.358806</td>\n",
       "      <td>0.421719</td>\n",
       "      <td>0.329297</td>\n",
       "      <td>0.260596</td>\n",
       "      <td>0.358806</td>\n",
       "      <td>0.358806</td>\n",
       "      <td>0.358806</td>\n",
       "      <td>0.552866</td>\n",
       "      <td>0.358806</td>\n",
       "      <td>0.301851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_language_arts</th>\n",
       "      <td>5113.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.702417</td>\n",
       "      <td>0.325629</td>\n",
       "      <td>1.365242e-08</td>\n",
       "      <td>0.459084</td>\n",
       "      <td>0.384388</td>\n",
       "      <td>0.345584</td>\n",
       "      <td>0.272522</td>\n",
       "      <td>0.459084</td>\n",
       "      <td>0.459084</td>\n",
       "      <td>0.459084</td>\n",
       "      <td>0.470232</td>\n",
       "      <td>0.459084</td>\n",
       "      <td>0.355658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_course</th>\n",
       "      <td>5014.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.108564</td>\n",
       "      <td>3.421437e-01</td>\n",
       "      <td>0.370770</td>\n",
       "      <td>0.223476</td>\n",
       "      <td>0.354154</td>\n",
       "      <td>0.223240</td>\n",
       "      <td>0.370770</td>\n",
       "      <td>0.370770</td>\n",
       "      <td>0.370770</td>\n",
       "      <td>0.204255</td>\n",
       "      <td>0.370770</td>\n",
       "      <td>0.229507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_networks</th>\n",
       "      <td>5104.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.108564</td>\n",
       "      <td>3.421437e-01</td>\n",
       "      <td>0.370770</td>\n",
       "      <td>0.223476</td>\n",
       "      <td>0.354154</td>\n",
       "      <td>0.223240</td>\n",
       "      <td>0.370770</td>\n",
       "      <td>0.370770</td>\n",
       "      <td>0.370770</td>\n",
       "      <td>0.204255</td>\n",
       "      <td>0.370770</td>\n",
       "      <td>0.229507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sciEntsBank</th>\n",
       "      <td>5095.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.465632</td>\n",
       "      <td>0.328063</td>\n",
       "      <td>1.023075e-28</td>\n",
       "      <td>0.648986</td>\n",
       "      <td>0.640566</td>\n",
       "      <td>0.615539</td>\n",
       "      <td>0.612205</td>\n",
       "      <td>0.648986</td>\n",
       "      <td>0.648986</td>\n",
       "      <td>0.648986</td>\n",
       "      <td>0.644118</td>\n",
       "      <td>0.648986</td>\n",
       "      <td>0.631873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>5059.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.157067</td>\n",
       "      <td>0.156810</td>\n",
       "      <td>7.521639e-02</td>\n",
       "      <td>0.298602</td>\n",
       "      <td>0.218021</td>\n",
       "      <td>0.226448</td>\n",
       "      <td>0.188405</td>\n",
       "      <td>0.298602</td>\n",
       "      <td>0.298602</td>\n",
       "      <td>0.298602</td>\n",
       "      <td>0.265691</td>\n",
       "      <td>0.298602</td>\n",
       "      <td>0.249236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texas</th>\n",
       "      <td>5041.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.008716</td>\n",
       "      <td>0.385388</td>\n",
       "      <td>1.655596e-05</td>\n",
       "      <td>0.386051</td>\n",
       "      <td>0.255895</td>\n",
       "      <td>0.202776</td>\n",
       "      <td>0.157588</td>\n",
       "      <td>0.386051</td>\n",
       "      <td>0.386051</td>\n",
       "      <td>0.386051</td>\n",
       "      <td>0.573085</td>\n",
       "      <td>0.386051</td>\n",
       "      <td>0.333977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       row_id  embedding_seperated  seed_data_split      rmse  \\\n",
       "dataset_name                                                                    \n",
       "ASAP_sas               5077.0                  1.0             42.0  0.857769   \n",
       "beetle                 5068.0                  1.0             42.0  0.460243   \n",
       "biology                5086.0                  1.0             42.0  0.598119   \n",
       "concatenated_datasets  5023.0                  1.0             42.0  0.800607   \n",
       "concatenated_domains   5032.0                  1.0             42.0  1.012688   \n",
       "english                5050.0                  1.0             42.0  0.768669   \n",
       "english_language_arts  5113.0                  1.0             42.0  0.702417   \n",
       "neural_course          5014.0                  1.0             42.0  0.700000   \n",
       "neural_networks        5104.0                  1.0             42.0  0.700000   \n",
       "sciEntsBank            5095.0                  1.0             42.0  0.465632   \n",
       "science                5059.0                  1.0             42.0  1.157067   \n",
       "texas                  5041.0                  1.0             42.0  1.008716   \n",
       "\n",
       "                       pears_correlation       p_value  accuracy  \\\n",
       "dataset_name                                                       \n",
       "ASAP_sas                        0.430399  2.648754e-55  0.368587   \n",
       "beetle                          0.358530  1.360652e-18  0.672816   \n",
       "biology                         0.345959  4.318794e-09  0.779559   \n",
       "concatenated_datasets           0.326487  2.129917e-69  0.460072   \n",
       "concatenated_domains            0.341081  5.385329e-43  0.299740   \n",
       "english                         0.441460  1.928315e-20  0.358806   \n",
       "english_language_arts           0.325629  1.365242e-08  0.459084   \n",
       "neural_course                   0.108564  3.421437e-01  0.370770   \n",
       "neural_networks                 0.108564  3.421437e-01  0.370770   \n",
       "sciEntsBank                     0.328063  1.023075e-28  0.648986   \n",
       "science                         0.156810  7.521639e-02  0.298602   \n",
       "texas                           0.385388  1.655596e-05  0.386051   \n",
       "\n",
       "                       precision_macro  recall_macro  f1_macro  \\\n",
       "dataset_name                                                     \n",
       "ASAP_sas                      0.300684      0.246250  0.206177   \n",
       "beetle                        0.664643      0.648562  0.649226   \n",
       "biology                       0.238103      0.258262  0.243585   \n",
       "concatenated_datasets         0.217728      0.209709  0.204760   \n",
       "concatenated_domains          0.225156      0.178993  0.129724   \n",
       "english                       0.421719      0.329297  0.260596   \n",
       "english_language_arts         0.384388      0.345584  0.272522   \n",
       "neural_course                 0.223476      0.354154  0.223240   \n",
       "neural_networks               0.223476      0.354154  0.223240   \n",
       "sciEntsBank                   0.640566      0.615539  0.612205   \n",
       "science                       0.218021      0.226448  0.188405   \n",
       "texas                         0.255895      0.202776  0.157588   \n",
       "\n",
       "                       precision_micro  recall_micro  f1_micro  \\\n",
       "dataset_name                                                     \n",
       "ASAP_sas                      0.368587      0.368587  0.368587   \n",
       "beetle                        0.672816      0.672816  0.672816   \n",
       "biology                       0.779559      0.779559  0.779559   \n",
       "concatenated_datasets         0.460072      0.460072  0.460072   \n",
       "concatenated_domains          0.299740      0.299740  0.299740   \n",
       "english                       0.358806      0.358806  0.358806   \n",
       "english_language_arts         0.459084      0.459084  0.459084   \n",
       "neural_course                 0.370770      0.370770  0.370770   \n",
       "neural_networks               0.370770      0.370770  0.370770   \n",
       "sciEntsBank                   0.648986      0.648986  0.648986   \n",
       "science                       0.298602      0.298602  0.298602   \n",
       "texas                         0.386051      0.386051  0.386051   \n",
       "\n",
       "                       precision_weighted  recall_weighted  f1_weighted  \n",
       "dataset_name                                                             \n",
       "ASAP_sas                         0.527995         0.368587     0.328672  \n",
       "beetle                           0.669626         0.672816     0.664357  \n",
       "biology                          0.700358         0.779559     0.735421  \n",
       "concatenated_datasets            0.470351         0.460072     0.453771  \n",
       "concatenated_domains             0.444775         0.299740     0.224327  \n",
       "english                          0.552866         0.358806     0.301851  \n",
       "english_language_arts            0.470232         0.459084     0.355658  \n",
       "neural_course                    0.204255         0.370770     0.229507  \n",
       "neural_networks                  0.204255         0.370770     0.229507  \n",
       "sciEntsBank                      0.644118         0.648986     0.631873  \n",
       "science                          0.265691         0.298602     0.249236  \n",
       "texas                            0.573085         0.386051     0.333977  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_by_group = performance.groupby(\"dataset_name\").mean()\n",
    "average_by_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
