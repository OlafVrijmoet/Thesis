row_id,question,question_id,student_answer,reference_answer,assigned_points,max_points,domain,dataset_name,normalized_points
0," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'simple', 'processing', 'unit', 'natural', 'propensity', 'store', 'experiential', 'knowledge', 'make', 'use', 'artificial', 'neural', 'network', 'similar', 'human', 'brain', 'two', 'way', '1', 'ann', 'work', 'process', 'learning', 'environment', '2', 'interferon', 'connection', 'called', 'synaptic', 'weight', 'used', 'store', 'knowledge', 'gained']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
1," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'consists', 'largely', 'parallel', 'distributed', 'processor', 'simple', 'processing', 'unit', 'ability', 'store', 'experiential', 'knowledge', 'making', 'available', 'use', 'resembles', 'human', 'brain', 'two', 'way', 'knowledge', 'acquired', 'environment', 'network', 'learning', 'process', 'synaptic', 'strength', 'called', 'weight', 'used', 'store', 'knowledge']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
2," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'massive', 'distributed', 'processor', 'consists', 'several', 'information', 'processing', 'unit', 'able', 'acquire', 'store', 'knowledge']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",1,2.0,neural_networks,neural_course,0.5
3," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['ann', 'layered', 'graphical', 'model', 'containing', 'neuron', 'weighted', 'connection', 'resembling', 'excitatory', 'property', 'human', 'brain', 'weight', 'ann', 'changed', 'presenting', 'training', 'example', 'environment', 'weight', 'changed', 'based', 'training', 'procedure', 'used', 'artificial', 'neuron', 'also', 'biased', 'like', 'real', 'one', 'adding', 'constant', 'level', 'activation', 'activated', 'nonlinear', 'activation', 'function', 'depending', 'training', 'procedure', 'weight', 'topology', 'even', 'activation', 'function', 'may', 'learned']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
4," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'large', 'parallel', 'processing', 'unit', 'natural', 'ability', 'learn', 'experiential', 'knowledge', 'composed', 'interconnected', 'neuron', 'basic', 'unit', 'turn', 'consists', 'weight', 'squashing', 'function', 'adder', 'function', 'ann', 'resembles', 'brain', 'manner', 'like', 'human', 'brain', 'composed', 'network', 'neuron', 'help', 'learning', 'adjusting', 'synaptic', 'weight', 'connection', 'neuron', 'enables', 'learn', 'experiential', 'knowledge']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
5," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'consists', 'neuron', 'neuron', 'several', 'weighted', 'input', 'activation', 'function', 'output', 'usually', 'several', 'neuron', 'connected', 'together', 'often', 'layer', 'network', 'calculates', 'output', 'given', 'input', 'network', 'human', 'brain', 'work', 'similar', 'way', 'also', 'consists', 'neuron', 'connected', 'several', 'way']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",1,2.0,neural_networks,neural_course,0.5
6," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['ann', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'capability', 'storing', 'experimental', 'knowledge', 'made', 'used', 'ann', 'resembles', 'brain', 'get', 'knowledge', 'learning', 'process', 'environment', 'store', 'knowledge', 'interferon', 'connection', 'synaptic', 'weight']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
7," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['ann', 'massively', 'distributed', 'processor', 'propensity', 'store', 'experimental', 'knowledge', 'make', 'available', 'used', 'knowledge', 'gained', 'throug', 'process', 'learning', 'knowledge', 'stored', 'weight', 'neuron', 'structure', 'resembles', 'structure', 'brain', 'neuron', 'basic', 'information', 'unit', 'ann', 'act', 'similar', 'real', 'neuron']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
8," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'defined', 'learning', 'machine', 'divided', 'layer', 'layer', 'composed', 'neuron', 'neuron', 'different', 'layer', 'connected', 'give', 'output', 'multiple', 'output', 'given', 'input', 'structure', 'similar', 'neurological', 'structure', 'brain', 'neuron', 'interconnected', 'synapsis', 'also', 'important', 'mention', 'feature', 'really', 'important', 'given', 'task', 'wil', 'connection', 'neuron', 'participating', 'like', 'human', 'brain', 'important', 'human', 'function', 'synapsis']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
9," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'graph', 'small', 'identical', 'processing', 'unit', 'small', 'unit', 'called', 'neuron', 'connected', 'different', 'architecture', 'whole', 'network', 'adapt', 'environment', 'input', 'trying', 'decrease', 'error', 'cost', 'function', 'increase', 'preciseness', 'manipulating', 'free', 'variable', 'network', 'synaptic', 'weight', 'similar', 'human', 'brain', 'similar', 'human', 'brain', 'many', 'small', 'processing', 'unit', 'connected', 'together', 'react', 'environment', 'learn', 'environment']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
10," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'highly', 'parallel', 'processing', 'mathematical', 'model', 'similar', 'human', 'brain', 'inspired', 'human', 'brain', 'computation', 'extremely', 'parallel', 'manner', 'similarity', 'also', 'lay', 'terminology', 'ann', 'using', 'neuron', 'smallest', 'computing', 'unit', 'network', 'similarly', 'human', 'brain']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",1,2.0,neural_networks,neural_course,0.5
11," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['massive', 'parallel', 'distributed', 'processor', 'made', 'smaller', 'processing', 'unit', 'acquire', 'knowledge', 'environment', 'learning', 'process', 'make', 'available', 'used', 'resembles', 'brain', 'two', 'way', 'knowledge', 'acquired', 'stimulating', 'process', 'environment', 'knowledge', 'embedded', 'synaptic', 'link', 'weight', 'neuron']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
12," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['ann', 'learning', 'machine', 'composed', 'neuron', 'unit', 'computation', 'ann', 'learns', 'via', 'interacting', 'environment', 'ann', 'builtin', 'capacity', 'dynamically', 'adapt', 'upon', 'input', 'stimulus', 'ann', 'motivated', 'biological', 'brain', 'resembles', 'human', 'brain', 'term', 'localized', 'representation', 'input', 'term', 'motor', 'cortex', 'sensory', 'stimulus', 'different', 'bodyparts', 'activates', 'local', 'part', 'brain', 'similar', 'ann', 'local', 'representation', 'similar', 'type', 'input']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
13," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'making', 'available', 'used', 'resembles', 'brain', 'two', 'respect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'stor', 'acquired', 'knowledge']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
14," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'consists', 'one', 'processing', 'unit', 'called', 'neuron', 'resembles', 'human', 'brain', 'acquires', 'knowledge', 'environment', 'learning', 'process', 'acquired', 'knowledge', 'stored', 'synapsis']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
15," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['definition', '1', 'artificial', 'neural', 'network', 'massively', 'distributed', 'parallel', 'processor', '2', 'made', 'small', 'unit', '3', 'propensity', 'storing', 'experiential', 'knowledge', '4', 'making', 'available', 'used', 'resembles', 'brain', '2', 'aspect', '1', 'similar', 'brain', 'artificial', 'neural', 'network', 'process', 'learning', 'environment', '2', 'pair', 'inter', 'neuron', 'link', 'known', 'synaptic', 'weight', 'used', 'storing', 'information']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
16," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'massive', 'parallel', 'distributed', 'processor', 'comprises', 'small', 'processing', 'unit', 'called', 'neuron', 'learns', 'experiential', 'knowledge', 'stored', 'used', 'making', 'prediction', 'resembles', 'human', 'brain', '2', 'way', 'learns', 'experiential', 'knowledge', 'knowledge', 'stored', 'synaptic', 'interferon', 'connection']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
17," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'massively', 'distributed', 'parallel', 'processor', 'composed', 'simple', 'processing', 'unit', 'called', 'neuron', 'natural', 'propensity', 'storing', 'experiential', 'information', 'making', 'available', 'used', 'resembles', 'human', 'brain', 'following', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'synaptic', 'link', 'used', 'store', 'acquired', 'knowledge']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
18," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['ann', 'learning', 'machine', 'perform', 'complex', 'parallel', 'computation', 'ability', 'learn', 'interaction', 'withthe', 'environment', 'store', 'learned', 'knowledge', 'resembles', 'human', 'brain', 'performing', 'complex', 'learning', 'task', 'acquiring', 'information', 'adapting', 'environment', 'exploiting', 'acquired', 'information']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
19," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'massively', 'distributed', 'parallel', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experimental', 'knowledge', 'making', 'available', 'future', 'used', 'resembles', 'brain', 'following', 'way', '1', 'artificial', 'neural', 'network', 'ability', 'acquire', 'knowledge', 'environment', 'embedded', '2', 'interneuron', 'connection', 'strength', 'called', 'synaptic', 'link', 'activate', 'neuron', 'learning', 'process']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
20," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'interacts', 'surrounding', 'environment', 'propensity', 'store', 'knowledge', 'make', 'available', 'used', 'resembles', 'brain', 'two', 'aspect', '1', 'ability', 'learn', 'environment', '2', 'knowledge', 'stored', 'synaptic', 'weight']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
21," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'massively', 'distributed', 'parallel', 'processor', 'containing', 'simple', 'processing', 'unit', 'natural', 'propensity', 'store', 'experiential', 'knowledge', 'use', 'tit', 'resembles', 'human', 'brain', 'two', 'aspect', 'gain', 'knowledge', 'environment', 'adapts', 'synaptic', 'weight', 'store', 'knowledge']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
22," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['massively', 'parallel', 'distributed', 'processor', 'consisting', 'simple', 'processing', 'unit', 'store', 'experiential', 'knowledge', 'make', 'available', 'used', 'resembles', 'human', 'brain', '2', 'way', '1', 'knowledge', 'acquired', 'environment', 'learning', 'process', '2', 'interferon', 'connection', 'used', 'store', 'experiential', 'knowledge']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
23," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'called', 'neuron', 'replicate', 'human', 'brain', 'storing', 'information', 'weight']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",1,2.0,neural_networks,neural_course,0.5
24," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'synaptic', 'link', 'able', 'store', 'experimental', 'knowledge', 'make', 'available', 'used', 'resembles', 'human', 'brain', 'two', 'way', 'knowledge', 'acquired', 'neural', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'called', 'synaptic', 'link', 'store', 'acquired', 'knowledge']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
25," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'network', 'unit', 'learn', 'data', 'environment', 'store', 'using', 'synaptic', 'weight', 'structure', 'artificial', 'neural', 'network', 'similar', 'human', 'brain', 'neuron', 'ieft', 'store', 'unit', 'atom', 'called', 'synapsis', 'link', 'stored', 'data']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",1,2.0,neural_networks,neural_course,0.5
26," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'massive', 'parallel', 'processor', 'made', 'simple', 'processing', 'unit', 'called', 'neuron', 'capable', 'storing', 'experiential', 'knowledge', 'make', 'available', 'later', 'used', 'similarity', 'human', 'brain', '1', 'learn', 'environment', '2', 'store', 'knowledge', 'synaptic', 'weight', 'interferon', 'connection']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
27," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'highly', 'distributed', 'processor', 'consists', 'several', 'simple', 'processing', 'unit', 'resembles', 'human', 'brain', 'processing', 'unit', 'neuron', 'connected', 'weight', 'human', 'brain', 'also', 'consists', 'neuron']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",1,2.0,neural_networks,neural_course,0.5
28," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['massively', 'distributed', 'processor', 'consisting', 'single', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experimental', 'knowledge', 'making', 'available', 'used']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",1,2.0,neural_networks,neural_course,0.5
29," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'consists', 'neuron', 'small', 'computation', 'devicesand', 'synapsis', 'connection', 'neuron', 'resembles', 'brain', 'also', 'neuron', 'synapsis', 'also', 'artificial', 'neural', 'network', 'weight', 'used', 'store', 'learned', 'feature', 'environment', 'like', 'brain', 'neural', 'network', 'learns', 'environment', 'artificial', 'neural', 'network', 'also', 'activation', 'function', 'creates', 'output']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
30," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'highly', 'parallel', 'computation', 'model', 'learning', 'memory', 'capacity', 'similar', 'brain', 'learns', 'environment', 'strengthening', 'synapsis', 'neuron', 'task', 'learned', 'quickly', 'used', 'reactivating', 'learned', 'synapsis']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",1,2.0,neural_networks,neural_course,0.5
31," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'highly', 'parallel', 'working', 'machine', 'consists', 'simple', 'processing', 'unit', 'neuron', 'connected', 'layer', 'function', 'approximates', 'brain', 'resembled', 'architecture', 'processing', 'unit', 'weight', 'learning', 'process', 'take', 'place', 'property', 'brain', 'fault', 'tolerance', 'parallel', 'computing']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",1,2.0,neural_networks,neural_course,0.5
32," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['ann', 'massively', 'parallel', 'distributed', 'leaving', 'machine', 'made', 'small', 'computational', 'unit', 'computational', 'unit', 'connected', 'via', 'synapsis', 'defined', 'weight', 'resembles', 'human', 'brain', 'two', 'aspect']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",1,2.0,neural_networks,neural_course,0.5
33," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'computing', 'unit', 'called', 'neuron', 'acquires', 'knowledge', 'environment', 'learning', 'resembles', 'brainlike', 'structure', 'two', 'way', '1', 'acquires', 'knowledge', 'learning', 'experience', '2', 'store', 'knowledge', 'interferon', 'connection', 'called', 'synapsis']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
34," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['ann', 'huge', 'parallel', 'distributed', 'processor', 'consist', 'simple', 'processing', 'unit', 'propensity', 'storing', 'experiential', 'knowledge', 'making', 'available', 'used']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",1,2.0,neural_networks,neural_course,0.5
35," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'acquire', 'knowledge', 'environment', 'make', 'available', 'future', 'used', 'resembles', 'human', 'brain', 'following', 'way', '1', 'acquire', 'knowledge', 'environment', '2', 'neuron', 'connected', 'synapsis', 'characterized', 'weight', 'adjusted']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
36," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['artificial', 'neural', 'network', 'massively', 'distributed', 'parallel', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'store', 'experiential', 'knowledge', 'make', 'knowledge', 'available', 'used', 'artificial', 'neural', 'network', 'us', 'inter', 'neuron', 'connection', 'called', 'synaptic', 'weight', 'store', 'knowledge', 'acquired', 'knowledge', 'similar', 'human', 'brain', 'work']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
37," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"['ann', 'massively', 'distributed', 'processor', 'consisting', 'simple', 'processing', 'unit', 'called', 'neuron', 'neuron', 'term', 'ann', 'similar', 'neuron', 'human', 'brain', 'neuron', 'characterized', 'synapsesconnection', 'link', 'represent', 'connection', 'used', 'data', 'flow', 'neuron', 'ann', 'human', 'brain', 'knowledge', 'represented', 'structure', 'activation', 'state', 'neuron']","['neural', 'network', 'massively', 'parallel', 'distributed', 'processor', 'made', 'simple', 'processing', 'unit', 'natural', 'propensity', 'storing', 'experiential', 'knowledge', 'neural', 'network', 'resemble', 'brain', 'two', 'aspect', 'knowledge', 'acquired', 'network', 'environment', 'learning', 'process', 'interferon', 'connection', 'strength', 'known', 'synaptic', 'weight', 'used', 'store', 'acquired', 'knowledge']",2,2.0,neural_networks,neural_course,1.0
38,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'simplest', 'processing', 'unit', 'neural', 'network', '1', 'synaptic', 'weight', 'store', 'knowledge', 'gained', '2', 'adder', 'function', 'linear', 'combined', 'add', 'weighted', 'value', 'input', 'signal', 'produce', 'local', 'field', '3', 'activation', 'function', 'squash', 'local', 'field', 'range', 'value', 'phisumi0n', 'wi', 'dot', 'xi']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
39,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['mathematical', 'model', 'neuron', 'given', 'phiv', 'activation', 'function', 'applied', 'local', 'fieldv', 'summation', 'wixi', 'local', 'field', 'weightedw', 'sum', 'inputsx', 'plus', 'biasb']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
40,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'information', 'processing', 'unit', 'consists', 'input', 'associated', 'weight', 'sum', 'input', 'activation', 'function']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",1,2.0,neural_networks,neural_course,0.5
41,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['input', 'vector', 'ex', 'weight', 'matrix', 'net', 'input', 'netsum', 'xtw', 'net', 'output', 'ophinet']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",1,2.0,neural_networks,neural_course,0.5
42,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'consists', 'three', 'basic', 'component', 'synaptic', 'weight', 'synaptic', 'weight', 'connection', 'neuron', 'adjusted', 'training', 'squashingactivation', 'function', 'squashing', 'function', 'may', 'non', 'linear', 'linear', 'function', 'applied', 'signal', 'neuron', 'ladder', 'function', 'adder', 'function', 'help', 'combining', 'output', 'several', 'neuron']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
43,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['number', 'input', 'exit', 'input', 'vj', 'local', 'field', 'varphivj', 'activation', 'function', 'yj', 'output', 'wji', 'weight', 'node', 'varphivj', 'sumi0nwjixi']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
44,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'simple', 'processing', 'unit', 'anna', 'made', 'synaptic', 'link', 'defines', 'weight', 'w1wn', 'adder', 'function', 'combine', 'weighted', 'input', 'wixi', 'plus', 'bias', 'b', 'local', 'field', 'sumwiwi', 'bv', 'activation', 'function', 'phi', 'squash', 'local', 'field', 'output', 'phivy']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
45,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'consists', 'synapsesconnecting', 'link', 'characterised', 'weight', 'linear', 'combined', 'sum', 'weighted', 'sum', 'input', 'local', 'field', 'local', 'field', 'passed', 'activation', 'function', 'result', 'activation', 'function', 'output']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
46,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'defined', 'following', 'element', 'number', 'input', 'value', 'number', 'weight', 'bias', 'activation', 'function', 'phi', 'input', 'multiplied', 'weight', 'result', 'summed', 'bias', 'also', 'bias', 'used', 'weight', 'value', 'single', 'connection', 'stable', 'input', 'equal', 'mathematical', 'simplicity', 'resulting', 'value', 'known', 'local', 'field', 'v', 'input', 'activation', 'function', 'mathematical', 'model', 'summarized', 'formula', 'iv', 'sumni', 'xiwi', 'phiv']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
47,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'consists', 'set', 'input', 'bias', 'input', 'redefined', 'bias', 'multiplied', 'weight', 'sum', 'result', 'input', 'bias', 'multiplied', 'weight', 'called', 'induced', 'field', 'send', 'activation', 'function', 'linear', 'nonlinear', 'function', 'output', 'function', 'final', 'output', 'neuron']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
48,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'simplest', 'computation', 'unit', 'neural', 'network', 'consists', 'input', 'variable', 'weight', 'bias', 'summation', 'term', 'combiner', 'activation', 'function', 'output', 'variable']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",1,2.0,neural_networks,neural_course,0.5
49,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'basic', 'processing', 'unit', 'neural', 'network', 'made', 'three', 'main', 'component', 'weight', 'w1', 'wn', 'adder', 'function', 'linear', 'combination', 'input', 'weight', 'plus', 'bias', 'induced', 'local', 'field', 'iv', 'sum', 'wi', 'xi', 'squashing', 'function', 'activation', 'function', 'applied', 'local', 'field', 'used', 'limit', 'output', 'neuron', 'phiv']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
50,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'computational', 'unit', 'composed', 'synapsis', 'stored', 'form', 'weight', 'w', 'variable', 'dynamical', 'summing', 'function', 'computes', 'weighted', 'sum', 'input', 'iv', 'sum', 'wixi', 'activation', 'function', 'phi', 'give', 'nonlinear', 'nature', 'network', 'determines', 'normalize', 'output', 'produced', 'neuron', 'edge', 'sigmoid', 'function', 'bias', 'another', 'synaptic', 'unable', 'variable', 'input', '1', 'therefore', 'net', 'output', 'neuron', 'sum', 'wixi', 'b']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
51,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['following', 'equation', 'describe', 'nonlinear', 'model', 'neuron', 'labeled', 'ke', 'fuk', 'sum', 'job', 'wkj', 'xj', '2yk', 'phiuk', 'bk', 'xj', 'input', 'signal', 'wkj', 'weight', 'neuron', 'uk', 'linear', 'combined', 'output', 'due', 'input', 'signal', 'bike', 'bias', 'phil', 'activation', 'function', 'ya', 'output', 'signal', 'te', 'neuron']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
52,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'processing', 'unit', 'contains', 'three', 'main', 'component', 'set', 'synaptic', 'weight', 'connect', 'neuron', 'neuron', 'adder', 'computes', 'induced', 'local', 'field', 'weighted', 'sum', 'signal', 'flowing', 'neuron', 'activation', 'function', 'constrains', 'magnitude', 'output', 'signal', 'neuron']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
53,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['mathematical', 'model', 'neuron', 'consists', '1', 'set', 'synaptic', 'link', 'classified', 'based', 'weightsw1', 'w3wn', '2', 'consists', 'adder', 'function', 'performs', 'weighted', 'sum', 'input', 'bias', 'sigmai1n', 'wax', '3', 'consists', 'activation', 'function', 'used', 'minimize', 'amplitude', 'neuron', 'output', 'phisigmai1n', 'wax']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
54,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['mathematical', 'model', 'neuron', 'comprises', '2', 'main', 'unit', 'adder', 'function', 'sum', 'product', 'synaptic', 'connection', 'input', 'neuron', 'synaptic', 'weight', 'interferon', 'connection', 'knowledge', 'stored', 'activation', 'function', 'used', 'introducing', 'nonlinearity']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
55,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuronal', 'model', 'consists', 'following', 'synaptic', 'link', 'characterized', 'weight', 'connects', 'network', 'environment', 'embedded', 'adder', 'function', 'sum', 'weighted', 'input', 'output', 'induced', 'local', 'field', 'neuron', 'activation', 'function', 'take', 'induced', 'local', 'field', 'neuron', 'input', 'limit', 'output', 'neuron']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
56,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['mathematical', 'model', 'neuron', 'consists', '3', 'important', 'part', 'neuron', 'smallest', 'computational', 'node', 'input', 'vector', 'set', 'vector', 'certain', 'dimension', 'train', 'model', 'weight', 'bias', 'input', 'vector', 'weighted', 'using', 'weight', 'vector', 'accordance', 'withthe', 'output', 'required', 'bias', 'added', 'necessary', 'activation', 'function', 'linear', 'combination', 'weight', 'input', 'passed', 'activation', 'function', 'produce', 'output']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
57,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'fundamental', 'processing', 'unit', 'artificial', 'neural', 'network', 'characterised', 'following', 'feature', '1', 'neuron', 'set', 'nonlinear', 'synaptic', 'link', 'externally', 'applied', 'bias', 'possibly', 'one', 'linear', 'activation', 'link', 'bias', 'represented', 'synaptic', 'link', 'input', 'fixed', '1', '2', 'synaptic', 'link', 'neuron', 'weight', 'respective', 'input', '3', 'adder', 'function', 'linear', 'combined', 'computes', 'weighted', 'sum', 'input', 'neuron', '4', 'activation', 'function', 'squashing', 'function', 'limit', 'amplitude', 'neuron', 'output']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
58,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['let', 'x1', 'x2', 'xn', 'input', 'neuron', 'win', 'corresponding', 'weight', 'connection', 'bias', 'varphi', 'activation', 'function', 'induced', 'field', 'given', 'rev', 'sumi', '1n', 'wi', 'xi', 'output', 'given', 'varphiv']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
59,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['mathematical', 'model', 'neuron', 'three', 'part', 'set', 'synapsis', 'connecting', 'link', 'characterized', 'weight', 'ow', 'adder', 'function', 'calculates', 'weighted', 'sum', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'minimize', 'amplitude']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
60,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['ask', 'sumj1m', 'wkj', 'xu', 'bk', 'phivk', 'wkj', 'synaptic', 'weight', 'connecting', 'neuron', 'input', 'data', 'je', 'xj', 'input', 'data', 'bk', 'bias', 'vk', 'induced', 'local', 'field', 'dyke', 'output', 'neuron']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
61,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'consists', 'synapse', 'connecting', 'link', 'adder', 'function', 'linear', 'combined', 'activation', 'function', 'rev', 'sigma', 'wi', 'dot', 'xi', 'b', 'exit', 'input', 'win', 'weight', 'bias']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",1,2.0,neural_networks,neural_course,0.5
62,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'basic', 'information', 'processing', 'unit', 'adder', 'function', 'compute', 'weighted', 'sum', 'input', 'plus', 'bias', 'apply', 'activation', 'function', 'result', 'phiv', 'sumlimitsi1n', 'omegaixi', 'bias']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
63,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'set', 'input', 'respective', 'weight', 'local', 'field', 'iv', 'sumwij', 'xiao', 'local', 'field', 'passed', 'activation', 'function', 'output', 'neuron', 'phiv', 'phisumwij', 'xi']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
64,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'basic', 'processing', 'unit', 'neural', 'network', 'output', 'neuron', 'phi', 'sum', 'wait', 'xi', 'consist', 'three', 'part', 'synaptic', 'weight', 'connection', 'neuron', 'characterised', 'weight', 'adder', 'function', 'calculates', 'weighted', 'sum', 'input', 'neuron', 'activation', 'function', 'limit', 'amplitude', 'output', 'neuron', 'phi']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
65,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['model', 'neuron', 'consists', 'synaptic', 'weight', 'applied', 'input', 'signal', 'weighted', 'input', 'summed', 'give', 'local', 'field', 'local', 'field', 'put', 'activation', 'function', 'whose', 'output', 'output', 'neuron']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
66,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['sumi0', 'phiwxi', 'neuron', 'consists', 'input', 'x', 'synaptic', 'weight', 'w', 'extra', 'input', 'w0', 'fixed', '1', 'bias', 'adder', 'function', 'creates', 'local', 'field', 'squashing', 'function', 'phi']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
67,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['sum', 'b', 'weight', 'change', 'input', 'according', 'learned', 'weight', 'input', 'environment', 'bias', 'shift', 'learned', 'decision', 'plane', 'activation', 'function', 'limit', 'output', 'desired', 'region', 'value']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
68,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'consists', 'one', 'multiple', 'input', 'gathered', 'summation', 'function', 'hereby', 'induced', 'local', 'field', 'neuron', 'processed', 'squashing', 'function', 'generates', 'output', 'neuron']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",1,2.0,neural_networks,neural_course,0.5
69,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'consist', 'input', 'connection', 'link', 'synaptic', 'weight', 'bias', 'adder', 'add', 'input', 'signal', 'bias', 'produce', 'local', 'field', 'local', 'field', 'processed', 'activation', 'function', 'produce', 'output', 'neuron']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
70,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'consists', 'input', 'node', 'xu', 'weight', 'linear', 'combined', 'sum', 'xi', 'wi', 'bias', 'result', 'called', 'local', 'field', 'used', 'input', 'activation', 'function', 'phiv']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
71,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'consists', 'three', 'unit', '1', 'synaptic', 'link', 'characterize', 'weight', 'nearly', 'way', 'input', '2', 'adder', 'add', 'weighted', 'input', 'generate', 'local', 'field', '3', 'activation', 'function', 'nonlinear', 'function', 'smashing', 'output', 'neuron']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
72,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'consist', 'synaptic', 'link', 'measured', 'term', 'weight', 'neuron', 'given', 'input', 'adder', 'function', 'combined', 'add', 'input', 'multiplied', 'weight', 'bias', 'extra', 'input', 'neuron', 'well', 'activation', 'link', 'limit', 'amplitude', 'output', 'neuron']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",1,2.0,neural_networks,neural_course,0.5
73,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'basic', 'information', 'processing', 'unit', 'main', 'component', 'neural', 'network', 'neuron', 'characterized', 'input', 'xi', 'synaptic', 'weight', 'wi', 'activation', 'function', 'phiv', 'mathematically', 'modelled', 'phiwixi', 'activation', 'function', 'bound', 'input', 'certain', 'level']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
74,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'three', 'component', 'synaptic', 'weight', 'adder', 'function', 'multiplies', 'input', 'weight', 'activation', 'function', 'squash', 'output', 'adder', 'function', 'sigmoid', 'hyperbolic', 'tangent', 'rectified', 'linear', 'unit', 'etc']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
75,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"['neuron', 'consist', 'set', 'input', 'take', 'data', 'environment', 'neuron', 'contains', 'synapsesconnection', 'link', 'characterized', 'weight', 'input', 'connected', 'summing', 'ladder', 'function', 'computes', 'weighted', 'sum', 'input', 'value', 'weighted', 'sum', 'called', 'local', 'field', 'neuron', 'value', 'local', 'field', 'limitedsquased', 'activation', 'function', 'thetav', 'result', 'squashing', 'function', 'output', 'neuron', 'thetav', 'additionally', 'bias', 'term', 'b', 'added', 'input', 'value', 'always', 'associated', 'weight', 'changed', 'training', 'period', 'finally', 'output', 'neuron', 'thetav', 'iv', 'sum', 'xu']","['mathematical', 'model', 'neuron', 'consists', 'set', 'synapsis', 'connecting', 'link', 'link', 'characterized', 'weight', 'adder', 'function', 'linear', 'combiner', 'computes', 'weighted', 'sum', 'local', 'field', 'input', 'plus', 'bias', 'activation', 'function', 'squashing', 'function', 'limiting', 'amplitude', 'neuron', 'output']",2,2.0,neural_networks,neural_course,1.0
76,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['1', 'label', 'one', 'class', 'positive', 'label', '1', 'class', 'negative', '1', '2', 'augment', 'data', 'additional', 'value', 'bias', 'term', '3', 'invert', 'sign', 'data', 'negative', 'class', '4', 'randomly', 'initialize', 'weight', '5', 'wet', 'dot', '0', 'update', 'weight', 'wn1', 'want', 'beta', 'xena', 'else', 'leave', 'weight', 'unchanged', '6', 'continue', 'step', '5', '7', 'terminate', 'longer', 'change', 'weight']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
77,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['1', 'initialization', 'time', 'step', 'iteration', '1', 'weight', 'small', 'randomly', 'initialized', '2', 'activation', 'perception', 'apply', 'training', 'pattern', 'activate', 'perception', '3', 'compute', 'output', 'apply', 'activation', 'function', 'local', 'fieldweighted', 'sum', 'input', 'plus', 'bias', '4', 'adjust', 'weight', 'adjust', 'weight', 'current', 'outputy', 'desired', 'outputd', '5', 'continuation', 'continue', 'increasing', 'iteration', 'repeat', 'step', '2', 'input', 'pattern', 'applied', 'network', 'also', 'error', 'minimized']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
78,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['denotes', 'actual', 'result', 'denotes', 'desired', 'result', 'positive', 'train', 'error', 'wnew', 'wold', 'negative', 'train', 'error', '0', 'wnew', 'wold', 'xu']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",1,2.0,neural_networks,neural_course,0.5
79,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['initialize', 'weight', 'zero', 'small', 'value', 'sample', 'data', 'point', 'feed', 'network', 'compute', 'net', 'output', 'use', 'step', 'activation', 'function', 'compute', 'error', 'edo', 'true', 'label', 'predicted', 'label', 'correct', 'weight', 'based', 'wt1wtalphadox', 'alpha', 'training', 'rate', 'input', 'pattern', 'repeat', 'pattern', 'convergence', 'reached']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
80,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['case', 'parameter', 'need', 'learned', 'slope', 'line', 'intercept', 'parameter', 'weight', 'vector', '1', 'initialize', 'random', 'small', 'value', 'weight', 'vector', '2', 'inputdata', 'exit', 'training', 'data', 'apply', 'input', 'weight', 'vector', 'e', 'difference', 'local', 'field', 'desired', 'output', 'diyi', 'update', 'weight', 'wn1', 'want', 'beta', 'e', 'xi']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",1,2.0,neural_networks,neural_course,0.5
81,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['varphiv', 'tanhv', 'single', 'node', 'network', 'mu', 'learning', 'rate', 'repeat', 'long', 'error', 'high', '1', 'present', 'sample', 'network', 'collect', 'output', '2', 'compare', 'actual', 'output', 'desired', 'output', '3', 'equal', 'adapt', 'weight', 'win', 'win', 'mudyxi']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
82,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['given', 'sky', 'date', 'point', 'xiyi', 'yiin11', 'given', 'learning', 'rate', 'point', 'add', 'bias', '1', 'point', '1xiyi', 'point', 'yi', '1', 'point', '1', 'point', 'nullvector', 'convergence', 'false', 'whileconvergence', 'false', 'convergence', 'true', 'point', 'training', 'set', 'ifwx0', 'wlearningratepointi', 'convergence', 'false']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
83,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['weight', 'weight', 'vector', 'phi', 'activation', 'function', 'eta', 'learning', 'rate', 'datapoint', 'xiyi', 'weightsi', 'weightsi', 'eta', 'xiiyiweightsi']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",1,2.0,neural_networks,neural_course,0.5
84,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['initweightsbias', 'weight', 'initialized', '0', 'random', 'initialized', '0', 'stopcriteria', 'iteration', 'stop', 'criterion', 'fulfilled', 'want', 'xena', 'calculate', 'output', 'e', '1', 'belongs', 'class', 'error', 'otherwise', '1', 'else', 'e', '1', 'e', 'update', 'weight', 'using', 'calculated', 'error', '1', 'end', 'stop', 'criterion', 'number', 'misclassified', 'input', 'data', 'stop']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
85,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['learning', 'process', 'consists', 'three', 'main', 'step', 'positive', 'error', 'calculate', 'error', 'data', 'set', 'learning', 'set', 'change', 'wweight', 'wn1', 'wnpositive', 'error', 'separate', 'data', 'point', 'based', 'new', 'negative', 'error', 'calculate', 'error', 'data', 'set', 'learning', 'set', 'change', 'wweight', 'wn1', 'wnnegative', 'error', 'separate', 'data', 'point', 'based', 'new', 'error', 'error', 'end', 'training']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",1,2.0,neural_networks,neural_course,0.5
86,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['define', 'bias', 'order', 'able', 'trigger', 'class', 'data', 'point', 'classified', 'assign', 'initial', 'randomly', 'chosen', 'weight', 'use', 'squashing', 'function', 'example', 'mccullon', 'pit', 'start', 'training', 'process', 'stop', 'error', 'output', 'desired', 'output', 'reached', 'desired', 'percentage']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",0,2.0,neural_networks,neural_course,0.0
87,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['initialize', 'weight', 'vector', 'hatw', 'every', 'training', 'sample', 'iv', 'sum', 'wi', 'xi', 'phiv', 'equal', 'ya', 'ow', 'beta', 'evil', 'xi', 'convergence']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
88,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['pseudo', 'code', 'initiate', 'weight', 'bias', 'randomly', 'compute', 'output', 'given', 'input', 'data', 'ya', 'sum', 'wixi', 'b', 'compute', 'error', 'computed', 'y', 'desired', 'output', 'update', 'weight', 'wn1', 'want', 'beta', 'yy', 'xu', 'stop', 'error', 'specified', 'threshold', 'becomes', 'zero', 'case', 'data', 'perfectly', 'nearly', 'separable']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
89,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,[],"['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",0,2.0,neural_networks,neural_course,0.0
90,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['initialize', 'perception', 'weight', 'equal', 'w0', '0', 'present', 'labeled', 'example', 'xi', 'perception', 'example', 'xi', 'compute', 'actual', 'output', 'yi', 'error', 'signal', 'update', 'weight', 'based', 'delta', 'rule', 'wn1', 'want', 'beta', 'dn', 'yn', 'xn']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",1,2.0,neural_networks,neural_course,0.5
91,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['use', 'threshold', 'function', 'activation', 'function', 'wax', '1', 'label', 'class', '1', 'else', 'label', 'class', '0']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",0,2.0,neural_networks,neural_course,0.0
92,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['end', 'current', 'error', 'bra', 'e', 'convergence', 'criterion', 'bra', 'learning', 'rate', 'bra', 'change', 'end', 'le', 'else', 'br', 'calculate', 'error', 'end', 'bra', 'wn1', 'want', 'end', 'xena', 'widow', 'hoffman', 'rule', 'bra']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
93,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['perception', 'learning', 'algorithm', 'initialize', 'network', 'assigning', 'random', 'weight', 'synaptic', 'link', 'calculate', 'error', 'difference', 'desired', 'output', 'actual', 'output', 'input', 'misclassified', 'positive', 'error', 'wnew', 'wcurrent', 'input', 'input', 'misclassified', 'negative', 'error', 'wnew', 'wcurrent', 'input', 'input', 'correctly', 'classified', 'change', 'made', 'weight', 'repeat', 'step', '2', 'long', 'error', 'defined', 'threshold', 'value']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
94,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['linear', 'binary', 'classifiable', 'data', 'consists', 'input', 'vector', 'ex', 'multiple', 'weight', 'added', 'bias', 'fall', 'class', 'class', 'depending', 'linear', 'combination', 'output', '0', 'class', 'algo', 'parameter', 'xydesired', 'output', 'weight', 'vector', 'initialized', 'small', 'random', 'value', 'input', 'vector', 'chosen', 'probability', 'output', 'computed', 'using', 'class', 'vector', 'output', '0', 'class', 'output', '0', 'weight', 'updated', 'accordingly', 'otherwise', 'weight', 'left', 'unchanged', 'treated', 'input', 'vector', 'convergence', 'output']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
95,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['1', 'initialization', 'time', 'step', 'n0', 'initialize', 'weight', 'vector', 'random', 'value', 'wj0', '2', 'activation', 'apply', 'input', 'example', 'xindin', 'activate', 'perception', 'heavyside', 'step', 'function', 'activation', 'function', '3', 'output', 'perception', 'yn', 'one', 'done', 'adjust', 'weight', 'vector', 'using', 'rule', 'wn1', 'want', 'beta', 'xndn', 'yn', '4', 'go', 'activation', 'repeat', 'change', 'weight', 'vector', 'observed']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
96,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['1', 'input', 'xu', 'x1', 'x2', 'xn', '2', 'desired', 'output', 'ya', 'y1', 'y2', 'sync', '3', 'initialize', 'weight', 'vector', 'random', 'small', 'value', '4', 'data', 'point', 'xn', 'xu', 'calculate', 'hatyn', 'xn', 'calculate', 'error', 'men', 'yn', 'hatyn', 'update', 'according', 'delta', 'rule', 'end']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
97,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,[],"['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",0,2.0,neural_networks,neural_course,0.0
98,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['apply', 'input', 'data', 'input', 'layer', 'initialize', 'small', 'value', 'weight', 'minimize', 'error', 'according', 'difference', 'desired', 'signal', 'output', 'signal', 'assign', 'test', 'vector', 'class', 'smallest', 'error']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
99,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['1', 'compute', 'initial', 'weight', 'input', 'vector', '2', 'apply', 'matrix', 'multiplication', 'input', 'weight', 'vector', '3', 'apply', 'linear', 'combined', '4', 'apply', 'activation', 'function', 'produce', 'output', '5', 'compute', 'error', '6', 'update', 'weight']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",0,2.0,neural_networks,neural_course,0.0
100,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['randomly', 'assign', 'value', 'initial', 'weight', 'run', 'perception', 'network', 'calculate', 'error', 'yada', 'e', 'error', 'output', 'desired', 'response', 'update', 'weight', 'based', 'error', 'error', 'positive', 'add', 'error', 'input', 'update', 'weight', 'error', 'negative', 'subtract', 'error', 'input', 'update', 'weight', 'error', 'dont', 'update', 'weight', 'repeat', 'process', 'calculated', 'error', 'approximately', 'equal', 'zero']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
101,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,[],"['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",0,2.0,neural_networks,neural_course,0.0
102,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['random', 'number', '1', 'every', 'data', 'training', 'set', 'first', 'layer', 'calculate', 'weighted', 'sum', 'using', 'adder', 'function', 'calculate', 'output', 'activation', 'function', 'output', 'layer', 'calculate', 'output', 'calculate', 'error', 'e', 'desired', 'output', 'change', 'weight', 'using', 'formula', 'delta', 'beta', 'xu', 'end', 'continue', 'till', 'error', 'converges']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
103,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['initialize', 'many', 'random', 'weight', 'dimension', 'data', 'point', 'data', 'point', 'output', 'match', 'desired', 'output', 'nothing', 'else', 'change', 'weight', 'direction', 'datapoint', 'datapoint', 'classified', 'correctly', 'end', 'end', 'weight', 'changed', 'start', 'loop', 'end']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
104,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['1', 'initialize', 'weight', 'random', '0', '2', 'activate', 'perception', 'giving', 'example', '3', 'compute', 'actual', 'output', 'neuron', '4', 'adjust', 'parameter', 'perception', '5', 'continue', 'convergence', 'achieved', 'rand', 'sumphiwx', 'wi', 'wi', 'wietaey']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",1,2.0,neural_networks,neural_course,0.5
105,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['initialize', 'weight', 'randomly', 'sum', 'b', 'compute', 'output', 'perception', 'using', 'input', 'xu', 'weight', 'bias', 'activation', 'function', 'f', 'calculate', 'error', 'subtracting', 'actual', 'output', 'desired', 'output', 'wnew', 'wold', 'learningrate', 'dot', 'dot', 'end', 'update', 'weight', 'formula', 'learning', 'rate', 'parameter', 'change', 'fast', 'perception', 'learns']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
106,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['iteration', 'datapoint', 'error', 'desired', 'output', 'error', '0', 'weight', 'weight', 'error', 'error', '0', 'weight', 'weight', 'error']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
107,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['pick', 'random', 'decision', 'boundary', 'one', 'data', 'point', 'wrong', 'class', 'turn', 'decision', 'boundary', 'using', 'vector', 'wrong', 'data', 'point', 'negative', 'rule', 'positive']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",1,2.0,neural_networks,neural_course,0.5
108,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['training', 'set', 'labeled', 'linear', 'venerable', 'data', 'point', 'weight', 'vector', 'dimension', 'input', 'data', 'local', 'field', 'phiv', 'activationfunction', 'threshold', 'function', 'output', 'e', 'error', 'desired', 'output', 'labeled', 'training', 'data', 'learning', 'rate', '01', 'assign', 'random', 'value', 'trainingset', 'sumxi', 'win', 'phiv', 'e', 'nxe', 'delta', 'rule', 'end']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
109,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['initialize', 'weight', 'bias', 'set', 'learning', 'rate', 'set', 'errorthreshold', 'upper', 'bound', 'error', 'error', 'errorthreshold', 'every', 'datapoint', 'training', 'dataset', 'ex', 'bias', 'represented', 'weight', 'fixed', 'input', 'positive', 'belongs', 'ca', 'otherwise', 'ca', 'store', 'predicted', 'class', 'find', 'error', 'predicted', 'output', 'respect', 'label', 'store', 'error', 'e', 'sum', 'sum', 'error', 'e', 'every', 'data', 'point', 'sum']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
110,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['binary', 'classifier', 'use', 'threshold', 'activation', 'function', 'randomly', 'initialize', 'weight', 'calculate', 'output', 'neuron', 'find', 'error', 'subtracting', 'expected', 'output', 'current', 'output', 'modify', 'weight', 'related', 'input', 'respect', 'error', 'repeat', 'process', '24', 'till', 'get', 'minimal', 'error']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
111,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,[],"['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",0,2.0,neural_networks,neural_course,0.0
112,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['continueprocess', 'true', 'randomlyinitialize', 'continueprocess', 'list', 'point', 'wax', 'diff', 'day', 'desired', 'output', 'ifdiff', 'else', 'point', 'classified', 'without', 'error', 'continueprocess', 'false']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
113,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"['leaving', 'rate', 'repeat', 'small', 'enough', 'tt1', 'point', 'training', 'set', 'compute', 'local', 'field', 'percepron', 'wax', 'apply', 'linear', 'activation', 'function', 'thetav', 'compute', 'current', 'error', 'e', 'dy', 'apply', 'delta', 'rule', 'wt1', 'nex', 'end']","['label', 'data', 'positive', 'negative', 'label', 'initialize', 'weight', 'randomly', 'apply', 'simplified', 'update', 'rule', 'etaxn', 'wx', 'repeat', 'epoch', 'till', 'weight', 'dont', 'change', 'much', 'algorithm', 'converge', 'data', 'nearly', 'separable']",2,2.0,neural_networks,neural_course,1.0
114,Explain classification and regression; what is the difference?,225,"['classification', 'classification', 'output', 'produced', 'discrete', 'value', 'indicates', 'class', 'input', 'belongs', 'regression', 'regression', 'output', 'produced', 'continuous', 'variable', 'could', 'used', 'instance', 'approximate', 'continuous', 'function']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
115,Explain classification and regression; what is the difference?,225,"['classification', 'output', 'value', 'always', 'discrete', 'regression', 'output', 'value', 'continuous']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
116,Explain classification and regression; what is the difference?,225,"['hydroplane', 'given', 'wax', 'regression', 'want', 'determine', 'classification', 'want', 'assign', 'class', 'set', 'observation', 'regression', 'want', 'determine', 'separating', 'hyerplane', 'classification', 'want', 'label', 'data', 'point', 'class']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
117,Explain classification and regression; what is the difference?,225,"['classification', 'task', 'assign', 'discrete', 'label', 'data', 'point', 'training', 'dataset', 'either', 'assigned', 'specific', 'label', 'binary', 'supervised', 'learning', 'datapoints', 'labeled', 'label', 'vector', 'ground', 'truth', 'regression', 'try', 'model', 'function', 'fit', 'data', 'point', 'training', 'data', 'thus', 'model', 'function', 'continuous', 'value']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
118,Explain classification and regression; what is the difference?,225,"['classification', 'refers', 'classifying', 'given', 'data', 'discrete', 'class', 'output', 'discrete', 'value', 'use', 'activity', 'like', 'pattern', 'recognition', 'etc', 'regression', 'refers', 'estimating', 'value', 'continuous', 'function', 'given', 'input', 'output', 'continuous', 'value', 'used', 'activity', 'like', 'motor', 'control', 'etc']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
119,Explain classification and regression; what is the difference?,225,"['classification', 'try', 'assign', 'class', 'input', 'data', 'regression', 'want', 'network', 'behave', 'like', 'given', 'systemformala', 'also', 'time', 'series', 'input', 'output', 'data']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
120,Explain classification and regression; what is the difference?,225,"['classification', 'goal', 'separate', 'point', 'different', 'class', 'outcome', 'class', 'able', 'regression', 'try', 'fit', 'hyperplante', 'point', 'cloud', 'best', 'future', 'data', 'represented', 'hyperplane', 'best', 'lm', 'try', 'minimize', 'distance', 'data', 'point', 'outcome', 'countinius', 'variable']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
121,Explain classification and regression; what is the difference?,225,"['learning', 'task', 'anna', 'classification', 'goal', 'assign', 'class', 'label', 'new', 'datapoints', 'regression', 'goal', 'estimate', 'unknown', 'function', 'difference', 'classification', 'us', 'discrete', 'class', 'label', 'regression', 'continuous', 'output', 'used']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
122,Explain classification and regression; what is the difference?,225,"['approach', 'classification', 'classify', 'set', 'input', 'data', 'correct', 'class', 'example', 'used', 'pattern', 'recognition', 'approach', 'regression', 'approximate', 'defined', 'function', 'calculating', 'error', 'function', 'result', 'algorithm', 'difference', 'classification', 'approach', 'applied', 'discreet', 'data', 'sample', 'different', 'point', 'input', 'space', 'regression', 'analogy', 'approach', 'whole', 'function', 'must', 'approximate', 'input', 'given']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
123,Explain classification and regression; what is the difference?,225,"['classification', 'classification', 'problem', 'different', 'group', 'data', 'common', 'property', 'training', 'want', 'model', 'detect', 'class', 'new', 'sample', 'correctly', 'regression', 'regression', 'series', 'value', 'want', 'use', 'previous', 'value', 'series', 'predict', 'next', 'value']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
124,Explain classification and regression; what is the difference?,225,"['classification', 'problem', 'distinguishing', 'discrete', 'class', 'input', 'variable', 'assigned', 'regression', 'estimation', 'output', 'figuring', 'continuous', 'trend', 'whole', 'dataset']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
125,Explain classification and regression; what is the difference?,225,"['classification', 'assign', 'class', 'category', 'data', 'regression', 'fit', 'data', 'function']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
126,Explain classification and regression; what is the difference?,225,"['regression', 'learns', 'modelfunction', 'predict', 'unseen', 'data', 'well', 'targetoutput', 'real', 'spaced', 'classification', 'learns', 'model', 'classifiesmaps', 'input', 'discrete', 'target', 'label', 'targetlabeloutput', 'binarydiscrete']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
127,Explain classification and regression; what is the difference?,225,"['classification', 'describes', 'application', 'sample', 'assigned', 'one', 'specific', 'pattern', 'problem', 'comparison', 'regression', 'output', 'deterministic', 'continuously', 'regression', 'output', 'continuous', 'describing']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
128,Explain classification and regression; what is the difference?,225,"['classification', 'task', 'classifying', 'input', 'signal', 'finite', 'number', 'group', 'output', 'number', 'indicates', 'certain', 'class', 'regression', 'task', 'approximating', 'function', 'estimating', 'value', 'given', 'input', 'signal', 'output', 'real', 'number']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
129,Explain classification and regression; what is the difference?,225,"['classification', 'need', 'predict', 'output', 'data', 'discretely', 'output', 'space', 'discrete', 'space', 'regression', 'need', 'predict', 'output', 'data', 'continuously', 'output', 'space', 'continuous', 'space', 'main', 'difference', 'discreteness', 'contionousness']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
130,Explain classification and regression; what is the difference?,225,"['classification', 'problem', 'assigning', 'particular', 'class', 'data', 'point', 'given', 'dataset', 'bra', 'regression', 'problem', 'fitting', 'given', 'dataset', 'particular', 'hyperplane', 'used', 'representing', 'given', 'data', 'find', 'hyperplane', 'minimise', 'mean', 'square', 'error']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
131,Explain classification and regression; what is the difference?,225,"['classification', 'problem', 'assigning', 'label', 'class', 'input', 'output', 'discrete', 'variable', 'regression', 'problem', 'assigning', 'continuous', 'variable', 'input']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
132,Explain classification and regression; what is the difference?,225,"['classification', 'problem', 'catergorization', 'discrete', 'class', 'regression', 'problem', 'continuous', 'space', 'goal', 'ether', 'minimize', 'maximize', 'cost', 'function', 'classification', 'process', 'dividing', 'set', 'discrete', 'input', 'class', 'corresponding', 'similar', 'pattern', 'clustering', 'regression', 'could', 'finding', 'pattern', 'distribution', 'data', 'fitting', 'line']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
133,Explain classification and regression; what is the difference?,225,"['classification', 'machine', 'learning', 'used', 'find', 'decision', 'surface', 'form', 'hyperplane', 'separate', 'set', 'input', 'example', 'set', 'pattern', 'respective', 'class', 'regression', 'hand', 'used', 'find', 'parameter', 'ie', 'weight', 'vector', 'bias', 'function', 'thatwas', 'best', 'fit', 'given', 'data', 'point', 'xidi', 'thus', 'classification', 'deal', 'predicting', 'class', 'label', 'discrete', 'data', 'point', 'whereas', 'regression', 'deal', 'fitting', 'continuous', 'real', 'valued', 'function']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
134,Explain classification and regression; what is the difference?,225,"['classification', 'separating', 'data', 'class', 'output', 'discontinuous', 'variable', 'regression', 'fitting', 'model', 'output', 'continuous', 'variable']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
135,Explain classification and regression; what is the difference?,225,"['classification', 'classifying', 'given', 'data', 'different', 'class', 'regression', 'finding', 'localglobal', 'minimawe', 'use', 'perception', 'classify', 'data', 'use', 'constrained', 'optimization', 'technique', 'like', 'newton', 'method', 'find', 'regression']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
136,Explain classification and regression; what is the difference?,225,"['classification', 'assign', 'test', 'data', 'class', 'prescribed', 'regression', 'approximating', 'unknown', 'function', 'minimization', 'error', 'inputoutput', 'mapping']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
137,Explain classification and regression; what is the difference?,225,"['classification', 'classification', 'output', 'variable', 'take', 'class', 'label', 'identifying', 'group', 'membershipbr', 'regression', 'regression', 'output', 'variable', 'take', 'continuous', 'value', 'predicting', 'response']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
138,Explain classification and regression; what is the difference?,225,"['classification', 'problem', 'used', 'classify', 'set', 'data', 'point', 'specific', 'group', 'regression', 'used', 'predict', 'time', 'series', 'data', 'classification', 'work', 'discrete', 'set', 'value', 'regression', 'work', 'continuous', 'value']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
139,Explain classification and regression; what is the difference?,225,"['classification', 'classification', 'done', 'class', 'machine', 'determines', 'class', 'data', 'belongs', 'regression', 'regression', 'expecting', 'output', 'input', 'machine', 'learns', 'given', 'data', 'model', 'function', 'new', 'input', 'given', 'expects', 'output', 'difference', 'classification', 'discrete', 'output', 'regression', 'continuous', 'output']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
140,Explain classification and regression; what is the difference?,225,"['regression', 'try', 'fit', 'line', 'curve', 'among', 'given', 'point', 'continuous', 'output', 'output', 'function', 'classification', 'try', 'classify', 'given', 'point', 'two', 'class', 'discrete', 'output', 'output', 'value', 'representing', 'class']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
141,Explain classification and regression; what is the difference?,225,"['classification', 'datapoint', 'assigned', 'class', 'regression', 'datapoint', 'assigned', 'value', 'classification', 'assign', 'class', 'label', 'datapoints', 'error', 'signal', 'true', 'false', 'regression', 'try', 'learn', 'function', 'error', 'prediction', 'number']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",2,2.0,neural_networks,neural_course,1.0
142,Explain classification and regression; what is the difference?,225,"['classification', 'binary', 'pattern', 'partitioned', 'two', 'class', 'regression', 'line', 'fitted', 'closest', 'datapoints', 'difference', 'classification', 'output', 'single', 'class', 'label', 'regression', 'output', 'continuous']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
143,Explain classification and regression; what is the difference?,225,"['classification', 'input', 'data', 'split', '2', 'class', 'goal', 'neural', 'network', 'learn', 'input', 'data', 'able', 'classify', 'new', 'input', 'data', 'class', 'based', 'learned', 'information', 'network', 'map', 'input', 'data', 'one', 'class', 'discrete', 'space', 'regression', 'input', 'data', 'learned', 'swell', 'network', 'try', 'predict', 'feature', 'value', 'continuous', 'space', 'network', 'try', 'predict', 'close', 'possible', 'new', 'input', 'data', 'using', 'learned', 'model']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
144,Explain classification and regression; what is the difference?,225,"['classification', 'try', 'label', 'discrete', 'data', 'point', 'distinct', 'class', 'regression', 'try', 'approximate', 'continuous', 'function', 'discrete', 'data', 'point', 'result', 'method', 'respectively', 'labeled', 'data', 'set', 'continuous', 'function']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
145,Explain classification and regression; what is the difference?,225,"['classification', 'task', 'give', 'discrete', 'output', 'value', 'input', 'assigned', 'one', 'defined', 'class', 'current', 'input', 'regression', 'try', 'approximate', 'function', 'minimizing', 'error', 'produce', 'continuous', 'output', 'value']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
146,Explain classification and regression; what is the difference?,225,"['classification', 'mean', 'mapping', 'input', 'data', 'class', 'label', 'example', '1', '1', 'regression', 'hand', 'continuous', 'function', 'learned', 'way', 'fix', 'fix', 'minimized', 'fix', 'function', 'learned', 'learning', 'machine', 'fix', 'original', 'function']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
147,Explain classification and regression; what is the difference?,225,"['classification', 'supervised', 'learning', 'underlying', 'function', 'representing', 'training', 'data', 'learn', 'training', 'data', 'predict', 'class', 'datapoints', 'pattern', 'drawn', 'similar', 'distribution', 'training', 'data', 'weight', 'neural', 'network', 'learned', 'minimize', 'error', 'classification', 'regression', 'supervised', 'learning', 'algorithm', 'underlying', 'function', 'representing', 'training', 'data', 'learn', 'training', 'data', 'predict', 'value', 'label', 'output', 'system', 'new', 'datapoint', 'pattern', 'similar', 'type', 'weight', 'neural', 'network', 'learned', 'minimize', 'error', 'prediction', 'function', 'difference', '1', 'output', 'classification', 'discrete', 'class', '123', 'whereas', 'output', 'regression', 'continuous', '2', 'error', 'classification', 'number', 'wrong', 'classification', 'whereas', 'error', 'classification', 'regression', 'distance', 'able', 'value', 'predicted', 'value']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",2,2.0,neural_networks,neural_course,1.0
148,Explain classification and regression; what is the difference?,225,"['classification', 'type', 'problem', 'algorithm', 'need', 'separate', 'one', 'data', 'class', 'another', 'data', 'class', '2', 'class', 'ca', 'ca', 'algorithm', 'classify', 'given', 'data', 'two', 'class', 'discreet', 'process', 'regression', 'predicting', 'next', 'point', 'depending', 'previous', 'point', 'continuous', 'process']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
149,Explain classification and regression; what is the difference?,225,"['classification', 'problem', 'input', 'data', 'put', 'two', 'class', 'distinctively', 'different', 'example', 'case', 'binary', 'classification', 'class', '1', '1', 'regression', 'hand', 'data', 'fitting', 'main', 'aim', 'find', 'hyperplane', 'fit', 'given', 'input', 'pattern']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
150,Explain classification and regression; what is the difference?,225,"['classification', 'task', 'partition', 'given', 'input', 'one', 'several', 'class', 'class', 'discrete', 'value', 'regression', 'regression', 'task', 'predicting', 'output', 'continuous', 'range', 'prediction', 'value', 'within', 'range']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
151,Explain classification and regression; what is the difference?,225,"['classification', 'task', 'aim', 'separate', 'data', 'different', 'class', 'output', 'give', 'value', 'class', 'index', 'input', 'point', 'egg', 'task', 'classify', 'binary', 'data', 'output', '0', 'value', 'represent', 'class', 'case', 'regression', 'task', 'aim', 'fit', 'data', 'namely', 'function', 'perform', 'inputouput', 'mapping', 'output', 'case', 'error', 'value', 'know', 'close', 'function', 'fitted', 'data', 'point']","['classification', 'task', 'mapping', 'data', 'discrete', 'label', 'regression', 'task', 'map', 'data', 'continuous', 'function', 'real', 'value', 'error', 'classification', 'number', 'misclassifications', 'regression', 'summed', 'distance', 'true', 'predicted', 'value']",1,2.0,neural_networks,neural_course,0.5
152,Write down the SOM learning in pseudo code.,226,"['1', 'arrange', 'weight', 'required', 'topology', 'according', 'problem', '2', 'initialize', 'weight', 'randomly', 'weight', 'different', '3', 'sample', 'input', 'input', 'space', '4', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', '5', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'reduce', 'learning', 'rate', 'make', 'sure', 'learning', 'rate', 'zero', '6', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'step', '3']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
153,Write down the SOM learning in pseudo code.,226,"['first', 'initialize', 'random', 'weight', 'neuron', 'ii', 'choose', 'random', 'input', 'input', 'space', 'iii', 'compute', 'distance', 'input', 'vector', 'weight', 'vector', 'ivy', 'neuron', 'minimum', 'euclidean', 'distance', 'input', 'vector', 'considered', 'winner', 'neuron', 'find', 'neighborhood', 'neuron', 'winning', 'neuron', 'via', 'adjust', 'weight', 'neighborhood', 'neuron', 'viii', 'reduce', 'learning', 'parameter', 'neighborhood', 'size', 'viii', 'continue', 'converges']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",1,2.0,neural_networks,neural_course,0.5
154,Write down the SOM learning in pseudo code.,226,"['denote', 'weight', 'denotes', 'threshold', 'denotes', 'neighborhood', 'function', 'decrease', 'distance', 'winning', 'neuron', 'hex', 'xwin', 'neighborhood', 'function', 'return', 'exp2xxwin', 'rand', 'initialize', 'weight', 'random', 'value', 'wdelta', 'proceed', 'noticeable', 'change', 'xwin', 'min', 'xw2determine', 'closest', 'competitive', 'leaving', 'update', 'weight', 'winning', 'neuron', 'weight', 'losing', 'neuron', 'updated', 'wnew', 'wold', 'xhx', 'xwinxwupdate', 'weight', 'neuron', 'neighborhood', 'winning', 'neuron']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
155,Write down the SOM learning in pseudo code.,226,"['initialize', 'weight', 'small', 'value', 'weight', 'vector', 'different', 'sample', 'datapoint', 'feed', 'network', 'determine', 'winning', 'neuron', 'lattice', 'picking', 'neuron', 'least', 'euclidean', 'distance', 'weight', 'vector', 'input', 'vector', 'determine', 'neighbourhood', 'winning', 'neuron', 'neighbourhood', 'function', 'change', 'weight', 'neuron', 'namely', 'spatially', 'pulling', 'weight', 'vector', 'neighbourhood', 'neuron', 'towards', 'input', 'vector', 'depending', 'timestep', 'reduce', 'learning', 'rate', 'neighbourhood', 'size', 'based', 'wether', 'organizing', 'finetuning', 'step', 'repeat', 'maximum', 'number', 'step']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
156,Write down the SOM learning in pseudo code.,226,"['1', 'randomly', 'initialize', 'weight', '2', 'randomly', 'select', 'input', 'training', 'data', '3', 'find', 'nearest', 'neighbour', 'input', 'weight', 'done', 'finding', 'euclidean', 'distance', 'input', 'weight', 'selecting', 'weight', 'least', 'distance', '4', 'update', 'weight', 'neuron', 'within', 'neighbourhood', 'hn', 'gaussian', 'function', 'exponentially', 'decaying', 'sigman', 'winning', 'neuron', 'learning', 'rate', 'etan', 'delta', 'wijetanhnxixj', 'etan', 'eta0ent1', 'sigman', 'sigma0ent1']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
157,Write down the SOM learning in pseudo code.,226,"['som', 'start', 'randomized', 'weight', 'mu', 'learning', 'create', 'dji', 'distance', 'neighbour', 'function', 'repeat', 'long', 'error', 'highmax', 'iteration', 'reached', '1', 'take', 'input', 'sample', '2', 'find', 'closest', 'nodeweight', '3', 'find', 'neighbour', '4', 'move', 'weight', 'neighbour', 'closer', 'given', 'input', 'use', 'neighbour', 'function', 'eg', 'gaussian', 'reduce', 'effect', 'far', 'distance', 'neighbour', '5', 'optional', 'adapt', 'learning', 'rate', 'neighbour', 'function']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
158,Write down the SOM learning in pseudo code.,226,"['given', 'neighbourhood', 'function', 'hijn', 'learning', 'rate', 'time', 'randomly', 'asking', 'different', 'weight', 'input', 'layer', 'neuron', 'second', 'layer', 'training', 'point', 'xi', 'find', 'winnertakesall', 'neuron', 'sky', 'min', 'xiwi', 'find', 'neighbour', 'sky', 'neighbourhood', 'function', 'compute', 'new', 'weight', 'neuron', 'using', 'neighbourhood', 'function', 'learning', 'rate', 'update', 'decrease', 'neighbourhood', 'function', 'learning', 'rate', 'end']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
159,Write down the SOM learning in pseudo code.,226,[],"['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",0,2.0,neural_networks,neural_course,0.0
160,Write down the SOM learning in pseudo code.,226,"['initweights', 'equal', 'zero', 'random', 'initialized', '0', 'stopcriteria', 'winnerneuron', 'ex', 'find', 'map', 'layer', 'neuron', 'closer', 'input', 'euclidean', 'distance', 'neighborhood', 'defineneighboorwinnerneuron', 'define', 'neighborhood', 'size', 'first', 'iteration', 'big', 'reduced', 'eta', 'definelearningraten', 'define', 'learning', 'rate', 'large', 'value', 'first', 'iteration', 'reduced', 'diff', 'adaptweightsneighborhood', 'eta', 'adapt', 'weight', 'winner', 'neuron', 'neighborhood', 'diff', 'update', 'weight', 'stopcritera', 'muststopy', 'xu', 'look', 'distance', 'input', 'winner', 'neuron', '0', 'really', 'close', 'end']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
161,Write down the SOM learning in pseudo code.,226,"['randomly', 'define', 'value', 'synaptic', 'connection', 'network', 'send', 'first', 'input', 'network', 'output', 'layermap', 'layer', 'select', 'neuron', 'lowest', 'errorcompetition', 'phase', 'based', 'redefined', 'method', 'define', 'neighborhood', 'selected', 'neuroncooparation', 'phase', 'change', 'weight', 'selected', 'neuron', 'neuron', 'located', 'neighborhoodadaptation', 'phase', 'stop', 'condition', 'satisfied', 'stop', 'process']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
162,Write down the SOM learning in pseudo code.,226,"['three', 'part', 'competition', 'cooperation', 'adaptation', 'get', 'input', 'variable', 'choose', 'amount', 'neuron', 'amount', 'variable', 'run', 'competition', 'input', 'neuron', 'competing', 'choosing', 'fit', 'finding', 'winning', 'neuron', 'change', 'weight', 'neighbouring', 'neuron', 'cooperation', 'weight', 'neighbouring', 'neuron', 'adjusted', 'cluster', 'adaptation', 'neuron', 'pulled', 'input', 'variable', 'establish', 'classification']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",0,2.0,neural_networks,neural_course,0.0
163,Write down the SOM learning in pseudo code.,226,"['find', 'winning', 'neuron', 'find', 'neighbor', 'winning', 'neuron']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",0,2.0,neural_networks,neural_course,0.0
164,Write down the SOM learning in pseudo code.,226,"['pseudo', 'code', '1', 'initialize', 'map', 'neuron', 'based', 'topology', 'could', 'lattice', 'circle', 'etc', '2', 'competition', 'find', 'map', 'neuron', 'closest', 'input', 'neuron', 'computing', 'distance', '3', 'update', 'position', 'closest', 'map', 'neuron', 'update', 'rule', '4', '2', '3', 'input', 'neuron', 'assigned', 'map', 'neuron', '23', '4', 'specified', 'iteration', 'net', 'cumulative', 'distance', 'go', 'specified', 'value', 'becomes', 'zero']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
165,Write down the SOM learning in pseudo code.,226,"['produce', 'transom', 'begin', 'randomized', 'weight', 'neuron', 'i1', 'iterationnumber', 'begin', 'take', 'random', 'input', 'pattern', 'find', 'winning', 'neuron', 'find', 'neighbor', 'winner', 'modify', 'synaptic', 'weight', 'neuron', 'reduce', 'learning', 'rate', 'lambda', 'end', 'end']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
166,Write down the SOM learning in pseudo code.,226,"['initialize', 'network', 'small', 'random', 'weight', 'sample', 'data', 'set', 'picking', 'input', 'randomly', 'determine', 'winning', 'neuron', 'based', 'output', 'value', 'determine', 'cooperating', 'neuron', 'based', 'using', 'neighborhood', 'function', 'update', 'weight', 'cooperating', 'neuron', 'adjust', 'learning', 'rate', 'stop', 'network', 'converges']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
167,Write down the SOM learning in pseudo code.,226,"['begin', 'range', 'data', 'set', 'initialise', 'weight', 'give', 'small', 'random', 'weight', 'range', 'select', 'input', 'signal', 'find', 'winning', 'neuron', 'based', 'similarity', 'weight', 'update', 'weight', 'neighboring', 'neuron', 'repeat', 'convergence', '1', 'initialising', '2', 'sampling', '3', 'similarity', 'matching', '4', 'updating', 'weight', '5', 'continuation']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
168,Write down the SOM learning in pseudo code.,226,"['initialise', 'weight', 'bra', 'significant', 'change', 'observed', 'topographic', 'pattern', 'br', 'take', 'random', 'input', 'sampling', 'bra', 'find', 'winning', 'output', 'neuron', 'competition', 'bra', 'adjust', 'weight', 'winning', 'neuron', 'neighbourhood', 'neuron', 'cooperation', 'bra', 'continue', 'bra']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
169,Write down the SOM learning in pseudo code.,226,"['som', 'learning', 'initialization', 'random', 'small', 'weight', 'sampling', 'picking', 'input', 'pattern', 'certain', 'probability', 'similarity', 'matching', 'finding', 'matching', 'neuron', 'ie', 'winning', 'neuron', 'synaptic', 'updating', 'updating', 'weight', 'neuron', 'also', 'neuron', 'neighbourhood', 'continuation', 'repeat', 'step', '2', '4', 'till', 'considerable', 'change', 'map']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
170,Write down the SOM learning in pseudo code.,226,"['parameter', 'ex', 'data', 'vector', 'weight', 'vector', 'lattice', 'etan', 'learning', 'rate', 'sigman', 'neighbourhood', 'width', 'hjix', 'neighbourhood', 'function', 'algo', 'initialize', 'weight', 'small', 'random', 'nonrepeatible', 'value', 'sample', 'data', 'vector', 'probability', 'compute', 'euclidean', 'distance', 'weight', 'vector', 'data', 'point', 'find', 'winning', 'neuron', 'minimum', 'distance', 'update', 'weight', 'winning', 'neuron', 'neighbourhood', 'towards', 'input', 'direction', 'using', 'neighbourhood', 'function', 'reduce', 'learning', 'rate', 'neighbour', 'hood', 'width', 'literate', 'step', '2', 'significant', 'change', 'weight', 'vector', 'input', 'seen']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
171,Write down the SOM learning in pseudo code.,226,"['1', 'initialization', 'initialize', 'weight', 'vector', 'random', 'value', 'wj0', 'different', 'weight', '2', 'sampling', 'draw', 'sample', 'example', 'ex', 'input', 'space', '3', 'similarity', 'matching', 'find', 'best', 'matching', 'weight', 'vector', 'input', 'vector', 'wi', 'arguing', 'ex', 'win', '4', 'adjust', 'weight', 'vector', 'neuron', 'neighbourhood', 'winning', 'neuron', '5', 'go', 'sampling', 'step', 'repeat', 'change', 'observed', 'local', 'neighbourhood', 'winning', 'neuron']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
172,Write down the SOM learning in pseudo code.,226,"['1', 'initialization', 'initialize', 'weight', 'neuron', 'small', 'random', 'value', 'weight', 'neuron', 'different', '2', 'sampling', 'sample', 'input', 'input', 'set', '3', 'similarity', 'matching', 'determine', 'neuron', 'nearest', 'sampled', 'input', 'based', 'distance', '4', 'weight', 'updating', 'update', 'weight', 'neighbouring', 'neuron', 'chosen', 'neighbourhood', 'function', 'hijn', '5', 'continuation', 'continue', 'sampling', 'change', 'weight']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
173,Write down the SOM learning in pseudo code.,226,"['som', 'referred', 'self', 'organized', 'map', 'unsupervised', 'training', 'algorithm', 'finding', 'spatial', 'pattern', 'data', 'without', 'using', 'external', 'helpthe', 'process', 'som', 'explained', 'initialization', 'initialize', 'random', 'weight', 'input', 'pattern', 'sampling', 'take', 'nah', 'random', 'sample', 'input', 'say', 'xu', 'similarity', 'matching', 'input', 'xu', 'find', 'best', 'match', 'weight', 'vector', 'ix', 'argminx', 'update', 'next', 'step', 'update', 'weight', 'wn1', 'want', 'etahjixix', 'continuation', 'continue', 'sampling', 'significant', 'change', 'feature', 'map']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
174,Write down the SOM learning in pseudo code.,226,"['initialization', 'set', 'random', 'small', 'value', 'weight', 'different', 'neuron', 'sampling', 'draw', 'sample', 'input', 'space', 'competition', 'identify', 'winning', 'neuron', 'using', 'min', 'xwi', 'mean', 'weight', 'vector', 'similar', 'input', 'cooperation', 'identify', 'neighbor', 'winning', 'neuron', 'using', 'neighborhood', 'function', 'hjix', 'n', 'shrink', 'time', 'weight', 'adaptation', 'adjustment', 'made', 'synaptic', 'weight', 'winning', 'neuron', 'neighbor', 'go', 'sampling', 'large', 'change', 'feature', 'map']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
175,Write down the SOM learning in pseudo code.,226,"['generate', 'random', 'weight', 'neuronsbr', 'maxiteration', 'dobr', 'take', 'random', 'input', 'patternbr', 'find', 'winning', 'neuronbr', 'find', 'neighbor', 'winning', 'neuronbr', 'compute', 'weighs', 'neuronsbr', 'reduce', 'eta', 'lambdabr', 'end']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
176,Write down the SOM learning in pseudo code.,226,"['initialize', 'neuron', 'weight', 'randomly', 'way', 'neuron', 'different', 'weight', 'generate', 'random', 'sample', 'input', 'space', 'literate', 'sample', 'compare', 'distance', 'current', 'input', 'neuron', 'weight', 'space', 'find', 'winning', 'neuron', 'shortest', 'distance', 'current', 'input', 'distance', 'calculated', 'using', 'euclidean', 'manhattan', 'distance', 'find', 'neuron', 'neighborhood', 'boundary', 'winning', 'neuron', 'update', 'weight', 'neighborhood', 'neuron', 'using', 'delta', 'rule', 'adapt', 'size', 'neighborhood', 'lambda', 'learning', 'rate', 'eta', 'iteration', 'repeat', 'process', 'neuron', 'neighborhood', 'boundary', 'input', 'moved', 'neuron']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
177,Write down the SOM learning in pseudo code.,226,"['step', 'selects', 'datapoint', 'random', 'sampling', 'step', 'find', 'nearest', 'neuron', 'competitive', 'learning', 'step', 'update', 'weight', 'winner', 'neuron', 'update', 'weight', 'neighbouring', 'neuron', 'fraction', 'step', 'continues', 'step', '3', 'change', 'weight', 'stopping', 'criterion', 'met']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
178,Write down the SOM learning in pseudo code.,226,"['take', 'random', 'point', 'training', 'data', 'competitive', 'phase', 'find', 'winning', 'neuron', 'neuron', 'similar', 'feature', 'using', 'eucledian', 'distance', 'formula', 'cooperative', 'phase', 'find', 'neighbor', 'winning', 'neuron', 'based', 'neighbor', 'function', 'beg', 'gaussian', 'function', 'adoption', 'phase', 'change', 'weight', 'neighboring', 'neuron', 'winning', 'node', 'using', 'formula', 'del', 'beta', 'xu']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
179,Write down the SOM learning in pseudo code.,226,"['input', 'distance', 'function', 'dex', 'learning', 'rate', 'mum', 'neighborhood', 'distance', 'initialize', 'map', 'layer', 'random', 'weight', 'input', 'find', 'weight', 'closest', 'input', 'minimum', 'dex', 'change', 'weight', 'direction', 'input', 'depending', 'learning', 'rate', 'change', 'weight', 'within', 'neighborhood', 'distance', 'depending', 'distance', 'learning', 'rate', 'reduce', 'learning', 'rate', 'neighborhood', 'distance']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
180,Write down the SOM learning in pseudo code.,226,"['1', 'initialize', 'small', 'random', 'weight', '2', 'draw', 'nah', 'sample', 'input', 'space', '3', 'similarity', 'matching', 'determine', 'winning', 'neuron', '4', 'update', 'weight', 'neuron', 'topological', 'neighborhood', '5', 'repeat', 'step', '24', 'random', 'exampledraw', 'wax', 'getminwin', 'getneighborhoodwmax', 'wi', 'wi', 'wietahy']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
181,Write down the SOM learning in pseudo code.,226,"['initialize', 'weight', 'randomly', 'create', 'term', 'decrease', 'learningrate', 'neighbourhood', 'function', 'respectively', 'calculate', 'ix', 'weight', 'closest', 'input', 'data', 'received', 'ix', 'neuron', 'win', 'competitive', 'process', 'neuron', 'neighbour', 'weight', 'updated', 'using', 'wnew', 'wold', 'learningrate', 'dot', 'hex', 'dot', 'ow', 'x', 'hex', 'neighbourhood', 'function', 'determines', 'neuron', 'updated', 'strong', 'changed', 'update', 'defined', 'using', 'distance', 'neuron', 'learningrate', 'updated', 'using', 'learningrate', 't1', 'also', 'neighbourhood', 'function', 'updated', 'way', 'using', 'learningrate', 'get', 'lower', '001', 'neighbourhood', 'function', 'get', 'low', 'winning', 'neuron', 'beginning', 'almost', 'every', 'neuron', 'updated', 'end', 'small', 'neighbourhood', 'neuron', 'updated']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
182,Write down the SOM learning in pseudo code.,226,"['iteration', 'winner', 'competitionbetweenneurons', 'neighbourhood', 'cooperationwithneighbourhoodfunctionwinner', 'updateweightsneighbourhood']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",1,2.0,neural_networks,neural_course,0.5
183,Write down the SOM learning in pseudo code.,226,"['given', 'map', 'layer', 'set', 'random', 'small', 'value', 'weight', 'input', 'map', 'layer', 'repeat', 'converged', 'find', 'best', 'match', 'input', 'value', 'weight', 'neuron', 'competitive', 'process', 'adapt', 'increase', 'weight', 'winning', 'neuron', 'neighborhood', 'gauss', 'function', 'neighborhood', 'size', 'cooperating', 'process', 'weight', 'adjustment', 'decrease', 'neighborhood', 'size']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
184,Write down the SOM learning in pseudo code.,226,[],"['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",0,2.0,neural_networks,neural_course,0.0
185,Write down the SOM learning in pseudo code.,226,"['initialize', 'weight', 'vector', 'hidden', 'neuron', 'dimension', 'data', 'number', 'hidden', 'neuron', 'significantly', 'greater', 'number', 'data', 'point', 'initialize', 'learning', 'rate', 'neighbouring', 'function', 'rate', 'change', 'weight', 'significant', 'every', 'datapoint', 'calculate', 'distance', 'neuron', 'data', 'select', 'winner', 'neuron', 'minimum', 'distance', 'maximum', 'similarity', 'error', 'distance', 'winner', 'form', 'datapoint', 'adjust', 'weight', 'neuron', 'rule', 'nherror']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
186,Write down the SOM learning in pseudo code.,226,"['randomly', 'minimize', 'weight', 'draw', 'sample', 'input', 'increase', 'weight', 'local', 'neighborhood', 'winning', 'neuron', 'repeat', 'process', 'process', 'till', 'one', 'winning', 'neuron']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",1,2.0,neural_networks,neural_course,0.5
187,Write down the SOM learning in pseudo code.,226,[],"['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",0,2.0,neural_networks,neural_course,0.0
188,Write down the SOM learning in pseudo code.,226,"['numofepochs', 'inputpoints', 'find', 'winning', 'neuron', 'find', 'neighbour', 'winning', 'neuron', 'within', 'distance', 'sigma', 'update', 'winning', 'neuron', 'neighbour', 'weight', 'update', 'sigma', 'learningrate', 'reduces', 'time']","['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",2,2.0,neural_networks,neural_course,1.0
189,Write down the SOM learning in pseudo code.,226,[],"['arrange', 'weight', 'required', 'topology', 'according', 'problem', 'initialize', 'weight', 'randomly', 'weight', 'different', 'sample', 'input', 'input', 'space', 'similarity', 'matching', 'match', 'input', 'neuron', 'topological', 'lattice', 'becomes', 'winning', 'neuron', 'update', 'weight', 'winning', 'neuron', 'neighbour', 'determined', 'neighbourhood', 'function', 'reduce', 'neighbourhood', 'decay', 'learning', 'rate', 'share', 'radius', 'ordering', 'convergence', 'complete', 'stop', 'else', 'continue', 'sampling', 'input', 'space']",0,2.0,neural_networks,neural_course,0.0
190,Give the basic idea of an SVM using the correct terminology!,227,"['support', 'vector', 'machine', 'maximum', 'margin', 'classifier', 'width', 'boundary', 'separation', 'maximized', 'margin', 'defined', 'width', 'boundary', 'hitting', 'point', 'maximum', 'margin', 'intuitively', 'feel', 'safe', 'experimentally', 'good']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
191,Give the basic idea of an SVM using the correct terminology!,227,"['basic', 'idea', 'sum', 'best', 'segregate', 'data', 'two', 'class', 'help', 'decision', 'boundary', 'decision', 'boundary', 'margin', 'always', 'try', 'maximize', 'margin', 'make', 'sure', 'data', 'classified', 'correctly']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
192,Give the basic idea of an SVM using the correct terminology!,227,"['support', 'vector', 'machine', 'goal', 'maximize', 'margin', 'closest', 'data', 'point', 'separating', 'hyperplane', 'separating', 'hyperplane', 'given', '0', 'wnxn', 'maximizing', 'margin', 'probability', 'classification', 'error', 'reduced']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
193,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'binary', 'linear', 'classifier', 'spanning', 'separating', 'hyperplane', 'two', 'class', 'datapoints', 'hyperplane', 'spanned', 'positive', 'negative', 'decision', 'boundary', 'supported', 'number', 'support', 'vector', 'support', 'vector', 'outermost', 'datapoints', 'span', 'hyperplane', 'training', 'distance', 'falsely', 'classified', 'data', 'point', 'correct', 'side', 'hyperplane', 'minimized', 'utilizing', 'quadratic', 'programming', 'formulation']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
194,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'binary', 'classifier', 'maximum', 'width', 'boundary', 'separating', 'two', 'class', 'us', 'support', 'vector', 'vector', 'push', 'boundary', 'equation', 'line', 'sum', 'wxb1for', 'class', '1', 'wxb1for', 'class', '1', 'width', 'boundary']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
195,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'binary', 'classifies', 'use', 'border', 'operate', 'data', 'border', 'typically', 'placed', 'largest', 'possible', 'distance', 'class', 'vector', 'border', 'touch', 'side', 'margin', 'support', 'vector']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
196,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'ann', 'supervised', 'learning', 'able', 'separate', 'two', 'class', 'datapoints', 'using', 'hyperlane', 'found', 'quadratic', 'programming', 'finding', 'biggest', 'margin', 'goal', 'classify', 'future', 'data', 'two', 'class']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
197,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'maximum', 'margin', 'classifier', 'used', 'binary', 'classify', 'datapoints', 'dichotomy', 'idea', 'find', 'line', 'nearly', 'separate', 'class', 'perfect', 'position', 'line', 'right', 'middle', 'class', 'find', 'linedescision', 'boundary', 'define', 'positive', 'negative', 'boundary', 'parallel', 'line', 'boundary', 'define', 'margin', 'class', 'idea', 'sum', 'datapoints', 'next', 'boundary', 'used', 'define', 'margin', 'called', 'support', 'vector', 'additional', 'every', 'problem', 'nearly', 'venerable', 'idea', 'transform', 'input', 'many', 'higher', 'dimension', 'using', 'kernel', 'function', 'discussed', 'kernel', 'function', 'polynomial', 'term', 'found', 'easy', 'computer']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
198,Give the basic idea of an SVM using the correct terminology!,227,"['support', 'vector', 'machine', 'type', 'learning', 'machine', 'try', 'classify', 'different', 'class', 'input', 'space', 'linear', 'separate', 'class', 'sum', 'try', 'calculate', 'line', 'separate', 'two', 'class', 'maximum', 'margin', 'support', 'vector', 'point', 'closer', 'margin', 'input', 'data', 'noisy', 'optimization', 'problem', 'two', 'aspect', 'maximum', 'margin', 'proper', 'classification', 'tradeoff', 'act', 'defined', 'tradeoff', 'calculated', 'sum', 'distance', 'misclassified', 'point', 'nonlinear', 'separate', 'class', 'kernel', 'defined', 'transform', 'input', 'data', 'higher', 'dimensional', 'space']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
199,Give the basic idea of an SVM using the correct terminology!,227,"['linear', 'sum', 'linear', 'border', 'line', 'classifier', 'separate', 'two', 'different', 'classespositive', 'negative', 'plane', 'calculate', 'distance', 'data', 'point', 'border', 'line', 'classifier', 'also', 'margin', 'defined', 'margin', 'maximized', 'touch', 'data', 'point', 'plane', 'data', 'point', 'margin', 'pushed', 'support', 'vector', 'error', 'wrongly', 'classified', 'datapoints', 'calculated', 'calculating', 'distance', 'data', 'point', 'correct', 'plane', 'sum', 'try', 'learn', 'classifier', 'margin', 'training', 'data']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
200,Give the basic idea of an SVM using the correct terminology!,227,"['support', 'vector', 'machine', 'classifies', 'using', 'support', 'vector', 'variable', 'dataset', 'variable', 'chosen', 'learning', 'algorithm', 'main', 'advantage', 'sum', 'overfishing', 'choosing', 'correct', 'margin', 'activation', 'function', 'linear', 'nonlinear', 'output', 'sum', 'always', 'true', 'false', 'given', 'variable']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
201,Give the basic idea of an SVM using the correct terminology!,227,"['support', 'vector', 'machine', 'type', 'neural', 'network', 'build', 'decision', 'boundary', 'around', 'class', 'margin', 'separation', 'class', 'maximized']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",0,2.0,neural_networks,neural_course,0.0
202,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'binary', 'classifier', 'learn', 'classification', 'memorizing', 'marginal', 'data', 'point', 'called', 'support', 'vector', 'make', 'decision', 'boundary', 'positive', 'negative']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
203,Give the basic idea of an SVM using the correct terminology!,227,"['abbreviation', 'sum', 'stand', 'support', 'vector', 'machine', 'sum', 'represent', 'feedforward', 'category', 'nna', 'sum', 'binary', 'learning', 'machine', 'whose', 'functionality', 'summarized', 'classification', 'problem', 'follows', 'given', 'training', 'sample', 'sum', 'construct', 'hyperplane', 'decision', 'surface', 'way', 'margin', 'separation', 'positive', 'negative', 'example', 'maximized', 'one', 'key', 'innovation', 'associated', 'sum', 'kernel', 'trick', 'kernel', 'trick', 'consists', 'observing', 'many', 'machine', 'learning', 'algorithm', 'written', 'exclusively', 'term', 'dot', 'product', 'example', 'allows', 'u', 'learn', 'model', 'nonlinear', 'function', 'using', 'convex', 'optimization', 'technique', 'guaranteed', 'converge', 'efficiently', 'besides', 'kernel', 'function', 'often', 'admits', 'implementation', 'significantly', 'computational', 'efficient', 'naively', 'constructing', 'two', 'vector', 'explicitly', 'taking', 'dot', 'product']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
204,Give the basic idea of an SVM using the correct terminology!,227,"['support', 'vector', 'machine', 'feedforward', 'network', 'hidden', 'layer', 'learn', 'task', 'supervised', 'learning', 'manner', 'network', 'try', 'construct', 'hyperplane', 'separate', 'data', 'point', 'two', 'different', 'class', 'maximizing', 'margin', 'separation', 'distance', 'hyperplane', 'closest', 'data', 'point', 'called', 'support', 'vector']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
205,Give the basic idea of an SVM using the correct terminology!,227,"['given', 'dataset', 'support', 'vector', 'machine', 'build', 'hyperplane', 'way', 'positive', 'negative', 'sample', 'separated', 'maximum', 'distance', 'width', 'margin', 'maximum', 'vector', 'marginsmargin', 'positive', 'negative', 'sample', 'pushed', 'called', 'support', 'vector']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
206,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'stand', 'support', 'vector', 'machine', 'creates', 'hyperplane', 'margin', 'separation', 'positive', 'negative', 'class', 'maximise']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
207,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'linear', 'machine', 'whose', 'goal', 'construct', 'optimal', 'hyperplane', 'marginal', 'separation', 'maximum', 'decision', 'boundary', 'decision', 'boundary', 'drawn', 'parallel', 'hyperplane', 'push', 'datapoints', 'closest', 'hyperplane', 'datapoints', 'closer', 'hyperplane', 'called', 'support', 'vector']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
208,Give the basic idea of an SVM using the correct terminology!,227,"['idea', 'sum', 'fit', 'supervised', 'model', 'onto', 'training', 'data', 'allowing', 'maximum', 'generalization', 'ability', 'done', 'computing', 'maximum', 'margin', 'different', 'class', 'data', 'using', 'support', 'vector', 'margin', 'computed', 'using', 'different', 'kernel', 'higher', 'dimensional', 'data']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
209,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'linear', 'machine', 'used', 'pattern', 'classification', 'problem', 'find', 'decision', 'surface', 'form', 'hyperplane', 'nearly', 'separate', 'class', 'margin', 'separation', 'class', 'large', 'possible', 'sam', 'approximate', 'implementation', 'induction', 'principle', 'structural', 'risk', 'minimization', 'based', 'fact', 'error', 'rate', 'testing', 'bounded', 'term', 'dependent', 'upon', 'sum', 'training', 'error', 'rate', 'dimension']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
210,Give the basic idea of an SVM using the correct terminology!,227,"['basic', 'idea', 'sum', 'determine', 'best', 'decision', 'boundary', 'idea', 'one', 'provides', 'maximum', 'margin', 'boundary', 'widened', 'touch', 'datapoint', 'done', 'using', 'support', 'vector', 'datapoints', 'margin', 'push']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
211,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'refers', 'support', 'vector', 'machinesin', 'term', 'linear', 'classification', 'problem', 'sum', 'defined', 'creating', 'hyper', 'plane', 'decision', 'surface', 'maximize', 'width', 'decision', 'boundaryin', 'case', 'problem', 'complex', 'sum', 'used', 'classifies', 'data', 'projecting', 'data', 'higher', 'dimensionif', 'data', 'separated', '3', 'class', 'use', '3', 'sam', 'three', 'different', 'class']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
212,Give the basic idea of an SVM using the correct terminology!,227,"['basic', 'idea', 'sum', 'construct', 'hyperplane', 'decision', 'surface', 'way', 'margin', 'separation', 'negative', 'example', 'positive', 'example', 'maximized']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
213,Give the basic idea of an SVM using the correct terminology!,227,"['idea', 'sum', 'construct', 'hyperplane', 'decision', 'surface', 'margin', 'separation', 'positive', 'negative', 'example', 'maximized']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
214,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'try', 'find', 'best', 'hyperplane', 'widest', 'margin', 'help', 'support', 'vector', 'data', 'point', 'classified', 'correctly']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
215,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'used', 'nearly', 'separate', 'data', 'hyperplane', 'used', 'separate', 'data', 'could', 'many', 'hyperplanes', 'separate', 'data', 'best', 'hyperplane', 'choose', 'separate', 'data', 'bigger', 'margin', 'sum', 'find', 'hyperplane', 'bigger', 'margin', 'hyperplane', 'positive', 'negative', 'data', 'line']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
216,Give the basic idea of an SVM using the correct terminology!,227,"['given', 'training', 'set', 'classification', 'basic', 'idea', 'sum', 'construct', 'hyperplane', 'decision', 'boundary', 'way', 'margin', 'positive', 'negative', 'point', 'maximum', 'support', 'vector', 'small', 'subset', 'training', 'data', 'boundary', 'pushed']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
217,Give the basic idea of an SVM using the correct terminology!,227,"['support', 'vector', 'machine', 'classifies', 'given', 'data', 'using', 'decision', 'boundary', 'width', 'decision', 'boundary', 'margin', 'maximized', 'ensure', 'good', 'result', 'maximized', 'width', 'robust', 'possible', 'margin', 'width', 'frac2sqrtw', 'w', 'maximize', 'quadratic', 'programming', 'used', 'order', 'handle', 'noisy', 'data', 'slack', 'variable', 'introduced', 'eliminate', 'duality', 'used']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
218,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'linear', 'classifier', 'divide', 'binary', 'pattern', 'line', 'maximizes', 'margin', 'line', 'respective', 'support', 'vector']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
219,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'learns', 'decision', 'boundary', 'input', 'data', 'additional', 'learns', 'two', 'margin', 'parallel', 'decision', 'boundary', 'lie', 'close', 'possible', 'data', 'point', 'support', 'vector', 'decision', 'boundary', 'chosen', 'margin', 'maximized', 'using', 'kernel', 'function', 'higher', 'dimensional', 'data', 'non', 'nearly', 'separate', 'data', 'learned', 'swell']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
220,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'learning', 'machine', 'try', 'learn', 'support', 'vector', 'two', 'class', 'data', 'set', 'get', 'maximum', 'margin', 'optimal', 'separating', 'hyperplane', 'two', 'class']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
221,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'us', 'data', 'point', 'support', 'vector', 'build', 'maximum', 'margin', 'classifier', 'search', 'separating', 'line', 'maximum', 'margin', 'datapoints', 'case', 'noise', 'separating', 'line', 'searched', 'minimizes', 'distance', 'point', 'wrong', 'category', 'data', 'cast', 'higher', 'dimensional', 'space', 'use', 'cover', 'theorem', 'using', 'kernel', 'data', 'likely', 'nearly', 'venerable', 'higher', 'dimensional', 'feature', 'space', 'using', 'structural', 'risk', 'minimization', 'dimensionality', 'reduced']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
222,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'used', 'nearly', 'separate', 'data', 'point', 'decision', 'boundary', 'line', 'hyperplane', 'higher', 'dimension', 'defines', 'able', 'data', 'point', 'decon', 'boundary', 'choose', 'way', 'margin', 'maximized', 'data', 'point', 'decon', 'boundary', 'called', 'support', 'vector', 'define', 'hyperplane', '2', 'dimension', 'data', 'liner', 'venerable', 'margin', 'equal', '2sqrtww', 'weight', 'vector', 'data', 'linear', 'seperable', 'input', 'projected', 'higher', 'dimension', 'space', 'increase', 'chance', 'linear', 'seperablity']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
223,Give the basic idea of an SVM using the correct terminology!,227,"['support', 'vector', 'machine', 'classifier', 'maximizes', 'margin', 'boundary', 'learned', 'two', 'class', 'margin', 'minimum', 'distance', 'boundary', 'increased', 'hitting', 'datapoints', 'support', 'vector', 'datapoints', 'main', 'push', 'boundary']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
224,Give the basic idea of an SVM using the correct terminology!,227,"['support', 'vector', 'machine', 'finding', 'classfiers', 'draw', 'vision', 'boundary', 'push', 'support', 'vector']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
225,Give the basic idea of an SVM using the correct terminology!,227,"['basic', 'idea', 'support', 'vector', 'machine', 'svm', 'find', 'width', 'line', 'hyperplane', 'divide', 'input', 'data', 'two', 'class', 'point', 'lying', 'edge', 'defined', 'width', 'called', 'support', 'vector']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
226,Give the basic idea of an SVM using the correct terminology!,227,"['sum', 'classifier', 'classifies', 'set', 'point', 'way', 'maximizes', 'margin', 'point', 'two', 'class', 'classification', 'linear', 'non', 'linear']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",1,2.0,neural_networks,neural_course,0.5
227,Give the basic idea of an SVM using the correct terminology!,227,"['idea', 'behing', 'sum', 'find', 'hyperplane', 'separate', 'data', 'class', 'first', 'required', 'find', 'data', 'point', 'closest', 'hyperplane', 'data', 'point', 'called', 'support', 'vector', 'next', 'task', 'find', 'maximum', 'possible', 'width', 'hyperplain', 'support', 'vector', 'edge', 'hyperplane', 'problem', 'formulated', 'minimal', 'constrained', 'optimization', 'problem', 'order', 'find', 'optimum', 'width', 'hyperplane', 'optimimum', 'function', 'idea', 'use', 'method', 'language', 'multiplied', 'additionally', 'data', 'nearly', 'separable', 'approach', 'project', 'data', 'higher', 'dimension', 'find', 'hyperplane', 'separate', 'data', 'dimension']","['sum', 'linear', 'bearable', 'machine', 'simplest', 'case', 'us', 'decision', 'boundary', 'maximum', 'margin', 'classify', 'data', 'different', 'class', 'data', 'point', 'near', 'decision', 'boundary', 'called', 'support', 'vector', 'margin', 'determined', 'based', 'point', 'kernel', 'used', 'separate', 'nonlinearly', 'separate', 'data', 'algorithm', 'solved', 'using', 'quadratic', 'programming']",2,2.0,neural_networks,neural_course,1.0
228, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'gradient', 'cost', 'function', 'found', 'partially', 'differentiating', 'respect', 'weight', 'weight', 'updated', 'opposite', 'direction', 'gradient', 'ensures', 'weight', 'move', 'steepest', 'direction', 'reduced', 'also', 'proven', 'weight', 'always', 'reduce', 'hence', 'steepest', 'descent', 'used', 'minimize', 'cost', 'function']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
229, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'method', 'optimizing', 'algorithm', 'minimizing', 'error', 'weight', 'adjusted', 'direction', 'sleeping', 'descent', 'opposite', 'direction', 'gradient']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",1,2.0,neural_networks,neural_course,0.5
230, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'move', 'error', 'within', 'error', 'surface', 'small', 'step', 'opposite', 'direction', 'gradient', 'help', 'steepest', 'descent', 'want', 'minimize', 'error', 'steepest', 'descent', 'stop', 'gradient', '0']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
231, What role does the method of steepest decent have when learning a network?,228,"['learning', 'weight', 'method', 'try', 'reduce', 'error', 'based', 'following', 'gradient', 'error', 'function', 'opposite', 'direction', 'effectively', 'trailing', 'error', 'surface', 'towards', 'minimum', 'error', 'function', 'typically', 'form', 'mean', 'squared', 'error', 'differentiated', 'wrt', 'individual', 'weight', 'expressing', 'much', 'weight', 'contributes', 'network', 'error', 'must', 'thus', 'corrected', 'due', 'gradient', 'pointing', 'direction', 'steepest', 'ascent', 'must', 'thus', 'step', 'negative', 'direction']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
232, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'used', 'error', 'minimization', 'updating', 'weight', 'according', 'update', 'weight', 'along', 'direction', 'minimizes', 'error', 'calculated', 'finding', 'slope', 'point']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",1,2.0,neural_networks,neural_course,0.5
233, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'decent', 'used', 'minimize', 'training', 'error', 'network', 'given', 'sample', 'input', 'desired', 'output', 'us', 'gradient', 'error', 'function', 'move', 'weight', 'closer', 'optimal', 'weight', 'lowest', 'output', 'error', 'using', 'learning', 'rate', 'influence', 'speed', 'stability', 'algorithm']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
234, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'decent', 'direction', 'error', 'function', 'fall', 'want', 'change', 'weight', 'direction', 'steepest', 'decent', 'opposite', 'direction', 'gradient', 'smaller', 'error', 'next', 'iteration', 'optimize', 'anna']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
235, What role does the method of steepest decent have when learning a network?,228,"['idea', 'learning', 'network', 'minimize', 'certain', 'costfunction', 'use', 'steepest', 'descent', 'minimize', 'cost', 'function', 'optimization', 'technique', 'used', 'optimization', 'steepest', 'decent', 'widely', 'used', 'optimization', 'technique', 'optimize', 'network', 'calculate', 'partial', 'derivativesgradient', 'use', 'update', 'weight', 'also', 'used']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
236, What role does the method of steepest decent have when learning a network?,228,"['approach', 'method', 'steepest', 'descent', 'find', 'direction', 'minimization', 'error', 'approximation', 'problem', 'cost', 'function', 'e', 'dependent', 'weight', 'dedicated', 'partial', 'derivative', 'defined', 'weight', 'gradient', 'used', 'updating', 'weight', 'next', 'iteration', 'direction', 'minimization', 'error', 'opposite', 'direction', 'gradient', 'go']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
237, What role does the method of steepest decent have when learning a network?,228,"['input', 'send', 'network', 'calculate', 'error', 'need', 'mechanism', 'learn', 'manipulate', 'free', 'parameter', 'network', 'learning', 'us', 'error', 'must', 'know', 'direction', 'searchoptimization', 'space', 'move', 'reach', 'global', 'minimal', 'error', 'use', 'steepest', 'decent', 'method', 'tell', 'u', 'direction', 'need', 'move', 'getting', 'gradient', 'error']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
238, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'method', 'weight', 'adaptation', 'using', 'first', 'order', 'derivative', 'approximate', 'function', 'therefore', 'rather', 'slow']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",1,2.0,neural_networks,neural_course,0.5
239, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'constrained', 'optimization', 'method', 'seek', 'minimize', 'error', 'function', 'function', 'iteratively', 'changed', 'direction', 'opposite', 'gradient', 'vector']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",1,2.0,neural_networks,neural_course,0.5
240, What role does the method of steepest decent have when learning a network?,228,"['method', 'steepest', 'descent', 'update', 'weight', 'direction', 'error', 'minimum']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",1,2.0,neural_networks,neural_course,0.5
241, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'method', 'algorithm', 'finding', 'nearest', 'local', 'minimum', 'function', 'presupposes', 'gradient', 'function', 'computed', 'property', 'used', 'determine', 'optimal', 'weight', 'nna']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
242, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'used', 'update', 'synaptic', 'weight', 'network', 'based', 'cost', 'function', 'expressed', 'error', 'output', 'weight', 'adjusted', 'direction', 'opposite', 'gradient', 'cost', 'function']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
243, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'adjustment', 'done', 'weight', 'vector', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'descent', 'learning', 'problem', 'basically', 'used', 'reduce', 'cost', 'based', 'weight', 'main', 'goal', 'find', 'optimal', 'weight']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
244, What role does the method of steepest decent have when learning a network?,228,"['method', 'steepest', 'decent', 'constrained', 'optimization', 'technique', 'used', 'learning', 'network', 'used', 'operative', 'manner', 'minimize', 'error', 'supervised', 'learning', 'find', 'direction', 'maximum', 'gradient', 'go', 'opposite', 'direction', 'hoping', 'find', 'minimal', 'convergence', 'algorithm', 'depends', 'learning', 'rate', 'also', 'condition', 'doesnt', 'get', 'stuck', 'local', 'minimal']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
245, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'method', 'network', 'move', 'towards', 'direction', 'maximum', 'gradient', 'learning', 'steepest', 'descent', 'method', 'slow', 'converge', 'exhibit', 'zigzag', 'behavior']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
246, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'involves', 'weight', 'updating', 'direction', 'maximum', 'steep', 'maximum', 'decrease', 'cost', 'function', 'ot', 'direction', 'opposite', 'gradient', 'function', 'weight', 'update', 'delta', 'want', 'beta', 'gn', 'eta', 'learning', 'rate', 'defines', 'magnitude', 'learning', 'using', 'gradient', 'gone', 'gradient', 'cost', 'function', 'error', 'nah', 'iteration', 'higher', 'eta', 'result', 'rapid', 'learning', 'oscillation', 'response']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
247, What role does the method of steepest decent have when learning a network?,228,"['method', 'steepest', 'descent', 'used', 'find', 'direction', 'error', 'function', 'viewed', 'function', 'weight', 'decreasing', 'rapidly', 'take', 'small', 'step', 'direction', 'learning', 'network', 'steepest', 'descent', 'enables', 'iteratively', 'adjust', 'weight', 'vector', 'optimal', 'weight', 'vector', 'minimise', 'cost', 'function', 'ie', 'error', 'function', 'error', 'computed', 'difference', 'desired', 'actual', 'response', 'network', 'found']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
248, What role does the method of steepest decent have when learning a network?,228,"['learning', 'network', 'steepest', 'descent', 'algorithm', 'update', 'weight', 'way', 'error', 'decrease', 'every', 'iteration']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",1,2.0,neural_networks,neural_course,0.5
249, What role does the method of steepest decent have when learning a network?,228,"['method', 'steepest', 'descent', 'move', 'direction', 'opposite', 'gradient', 'minimize', 'cost', 'function']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
250, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'decent', 'method', 'based', 'minimization', 'error', 'cost', 'function', 'xiw', '05', 'e2kn', 'synaptic', 'weight', 'network', 'updated', 'direction', 'opposite', 'gradient', 'vector', 'xiw', 'wkn1', 'wkn', 'beta', 'unable', 'xiw', 'wkn', 'beta', 'eking', 'xn', 'beta', 'learning', 'rateekn', 'neuron', 'error', 'signal', 'xjn', 'input', 'data']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
251, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'used', 'find', 'direction', 'e', 'decreasing', 'rapidly', 'adjustment', 'applied', 'weight', 'direction', 'steepest', 'descent']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
252, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'decent', 'help', 'minimize', 'value', 'error', 'function', 'e', 'finding', 'right', 'direction', 'move', 'weight', 'vector', 'reach', 'global', 'minimal', 'direction', 'always', 'opposite', 'direction', 'actual', 'gradient', 'vector']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
253, What role does the method of steepest decent have when learning a network?,228,"['method', 'steepest', 'descent', 'used', 'reduce', 'error', 'backpropogation', 'backward', 'pas', 'need', 'know', 'much', 'amount', 'weight', 'changed', 'known', 'use', 'steepest', 'descent', 'find', 'gradient', 'error', 'use', 'reduce', 'error']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
254, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'find', 'direction', 'error', 'function', 'try', 'reduce', 'adding', 'opposite', 'direction', 'del', 'beta', 'gn', 'gn', 'gradient', 'cost', 'function']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
255, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'used', 'find', 'right', 'direction', 'weight', 'changed', 'learning', 'network', 'private', 'error', 'used', 'weight', 'changed', 'direction', 'make', 'error', 'smaller', 'fast', 'possible']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
256, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'used', 'optimize', 'weight', 'network', 'steepest', 'descent', 'error', 'function', 'function', 'weight', 'determine', 'direction', 'steepest', 'descent', 'error', 'surface', 'go', 'direction', 'minimize', 'error', 'weight', 'optimize']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",1,2.0,neural_networks,neural_course,0.5
257, What role does the method of steepest decent have when learning a network?,228,"['method', 'steepest', 'descent', 'used', 'minimize', 'error', 'function', 'error', 'function', 'gradient', 'error', 'delta', 'e', 'desired', 'output', 'actual', 'output', 'neuron']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
258, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'basic', 'learning', 'algorithm', 'others', 'derived', 'goal', 'learning', 'network', 'minimize', 'error', 'achieved', 'starting', 'random', 'position', 'going', 'opposite', 'direction', 'gradient', 'vector', 'steepest', 'descent']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
259, What role does the method of steepest decent have when learning a network?,228,"['error', 'function', 'computer', 'adapt', 'weight', 'learn', 'network', 'error', 'function', 'followed', 'small', 'step', 'direction', 'steepest', 'descent', 'decrease', 'error', 'using', 'iteration', 'error', 'decreased', 'step', 'end', 'local', 'minimum', 'used', 'backpropagation']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",1,2.0,neural_networks,neural_course,0.5
260, What role does the method of steepest decent have when learning a network?,228,"['error', 'correction', 'learning', 'weight', 'network', 'learned', 'way', 'ex', 'minimized', 'ex', 'error', 'function', 'order', 'minimize', 'error', 'function', 'method', 'steepest', 'defend', 'used', 'negative', 'gradient', 'ex', 'point', 'direction', 'steepest', 'defend', 'steepest', 'descend', 'single', 'layer', 'feed', 'forward', 'network', 'lead', 'delta', 'rule']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
261, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'descent', 'adjust', 'parameter', 'weight', 'bias', 'minimize', 'error', 'adjusting', 'weight', 'direction', 'steepest', 'descent', 'error', 'function']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",1,2.0,neural_networks,neural_course,0.5
262, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'decent', 'move', 'direction', 'max', 'improvement', 'term', 'decreasing', 'cost', 'function', 'error', 'learning', 'rate', 'large', 'follows', 'zigzag', 'motion', 'learning', 'rate', 'low', 'take', 'time', 'converging']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",1,2.0,neural_networks,neural_course,0.5
263, What role does the method of steepest decent have when learning a network?,228,"['method', 'steepest', 'descent', 'responsible', 'weight', 'adjustment', 'network', 'weight', 'adjusted', 'direction', 'steepest', 'descent', 'equal', 'negative', 'grad', 'error', 'ensures', 'weight', 'decreased', 'every', 'iteration', 'step']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
264, What role does the method of steepest decent have when learning a network?,228,"['steepest', 'decent', 'method', 'help', 'making', 'adjustment', 'weight', 'neural', 'network', 'way', 'minimizes', 'average', 'squared', 'error', 'step', 'give', 'direction', 'towards', 'maximum', 'decrease', 'average', 'squared', 'error', 'achieved']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",1,2.0,neural_networks,neural_course,0.5
265, What role does the method of steepest decent have when learning a network?,228,"['method', 'steepest', 'decent', 'used', 'finding', 'minimum', 'costerror', 'function', 'steepest', 'decent', 'operates', 'possible', 'value', 'weight', 'vector', 'optimize', 'function', 'used', 'deriving', 'error', 'function', 'adalind', 'adaptive', 'linear', 'element', 'algorithm', 'used', 'also', 'backpropagation', 'method', 'training', 'multiplayer', 'nose']","['steepest', 'descent', 'used', 'update', 'weight', 'learning', 'phase', 'help', 'navigate', 'cost', 'function', 'find', 'parameter', 'cost', 'minimum', 'weight', 'updated', 'direction', 'steepest', 'descent', 'direction', 'opposite', 'gradient', 'vector', 'method', 'could', 'suffer', 'local', 'minimal', 'may', 'become', 'unstable']",2,2.0,neural_networks,neural_course,1.0
266,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['dataset', 'subseteq', 'datapoints', '2n', 'binary', 'map', 'binary', 'map', 'hypothesis', 'oh', 'split', 'positive', 'data', 'negative', 'data', 'training', 'error', 'said', 'shatters', 'dataset']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
267,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,[],"['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",0,2.0,neural_networks,neural_course,0.0
268,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['hypothesis', 'oh', 'shatters', 'dataset', 'subseteq', 'leftrightarrow', 'ldots', 'exists', 'alpha', 'every', 'training', 'set', 'zero', 'training', 'error']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",1,2.0,neural_networks,neural_course,0.5
269,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['learned', 'machine', 'achieves', 'zero', 'training', 'error', 'every', 'classification', 'problem', 'dataset', 'since', 'got', 'selection', 'point', 'dataset', 'number', 'problem', 'binary', 'classification', '2', 'power', 'didnt', 'find', 'dacha', 'symbol', 'english', 'keyboard']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
270,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['considering', 'dataset', 'subseteq', 'xu', 'instance', 'space', 'contains', 'element', '2n', 'binary', 'map', 'learning', 'problem', 'separate', 'two', 'class', 'problem', 'separated', 'completely', 'hypothesis', 'oh', 'said', 'shatter', 'ie', 'hypothesis', 'shatters', 'dataset', 'completely', 'separate', 'class', 'zero', 'error', 'possible', 'combination', 'label', 'dataset']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
271,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['every', 'possible', 'combination', 'input', 'desired', 'output', 'classified', 'using']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",1,2.0,neural_networks,neural_course,0.5
272,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['hypothesis', 'oh', 'shatters', 'dataset', 'subseteq', 'xu', 'every', 'point', 'xi', 'label', 'yi', '11', 'separate', 'two', 'class', 'using', 'training', 'error']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
273,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['exists', 'arrangement', 'point', 'possible', 'combination', 'label', 'point', 'hypothesis', 'zero', 'training', 'error']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",0,2.0,neural_networks,neural_course,0.0
274,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['hypothesis', 'shatters', 'dataset', 'given', 'data', 'set', 'able', 'distinguish', 'separate', 'different', 'class', 'data', 'set']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
275,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['shatters', 'set', 'input', 'data', 'point', 'exist', 'least', 'one', 'training', 'error', 'zero']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
276,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['shatters', 'example', 'given', 'dataset', 'x1x2xr', 'output', 'form', 'x1', 'y1x2y2xryr', 'found', '0', 'error']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
277,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['machine', 'shatter', 'set', 'point', 'x1', 'xu', 'x3', 'every', 'training', 'set', 'weight', 'vector', 'alpha', 'produce', 'zero', 'training', 'error']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
278,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['hypothesis', 'oh', 'shatters', 'dataset', 'subset', 'leftrightarrow', 'assignable', 'configuration', 'xi', 'yinlin', 'perfectly', 'classifies', 'element', 'set']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
279,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,[],"['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",0,2.0,neural_networks,neural_course,0.0
280,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['hypothesis', 'oh', 'shatters', 'dataset', 'subseteq', 'leftrightarrow', 'least', 'possible', 'combination', 'dataset', 'classified', 'hypothesis', 'oh', 'zero', 'training', 'error']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",0,2.0,neural_networks,neural_course,0.0
281,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['given', 'dataset', 'subseteq', 'instant', 'data', 'space', 'given', 'problem', 'dataset', 'learning', 'machine', 'able', 'successfully', 'split', 'positive', 'negative', 'data', 'say', 'shattered', 'learning', 'machine']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
282,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['suppose', 'training', 'dataset', 'subset', 'training', 'dataset', 'hypothesis', 'said', 'shatter', 'correctly', 'classify', 'point', 'ice', 'zero', 'training', 'error']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
283,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['hypothesis', 'oh', 'shatters', 'dataset', 'subseteq', 'leftrightarrow', 'ldots', 'hypothesis', 'clearly', 'distinguish', 'positive', 'example', 'negative', 'example']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",1,2.0,neural_networks,neural_course,0.5
284,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['hypothesis', 'model', 'separate', 'dataset', 'consisting', 'taxi', 'ying', 'sample', 'positive', 'negative', 'sample', 'said', 'shatter', 'given', 'subset', 'dataset', 'successfully', 'separate', 'least', 'one', 'configuration', 'subset', 'dataset']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",0,2.0,neural_networks,neural_course,0.0
285,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['hypothesis', 'oh', 'shatters', 'dataset', 'subseteq', 'exists', 'alpha', 'zero', 'training', 'error']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
286,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['2n', 'size', 'combination', 'input', 'output', 'mapping', 'form', 'xi', 'yi', 'able', 'classify', 'data', 'correctly', 'zero', 'error']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
287,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,[],"['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",0,2.0,neural_networks,neural_course,0.0
288,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['possible', 'binary', 'labeling', 'dataset', 'find', 'hypothesis', 'separate', 'positive', 'example', 'negative', 'example', 'shatters']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
289,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['hypothesis', 'shatter', 'point', 'x1', 'x2', 'xn', 'every', 'possible', 'training', 'set', 'form', 'x1', 'y1', 'x2', 'y2', 'xn', 'yn', 'exist', 'value', 'alpha', 'get', 'zero', 'training', 'error']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
290,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['hypothesis', 'space', 'shatters', 'dataset', 'possbile', 'alpha', 'weight', 'vector', 'hypothesis', 'space', 'seperates', 'positive', 'data', 'negative', 'data']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",1,2.0,neural_networks,neural_course,0.5
291,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['hypothesis', 'oh', 'shatters', 'subseteq', 'xu', 'exists', 'value', 'alpha', 'training', 'error', 'zero']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",1,2.0,neural_networks,neural_course,0.5
292,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['dimension', 'learning', 'machine', 'shatter', 'point', 'dimension', 'learning', 'machine', 'maximum', 'number', 'point', 'arranged', 'learning', 'machine', 'shatter', 'shattering', 'learning', 'machine', 'said', 'shatter', 'point', 'x1', 'xray', 'possible', 'training', 'set', 'x1y1', 'xryr', 'classified', 'zero', 'training', 'error']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
293,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['hypothesis', 'shatters', 'dataset', 'correctly', 'classify', 'combination', 'labelling', 'point', 'dataset']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
294,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['exists', 'configuration', 'x', 'get', 'zero', 'training', 'error', 'dichotomy', 'datapoints']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",0,2.0,neural_networks,neural_course,0.0
295,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['exist', 'weight', 'produce', 'perfect', 'classification']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",0,2.0,neural_networks,neural_course,0.0
296,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['possible', 'classified', 'subset', 'dataset', 'hypothesis', 'separate']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
297,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['combination', 'position', 'labeling', 'data', 'separated', 'given', 'class', 'hypothesis']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
298,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['shatters', 'possibility', 'a1', 'y1', 'a2', 'y2', 'yn', 'class', 'able', '1', 'exists', 'alpha', 'learning', 'machine', 'produce', '0', 'training', 'error']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
299,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['exist', 'atleast', 'one', 'configuration', 'training', 'error', 'zero', 'idea', 'successfully', 'classifies', 'point']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",0,2.0,neural_networks,neural_course,0.0
300,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['exist', 'linear', 'saperater', 'separate', 'positive', 'example', 'negative', 'example', 'correctly', 'say', 'shatter']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
301,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['given', 'data', 'set', 'possible', 'find', 'hypothesis', 'separate', 'data', 'set', 'binary', 'form', 'without', 'error', 'say', 'hypothesis', 'oh', 'shatters', 'dataaet', 'subseteq', 'leftrightarrow', 'ldots']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
302,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['mean', 'point', 'input', 'output', 'pair', 'xy', 'combination', 'xiyi', 'exist', 'parameter', 'alpha', 'enables', 'classify', 'point', 'zero', 'error']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",2,2.0,neural_networks,neural_course,1.0
303,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"['say', 'hypothesis', 'shatters', 'dataset', 'iff', 'produce', 'zero', 'training', 'error', 'certain', 'data', 'set', 'word', 'say', 'hypothesis', 'shatters', 'dataset', 'separate', 'data', 'two', 'class', 'without', 'error']","['possible', 'binary', 'labeling', 'every', 'data', 'hypothesis', 'split', 'positive', 'data', 'negative', 'data', 'error', 'mean', 'hypothesis', 'shatters', 'dataset']",0,2.0,neural_networks,neural_course,0.0
304,Write down and explain the Widrow-Hoff learning rule!,230,"['delta', 'beta', 'enxn', 'eta', 'learning', 'rate', 'widrowhoff', 'rule', 'state', 'change', 'weight', 'proportional', 'product', 'error', 'input', 'corresponding', 'synapsis']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
305,Write down and explain the Widrow-Hoff learning rule!,230,"['weight', 'adjusted', 'proportional', 'product', 'error', 'signal', 'input', 'vector', 'win', 'want', 'etadyxn', 'eta', 'learning', 'rate', 'desired', 'output', 'current', 'output', 'xena', 'input', 'vector']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
306,Write down and explain the Widrow-Hoff learning rule!,230,"['adoption', 'weight', 'proportional', 'product', 'input', 'error', 'wnew', 'wold', 'xie']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",1,2.0,neural_networks,neural_course,0.5
307,Write down and explain the Widrow-Hoff learning rule!,230,"['neuron', 'linear', 'activation', 'function', 'adaline', 'wt1wtalpha', 'dyx', 'input', 'pattern', 'true', 'value', 'net', 'output', 'notice', 'delta', 'rule', 'look', 'similar', 'perception', 'learning', 'rule', 'derived', 'whereas', 'perception', 'work', 'step', 'function', 'fully', 'differentiable']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
308,Write down and explain the Widrow-Hoff learning rule!,230,"['widrowhoff', 'learning', 'rule', 'also', 'known', 'error', 'correction', 'rule', 'used', 'update', 'weight', 'delta', 'beta', 'diyixi', 'desired', 'output', 'output', 'network', 'generates', 'input']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",1,2.0,neural_networks,neural_course,0.5
309,Write down and explain the Widrow-Hoff learning rule!,230,"['wn1', 'want', 'mu', 'dn', 'ynxn', 'change', 'weight', 'determined', 'using', 'error', 'dn', 'yn', 'input', 'given', 'network', 'learning', 'rate', 'improve', 'leaving', 'speed', 'new', 'weight', 'dependent', 'old', 'one', 'change', 'calculated']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",1,2.0,neural_networks,neural_course,0.5
310,Write down and explain the Widrow-Hoff learning rule!,230,"['wijn', 'wijn1', 'learningratedjyjxi', 'change', 'weight', 'computing', 'error', 'deja', 'djyj', 'input', 'multiply', 'learningrate', 'exit', 'adding', 'old', 'weight', 'minimise', 'squared', 'error', 'function', 'cost', 'function', 'online', 'variant', 'steepest', 'decent', 'method']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
311,Write down and explain the Widrow-Hoff learning rule!,230,"['delta', 'want', 'beta', 'enwn', 'end', 'yd', 'widow', 'learning', 'rule', 'error', 'correction', 'learning', 'used', 'train', 'network', 'supervised', 'manner', 'widow', 'learning', 'rule', 'derived', 'gradient', 'decent', 'rule', 'consists', 'error', 'end', 'neuron', 'multiplied', 'weight', 'impact', 'weight', 'error', 'incorporated', 'update', 'learning', 'rule', 'use', 'adjustment', 'much', 'trust', 'weight', 'change', 'error', 'calculate', 'difference', 'current', 'expected', 'output']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
312,Write down and explain the Widrow-Hoff learning rule!,230,"['widrowhoff', 'learning', 'rule', 'defined', 'want', 'beta', 'xena', 'en', 'widrowhoff', 'learning', 'rule', 'rule', 'adjusting', 'weight', 'error', 'correction', 'learning', 'task', 'learning', 'rule', 'derived', 'steepest', 'descent', 'method', 'direction', 'minimization', 'error', 'defined', 'opposite', 'direction', 'cost', 'function', 'gradient', 'gradient', 'simplified', 'xn', 'en', 'end', 'defined', 'difference', 'desired', 'response', 'actual', 'response', 'learning', 'machine', 'nn', 'en', 'done', 'yn', 'eta', 'defines', 'learning', 'rate', 'used']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
313,Write down and explain the Widrow-Hoff learning rule!,230,[],"['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",0,2.0,neural_networks,neural_course,0.0
314,Write down and explain the Widrow-Hoff learning rule!,230,"['windrowhoff', 'rule', 'wnewxinputwolddoutputyoutputetaa', 'wnewnew', 'weightwoldold', 'weightdoutputdesired', 'outputyoutputactual', 'outputxinputinput', 'etalearning', 'rate', 'learning', 'constant']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",0,2.0,neural_networks,neural_course,0.0
315,Write down and explain the Widrow-Hoff learning rule!,230,"['widrowholf', 'delta', 'rule', 'gradient', 'descent', 'learning', 'rule', 'used', 'adapt', 'weight', 'perception', 'delta', 'want', 'etadn', 'ynxn', 'delta', 'want', 'beta', 'enxn']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",1,2.0,neural_networks,neural_course,0.5
316,Write down and explain the Widrow-Hoff learning rule!,230,"['widrowhoff', 'delta', 'learning', 'rule', 'given', 'wn1', 'want', 'beta', 'xena', 'en', 'en', 'error', 'vector', 'eta', 'learning', 'parameter', 'xn', 'input', 'vector']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",1,2.0,neural_networks,neural_course,0.5
317,Write down and explain the Widrow-Hoff learning rule!,230,"['widrowhoff', 'learning', 'rule', 'also', 'referred', 'delta', 'least', 'mean', 'square', 'alms', 'rule', 'used', 'minimize', 'cost', 'function', 'defined', 'follows', 'delta', 'wjin', 'eta', 'partial', 'xing', 'partial', 'wjin', 'eta', 'learning', 'rate', 'parameter', 'xing', 'total', 'instantaneous', 'error', 'energy', 'weight']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",1,2.0,neural_networks,neural_course,0.5
318,Write down and explain the Widrow-Hoff learning rule!,230,"['widrowhoff', 'learning', 'rule', 'also', 'called', 'delta', 'rule', 'used', 'learning', 'network', 'adjusting', 'synaptic', 'weight', 'network', 'error', 'signal', 'wn1', 'want', 'beta', 'dn', 'yn', 'xena', 'number', 'iteration', 'eta', 'learning', 'rate', 'dn', 'desired', 'output', 'signal', 'yn', 'actual', 'output', 'signal', 'xn', 'input', 'signal', 'dn', 'yn', 'error', 'signal']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
319,Write down and explain the Widrow-Hoff learning rule!,230,"['widow', 'offs', 'learning', 'rule', 'state', 'adjustment', 'weight', 'synapsis', 'promotional', 'product', 'error', 'function', 'input', 'given', 'synapsis', 'based', 'problem']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",1,2.0,neural_networks,neural_course,0.5
320,Write down and explain the Widrow-Hoff learning rule!,230,"['widow', 'rule', 'based', 'minimising', 'mean', 'square', 'error', 'using', 'gradient', 'descent', 'alogirthm', 'weight', 'adjusted', 'following', 'mannerbr', 'wn1', 'want', 'gradient', 'mean', 'square', 'error', 'bra', 'take', 'gradient', 'mean', 'square', 'error', '05', 'e2n', 'end', 'fracpartial', 'enpartial', 'end', 'xn']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
321,Write down and explain the Widrow-Hoff learning rule!,230,"['widow', 'rule', 'delta', 'beta', 'end', 'xn', 'widrowhoff', 'rule', 'state', 'input', 'xena', 'produce', 'error', 'en', 'change', 'weight', 'directly', 'proportional', 'error', 'signal', 'input', 'signal']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",1,2.0,neural_networks,neural_course,0.5
322,Write down and explain the Widrow-Hoff learning rule!,230,"['widow', 'learning', 'rule', 'also', 'called', 'error', 'correction', 'learning', 'rule', 'error', 'defined', 'difference', 'desired', 'actual', 'output', 'learning', 'machine', 'assuming', 'desired', 'sign', 'available', 'error', 'computed', 'weight', 'neural', 'network', 'updated', 'direction', 'reduction', 'error', 'error', 'input', 'sample', 'neuron', 'computed', 'using', 'eki', 'dki', 'yki', 'weight', 'change', 'delta', 'dot', 'product', 'error', 'weight', 'computed']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
323,Write down and explain the Widrow-Hoff learning rule!,230,"['given', 'neuron', 'excited', 'input', 'signal', 'xi', 'wki', 'synaptic', 'weight', 'neuron', 'widrowhoff', 'learning', 'rule', 'give', 'weight', 'adjustment', 'delta', 'wki', 'applied', 'neuron', 'mathematical', 'term', 'follows', 'delta', 'wiki', 'beta', 'xinen', 'end', 'instantaneous', 'value', 'error', 'signal', 'thus', 'widrowhoff', 'rule', 'state', 'synaptic', 'adjustment', 'applied', 'weight', 'neuron', 'proportional', 'product', 'input', 'signal', 'neuro', 'instantaneous', 'value', 'error', 'signal', 'rule', 'assumes', 'neuron', 'external', 'supply', 'desired', 'response', 'error', 'computed']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
324,Write down and explain the Widrow-Hoff learning rule!,230,"['widrowhoff', 'learning', 'rule', 'given', 'wn', 'want', 'beta', 'end', 'xn', 'wn', 'weight', 'iteration', 'en', 'done', 'yn', 'error', 'dn', 'desired', 'output', 'yn', 'actual', 'output', 'xn', 'input', 'eta', 'learning', 'rate']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",1,2.0,neural_networks,neural_course,0.5
325,Write down and explain the Widrow-Hoff learning rule!,230,"['widow', 'learning', 'rule', 'state', 'adaptation', 'made', 'synaptic', 'weight', 'proportional', 'product', 'input', 'error', 'functionit', 'basically', 'state', 'error', 'high', 'product', 'input', 'error', 'also', 'high', 'thus', 'adjustment', 'made', 'weight', 'would', 'wjn1', 'wjn', 'etaerrorinput']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
326,Write down and explain the Widrow-Hoff learning rule!,230,"['based', 'minimization', 'error', 'cost', 'function', 'xiw', '05', 'e2kn', 'synaptic', 'weight', 'neuron', 'input', 'updated', 'direction', 'opposite', 'gradient', 'vector', 'xiw', 'wkjn1', 'wkjn', 'beta', 'unable', 'xiw', 'wkjn', 'beta', 'eking', 'xjn', 'beta', 'learning', 'rateekn', 'neuron', 'error', 'signal', 'xjn', 'input', 'data']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
327,Write down and explain the Widrow-Hoff learning rule!,230,"['windrowhoff', 'error', 'correction', 'learning', 'rule', 'say', 'adjustment', 'weight', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'weight']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",1,2.0,neural_networks,neural_course,0.5
328,Write down and explain the Widrow-Hoff learning rule!,230,"['bigtriangleup', 'omegaji', 'e', 'xiao', 'omegan1', 'omegan', 'beta', 'bigtriangleup', 'omegaji', 'widow', 'learning', 'rule', 'say', 'synaptic', 'weight', 'update', 'directly', 'proportional', 'product', 'error', 'input']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
329,Write down and explain the Widrow-Hoff learning rule!,230,"['widrowhoff', 'learning', 'rule', 'rule', 'state', 'weight', 'update', 'directly', 'proportional', 'product', 'input', 'neuron', 'error', 'delta', 'wij', 'beta', 'end', 'sum', 'xin']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",1,2.0,neural_networks,neural_course,0.5
330,Write down and explain the Widrow-Hoff learning rule!,230,"['delta', 'wkj', 'beta', 'ek', 'xu', 'widow', 'rule', 'state', 'change', 'synaptic', 'weight', 'proportional', 'product', 'error', 'signal', 'input', 'signal']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",1,2.0,neural_networks,neural_course,0.5
331,Write down and explain the Widrow-Hoff learning rule!,230,"['delta', 'want', 'mu', 'xena', 'en', 'mu', 'learning', 'rate', 'xn', 'input', 'trimester', 'en', 'done', 'yn', 'dn', 'desired', 'signal', 'trimester', 'yn', 'output', 'network', 'trimester', 'widroffhoff', 'delta', 'rule', 'change', 'weight', 'depending', 'input', 'error', 'difference', 'output', 'network', 'desired', 'output', 'weight', 'change', 'scaled', 'learning', 'rate']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
332,Write down and explain the Widrow-Hoff learning rule!,230,"['widrowhoff', 'rule', 'used', 'errorcorrection', 'learning', 'us', 'current', 'error', 'output', 'system', 'determine', 'new', 'weight', 'wn1', 'wneta', 'dot', 'end', 'dot', 'yen']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",1,2.0,neural_networks,neural_course,0.5
333,Write down and explain the Widrow-Hoff learning rule!,230,"['delta', 'want', 'learningrate', 'dot', 'xena', 'dot', 'en', 'input', 'data', 'ya', 'error', 'desired', 'output', 'actual', 'output', 'learningrate', 'parameter', 'chosen', 'necessary', 'change', 'speed', 'learning', 'wnew', 'wold', 'learningrate', 'dot', 'dot', 'end', 'formula', 'update', 'weight', 'learn', 'input', 'data']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
334,Write down and explain the Widrow-Hoff learning rule!,230,"['weightst', 'weightst1', 'learningrate', 'desiredt', 'outputt', 'widrowhoff', 'rule', 'also', 'delta', 'rule', 'used', 'update', 'weight', 'neural', 'network', 'learning', 'algorithm', 'us', 'previous', 'weight', 'result', 'compare', 'desired', 'result', 'discrepancy', 'applied', 'update', 'weight', 'based', 'learning', 'rate']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
335,Write down and explain the Widrow-Hoff learning rule!,230,"['new', 'wold', 'learningparameter', 'errorn', 'inputn', 'error', 'desiredinput', 'currentoutput', 'new', 'value', 'synaptic', 'weight', 'computed', 'old', 'value', 'plus', 'learning', 'rate', 'time', 'current', 'error', 'input', 'output', 'error', 'decreased', 'step', 'change', 'small', 'generalization', 'sufficient']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
336,Write down and explain the Widrow-Hoff learning rule!,230,"['rule', 'learning', 'rate', 'input', 'output', 'network', 'desired', 'output', 'widrowhoff', 'rule', 'minimizes', 'error', 'yd', 'weight', 'change', 'proportional', 'input', 'error', 'derived', 'steepest', 'descend']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
337,Write down and explain the Widrow-Hoff learning rule!,230,[],"['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",0,2.0,neural_networks,neural_course,0.0
338,Write down and explain the Widrow-Hoff learning rule!,230,"['basically', 'calculating', 'mean', 'squared', 'error', 'mse', 'expected', 'output', 'real', 'output', 'modifying', 'weight', 'minimizing']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",0,2.0,neural_networks,neural_course,0.0
339,Write down and explain the Widrow-Hoff learning rule!,230,"['widrowhoff', 'rule', 'state', 'weight', 'adjustment', 'proportional', 'product', 'input', 'error', 'output', 'also', 'called', 'delta', 'rule', 'delta', 'wji', 'beta', 'xieji', 'eta', 'proportional', 'constant', 'also', 'called', 'learning', 'constant', 'wiwi1delta', 'wji']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
340,Write down and explain the Widrow-Hoff learning rule!,230,"['delta', 'wji', 'beta', 'exit', 'adjustment', 'made', 'weight', 'neuron', 'proportional', 'product', 'error', 'neuron', 'input', 'applied', 'neuron']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
341,Write down and explain the Widrow-Hoff learning rule!,230,"['widrowhoff', 'learning', 'rule', 'derived', 'le', 'error', 'method', 'defined', 'wt1', 'mu', 'dot', 'delta', 'mu', 'represent', 'learning', 'rate', 'delta', 'gradient', 'instantaneous', 'error', 'represent', 'desired', 'signal', 'represent', 'output', 'signal', 'neuron', 'ex', 'represent', 'input', 'neuron']","['adjustment', 'made', 'synaptic', 'weight', 'neuron', 'proportional', 'product', 'error', 'signal', 'input', 'signal', 'synapse', 'question', 'rule', 'derived', 'steepest', 'descent', 'method']",2,2.0,neural_networks,neural_course,1.0
342,"Explain back propagation, use the correct technical terms!",231,"['backpropagation', 'gradient', 'error', 'produced', 'output', 'layer', 'partially', 'differentiating', 'cost', 'function', 'respect', 'weight', 'propagated', 'backwards', 'one', 'layer', 'time', 'back', 'input', 'layer', 'propagated', 'gradient', 'used', 'update', 'weight', 'corresponding', 'layer', 'backpropagation', 'necessary', 'desired', 'output', 'every', 'layer', 'known', 'possible', 'formulate', 'cost', 'function', 'output', 'layer']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
343,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'two', 'phase', '1', 'forward', 'phase', 'first', 'apply', 'input', 'network', 'compute', 'current', 'output', '2', 'backward', 'phase', 'compute', 'error', 'current', 'desired', 'output', 'error', 'minimized', 'computing', 'gradient', 'error', 'respect', 'weight', 'return', 'weight', 'adjust', 'adjusting', 'weight', 'backward', 'phase', 'go', 'forward', 'phase', 'compute', 'current', 'output', 'check', 'whether', 'error', 'minimized']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
344,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'want', 'minimize', 'error', 'function', 'e', 'e', 'given', 'frac12sum', 'en2', 'error', 'function', 'minimized', 'calculating', 'gradient', 'starting', 'output', 'term', 'calculating', 'gradient', 'differs', 'depends', 'whether', 'neuron', 'gradient', 'calculated', 'output', 'neuron', 'hidden', 'neuron']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
345,"Explain back propagation, use the correct technical terms!",231,"['backpropagation', 'general', 'form', 'delta', 'rule', 'formulated', 'network', 'multiple', 'hidden', 'layer', 'propagate', 'error', 'network', 'back', 'input', 'layer', 'determine', 'change', 'weight', 'using', 'error', 'signal', 'output', 'layer', 'subsequently', 'local', 'gradient', 'hidden', 'layer', 'forward', 'pas', 'compute', 'net', 'output', 'forward', 'backward', 'pas', 'propagate', 'error', 'backwards', 'rule', 'derived', 'error', 'gradient', 'wrt', 'weight', 'application', 'chain', 'rule']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
346,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'propagation', 'error', 'output', 'layer', 'hidden', 'layer', 'network', 'multiple', 'layer', 'done', 'calculating', 'local', 'gradient', 'node', 'using', 'along', 'weight', 'determine', 'much', 'error', 'propagated', 'particular', 'node']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
347,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'used', 'multi', 'layer', 'network', 'consists', 'two', 'phase', 'forward', 'backwards', 'forward', 'phase', 'give', 'input', 'network', 'calculate', 'output', 'also', 'memorize', 'local', 'field', 'node', 'local', 'gradient', 'delta', 'used', 'adapt', 'weight', 'layer', 'different', 'output', 'remaining', 'layer', 'node', 'output', 'layer', 'deltaivi', 'varphiprimevidi', 'ying', 'node', 'layer', 'deltaivi', 'varphiprimevisumjin', 'ca', 'wi', 'deltajvj', 'act', 'node', 'use', 'node', 'output', 'input', 'repeat', 'process', 'input', 'data', 'error', 'small', 'enough']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
348,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'algorithm', 'train', 'multiplayer', 'feedforward', 'anna', 'change', 'weight', 'computing', 'local', 'radiant', 'neuron', 'using', 'neuron', 'layer', 'local', 'gradient', 'output', 'neuron', 'computed', 'easily', 'activation', 'function', 'differantable', 'backpropagation', 'algorithm', 'forward', 'pas', 'compute', 'output', 'output', 'layer', 'backyard', 'pas', 'use', 'output', 'desired', 'output', 'compute', 'local', 'gradient', 'output', 'layer', 'go', 'back', 'layer', 'layer', 'use', 'local', 'gradient', 'compute', 'new', 'local', 'gradient', 'minimize', 'average', 'squared', 'error', 'function']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
349,"Explain back propagation, use the correct technical terms!",231,"['backpropagation', 'learning', 'algorithm', 'multiplayer', 'nna', 'supervised', 'error', 'correction', 'learning', 'weight', 'initialized', 'randomly', 'algorithm', 'step', 'forward', 'pas', 'output', 'calculated', 'using', 'current', 'weight', 'backward', 'pas', 'weight', 'update', 'outputlayer', 'like', 'single', 'layer', 'error', 'used', 'update', 'weight', 'allows', 'u', 'also', 'calculate', 'error', 'hidden', 'layer', 'hidden', 'layer', 'use', 'local', 'gradient', 'error', 'local', 'gradient', 'sum', 'weighted', 'error', 'following', 'layer', 'passed', 'trough', 'private', 'activation', 'function', 'possible', 'backpropagate', 'error', 'output', 'layer', 'first', 'layer', 'common', 'problem', 'vanishing', 'gradient', 'problem', 'depending', 'activation', 'function', 'used', 'local', 'gradient', 'get', 'smaller', 'layer', 'eventually', 'le', 'floating', 'point', 'precision', 'used', 'limit', 'number', 'layer', 'stacked']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
350,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'algorithm', 'learning', 'algorithm', 'updating', 'weight', 'multiplayer', 'neural', 'network', 'updating', 'weight', 'layer', 'error', 'neuron', 'must', 'calculated', 'back', 'propagation', 'algorithm', 'two', 'phase', 'defined', 'forward', 'phase', 'output', 'neural', 'network', 'calculated', 'also', 'error', 'neuron', 'output', 'layer', 'backward', 'phase', 'gradient', 'neuron', 'calculated', 'using', 'calculated', 'error', 'output', 'layer', 'defined', 'connection', 'hidden', 'layer', 'output', 'layer', 'multiple', 'hidden', 'layer', 'defined', 'error', 'iteratevely', 'given', 'backwards', 'weight', 'neuron', 'updated']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
351,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'steepest', 'decent', 'method', 'us', 'final', 'produced', 'error', 'local', 'gradient', 'define', 'amount', 'change', 'needed', 'synaptic', 'weight', 'method', 'two', 'phase', 'forward', 'phase', 'phase', 'feed', 'input', 'network', 'network', 'calculate', 'output', 'backward', 'phase', 'phase', 'first', 'calculate', 'error', 'use', 'local', 'gradient', 'propagate', 'error', 'network', 'last', 'layer', 'first', 'manipulate', 'synaptic', 'weight']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
352,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'consists', 'two', 'step', '1', 'forward', 'pas', 'data', 'passed', 'network', 'weight', 'adapted', '2', 'backward', 'pas', 'using', 'local', 'field', 'neuron', 'error', 'signal', 'propagated', 'backward', 'using', 'local', 'field', 'neuron', 'end', 'beginning', 'stacking', 'local', 'field', 'partial', 'derivative', 'output', 'signal', 'neuron', 'output', 'neuron', 'simplest', 'calculate', 'desired', 'output', 'actual', 'output', 'deal']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
353,"Explain back propagation, use the correct technical terms!",231,"['backpropagation', 'learning', 'algorithm', 'multi', 'layer', 'network', 'consists', 'two', 'phase', 'forward', 'pas', 'backward', 'pas', 'forward', 'pas', 'output', 'calculated', 'passing', 'activation', 'layer', 'layer', 'starting', 'input', 'hidden', 'layer', 'finally', 'output', 'error', 'calculated', 'output', 'layer', 'propagated', 'backward', 'network', 'forward', 'pas', 'weight', 'change', 'backward', 'pas', 'weight', 'change', 'proportion', 'local', 'gradient']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
354,"Explain back propagation, use the correct technical terms!",231,"['backpropagation', 'neural', 'network', 'based', 'learning', 'algorithm', 'network', 'learns', 'propagating', 'error', 'network', 'consists', 'two', 'stage', 'forward', 'pas', 'error', 'computed', 'feeding', 'input', 'network', 'backward', 'pas', 'error', 'propagated', 'network', 'weight', 'update', 'locally', 'since', 'vanishing', 'gradient', 'problem', 'useful', 'use', 'activation', 'function', 'infinitely', 'differential', 'sigmoid', 'function']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
355,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'algorithm', 'used', 'calculate', 'error', 'contribution', 'neuron', 'batch', 'data', 'processed', 'required', 'known', 'desired', 'output', 'input', 'value', 'thus', 'back', 'propagation', 'algorithm', 'supervised', 'method', 'algorithm', 'subdivided', 'two', 'phase', 'propagation', 'propagation', 'forward', 'network', 'generate', 'output', 'value', 'calculation', 'cost', 'error', 'term', 'propagation', 'output', 'activation', 'back', 'network', 'using', 'training', 'pattern', 'target', 'order', 'generate', 'delta', 'difference', 'desired', 'actual', 'output', 'output', 'hidden', 'neuron', 'recursevliy', 'computing', 'local', 'gradient', 'neuron', 'weight', 'update', 'weight', 'following', 'step', 'need', 'applied', 'weight', 'output', 'delta', 'input', 'activation', 'multiplied', 'find', 'gradient', 'weight', 'ratio', 'percentage', 'weight', 'gradient', 'subtracted', 'weight', 'ration', 'also', 'referred', 'learning', 'rate', 'influence', 'speed', 'quality', 'learning', 'learning', 'repeated', 'every', 'new', 'batch', 'network', 'performs', 'adequately']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
356,"Explain back propagation, use the correct technical terms!",231,"['backpropagation', 'algorithm', 'training', 'neural', 'network', 'contains', 'two', 'main', 'stage', 'first', 'stage', 'compute', 'actual', 'output', 'given', 'input', 'stage', 'signal', 'flow', 'forward', 'input', 'layer', 'output', 'layer', 'synaptic', 'weight', 'fixed', 'second', 'stage', 'update', 'synaptic', 'weight', 'propagating', 'error', 'signal', 'backward', 'output', 'layer', 'layerbylayer', 'manner', 'neuron', 'local', 'gradient', 'partial', 'derivative', 'cost', 'function', 'local', 'field', 'computed']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
357,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'usually', 'occurs', 'multi', 'layer', 'perception', 'us', 'non', 'linear', 'activation', 'function', 'basic', 'element', '1', 'functional', 'signal', 'input', 'signal', 'pass', 'network', 'left', 'right', 'name', 'denotes', 'performs', 'useful', 'function', 'output', 'neuron', 'another', 'reason', 'name', 'functional', 'signal', 'calculated', 'based', 'parameter', 'activation', 'function', '2', 'error', 'signal', 'error', 'signal', 'propagate', 'usually', 'reverse', 'direction', 'contains', 'error', 'based', 'desired', 'output', 'consists', '2', 'phase', '1', 'forward', 'phase', 'forward', 'phase', 'signal', 'propagate', 'left', 'right', 'weight', 'fixed', 'pass', 'layer', 'network', 'undergo', 'activation', '2', 'reverse', 'phase', 'reverse', 'phase', 'local', 'gradient', 'calculated', 'propagated', 'backward', 'direction', 'weight', 'change']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
358,"Explain back propagation, use the correct technical terms!",231,"['backpropogation', 'used', 'training', 'multi', 'layer', 'network', 'constitutes', 'forward', 'pas', 'backward', 'pas', 'forward', 'pas', 'network', 'computes', 'output', 'based', 'error', 'calculated', 'based', 'difference', 'network', 'output', 'desired', 'output', 'error', 'backpropogated', 'network', 'backward', 'pas', 'used', 'adjusting', 'synaptic', 'weight']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
359,"Explain back propagation, use the correct technical terms!",231,"['backpropagation', 'used', 'multiplayer', 'perception', 'network', 'consists', 'two', 'pass', 'forward', 'pas', 'output', 'calculated', 'every', 'computational', 'node', 'passed', 'till', 'output', 'node', 'error', 'calculated', 'difference', 'desired', 'output', 'actual', 'output', 'pas', 'weight', 'synaptic', 'link', 'changed', 'backward', 'pas', 'error', 'generated', 'output', 'neuron', 'passed', 'backward', 'direction', 'ie', 'direction', 'synapsis', 'local', 'gradient', 'error', 'calculated', 'every', 'neuron']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
360,"Explain back propagation, use the correct technical terms!",231,"['back', 'prop', 'way', 'training', 'neural', 'network', 'adapting', 'weight', 'using', 'error', 'produced', 'consists', 'two', 'phase', 'forward', 'backwards', 'forward', 'phase', 'computes', 'output', 'along', 'network', 'using', 'function', 'signal', 'backward', 'phase', 'error', 'output', 'fromthe', 'desired', 'output', 'computed', 'local', 'gradient', 'error', 'used', 'update', 'weight', 'network', 'local', 'gradient', 'considers', 'credit', 'blame', 'corresponding', 'weight', 'neuron', 'producing', 'output']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
361,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'algorithm', 'based', 'error', 'correction', 'learning', 'rule', 'consists', 'two', 'pass', '1', 'forward', 'pas', 'input', 'signal', 'applied', 'source', 'node', 'network', 'propagated', 'forward', 'different', 'layer', 'network', 'output', 'computed', 'output', 'layer', 'network', '2', 'backward', 'pas', 'error', 'signal', 'computed', 'output', 'propagated', 'backwards', 'local', 'gradient', 'computed', 'hidden', 'layer', 'neuron', 'order', 'adjust', 'synaptic', 'weight', 'neuron', 'network']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
362,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'moving', 'error', 'backwards', 'recursive', 'network', 'calculating', 'local', 'field', 'every', 'neuron', 'update', 'weight', 'based', 'chaining', 'rule', 'derivative']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
363,"Explain back propagation, use the correct technical terms!",231,"['backpropagation', 'neural', 'network', 'two', 'stage', 'forward', 'pas', 'forward', 'pas', 'error', 'calculated', 'output', 'layer', 'help', 'desired', 'output', 'given', 'output', 'e', 'backward', 'pas', 'begin', 'output', 'layer', 'case', 'error', 'passed', 'backwards', 'calculation', 'gradient', 'layer', 'neural', 'network', 'back', 'propagation', 'adjustment', 'weight', 'made', 'based', 'local', 'gradient', 'calculated', 'layer']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
364,"Explain back propagation, use the correct technical terms!",231,"['contains', 'forward', 'pas', 'backward', 'pas', 'forward', 'pas', 'input', 'applied', 'network', 'propagate', 'forward', 'network', 'compute', 'output', 'neuron', 'output', 'layer', 'error', 'output', 'neuron', 'backward', 'pas', 'compute', 'local', 'gradient', 'update', 'synaptic', 'weight', 'according', 'error', 'correction', 'rule', 'neuron', 'layer', 'layer', 'backward', 'direction']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
365,"Explain back propagation, use the correct technical terms!",231,"['backpropagation', 'algorithm', 'consists', 'two', 'passesbr', '1', 'forward', 'pas', 'input', 'vector', 'applied', 'network', 'layer', 'layer', '2', 'backward', 'pas', 'weight', 'adjusted', 'based', 'error', 'correction', 'learning', 'rule', 'bra', 'bra', 'back', 'propagation', 'us', 'error', 'correction', 'learning', 'rule', 'objective', 'minimize', 'average', 'squared', 'error']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
366,"Explain back propagation, use the correct technical terms!",231,"['backpropagation', 'steepest', 'decent', 'method', 'calculates', 'error', 'output', 'neuron', 'backpropagates', 'error', 'backwards', 'update', 'weight', 'neuron', 'synaptic', 'weight', 'updated', 'directly', 'proportional', 'partial', 'derivative', 'local', 'gradient', 'calculated', 'output', 'neuron', 'hidden', 'neuron', 'local', 'gradient', 'output', 'neuron', 'calculated', 'using', 'observed', 'error', 'error', 'function', 'missing', 'hidden', 'neuron', 'local', 'gradient', 'hidden', 'neuron', 'calculated', 'recursive', 'local', 'gradient', 'neuron', 'connected', 'directly', 'hidden', 'neuron', 'je']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
367,"Explain back propagation, use the correct technical terms!",231,"['backpropogation', '2', 'step', 'forward', 'pas', 'forward', 'pas', 'data', 'run', 'network', 'error', 'calculated', 'backward', 'pas', 'backward', 'pas', 'weight', 'adjusted', 'using', 'local', 'gradient', 'error', 'error', 'minimized', 'many', 'way', 'weight', 'adjustment', 'like', 'steepest', 'descent', 'newton', 'method', 'gauss', 'newton', 'method']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
368,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'learning', 'method', 'neural', 'network', 'back', 'propagation', 'enables', 'feed', 'forward', 'network', 'represent', 'gate', 'two', 'phase', 'forward', 'pas', 'initial', 'weight', 'used', 'calculate', 'value', 'output', 'neuron', 'backward', 'pas', 'start', 'output', 'layer', 'travel', 'backwards', 'phase', 'weight', 'changed', 'based', 'local', 'gradient', 'neuron']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
369,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'used', 'learn', 'weight', 'multiplayer', 'feed', 'forward', 'network', 'divided', 'two', 'step', 'forward', 'backwards', 'forward', 'step', 'one', 'input', 'passed', 'network', 'calculate', 'output', 'network', 'output', 'used', 'calculate', 'error', 'output', 'neuron', 'given', 'desired', 'output', 'forward', 'step', 'backward', 'step', 'weight', 'changed', 'beginning', 'end', 'network', 'weight', 'changed', 'taking', 'derivative', 'activation', 'function', 'neuron', 'time', 'either', 'error', 'following', 'neuron', 'output', 'neuron', 'local', 'gradient', 'connected', 'neuron', 'time', 'corresponding', 'weight', 'weight', 'change', 'local', 'field']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
370,"Explain back propagation, use the correct technical terms!",231,"['backpropagation', 'used', 'multiplayer', 'perception', 'give', 'method', 'adapting', 'weight', 'first', 'forward', 'phase', 'run', 'like', 'regular', 'feedforward', 'network', 'output', 'thus', 'error', 'determined', 'error', 'backpropagated', 'output', 'layer', 'network', 'since', 'multiple', 'layer', 'desired', 'output', 'network', 'last', 'layer', 'counteract', 'problem', 'gradient', 'calculated', 'every', 'neuron', 'backward', 'pas', 'gradient', 'giving', 'measure', 'contribution', 'neuron', 'final', 'error', 'gradient', 'used', 'update', 'neuron', 'weight', 'neuron', 'part', 'output', 'layer', 'previous', 'gradient', 'used', 'calculate', 'new', 'gradient', 'instead', 'using', 'error']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
371,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'consists', 'two', 'step', '1', 'step', 'forward', 'pas', 'input', 'data', 'fed', 'network', 'output', 'calculated', 'output', 'node', 'usual', 'calculation', 'induced', 'local', 'field', 'done', 'using', 'formula', 'iv', 'sum', 'output', 'calculated', 'using', 'formula', 'fv', 'activation', 'function', '2', 'step', 'backward', 'pas', 'error', 'backpropagated', 'network', 'output', 'layer', 'input', 'layer', 'output', 'layer', 'error', 'calculated', 'using', 'formula', 'delta', 'using', 'desired', 'output', 'actual', 'output', 'ya', 'layer', 'output', 'layer', 'local', 'gradient', 'used', 'calculate', 'error', 'using', 'error', 'output', 'layer', 'delta', 'delta', 'xu', 'additionally', 'weight', 'updated', 'using', 'wnew', 'wold', 'learningrate', 'dot', 'delta', 'xu']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
372,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'learning', 'algorithm', 'multiplayer', 'neural', 'network', 'first', 'input', 'propagated', 'network', 'end', 'reached', 'error', 'calculated', 'desired', 'result', 'error', 'used', 'update', 'weight', 'back', 'front', 'output', 'layer', 'weight', 'updated', 'directly', 'calculated', 'error', 'following', 'layer', 'use', 'local', 'gradient', 'previous', 'error', 'calculated', 'derivative', 'activation', 'function', 'error', 'used', 'update', 'weight', 'repeated', 'front', 'reached']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
373,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'used', 'multiplayer', 'feedforward', 'network', 'first', 'forward', 'pas', 'computed', 'given', 'error', 'output', 'node', 'used', 'compute', 'weight', 'change', 'using', 'widrowhoff', 'learning', 'rule', 'error', 'given', 'back', 'layer', 'layer', 'backward', 'pas', 'compute', 'error', 'weight', 'changing', 'layer', 'recursivly', 'learning', 'done', 'sequential', 'online', 'batch', 'mode', 'offline']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
374,"Explain back propagation, use the correct technical terms!",231,"['multi', 'layer', 'network', 'error', 'available', 'last', 'layer', 'therefore', 'error', 'propagated', 'back', 'network', 'using', 'backpropagtion', 'algorithm', 'order', 'local', 'gradient', 'calculated', 'update', 'weight', 'gradient', 'put', 'output', 'previous', 'layer', 'local', 'gradient', 'calculated', 'differently', 'depending', 'neuron', 'output', 'layer', 'hidden', 'layer', 'output', 'layer', 'gradient', 'phix', 'hidden', 'layer', 'gradient', 'phijx', 'sumwi', 'local', 'gradient']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
375,"Explain back propagation, use the correct technical terms!",231,"['steepest', 'gradient', 'weight', 'adjusted', 'decreasing', 'direction', 'error', 'function', 'hidden', 'neuron', 'label', 'available', 'calculate', 'error', 'hence', 'final', 'output', 'error', 'backpropogated', 'layer', 'inside', 'hidden', 'layer', 'nna', 'possible', 'continuous', 'activation', 'function', 'chain', 'rule', 'derivative', 'final', 'error', 'differentiated', 'respect', 'hidden', 'weight', 'chain', 'rule', 'applied', 'find', 'local', 'error', 'hidden', 'neuron']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
376,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'algorithm', 'consist', 'forward', 'pas', 'backward', 'pas', 'computes', 'output', 'neuron', 'propagates', 'backward', 'direction', 'recursive', 'compute', 'local', 'gradient', 'neuron', 'weight', 'adjusted', 'accordingly']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
377,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'process', 'learning', 'multi', 'layer', 'perception', 'error', 'output', 'network', 'fed', 'back', 'network', 'adjust', 'weight', 'hidden', 'layer', 'error', 'back', 'propagates', 'network', 'enable', 'network', 'learn', 'adjusting', 'synaptic', 'weight', 'based']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
378,"Explain back propagation, use the correct technical terms!",231,"['back', 'propagation', 'process', 'make', 'adjustment', 'weight', 'neural', 'network', 'way', 'minimizes', 'average', 'squared', 'error', 'training', 'data', 'us', 'steepest', 'decent', 'method', 'step', 'move', 'towards', 'direction', 'give', 'maximum', 'decrease', 'error', 'back', 'propagation', 'error', 'prepared', 'backward', 'last', 'layer', 'towards', 'earlier', 'layer', 'adjustment', 'made', 'weight', 'proportional', 'partial', 'derivative', 'error', 'respect', 'weight', 'partial', 'derivative', 'calculated', 'using', 'repeated', 'application', 'chain', 'rule']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",1,2.0,neural_networks,neural_course,0.5
379,"Explain back propagation, use the correct technical terms!",231,"['idea', 'back', 'propagation', 'method', 'propagate', 'error', 'output', 'final', 'layer', 'backward', 'hidden', 'layer', 'adjust', 'weighs', 'neuron', 'hidden', 'layer', 'based', 'error', 'required', 'error', 'information', 'hidden', 'layer', 'output', 'neuron', 'error', 'output', 'layer', 'propagated', 'hidden', 'layer', 'using', 'idea', 'steepest', 'descent', 'method', 'namely', 'local', 'gradient', 'computed', 'neuron', 'backpropagation', 'local', 'gradient', 'define', 'error', 'change', 'term', 'weight', 'local', 'gradient', 'derived', 'chain', 'rule', 'layer', 'fact', 'local', 'gradient', 'hidden', 'layer', 'derived', 'based', 'local', 'gradient', 'previous', 'layer', 'defines', 'propagate', 'hidden', 'layer', 'nna', 'gradient', 'error', 'function', 'vanishes', 'mean', 'go', 'deeply', 'back', 'nna', 'change', 'weight', 'becoming', 'smaller', 'smaller', 'drawback', 'back', 'propagation', 'method']","['backpropagation', 'lower', 'error', 'map', 'level', 'level', 'recursive', 'backwards', 'back', 'propagates', 'error', 'last', 'layer', 'first', 'layer', 'updating', 'weight', 'update', 'determined', 'local', 'gradient', 'level', 'computed', 'partial', 'derivative', 'error', 'chain', 'rule']",2,2.0,neural_networks,neural_course,1.0
380,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'control', 'speed', 'descent', 'learning', 'rate', 'low', 'weight', 'updating', 'overlapped', 'convergence', 'slow', 'learning', 'rate', 'high', 'weight', 'updating', 'underdamped', 'zigzagging', 'behaviour', 'exhibited', 'weight', 'space', 'learning', 'rate', 'large', 'learning', 'becomes', 'unstable']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
381,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'smaller', 'transition', 'overdamping', 'trajectory', 'weight', 'vector', 'follows', 'smooth', 'path', 'learning', 'rate', 'large', 'transition', 'underdamping', 'trajectory', 'weight', 'vector', 'exhibit', 'zigzaggingor', 'oscillator', 'behavior', 'learning', 'get', 'higher', 'threshold', 'learning', 'algorithm', 'get', 'unstable', 'diverged']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",1,2.0,neural_networks,neural_course,0.5
382,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'determines', 'stride', 'delta', 'weight', 'learning', 'rate', 'large', 'weight', 'start', 'ziggerate']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",1,2.0,neural_networks,neural_course,0.5
383,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['training', 'learning', 'rate', 'determines', 'step', 'size', 'take', 'towards', 'negative', 'gradient', 'learning', 'rate', 'small', 'weight', 'may', 'overlapped', 'reach', 'error', 'function', 'minimum', 'slowly', 'eventually', 'getting', 'stuck', 'local', 'minimal', 'step', 'size', 'big', 'weight', 'may', 'underdampened', 'bouncing', 'ridge', 'error', 'surface', 'never', 'find', 'minimum', 'especially', 'minimum', 'steep', 'ravine', 'error', 'surface']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
384,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'used', 'control', 'much', 'wright', 'update', 'affected', 'error', 'correction', 'learning', 'rate', 'low', 'learning', 'slow', 'take', 'time', 'learning', 'rate', 'high', 'learning', 'fast', 'cause', 'zigzagging', 'behaviour', 'convergence', 'learning', 'rate', 'high', 'may', 'result', 'situation', 'zigzagging', 'behaviour', 'cause', 'overshoot', 'may', 'never', 'finally', 'converge']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
385,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'defines', 'speed', 'weight', 'change', 'learning', 'rate', 'high', 'lead', 'oscillation', 'around', 'optimal', 'weight', 'never', 'reached', 'learning', 'rate', 'low', 'result', 'slow', 'learning', 'slow', 'convergence']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",1,2.0,neural_networks,neural_course,0.5
386,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'needed', 'make', 'algorithm', 'stable', 'high', 'learning', 'rate', 'make', 'weightchanges', 'zickzacking', 'algorithm', 'might', 'converge', 'low', 'learning', 'rate', 'make', 'path', 'plane', 'smooth', 'learning', 'rate', 'get', 'certain', 'critical', 'value', 'algorithm', 'might', 'converge']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
387,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'create', 'factor', 'much', 'trust', 'datapoint', 'normally', 'range', '01', 'high', 'learning', 'rate', 'normally', 'result', 'faster', 'convergence', 'lower', 'rate', 'slower', 'conversion', 'rate', 'choose', 'high', 'possible', 'cost', 'function', 'divergent', 'rate', 'slow', 'possible', 'rate', 'conversion', 'slow', 'never', 'reach', 'local', 'minimum']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
388,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'parameter', 'using', 'updating', 'weight', 'given', 'iteration', 'parameter', 'represents', 'importance', 'given', 'adaptation', 'weight', 'setting', 'learning', 'rate', 'small', 'learning', 'machine', 'learn', 'slower', 'also', 'stable', 'way', 'hand', 'setting', 'learning', 'rate', 'large', 'value', 'learning', 'machine', 'learn', 'faster', 'unstable', 'way', 'danger', 'depending', 'learning', 'rate', 'value', 'algorithm', 'may', 'never', 'come', 'perfect', 'value', 'learning', 'rate', 'small', 'may', 'land', 'local', 'minimum', 'never', 'approach', 'global', 'minimum', 'function', 'learning', 'rate', 'big', 'learning', 'progression', 'zigzagging', 'behaviour', 'never', 'approach', 'ideal', 'value']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
389,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'defines', 'size', 'step', 'method', 'move', 'search', 'space', 'learning', 'rate', 'small', 'method', 'need', 'take', 'huge', 'number', 'step', 'maybe', 'stuck', 'local', 'minimal', 'learning', 'rate', 'big', 'method', 'converge', 'fast', 'toward', 'global', 'minimal', 'probability', 'oscillates', 'around', 'global', 'minimal', 'never', 'reach']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
390,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'large', 'process', 'oscillate', 'lot', 'might', 'converge', 'learning', 'rate', 'small', 'convergence', 'happen', 'slowly']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",1,2.0,neural_networks,neural_course,0.5
391,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'tell', 'u', 'confident', 'error', 'affect', 'convergence', 'rate', 'low', 'learning', 'rate', 'slow', 'convergence', 'making', 'system', 'overdamped', 'high', 'learning', 'rate', 'speed', 'convergence', 'value', 'oscillates', 'making', 'system', 'underdamped', 'system', 'become', 'unstable', 'learning', 'rate', 'threshold', 'value']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
392,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'small', 'system', 'overlapped', 'algorithm', 'take', 'long', 'time', 'converge', 'learning', 'rate', 'large', 'system', 'underdamped', 'algorithm', 'oscillates', 'around', 'optimal', 'solution', 'could', 'potentially', 'make', 'system', 'unstable']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
393,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['steepest', 'descent', 'method', 'algorithm', 'finding', 'nearest', 'local', 'minimum', 'function', 'presupposes', 'gradient', 'function', 'computed', 'method', 'steepest', 'descent', 'start', 'point', 'pa', 'many', 'time', 'needed', 'move', 'pi', 'pi1', 'minimizing', 'along', 'line', 'extending', 'pi', 'direction', 'gradient', 'fpi', 'local', 'downhill', 'gradient', 'danger', 'algorithm', 'get', 'stuck', 'local', 'minimal']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
394,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'determines', 'rate', 'learning', 'smaller', 'leaving', 'rate', 'slower', 'learning', 'process', 'path', 'weight', 'adjustment', 'smoother', 'larger', 'value', 'faster', 'leaving', 'process', 'result', 'oscillation', 'instability']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
395,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'eta', 'based', 'learning', 'rate', 'undergoes', 'various', 'oscillation', 'could', 'see', 'zigzagging', 'behaviour', '1', 'learning', 'rate', 'large', 'system', 'said', 'dumped', '2', 'learning', 'rate', 'small', 'system', 'said', 'dumped', 'see', 'zigzagging', 'behaviour', 'towards', 'convergence', 'phase', '3', 'learning', 'rate', 'cross', 'certain', 'value', 'becomes', 'unstable', 'may', 'stuck', 'local', 'minimal', 'considered', 'another', 'danger']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
396,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'steepest', 'descent', 'directly', 'affect', 'convergence', 'algorithm', 'learning', 'rate', 'small', 'algorithm', 'take', 'long', 'time', 'converge', 'ice', 'response', 'ovderdamped', 'learning', 'rate', 'made', 'high', 'may', 'observe', 'zigzagging', 'oscillatory', 'behaviour', 'sometimes', 'algorithm', 'may', 'fail', 'converge', 'underdamped', 'response']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
397,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'small', 'learning', 'slow', 'learning', 'rate', 'large', 'learning', 'unstable', 'exhibit', 'zigzag', 'behavior', 'learning', 'rate', 'large', 'learning', 'never', 'converges']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
398,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'defines', 'efficiency', 'learning', 'machine', 'small', 'system', 'response', 'may', 'overdamped', 'large', 'response', 'may', 'underdamped', 'exceeds', 'critical', 'value', 'response', 'may', 'diverged', 'danger', 'possibility', 'system', 'output', 'converge', 'ensured', 'scaling', 'learning', 'rate', 'using', 'largest', 'einen', 'value', 'correction', 'matrix', 'input']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
399,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['value', 'learning', 'rate', 'parameter', 'eta', 'control', 'speed', 'descent', 'convergence', 'towards', 'optimal', 'weight', 'vector', 'small', 'value', 'eta', 'transient', 'response', 'algorithm', 'overlapped', 'weight', 'trajectory', 'follows', 'smooth', 'path', 'hand', 'value', 'eta', 'large', 'transient', 'response', 'algorithm', 'underdamped', 'weight', 'trajectory', 'follows', 'oscillator', 'path', 'wplane']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
400,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'eta', 'profound', 'impact', 'learning', 'steepest', 'descent', '1', 'eta', 'small', 'system', 'underdamped', 'convergence', 'slow', '2', 'larger', 'eta', 'system', 'overlapped', 'tends', 'oscillates', '3', 'eta', 'exceeds', 'certain', 'critical', 'value', 'steepest', 'descent', 'may', 'even', 'diverged']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
401,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'huge', 'impact', 'convergence', 'network', 'learning', 'rate', 'low', 'transient', 'response', 'algorithm', 'overlapped', 'trajectory', 'want', 'smooth', 'learning', 'rate', 'high', 'transient', 'response', 'algorithm', 'underdamped', 'trajectory', 'want', 'zigzag', 'choose', 'wrong', 'learning', 'rate', 'network', 'might', 'converge']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
402,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'control', 'speed', 'convergence', 'steepest', 'descent', 'method', '1', 'small', 'trajectory', 'weight', 'vector', 'follows', 'smooth', 'path', 'plane', '2', 'large', 'trajectory', 'weight', 'vector', 'follows', 'zigzagging', 'path', '3', 'exceeds', 'critical', 'value', 'algorithm', 'unstable']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
403,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['1', 'large', 'learning', 'rate', 'eta', 'result', 'zigzagging', 'behavior', 'converge', 'quickly', '2', 'small', 'learning', 'rate', 'eta', 'result', 'smooth', 'behavior', 'slow', 'converge']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
404,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'tell', 'network', 'much', 'step', 'move', 'towards', 'direction', 'opposite', 'gradient', 'vector', 'learning', 'rate', 'large', 'weight', 'updating', 'high', 'danger', 'learning', 'may', 'oscillate', 'network', 'overdid', 'data']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
405,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'used', 'regulate', 'speed', 'learning', 'learning', 'rate', 'small', 'learning', 'slow', 'learning', 'rate', 'high', 'oscillates', 'exceeds', 'critical', 'value', 'algorithm', 'unstable']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
406,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'used', 'decide', 'fast', 'network', 'converge', 'training', 'phase', 'learning', 'rate', 'high', 'system', 'oscillates', 'becomes', 'overlapped', 'low', 'system', 'becomes', 'underdamped', 'learns', 'slow']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
407,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'tell', 'long', 'one', 'step', 'method', 'steepest', 'descent', 'learning', 'rate', 'high', 'learning', 'oscillate', 'may', 'converge', 'learning', 'rate', 'small', 'convergence', 'take', 'many', 'iteration']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
408,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['use', 'steepest', 'descent', 'use', 'learning', 'rate', 'adjust', 'speed', 'convergence', 'minimum', 'error', 'learning', 'rate', 'small', 'learning', 'going', 'rather', 'slow', 'rate', 'high', 'error', 'zigzagging', 'error', 'surface', 'towards', 'minimum', 'learning', 'rate', 'high', 'might', 'converge', 'diverged']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
409,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'value', '0', 'determines', 'fast', 'network', 'learns', 'using', 'small', 'value', 'learning', 'rate', 'network', 'converges', 'slowly', 'need', 'lot', 'processing', 'choosing', 'big', 'value', 'learning', 'oscillates', 'becomes', 'unstable', 'goal', 'choose', 'learning', 'rate', 'way', 'learn', 'slow', 'need', 'input', 'data', 'convergence', 'become', 'unstable']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
410,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'defines', 'speed', 'learning', 'convergence', 'high', 'value', 'lead', 'faster', 'learning', 'und', 'low', 'value', 'slower', 'learning', 'however', 'high', 'value', 'lead', 'oscillation', 'learning', 'space', 'may', 'overshoot', 'desired', 'result', 'never', 'reach']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
411,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'give', 'speed', 'learning', 'defines', 'stepwidth', 'direction', 'steepest', 'descent', 'learning', 'rate', 'small', 'learning', 'stable', 'slower', 'high', 'learning', 'unstable', 'faster', 'danger', 'overcome', 'minimum', 'result', 'oscillating', 'behaviour']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
412,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['small', 'leaving', 'rate', 'lead', 'slow', 'convergence', 'convergence', 'time', 'learn', 'becomes', 'long', 'high', 'learning', 'rate', 'lead', 'oscillating', 'behavior', 'prevent', 'convergence']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
413,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'scalar', 'multiplied', 'adjustment', 'term', 'adjust', 'weight', 'ensures', 'rate', 'learning', 'typical', 'greater', '0', 'le', 'equal', '1', 'cover', 'rate', 'sliding', 'along', 'curve', 'towards', 'minimal', '1', 'lower', 'learning', 'rate', 'result', 'slow', 'learning', 'chance', 'finding', 'optimal', 'minimal', 'greater', '2', 'higher', 'learning', 'result', 'hopping', 'either', 'side', 'minimal', 'hence', 'zigzag', 'behaviour', '3', 'high', 'learning', 'may', 'converge']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
414,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'large', 'follows', 'zigzag', 'motion', 'learning', 'rate', 'low', 'take', 'time', 'converging', 'learning', 'rate', 'large', 'critical', 'becomes', 'unstable', 'processing', 'possibility', 'get', 'stuck', 'local', 'minimal']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
415,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['using', 'steepest', 'descent', 'learning', 'rateeta', 'determines', 'speed', 'weight', 'adjusted', 'nna', 'two', 'possible', 'danger', 'related', 'learning', 'rate', 'depending', 'magnitude', '1', 'low', 'learning', 'rateeg', 'beta', '001', 'result', 'smooth', 'variation', 'weight', 'make', 'process', 'becomes', 'slow', '2', 'hight', 'learning', 'rate', 'beg', 'beta', '001', 'result', 'faster', 'weight', 'adjustment', 'lead', 'oscillator', 'nature', 'learning', 'unwanted']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
416,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['small', 'learning', 'rate', 'network', 'converge', 'slowly', 'towards', 'optimal', 'weight', 'network', 'give', 'better', 'performance', 'generalization', 'high', 'learning', 'rate', 'zigzag', 'effect', 'large', 'rate', 'network', 'may', 'miss', 'local', 'minimal', 'jump', 'higher', 'point', 'high', 'learning', 'rate', 'network', 'may', 'become', 'unstable']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
417,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"['learning', 'rate', 'defines', 'speed', 'steepest', 'descent', 'search', 'min', 'error', 'function', 'word', 'defines', 'strong', 'change', 'weight', 'throughout', 'optimization', 'procedure', 'higher', 'learning', 'rate', 'faster', 'learning', 'learning', 'characterized', 'oscillation', 'search', 'mind', 'dangerous', 'learning', 'rate', 'becomes', 'bigger', 'certain', 'value', 'make', 'search', 'steepest', 'descent', 'unstable', 'case', 'steepest', 'descent', 'start', 'diverged', 'instead', 'converging', 'mind', 'case', 'leaving', 'rate', 'small', 'learning', 'slower', 'safer', 'learning', 'path', 'oscilatory']","['learning', 'rate', 'control', 'speed', 'convergence', 'learning', 'rate', 'low', 'convergence', 'overlapped', 'slow', 'learning', 'rate', 'high', 'convergence', 'underdamped', 'follows', 'zigzagging', 'path', 'learning', 'rate', 'exceeds', 'critical', 'value', 'learning', 'becomes', 'unstable']",2,2.0,neural_networks,neural_course,1.0
418,How does a Reduced Boltzman Machine work (main idea)?,233,"['reduced', 'blotzman', 'machine', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",2,2.0,neural_networks,neural_course,1.0
419,How does a Reduced Boltzman Machine work (main idea)?,233,"['recurrent', 'network', 'operates', 'flipping', 'two', 'group', 'neuron', 'visible', 'neuron', 'hidden', 'neuron', 'visible', 'neuron', 'provides', 'interaction', 'environment', 'network', 'hidden', 'neuron', 'running', 'freely', 'two', 'mode', 'operation', 'clamped', 'state', 'state', 'neuron', 'clamped', 'free', 'running', 'state', 'neuron', 'running', 'free', 'condition']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",2,2.0,neural_networks,neural_course,1.0
420,How does a Reduced Boltzman Machine work (main idea)?,233,[],"['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",0,2.0,neural_networks,neural_course,0.0
421,How does a Reduced Boltzman Machine work (main idea)?,233,"['rum', 'implement', 'combination', 'graphical', 'probabilistic', 'idea', 'using', 'probability', 'activation', 'inspired', 'energy', 'based', 'network', 'present', 'training', 'input', 'rum', 'determine', 'hidden', 'activation', 'based', 'probability', 'net', 'input', 'edge', 'weight', 'clamping', 'training', 'data', 'network', 'sample', 'distribution', 'hidden', 'layer', 'rum', 'try', 'rebuild', 'distribution', 'input', 'data', 'rum', 'may', 'used', 'data', 'completion', 'denoising', 'edge', 'incomplete', 'image', 'completed', 'based', 'learned', 'probability', 'distribution']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",2,2.0,neural_networks,neural_course,1.0
422,How does a Reduced Boltzman Machine work (main idea)?,233,"['rum', 'two', 'layer', 'interconnected', 'recurrent', 'operates', 'flipping', 'internal', 'state', '1', 'unlike', 'boltzmann', 'machine', 'reduced', 'boltzmann', 'machine', 'contain', 'interconnection', 'among', 'layer', 'weight', 'update', 'done', 'difference', 'correlation', 'clamped', 'free', 'running', 'model']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",2,2.0,neural_networks,neural_course,1.0
423,How does a Reduced Boltzman Machine work (main idea)?,233,"['consists', 'two', 'layer', 'input', 'hidden', 'layer', 'training', 'data', 'presented', 'input', 'hidden', 'layer', 'start', 'oscillating']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",0,2.0,neural_networks,neural_course,0.0
424,How does a Reduced Boltzman Machine work (main idea)?,233,"['reduced', 'boatman', 'machine', 'stochastic', 'recurrent', 'anna', 'operates', 'two', 'class', 'neuron', 'hidden', 'visible', 'operates', 'neuronflipping', 'probability', 'impacted', 'neuron', 'around', 'us', 'lesbian', 'rule', 'reduced', 'boatman', 'machine', 'learn', 'classify', 'data', 'reproduce', 'learned', 'pattern']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",2,2.0,neural_networks,neural_course,1.0
425,How does a Reduced Boltzman Machine work (main idea)?,233,"['strutted', 'rum', 'bitpartied', 'graph', 'us', 'lesbian', 'learning', 'training', 'neuron', 'used', 'binary', 'stochastic', 'neuron', 'binary', 'state', 'fire', 'based', 'probability', 'training', 'achieved', 'passing', 'information', 'many', 'time', 'hidden', 'layer', 'input', 'layer', 'weightsare', 'updated', 'pas', 'hidden', 'layer', 'weighs', 'input', 'activation', 'hidden', 'layer', 'increased', 'weight', 'generated', 'input', 'rum', 'hidden', 'layer', 'decreased']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",2,2.0,neural_networks,neural_course,1.0
426,How does a Reduced Boltzman Machine work (main idea)?,233,"['main', 'idea', 'rum', 'defined', 'follows', 'two', 'layer', 'defined', 'neuron', 'connected', 'every', 'neuron', 'layer', 'input', 'passed', 'first', 'layer', 'second', 'one', 'state', 'neuron', 'second', 'layer', 'calculated', 'neuron', 'active', 'state', 'pas', 'value', 'input', 'layer', 'value', 'given', 'second', 'layer', 'compared', 'input', 'value', 'two', 'state', 'weight', 'adjusted']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",1,2.0,neural_networks,neural_course,0.5
427,How does a Reduced Boltzman Machine work (main idea)?,233,[],"['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",0,2.0,neural_networks,neural_course,0.0
428,How does a Reduced Boltzman Machine work (main idea)?,233,"['neural', 'network', 'one', 'hidden', 'layer', 'neuron', 'input', 'hidden', 'layer', 'fully', 'connected', 'neuron', 'hidden', 'layer', 'output', 'layer', 'fully', 'connected', 'well']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",0,2.0,neural_networks,neural_course,0.0
429,How does a Reduced Boltzman Machine work (main idea)?,233,"['reduced', 'boatman', 'machine', 'work', 'flipping', 'neuron', 'operate', 'clamped', 'free', 'running', 'state', 'two', 'connected', 'neuron', 'activated', 'time', 'weight', 'increased', 'two', 'neuron', 'fired', 'asynchronously', 'weight', 'reduced', 'removed']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",1,2.0,neural_networks,neural_course,0.5
430,How does a Reduced Boltzman Machine work (main idea)?,233,"['reduced', 'boatman', 'machine', 'reduced', 'input', 'share', 'information', 'via', 'synapsis', 'one', 'initial', 'nun', 'consists', 'input', 'layer', 'hidden', 'layer', 'system', 'adapts', 'internal', 'weight', 'try', 'reproduce', 'input']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",1,2.0,neural_networks,neural_course,0.5
431,How does a Reduced Boltzman Machine work (main idea)?,233,"['rum', 'shallow', 'two', 'layer', 'network', 'containing', 'visible', 'hidden', 'layer', 'node', 'visible', 'layer', 'connected', 'node', 'hidden', 'layer', 'considered', 'restricted', 'two', 'node', 'one', 'layer', 'share', 'connection', 'rum', 'mathematical', 'equivalent', 'two', 'way', 'translator', 'forward', 'pas', 'rum', 'take', 'input', 'translates', 'set', 'number', 'encode', 'input', 'backward', 'pas', 'take', 'set', 'number', 'translates', 'back', 'form', 'reconstructed', 'input', 'well', 'trained', 'rum', 'able', 'perform', 'backward', 'translation', 'higher', 'degree', 'accuracy', 'three', 'step', 'repeated', 'training', 'process', 'forward', 'pas', 'backward', 'pas', 'evaluate', 'quality', 'reconstruction', 'visible', 'layer', 'often', 'solved', 'al', 'divergence']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",1,2.0,neural_networks,neural_course,0.5
432,How does a Reduced Boltzman Machine work (main idea)?,233,[],"['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",0,2.0,neural_networks,neural_course,0.0
433,How does a Reduced Boltzman Machine work (main idea)?,233,[],"['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",0,2.0,neural_networks,neural_course,0.0
434,How does a Reduced Boltzman Machine work (main idea)?,233,"['rum', 'unsupervised', 'learning', 'technique', 'visible', 'neuron', 'hidden', 'neuron', 'neuron', 'either', '1', '1', 'state', 'us', 'idea', 'simulated', 'appealing', 'flip', 'neuron', 'state', 'based', 'energy', 'function', 'pseudo', 'temperature', 'operates', '2', 'state', 'clamped', 'state', 'free', 'flowing', 'state', 'clamped', 'state', 'hidden', 'neuron', 'flipped', 'free', 'flowing', 'state', 'visible', 'hidden', 'neuron', 'flipped', 'weight', 'adjusted', 'based', 'average', 'correlation', 'difference', 'neuron', 'clamped', 'free', 'flowing', 'state']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",2,2.0,neural_networks,neural_course,1.0
435,How does a Reduced Boltzman Machine work (main idea)?,233,[],"['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",0,2.0,neural_networks,neural_course,0.0
436,How does a Reduced Boltzman Machine work (main idea)?,233,"['rim', 'work', 'principle', 'binary', 'state', 'freerunning', 'clamped', 'weight', 'update', 'done', 'based', 'botlzmanns', 'formula', 'using', 'pseudotemperature', 'give', 'probability', 'error']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",1,2.0,neural_networks,neural_course,0.5
437,How does a Reduced Boltzman Machine work (main idea)?,233,"['reduced', 'boatman', 'machine', 'function', 'using', 'two', 'type', 'neuron', 'visible', 'neuron', 'provide', 'interface', 'environment', 'network', 'hidden', 'neuron', 'operate', 'freely', 'learning', 'proceed', 'two', 'condition', 'namely', '1', 'clamped', 'state', 'visible', 'neuron', 'clamped', 'particular', 'state', 'environment', '2', 'free', 'running', 'state', 'visible', 'hidden', 'neuron', 'operate', 'freely', 'rhoij', 'indicates', 'probability', 'correlation', 'state', 'neuron', 'clamped', 'state', 'rhoij', 'indicates', 'probability', 'correlation', 'state', 'neuron', 'free', 'running', 'state', 'weight', 'adjustment', 'delta', 'wij', 'beta', 'rhoij', 'rhoij']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",2,2.0,neural_networks,neural_course,1.0
438,How does a Reduced Boltzman Machine work (main idea)?,233,"['reduced', 'boltzmann', 'machine', 'rbm', 'consists', 'two', 'layer', 'neuron', 'visible', 'hidden', 'neuron', 'may', 'two', 'state', 'idea', 'activated', 'flip', 'according', 'certain', 'probability', 'based', 'weight', 'state', 'neuron', 'rum', 'two', 'modest', '1', 'clamped', 'visible', 'layer', 'clamped', 'certain', 'input', 'hidden', 'neuron', 'allowed', 'change', 'state', 'network', 'settle', 'correlation', 'state', 'given', 'rhoij', '2', 'freerunning', 'state', 'network', 'allowed', 'flip', 'neuron', 'settle', 'correlation', 'rhoij', 'weight', 'update', 'rule', 'given', 'delta', 'wij', 'beta', 'rhoij', 'rhoij']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",2,2.0,neural_networks,neural_course,1.0
439,How does a Reduced Boltzman Machine work (main idea)?,233,"['boltzmann', 'machine', 'neural', 'network', 'recurrent', 'structureit', 'two', 'state', 'either', '1', '1the', 'energy', 'function', 'given', '11expdelta', 'etemperature', 'state', 'input', 'turned', '1', '1', 'based', 'change', 'energy', 'delta', 'pseudo', 'temperature']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",1,2.0,neural_networks,neural_course,0.5
440,How does a Reduced Boltzman Machine work (main idea)?,233,"['neuron', 'operate', 'binary', 'state', 'clamped', 'condition', 'visible', 'neuron', 'clamped', 'specific', 'state', 'environment', 'free', 'running', 'condition', 'neuron', 'including', 'visible', 'hidden', 'neuron', 'operate', 'freely']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",1,2.0,neural_networks,neural_course,0.5
441,How does a Reduced Boltzman Machine work (main idea)?,233,"['us', 'energy', 'function', 'oversee', 'learning', 'process']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",0,2.0,neural_networks,neural_course,0.0
442,How does a Reduced Boltzman Machine work (main idea)?,233,"['reduced', 'boatman', 'machine', 'work', 'based', 'flipping', 'operation', 'calculating', 'probability', 'variance', 'clamped', 'state', 'freely', 'running', 'state']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",1,2.0,neural_networks,neural_course,0.5
443,How does a Reduced Boltzman Machine work (main idea)?,233,"['rim', 'run', 'boltzmann', 'learning', 'rule', 'neuron', '2', 'mode', 'operation', 'clipped', 'free', 'running', 'neuron', 'binary', 'unit', 'status', 'changed', 'flipping', 'neuron', 'position', 'clipped', 'together']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",1,2.0,neural_networks,neural_course,0.5
444,How does a Reduced Boltzman Machine work (main idea)?,233,"['structure', 'recurrent', 'neural', 'network', 'two', 'layer', 'neuron', 'visible', 'hidden', 'neuron', 'store', 'binary', 'value', 'work', 'based', 'flipping', 'mode', 'free', 'running', 'clamped', 'weight', 'change', 'based', 'correlation', 'neuron', 'free', 'running', 'mode', 'clamped', 'mode']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",1,2.0,neural_networks,neural_course,0.5
445,How does a Reduced Boltzman Machine work (main idea)?,233,"['reduced', 'boatman', 'machine', 'one', 'visible', 'least', 'one', 'hidden', 'layer', 'visible', 'layer', 'input', 'act', 'output', 'time', 'input', 'neuron', 'visible', 'layer', 'assigned', 'value', 'weight', 'hidden', 'neuron', 'may', 'either', 'activated', 'input', 'passed', 'hidden', 'layer', 'value', 'passed', 'way', 'back', 'visible', 'layer', 'different', 'weight', 'used', 'since', 'value', 'move', 'opposite', 'direction']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",1,2.0,neural_networks,neural_course,0.5
446,How does a Reduced Boltzman Machine work (main idea)?,233,"['rim', 'two', 'state', 'free', 'running', 'clamped', 'state', 'clamped', 'state', 'input', 'neuron', 'clamped', 'output', 'neuron', 'network', 'clamped', 'probability', 'hidden', 'state', 'certain', 'state', 'calculated', 'determine', 'probability', 'output', 'correct']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",1,2.0,neural_networks,neural_course,0.5
447,How does a Reduced Boltzman Machine work (main idea)?,233,"['reduced', 'boatman', 'machine', 'hast', 'input', 'layer', 'hidden', 'layer', 'neuron', 'state', 'probability', 'turn', 'neuron', 'turn', 'data', 'pass', 'trough', 'weight', 'updated', 'probability', 'turning', 'calculated', 'network']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",1,2.0,neural_networks,neural_course,0.5
448,How does a Reduced Boltzman Machine work (main idea)?,233,"['two', 'fully', 'connected', 'layer', 'one', 'input', 'one', 'hidden', 'layer', 'used', 'input', 'layer', 'connection', 'environment', 'rum', 'specified', 'energy', 'level', 'changed', 'however', 'distribution', 'energy', 'node', 'changed', 'based', 'data', 'input', 'every', 'node', 'chance', 'flip', 'based', 'input', 'connection']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",1,2.0,neural_networks,neural_course,0.5
449,How does a Reduced Boltzman Machine work (main idea)?,233,"['binary', 'state', 'neuron', 'flipped', 'given', 'probability', 'stochastic', 'learning']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",0,2.0,neural_networks,neural_course,0.0
450,How does a Reduced Boltzman Machine work (main idea)?,233,"['neuron', 'state', 'edge', 'neuron', 'probability', 'flip', 'one', 'state', 'another']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",0,2.0,neural_networks,neural_course,0.0
451,How does a Reduced Boltzman Machine work (main idea)?,233,[],"['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",0,2.0,neural_networks,neural_course,0.0
452,How does a Reduced Boltzman Machine work (main idea)?,233,"['main', 'idea', 'rum', 'compute', 'least', 'mean', 'square', 'error', 'difference', 'expected', 'output', 'real', 'output']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",0,2.0,neural_networks,neural_course,0.0
453,How does a Reduced Boltzman Machine work (main idea)?,233,[],"['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",0,2.0,neural_networks,neural_course,0.0
454,How does a Reduced Boltzman Machine work (main idea)?,233,"['recurrent', 'neural', 'network', 'us', 'two', 'group', 'neuron', 'hidden', 'visible', 'process', 'training', 'data', 'flipping', 'neuron']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",1,2.0,neural_networks,neural_course,0.5
455,How does a Reduced Boltzman Machine work (main idea)?,233,"['reduced', 'boatman', 'machine', 'departed', 'two', 'part', 'recurrent', 'nna', 'two', 'layer', 'visible', 'hidden', 'layer', 'reduced', 'boatman', 'machine', 'neuron', 'two', 'state', 'namely', 'depending', 'current', 'time', 'step', 'time', 'step', 'state', 'neuron', 'flipped', 'visible', 'layer', 'represent', 'interface', 'connection', 'environment', 'hidden', 'layer', 'operates', 'clamped', 'mode', 'limited', 'value', 'environment', 'hidden', 'layer', 'operates', 'free', 'model']","['reduced', 'boltzmann', 'machine', 'imparted', 'graph', 'work', 'flipping', 'state', 'binary', 'neuron', 'based', 'probability', 'determined', 'activation', 'produced', 'neuron', 'neuron', 'arranged', 'visible', 'hidden', 'layer', 'recurrent', 'fashion', 'two', 'state', 'involved', 'called', 'clamped', 'state', 'visible', 'neuron', 'connected', 'input', 'free', 'running', 'state', 'layer', 'run', 'free']",2,2.0,neural_networks,neural_course,1.0
456,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'atleast', 'one', 'cyclic', 'feedback', 'connection', 'en', 'consists', 'dynamic', 'reservoir', 'output', 'layer', 'neuron', 'dynamic', 'reservoir', 'consists', 'randomly', 'initialized', 'neuron', 'random', 'structure', 'connection', 'atleast', 'one', 'feedback', 'connection', 'output', 'layer', 'combine', 'dynamic', 'behaviour', 'reservoir', 'required', 'fashion', 'weight', 'output', 'neuron', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'could', 'persisting', 'activation', 'even', 'input', 'case', 'nna', 'en', 'approximate', 'dynamic', 'system']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
457,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'network', 'recurrent', 'neural', 'network', 'mean', 'network', 'feedback', 'feedforward', 'neural', 'network', 'feedback', 'feedfoward', 'training', 'data', 'input', 'dependent', 'system', 'memory', 'sense', 'training', 'input', 'dependent', 'system', 'memory', 'echo', 'state', 'network', 'fixed', 'random', 'generate', 'reservoir', 'weight', 'weight', 'trained', 'output', 'weight', 'trained']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
458,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['en', 'recurrent', 'neural', 'network', 'many', 'layer', 'fixed', 'weight', 'several', 'difference', 'en', 'cycle', 'mean', 'within', 'network', 'backwards', 'connection', 'feedforwad', 'connection', 'within', 'weight', 'trained', 'within', 'en', 'output', 'weight', 'trained', 'en', 'produce', 'output', 'without', 'input', 'need', 'input', 'produce', 'output']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
459,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['en', 'different', 'finn', 'far', 'consist', 'reservoir', 'hidden', 'neuron', 'may', 'connected', 'recurrent', 'opposed', 'feed', 'forward', 'architecture', 'input', 'connected', 'recurrent', 'dynamic', 'reservoir', 'whereas', 'connected', 'linear', 'output', 'layer', 'output', 'layer', 'may', 'connected', 'dry', 'whereas', 'training', 'weight', 'last', 'layer', 'learned', 'weight', 'en', 'thus', 'initialized', 'never', 'learning', 'although', 'since', 'extended', 'minimal', 'complexity', 'architecture']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
460,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['en', 'recurrent', 'neural', 'network', 'large', 'reservoir', 'echo', 'chamber', 'many', 'node', 'recurrent', 'weight', 'learnt', 'connection', 'reservoir', 'output', 'layer', 'weight', 'learnt', 'node', 'inside', 'reservoir', 'main', 'idea', 'training', 'input', 'layer', 'case', 'state', 'inside', 'reservoir', 'behave', 'certain', 'way', 'weight', 'output', 'layer', 'adjusted', 'match', 'labelled', 'output', 'finn', 'feed', 'forward', 'network', 'ie', 'recurrent', 'connection', 'main', 'difference', 'respect', 'en']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
461,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['eon', 'special', 'class', 'recurrent', 'neural', 'network', 'contrast', 'also', 'allow', 'backward', 'node', 'connection', 'thus', 'able', 'memorize', 'data', 'defined', 'exit', 'input', 'yi', 'output', 'dynamic', 'resaviour', 'weight', 'connecting', 'component', 'dynamic', 'behaviour', 'generated', 'randomly', 'fixed', 'topology', 'including', 'weight', 'never', 'changed', 'weight', 'output', 'layer', 'dynamic', 'behaviour', 'changed', 'training', 'dynamic', 'behaviour', 'allows', 'kind', 'connection', 'node', 'contain', 'memory', 'able', 'remember', 'data', 'also', 'spectral', 'radius']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
462,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['en', 'recurrent', 'ann', 'random', 'sparse', 'fixed', 'interferon', 'connection', 'hidden', 'layer', 'output', 'layer', 'weight', 'get', 'trained', 'network', 'complex', 'model', 'much', 'training', 'successful', 'create', 'new', 'random', 'end', 'training', 'complete', 'en', 'would', 'complex', 'would', 'take', 'long', 'recurrent', 'feedback', 'weight', 'get', 'trained', 'time', 'interferon', 'connection', 'sparkly']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
463,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'network', 'run', 'dynamic', 'reservoir', 'neuron', 'connected', 'typically', 'consists', '100', 'neuron', 'outputlayer', 'consists', 'linear', 'readout', 'dry', 'neuron', 'output', 'layer', 'sum', 'weighted', 'behaviour', 'neuron', 'randomly', 'initialized', 'output', 'layer', 'trained', 'supervised', 'learning', 'main', 'difference', 'en', 'run', 'contrast', 'finn', 'resemble', 'dynamic', 'system', 'usually', 'used', 'time', 'series', 'prediction']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
464,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'input', 'layer', 'interconnected', 'reservoir', 'random', 'initialized', 'group', 'neuron', 'also', 'random', 'interconnection', 'reservoir', 'connected', 'output', 'reservoir', 'adjusted', 'output', 'weight', 'output', 'weight', 'also', 'recurrent', 'connection', 'reservoir', 'state', 'reservoir', 'neuron', 'calculated', 'state', 'output', 'weight', 'output', 'extracted', 'main', 'difference', 'feed', 'forward', 'neural', 'network', 'nna', 'ffnns', 'there', 'recurrence', 'input', 'value', 'passed', 'next', 'layer']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
465,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['en', 'huge', 'recurrent', 'network', 'called', 'dynamic', 'reservoirdr', 'output', 'layer', 'connected', 'train', 'network', 'adapting', 'manipulating', 'connection', 'weight', 'output', 'layer', 'unlike', 'feedforward', 'network', 'en', 'least', 'one', 'loop', 'return', 'output', 'neuron', 'time', 'delay', 'therefore', 'memory', 'network', 'nun', 'dont', 'memory']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
466,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'network', 'recurrent', 'neural', 'network', 'type', 'meaning', 'feedback', 'structure', 'usually', 'connected', 'main', 'difference', 'reservoir', 'hidden', 'layer', 'neuron', 'randomly', 'connected', 'random', 'weight', 'etc', 'learning', 'phase', 'weight', 'outpouring', 'neuron', 'changed', 'required', '100', 'neuron', 'reservoir']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
467,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['en', 'type', 'neural', 'network', 'model', 'us', 'recurrent', 'neural', 'network', 'large', 'random', 'fixed', 'dynamic', 'reservoir', 'remains', 'unchanged', 'training', 'change', 'weight', 'reservoir', 'output', 'layer']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",1,2.0,neural_networks,neural_course,0.5
468,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['eon', 'form', 'recurrent', 'neural', 'network', 'least', 'one', 'recurrent', 'input', 'eon', 'reservoir', 'computer', 'memory', 'activated', 'without', 'input', 'sense', 'instead', 'training', 'evolve', 'network', 'state', 'feeding', 'input', 'sequence', 'eon', 'different', 'nun', 'eon', 'contains', 'least', 'one', 'recurrent', 'connection', 'feedback']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",1,2.0,neural_networks,neural_course,0.5
469,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['basic', 'idea', 'eon', 'use', 'large', 'random', 'fixed', 'recurrent', 'preferred', 'dynamic', 'reservoir', 'train', 'connection', 'reservoir', 'output', 'main', 'difference', 'lie', 'recurrent', 'part', 'network', 'back', 'pass', 'built', 'giving', 'feedback', 'previous', 'layer', 'possible', 'maintain', 'reservoir', 'beforehand', 'suit', 'given', 'problem', 'lack', 'investigation', 'reservoir', 'construction']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
470,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'network', 'esn', 'modified', 'version', 'recurrent', 'network', 'reservoir', 'large', 'number', 'hidden', 'neuron', 'sparselyconnected', 'random', 'fixed', 'weight', 'train', 'end', 'weight', 'connecting', 'reservoir', 'output', 'layer', 'adjusted', 'therefore', 'efficiency', 'better', 'normal', 'recurrent', 'network']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",1,2.0,neural_networks,neural_course,0.5
471,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'network', 'provides', 'structure', 'supervised', 'learning', 'recurrent', 'neural', 'network', 'mainly', 'directs', 'fixed', 'large', 'recurrent', 'neural', 'network', 'providing', 'input', 'stimulus', 'also', 'fix', 'response', 'signal', 'neuron', 'present', 'inside', 'reservoirpool', 'neuron', 'directed', 'get', 'desired', 'response', 'traceable', 'linear', 'combined', 'response', 'signal', 'unlike', 'nose', 'isnt', 'memory', 'also', 'activated', 'without', 'input', 'stimulus', 'whereas', 'case', 'nna', 'require', 'external', 'stimulus', 'activated', 'also', 'neuron', 'need', 'connected', 'one', 'full', 'cycle']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
472,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'newton', 'type', 'run', 'dynamic', 'reservoir', 'unit', 'exhibit', 'different', 'dynamic', 'weight', 'reservoir', 'unit', 'fixed', 'changed', 'training', 'phase', 'reservoir', 'output', 'weight', 'changed', 'learn', 'input', 'network', 'converge', 'reservoir', 'unit', 'exhibit', 'echo', 'state', 'property', 'ice', 'output', 'depends', 'previous', 'input', 'property', 'satisfied', 'spectral', 'norm', 'reservoir', 'weight', 'le', '1']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
473,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'network', 'recurrent', 'neural', 'network', 'large', 'reservoir', 'oscillator', 'function', 'connected', 'input', 'layer', 'nose', 'considerthe', 'output', 'hidden', 'layer', 'also', 'considered', 'sense', 'output', 'reservoir', 'final', 'output', 'layer', 'considered']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",1,2.0,neural_networks,neural_course,0.5
474,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['en', 'another', 'implementation', 'run', 'training', 'method', 'completely', 'different', 'comprise', 'dynamic', 'reservoir', 'fixed', 'hidden', 'hidden', 'connection', 'make', 'run', 'sparse', 'connectivity', 'output', 'weight', 'connect', 'dynamic', 'unit', 'output', 'reservoir', 'trained', 'using', 'error', 'unlike', 'run', 'hidden', 'weight', 'also', 'trained', 'eon', 'le', 'computational', 'expensive', 'since', 'easily', 'trained', 'experimentation', 'however', 'run', 'use', 'much', 'le', 'hidden', 'unit', 'compared', 'en', 'similar', 'task']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",1,2.0,neural_networks,neural_course,0.5
475,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'network', 'esn', 'neural', 'network', 'us', 'recurrent', 'neural', 'network', 'rnn', 'dynamic', 'reservoir', 'changed', 'training', 'train', 'connection', 'dynamic', 'reservoir', 'output', 'layer', 'echo', 'state', 'network', 'different', 'nun', 'due', 'presence', 'feedback', 'connection', 'dynamic', 'reservoir', 'enables', 'maintain', 'activation', 'even', 'without', 'input', 'unit', 'within', 'dynamic', 'reservoir', 'eon', 'excited', 'differently', 'different', 'input']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
476,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['eon', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'connection', 'based', 'concept', 'reservoir', 'contrast', 'nun', 'cyclic', 'connection', 'additionally', 'en', 'output', 'weight', 'trained', 'reservoir', 'weight', 'whereas', 'nun', 'weight', 'trained', 'en', 'memory', 'nun', 'memory']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
477,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['en', 'refers', 'echo', 'state', 'network', 'echo', 'state', 'network', 'recurrent', 'neural', 'network', 'hidden', 'hidden', 'layer', 'weight', 'selected', 'randomly', 'fixed', 'hidden', 'output', 'layer', 'weight', 'changed', 'learning', 'processsince', 'en', 'recurrent', 'neural', 'network', 'hence', 'output', 'echo', 'network', 'even', 'input', 'net', 'feedback', 'output', 'input']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",1,2.0,neural_networks,neural_course,0.5
478,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['en', 'kind', 'recurrent', 'nna', 'large', 'random', 'fixed', 'run', 'called', 'dynamic', 'reservoir', 'weight', 'connecting', 'reservoir', 'output', 'layer', 'trained', 'en', 'combine', 'desired', 'system', 'function', 'inputoutput', 'history', 'echo', 'function']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",1,2.0,neural_networks,neural_course,0.5
479,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['en', 'provides', 'architecture', 'supervised', 'learning', 'principle', 'run', 'different', 'nose', 'reservoir', 'based', 'run', 'find', 'non', 'linear', 'signal', 'response', 'combine', 'desired', 'output', 'traceable', 'linear', 'combination', 'response']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",1,2.0,neural_networks,neural_course,0.5
480,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'network', 'recurrent', 'neural', 'network', 'dynamic', 'reservoir', 'weight', 'initialized', 'dynamic', 'reservoir', 'updated', 'training', 'weight', 'output', 'layer', 'readout', 'state', 'updated', 'iteration', 'nna', 'neuron', 'connected', 'neuron', 'next', 'layer', 'weight', 'updated', 'iteration', 'end', 'neuron', 'connected', 'randomly', 'neuron', 'recursive', 'weight', 'updated', 'dynamic', 'reservoir']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
481,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['en', 'type', 'run', 'dynamic', 'reservoir', 'neuron', 'connected']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",1,2.0,neural_networks,neural_course,0.5
482,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'network', 'large', 'number', 'recurrent', 'neural', 'network', 'set', 'run', 'called', 'dynamic', 'reservoir', 'approximate', 'dynamic', 'model', 'train', 'model', 'changing', 'weight', 'connection', 'output', 'dynamic', 'reservoir', 'output', 'network', 'approximate', 'continuous', 'function', 'train', 'adapting', 'weight', 'network']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
483,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'network', 'contains', 'input', 'layer', 'connected', 'reservoir', 'big', 'recurrent', 'network', 'output', 'layer', 'connected', 'neuron', 'reservoir', 'learning', 'end', 'weight', 'reservoir', 'output', 'layer', 'changed', 'change', 'within', 'reservoir', 'difference', 'feed', 'forward', 'network', 'reservoir', 'recurrent', 'training', 'weight', 'changed', 'one', 'output', 'layer', 'reservoir']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",1,2.0,neural_networks,neural_course,0.5
484,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['contrast', 'regular', 'feedforward', 'network', 'en', 'belongs', 'group', 'recurrent', 'neural', 'network', 'regular', 'input', 'layer', 'like', 'come', 'dynamic', 'reservoir', 'layer', 'neuron', 'least', 'one', 'full', 'cycle', 'connection', 'neuron', 'given', 'connection', 'inside', 'reservoir', 'constrained', 'thus', 'possible', 'connection', 'reservoir', 'randomly', 'initialized', 'kept', 'way', 'respective', 'connection', 'output', 'layer', 'trained', 'learning', 'process']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",1,2.0,neural_networks,neural_course,0.5
485,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['en', 'input', 'layer', 'connected', 'reservoir', 'recurrent', 'neural', 'network', 'reservoir', 'connected', 'output', 'layer', 'connection', 'output', 'layer', 'weight', 'updated', 'network', 'weight', 'reservoir', 'chosen', 'randomly', 'updated']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",1,2.0,neural_networks,neural_course,0.5
486,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['en', 'recurrent', 'neural', 'network', 'consists', 'input', 'layer', 'dynamic', 'reservoir', 'output', 'layer', 'dynamic', 'reservoir', 'feedback', 'loop', 'possible', 'contrast', 'feedforward', 'network', 'however', 'dynamic', 'reservoir', 'randomly', 'initialed', 'learned', 'connection', 'output', 'reservoir', 'learned', 'normally', 'nun', 'connection', 'trained']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",1,2.0,neural_networks,neural_course,0.5
487,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'network', 'dynamic', 'reservoir', 'hidden', 'layer', 'dynamic', 'reservoir', 'consists', 'recurrent', 'nonlinear', 'neuron', 'linear', 'connection', 'dynamic', 'reservoir', 'output', 'layer', 'trained', 'difference', 'en', 'recurrent', 'network']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",1,2.0,neural_networks,neural_course,0.5
488,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['core', 'en', 'arbitrary', 'network', 'recurrence']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",0,2.0,neural_networks,neural_course,0.0
489,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'network', 'dynamic', 'reservoir', 'echo', 'state', 'property', 'randomly', 'initialized', 'run', 'hence', 'maintain', 'internal', 'state', 'possible', 'nna', 'run', 'feedback', 'connection', 'echo', 'back', 'state', 'reservoir', 'well', 'previously', 'applied', 'input', 'hence', 'model', 'dynamic', 'system', 'possible', 'funny']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",1,2.0,neural_networks,neural_course,0.5
490,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['en', 'run', 'recurrent', 'neural', 'network', 'least', 'one', 'feedback', 'cycle', 'normally', 'forward', 'moving', 'network', 'input', 'one', 'layer', 'fed', 'next', 'layer', 'generated', 'output', 'en', 'put', 'fed', 'back', 'input', 'en', 'tend', 'revoir', 'randomly', 'connected']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",0,2.0,neural_networks,neural_course,0.0
491,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['echo', 'state', 'network', 'type', 'neural', 'network', 'recurrent', 'network', '100', '1000', 'neuron', 'called', 'dynamic', 'reservoir', 'hidden', 'layer', 'weight', 'choose', 'randomly', 'synaptic', 'weight', 'reservoir', 'output', 'layer', 'adjusted', 'learning', 'process', 'different', 'nun', 'following', 'regard', '1', 'en', 'atleast', 'one', 'loop', 'whereas', 'nun', 'dont', '2', 'output', 'weight', 'adjusted', 'en', 'nun', 'input', 'output', 'weight', 'adjusted', '3', 'en', 'memory', 'nun', 'dont']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
492,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"['en', 'us', 'large', 'set', 'recurrent', 'neuron', 'called', 'reservoir', 'weight', 'reservoir', 'neuron', 'change', 'initialization', 'network', 'year', 'weight', 'reservoir', 'output', 'work', 'well', 'one', 'dimensional', 'time', 'series', 'data', 'feed', 'forward', 'network', 'work', 'differently', 'input', 'feed', 'network', 'layer', 'layer', 'error', 'prepared', 'backward', 'make', 'adjustment', 'till', 'first', 'layer', 'case', 'en', 'adjustment', 'made', 'reservoir', 'output', 'weight']","['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",2,2.0,neural_networks,neural_course,1.0
493,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,[],"['echo', 'state', 'network', 'type', 'recurrent', 'neural', 'network', 'least', 'one', 'cyclic', 'feedback', 'connection', 'weight', 'output', 'layer', 'updated', 'learning', 'en', 'consists', 'feedback', 'connection', 'en', 'approximate', 'dynamic', 'system']",0,2.0,neural_networks,neural_course,0.0
494,Describe: the structure on an CNN.,235,"['convolution', 'neural', 'network', 'layer', 'order', '1', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'incase', 'first', 'layer', 'feature', 'map', 'otherwise', '2', 'activation', 'layer', 'rely', 'activation', '3', 'pooling', 'layer', 'max', 'average', 'pooling', '3', 'layer', 'repeated', 'number', 'time', '4', 'finally', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",2,2.0,neural_networks,neural_course,1.0
495,Describe: the structure on an CNN.,235,"['mainly', 'three', 'layer', 'convolution', 'layer', 'used', 'capture', 'lowlevel', 'high', 'level', 'feature', 'using', 'kernel', 'image', 'ii', 'pooling', 'layer', 'used', 'dimensionality', 'reduction', 'translation', 'variance', 'iii', 'fully', 'connected', 'layer', 'layer', 'regular', 'nose', 'node', 'fully', 'connected', 'mostly', 'sigmoid', 'activation', 'function', 'used', 'compute', 'probability', 'outputclass', 'furthermore', 'can', 'use', 'rectified', 'linear', 'unitrelu', 'activation', 'function']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",2,2.0,neural_networks,neural_course,1.0
496,Describe: the structure on an CNN.,235,"['convolution', 'neural', 'network', 'kernel', 'much', 'smaller', 'input', 'operate', 'much', 'efficient', 'normal', 'neural', 'network', 'normal', 'neural', 'network', 'time', 'convolution', 'neural', 'network', 'time', 'kid', 'much', 'smaller', 'convolution', 'network', 'operates', 'large', 'image', 'input', 'repressed', 'many', 'layer', 'given', 'normal', 'neural', 'network', 'reprocessing', 'transforms', 'input', 'linear', 'separate', 'problem']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
497,Describe: the structure on an CNN.,235,"['learn', 'grid', 'data', 'image', 'ad', 'volume', 'using', 'filter', 'instead', 'matrix', 'multiplication', 'filter', 'convoluted', 'input', 'convolution', 'layer', 'per', 'neuron', 'slide', 'filter', 'defined', 'filter', 'size', 'stimes', 'input', 'stride', 'step', 'size', 'optional', 'zero', 'padding', 'strictly', 'speaking', 'since', 'rob', 'image', 'working', 'three', 'color', 'channel', 'work', 'volume', 'filter', 'example', 'rob', 'image', 'size', '32times', '32times', '3', 'filter', 'window', 'size', 's5', 'dimension', '5times5times3', 'instead', 'learning', 'volume', 'weight', 'convolution', 'step', 'share', 'weight', 'considering', 'one', 'feature', 'detected', 'one', 'part', 'image', 'may', 'interest', 'another', 'part', 'apply', 'nonlinearity', 'commonly', 'rely', 'activation', 'introduce', 'nonlinearity', 'model', 'reduce', 'spatial', 'size', 'input', 'either', 'use', 'higher', 'striped', 'convolution', 'layer', 'pooling', 'layer', 'example', 'popular', 'max', 'pooling', 'layer', 'maximum', 'value', 'subvolume', 'picked', 'layer', 'stacked', 'last', 'layer', 'fully', 'connected', 'neuron', 'typically', 'used', 'reduce', 'data', 'example', 'classification', 'vector']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",2,2.0,neural_networks,neural_course,1.0
498,Describe: the structure on an CNN.,235,"['us', 'convolution', 'instead', 'matrix', 'multiplication', 'non', 'linearity', 'may', 'function', 'like', 'relax', 'also', 'pooling', 'stage', 'used', 'pool', 'important', 'feature', 'can', 'translation', 'invartiant']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
499,Describe: the structure on an CNN.,235,"['convolution', 'neural', 'network', 'consists', 'convolution', 'layer', 'convolution', 'layer', 'applies', 'one', 'multiple', 'kernel', 'matrix', 'input', 'vectormatrix', 'typically', 'image', 'instead', 'connecting', 'single', 'input', 'input', 'vector', 'next', 'layer', 'separate', 'weight', 'instead', 'training', 'kernel', 'updated', 'convolution', 'layer', 'typical', 'pooling', 'layer', 'given', 'window', 'size', 'reduce', 'dimensional', 'size', 'output', 'convolution', 'layer', 'using', 'edge', 'max', 'ave', 'pooling', 'afterwards', 'activation', 'layer', 'applies', 'activation', 'function', 'output', 'pooling', 'layer', 'end', 'typically', 'fully', 'connected', 'regular', 'layer', 'resulting', 'softmax', 'activation', 'function', 'assigns', 'probability', 'class', 'output']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",2,2.0,neural_networks,neural_course,1.0
500,Describe: the structure on an CNN.,235,"['convalutional', 'neuron', 'network', 'assumes', 'input', 'image', 'architecture', 'abwechselnt', 'coalition', 'subsampling', 'layer', 'last', 'subsampling', 'layer', 'normal', 'classify', 'input']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
501,Describe: the structure on an CNN.,235,"['typically', 'consists', 'multiple', 'layer', 'fully', 'connected', 'network', 'layer', 'ill', 'assume', 'fully', 'connected', 'part', 'relevant', 'question', 'layer', 'typically', 'convolution', 'layer', 'pooling', 'layer', 'convolution', 'layer', 'kernel', 'involved', 'onto', 'input', 'zero', 'padding', 'used', 'result', 'dimensionality', 'depending', 'kernel', 'convolution', '2', 'pooling', 'layer', 'result', 'convolution', 'reduced', 'focus', 'ont', 'important', 'feature', 'also', 'help', 'transnational', 'invariance']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",2,2.0,neural_networks,neural_course,1.0
502,Describe: the structure on an CNN.,235,"['convolution', 'neural', 'network', 'following', 'structure', 'input', 'defined', 'grid', 'image', 'video', 'sequence', 'used', 'several', 'number', 'convolution', 'layer', 'also', 'subsampling', 'pooling', 'used', 'convolution', 'step', 'filter', 'used', 'layer', 'applying', 'multiple', 'convolution', 'layer', 'normal', 'feedforward', 'network', 'applied', 'example', 'back', 'propagation', 'algorithm', 'used', 'updating', 'weight', 'numerous', 'iteration']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
503,Describe: the structure on an CNN.,235,"['network', 'consists', 'input', 'layer', 'conclusion', 'layer', 'detection', 'layer', 'pooling', 'layer', 'next', 'layerbecause', 'consists', 'many', 'layer', 'another', 'block', 'layer', 'similar', 'described']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
504,Describe: the structure on an CNN.,235,"['convolution', 'neural', 'network', 'first', 'layer', 'fully', 'connected', 'way', 'neuron', 'connection', 'overlap', 'leading', 'grid', 'type', 'structure', 'overlapping', 'circle', 'another', 'layer', 'connected', 'node', 'responsible', 'particular', 'feature', 'convolution', 'next', 'layer', 'choosing', 'convolution', 'ensemble', 'appropriate', 'next', 'layer', 'fully', 'connected', 'output', 'neuron']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
505,Describe: the structure on an CNN.,235,"['input', 'layer', 'input', 'layer', 'connected', 'convolution', 'layer', 'consisting', 'three', 'phase', 'convolution', 'stage', 'detector', 'stage', 'pooling', 'stage', 'next', 'layer', 'traditional', 'funny']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
506,Describe: the structure on an CNN.,235,"['can', 'feed', 'forward', 'neural', 'network', 'replaces', 'matrix', 'multiplication', 'task', 'convolution', 'operation', 'much', 'sparse', 'contain', 'following', 'stage', 'convolution', 'learns', 'local', 'feature', 'max', 'pooling', 'coarsegraining', 'learn', 'better', 'abstraction', 'input', 'image']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
507,Describe: the structure on an CNN.,235,"['comparison', 'nna', 'matrix', 'multiplication', 'replaced', 'convolution', 'everything', 'else', 'remains']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",0,2.0,neural_networks,neural_course,0.0
508,Describe: the structure on an CNN.,235,"['covolutional', 'neural', 'network', 'contains', 'set', 'hidden', 'layer', 'feature', 'extraction', 'convolutional', 'layer', 'pooling', 'layer', 'fullyconnected', 'layer', 'classifies', 'feature', 'covolutional', 'layer', 'used', 'carry', 'revolution', 'incoming', 'signal', 'set', 'filter', 'resulting', 'set', 'feature', 'map', 'pooling', 'layer', 'used', 'reduce', 'dimensionality', 'feature', 'map', 'make', 'feature', 'variant', 'rotation', 'displacement']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
509,Describe: the structure on an CNN.,235,"['1', 'start', 'input', 'perform', 'convolution', 'provides', 'piece', 'activation', '2', 'next', 'sent', 'activation', 'layer', 'otherwise', 'known', 'detection', 'layer', '3', 'final', 'stage', 'pooling']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
510,Describe: the structure on an CNN.,235,"['different', 'kernel', 'used', 'extracting', 'certain', 'property', 'input', 'called', 'feature', 'map', 'detection', 'phase', 'introduces', 'nonlinearity', 'pooling', 'introduces', 'transnational', 'invariance', 'many', 'layer', 'feature', 'map', 'pooling', 'finally', 'reduced', 'single', 'row', 'input', 'trained', 'using', 'traditional', 'method', 'like', 'back', 'propagation', 'algorithm']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",2,2.0,neural_networks,neural_course,1.0
511,Describe: the structure on an CNN.,235,"['convolution', 'neural', 'network', '4', 'main', 'layer', 'input', 'layer', 'connected', 'convolution', 'subsampling', 'layer', 'followed', 'another', 'set', 'convolution', 'subsampling', 'layer', 'connected', 'output', 'layer', 'designed', 'specifically', 'recognize', 'shape', 'variant', 'skewing', 'rotation', 'actual', 'location', 'object']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
512,Describe: the structure on an CNN.,235,"['comprises', 'multiple', 'layer', 'neuron', 'perform', 'specific', 'task', 'initial', 'layer', 'convolution', 'layer', 'performs', 'convolution', 'input', 'element', 'given', 'kernel', 'simpler', 'task', 'edge', 'detection', 'performed', 'detector', 'layer', 'form', 'second', 'layer', 'output', 'convolution', 'layer', 'fed', 'activation', 'function', 'relax', 'data', 'pooled', 'pooling', 'layer', 'downsamping', 'done', 'reduce', 'dimensionality', 'layer', 'repeated', 'perform', 'complex', 'feature', 'extraction', 'operation']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
513,Describe: the structure on an CNN.,235,"['neural', 'network', 'replaces', 'matrix', 'multiplication', 'mathematical', 'operation', 'called', 'convolution', 'one', 'layer', 'main', 'idea', 'behind', 'structure', 'replace', 'activation', 'neuron', 'flipped', 'filter', 'convolution', 'layer', 'apply', 'another', 'function', 'called', 'pooling', 'dust', 'output']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
514,Describe: the structure on an CNN.,235,"['consists', 'several', 'stacked', 'convolution', 'layer', 'separated', 'layer', 'pooling', 'activation', 'zeropadding', 'dropout', 'form', 'regularization', 'output', 'layer', 'generally', 'dependent', 'task', 'could', 'softmax', 'activation', 'fully', 'connected', 'also', 'called', 'densely', 'connected', 'layer', 'number', 'output', 'usually', 'number', 'class']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",2,2.0,neural_networks,neural_course,1.0
515,Describe: the structure on an CNN.,235,"['structure', 'follows', 'convolution', 'layer', 'convolution', 'take', 'place', 'instead', 'matrix', 'multiplication', 'deconvolution', 'layer', 'deconvolution', 'take', 'place', 'matrix', 'multiplication', 'average', 'weight', 'layer', 'max', 'pooling', 'layer']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
516,Describe: the structure on an CNN.,235,"['1', 'first', 'stage', 'layer', 'performs', 'several', 'convolution', 'parallel', 'produce', 'set', 'linear', 'activation', '2', 'detector', 'stage', 'linear', 'activation', 'run', 'nonlinear', 'activation', '3', 'third', 'stage', 'use', 'pooling', 'function', 'modify', 'output', 'layer']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
517,Describe: the structure on an CNN.,235,"['1', 'convolution', 'matrix', 'multiplication', 'produce', 'output', 'hidden', 'layer', '2', 'deconvolution', 'matrix', 'multiplication', 'transpose', 'matrix', 'apply', 'back', 'propagation', 'error', 'output', 'input', '3', 'weight', 'update', 'apply', 'back', 'propagation', 'error', 'output', 'weight']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
518,Describe: the structure on an CNN.,235,"['input', 'layer', 'convoluted', 'layer', 'caffeine', 'transformation', 'filtering', 'layer', 'sampling', 'learning', 'layer', 'output', 'layer']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
519,Describe: the structure on an CNN.,235,"['basically', 'four', 'type', 'layer', 'convolution', 'layer', 'rely', 'layer', 'pooling', 'layer', 'fully', 'connected', 'layer', 'arrange', 'convolution', 'layer', 'rely', 'layer', 'different', 'way', 'one', 'way', '1', 'convolution', 'layer', '1', 'pooling', 'layer', '1', 'rely', 'layer', 'repeat', '3', 'layer', 'finally', 'fully', 'connected', 'layer', 'another', 'way', '1', 'convolution', 'layer', '1', 'pooling', 'layer', 'repeat', 'convolution', 'pooling', 'layer', '1', 'rely', 'layer', 'finally', 'fully', 'connected', 'layer', 'convolution', 'layer', 'used', 'find', 'feature', 'space']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",2,2.0,neural_networks,neural_course,1.0
520,Describe: the structure on an CNN.,235,"['input', 'layer', 'convolution', 'layer', 'convolution', 'sub', 'sampling', 'feature', 'map', 'take', 'place', 'feed', 'forward', 'neural', 'network', 'layer', 'output', 'layer']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
521,Describe: the structure on an CNN.,235,"['convolution', 'neural', 'network', 'us', 'step', 'convolution', 'subsampling', 'alternating', 'beginning', 'using', 'different', 'kernel', 'convolution', 'many', 'feature', 'map', 'created', 'subsampling', 'step', 'merges', 'map', 'reduce', 'amount', 'step', 'classical', 'feed', 'forward', 'network', 'end', 'transform', 'different', 'feature', 'map', 'one', 'output', 'layer']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
522,Describe: the structure on an CNN.,235,"['concolutional', 'neural', 'network', 'alternating', 'layer', 'convolution', 'pooling', 'convolution', 'layer', 'applying', 'filter', 'input', 'pooling', 'layer', 'subsamples', 'input', 'network', 'replaced', 'striped', 'convolution', 'combine', 'two', 'step', 'one', 'structure', 'end', 'equal', 'regular', 'feedforward', 'network']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
523,Describe: the structure on an CNN.,235,[],"['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",0,2.0,neural_networks,neural_course,0.0
524,Describe: the structure on an CNN.,235,"['basic', 'structured', 'three', 'layer', 'convolution', 'detector', 'pooling', 'first', 'layer', 'convolution', 'operation', 'performed', 'input', 'second', 'layer', 'activation', 'function', 'mostly', 'relax', 'applied', 'result', 'convolution', 'last', 'layer', 'used', 'reduce', 'size', 'resulting', 'convoluted', 'image', 'edge', 'max', 'pooling']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",2,2.0,neural_networks,neural_course,1.0
525,Describe: the structure on an CNN.,235,"['convolution', 'neural', 'network', 'often', 'image', 'video', 'sequence', 'input', 'input', 'computed', 'convolution', 'different', 'kernel', 'downsampling', 'many', 'step', 'smaller', 'many', 'input', 'matrix', 'last', 'step', 'matrix', 'connected', 'classical', 'nna']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
526,Describe: the structure on an CNN.,235,"['consists', 'one', 'convolution', 'layer', 'well', 'subsampling', 'pooling', 'layer', 'followed', 'fully', 'connected', 'standard', 'find', 'convolutution', 'layer', 'kernel', 'used', 'create', 'feature', 'map', 'kernel', 'smaller', 'matrix', 'applied', 'possible', 'position', 'input', 'matrix', 'pooling', 'stage', 'dimension', 'feature', 'map', 'reduced', 'example', 'max', 'pooling']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
527,Describe: the structure on an CNN.,235,"['us', 'convolution', 'layer', 'extract', 'primitive', 'information', 'pattern', 'first', 'data', 'involved', 'first', 'layer', 'extract', 'feature', 'output', 'layer', 'passed', 'rely', 'function', 'rectify', 'downsampled', 'pulling', 'layer', 'basically', 'chooses', 'relevant', 'output', 'convolution', 'layer', 'processing', 'rely', 'chosen', 'instead', 'sigmoid', 'doesnt', 'allow', 'gradient', 'vanish', 'backpropogation']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",2,2.0,neural_networks,neural_course,1.0
528,Describe: the structure on an CNN.,235,"['multiple', 'layer', 'dont', 'use', 'multiplication', 'matrix']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",0,2.0,neural_networks,neural_course,0.0
529,Describe: the structure on an CNN.,235,"['convolution', 'neural', 'networkcnn', 'three', 'main', 'layer', '1', 'convolution', 'layer', '2', 'pooling', 'subsampling', 'layer', '3', 'output', 'layer']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",1,2.0,neural_networks,neural_course,0.5
530,Describe: the structure on an CNN.,235,"['three', 'component', 'input', 'convolution', 'stage', 'feed', 'forward', 'network', 'input', 'pas', 'one', 'convolution', 'stage', 'befor', 'feed', 'feed', 'forward', 'network', 'convolution', 'stage', 'us', 'hierarchical', 'set', 'filter', 'rely', 'polling', 'extract', 'low', 'level', 'well', 'high', 'level', 'concept', 'input', 'feed', 'forward', 'network', 'along', 'us', 'output', 'convolution', 'stage', 'back', 'propagation', 'used', 'make', 'adjustment', 'network', 'weight', 'well', 'filter', 'convolution', 'stage']","['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",2,2.0,neural_networks,neural_course,1.0
531,Describe: the structure on an CNN.,235,[],"['convolution', 'neural', 'network', 'consists', 'many', 'layer', 'convolution', 'layer', 'kernel', 'involve', 'input', 'image', 'activation', 'layer', 'rely', 'activation', 'pooling', 'layer', 'max', 'average', 'pooling', 'one', 'fully', 'connected', 'layer', 'followed', 'softmax', 'layer']",0,2.0,neural_networks,neural_course,0.0
532,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['three', 'item', 'learn', 'rbfn', '1', 'centroid', 'input', 'cluster', '2', 'width', 'cluster', '3', 'weight', 'synapsis', 'connecting', 'hidden', 'layer', 'output', 'layer', 'centroid', 'width', 'learned', 'unsupervised', 'fashion', 'weight', 'supervised', 'fashion', 'run', 'combine', 'unsupervised', 'supervised', 'learning', 'regular', 'completely', 'supervised', 'completely', 'unsupervised', 'learning', 'fast', 'sensitive', 'unsupervised', 'part']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",2,2.0,neural_networks,neural_course,1.0
533,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['ref', 'network', 'need', 'learn', 'centre', 'width', 'gaussian', 'function', 'also', 'learn', 'output', 'weight', 'difference', 'ref', 'nose', 'raft', 'one', 'hidden', 'layer', 'nose', 'one', 'hidden', 'layer', 'ii', 'raft', 'activation', 'function', 'hidden', 'layer', 'gaussian', 'parameter', 'euclidean', 'norm', 'nose', 'parameter', 'activation', 'function', 'product', 'weight', 'input', 'iii', 'parameter', 'computation', 'different', 'ref', 'compute', 'nose', 'like', 'compute', 'centre', 'cluster', 'ref', 'help', 'mean', 'clustering']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",2,2.0,neural_networks,neural_course,1.0
534,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['ref', 'network', 'need', 'learn', 'center', 'activation', 'function', 'difference', 'many', 'activation', 'function', 'data', 'point', 'one', 'con', 'radial', 'basis', 'function', 'due', 'many', 'activation', 'function', 'ref', 'network', 'huge', 'computational', 'effort']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
535,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['raft', 'learn', 'center', 'radial', 'basis', 'function', 'using', 'unsupervised', 'clustering', 'method', 'weight', 'last', 'output', 'layer', 'width', 'radial', 'basis', 'function', 'opposed', 'multi', 'layer', 'nna', 'dont', 'need', 'expensive', 'backpropagation', 'need', 'train', 'last', 'layer', 'unsupervised', 'training', 'algorithm', 'work', 'ref', 'center', 'possible', 'con', 'would', 'ref', 'center', 'dont', 'represent', 'training', 'data', 'point', 'distribution', 'well', 'data', 'point', 'may', 'hard', 'model']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",2,2.0,neural_networks,neural_course,1.0
536,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['1', 'weight', '2', 'centre', 'mean', 'cluster', '3', 'sigma', 'width', 'cluster', 'difference', 'us', 'function', 'radically', 'invariant', 'pro', 'easy', 'learn', 'nonlinearity', 'dependent', 'radial', 'distance', 'con', 'data', 'required', 'overfishing']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",2,2.0,neural_networks,neural_course,1.0
537,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['ref', 'network', 'relies', 'clustering', 'algorithm', 'edge', 'mean', 'clustering', 'three', 'item', 'learned', '1', 'cluster', 'center', '2', 'cluster', 'size', '3', 'weight', 'connecting', 'hidden', 'node', 'output', 'layer', 'difference', 'nose', 'three', 'layer', 'input', 'hidden', 'output', 'node', 'hidden', 'layer', 'us', 'different', 'activation', 'function', 'depended', 'cluster', 'assigned', 'output', 'weight', 'trained']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",2,2.0,neural_networks,neural_course,1.0
538,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['ref', 'network', 'used', 'gauss', 'function', 'activation', 'function', 'think', 'learned', 'centroid', 'acid', 'unsupervised', 'sigma', 'unsupervised', 'weight', 'output', 'layer', 'supervised', 'ref', 'network', 'easy', 'learning', 'sensitive', 'unsupervised', 'learning', 'part']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",2,2.0,neural_networks,neural_course,1.0
539,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['question', 'really', 'unspecified', 'difference', 'nns', 'center', 'width', 'weight', 'main', 'difference', 'ref', 'us', 'localized', 'activation', 'function', 'one', 'hidden', 'layer', 'apply', 'nonlinear', 'transformation', 'input', 'space', 'hidden', 'space', 'linear', 'transformation', 'hidden', 'space', 'output', 'space', 'important', 'use', 'regularization', 'ref', 'ref', 'work', 'well', 'interpolation', 'work', 'good', 'regression']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",2,2.0,neural_networks,neural_course,1.0
540,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['radial', 'basis', 'function', 'network', 'following', 'structure', 'input', 'layer', 'hidden', 'layer', 'nonlinear', 'dimensional', 'transformation', 'used', 'neuron', 'hidden', 'layer', 'defined', 'center', 'extracted', 'previous', 'step', 'linear', 'transformation', 'used', 'hidden', 'data', 'space', 'output', 'calculated', 'three', 'item', 'must', 'learning', 'ref', 'network', 'center', 'hidden', 'neuron', 'using', 'example', 'mean', 'neighbour', 'algorithm', 'radial', 'function', 'used', 'nonlinear', 'transformation', 'weight', 'applied', 'output', 'layer']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",2,2.0,neural_networks,neural_course,1.0
541,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['three', 'item', 'must', 'learned', 'ref', 'center', 'kernel', 'sizestandard', 'deviation', 'kernel']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",0,2.0,neural_networks,neural_course,0.0
542,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,[],"['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",0,2.0,neural_networks,neural_course,0.0
543,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['use', 'distance', 'center', 'argument', 'computation', 'local', 'field', 'use', 'radial', 'basis', 'function', 'activation', 'rib', 'global', 'approximators', 'splitter', 'learning', 'instead', 'global', 'learning']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
544,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['kernel', 'neighbourhood', 'computed', 'based', 'distance', 'radius', 'neighbourhood', 'pro', 'ref', 'simple', 'easy', 'computer', 'con', 'remember', 'data', 'point']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
545,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['difference', 'run', 'single', 'hidden', 'layer', 'nonlinear', 'hidden', 'layer', 'linear', 'output', 'layer', 'argument', 'hidden', 'unit', 'euclidean', 'norm', 'universal', 'approximation', 'property', 'local', 'approximators', 'splitter', 'learning']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
546,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['mean', 'cluster']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",0,2.0,neural_networks,neural_course,0.0
547,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['three', 'item', 'need', 'learnt', 'center', 'width', 'depth', 'compared', 'standard', '3', 'layer', 'structure', 'one', 'hidden', 'layer']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
548,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['ref', 'first', 'input', 'transformed', 'higher', 'dimension', 'using', 'non', 'linear', 'transformation', 'based', 'unsupervised', 'learning', 'input', 'learned', 'using', 'least', 'square', 'estimation', 'supervised', 'learning', 'ref', 'based', 'cover', 'theorem', 'state', 'higher', 'probability', 'data', 'nearly', 'separate', 'higher', 'dimension']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",0,2.0,neural_networks,neural_course,0.0
549,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['ref', 'dependent', 'radial', 'distance', 'ie', 'distance', 'center', 'input']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",0,2.0,neural_networks,neural_course,0.0
550,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['three', 'parameter', 'learned', 'generalized', 'ref', 'cluster', 'center', 'basis', 'function', 'spread', 'width', 'basis', 'function', 'sigma', 'weight', 'connecting', 'input', 'hidden', 'layer', 'ref', 'different', 'nun', 'different', 'way', 'kernel', 'localized', 'function', 'nun', 'globalized', 'use', 'euclidean', 'distance', 'activation', 'function', 'nun', 'use', 'inner', 'product', 'single', 'hidden', 'layer', 'output', 'linear', 'combination', 'nun', 'compulsorily']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
551,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,[],"['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",0,2.0,neural_networks,neural_course,0.0
552,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['three', 'open', 'parameter', 'ref', 'network', '1', 'center', 'acid', '2', 'width', 'sigmai', '3', 'weight', 'win', 'number', 'center', 'sky', 'determined', 'trial', 'error']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
553,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['ref', 'main', 'advantage', 'follows', 'cover', 'theorem', 'complex', 'pattern', 'classification', 'problem', 'solved']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",0,2.0,neural_networks,neural_course,0.0
554,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['1', 'nonlinear', 'transformation', 'function', 'input', 'space', 'feature', 'space', '2', 'center', 'input', 'data', 'used', 'hidden', 'neuron', '3', 'synaptic', 'weight', 'connecting', 'hidden', 'layer', 'output', 'layer']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
555,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,[],"['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",0,2.0,neural_networks,neural_course,0.0
556,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['three', 'item', 'learned', 'origin', 'center', 'pro', 'transform', 'data', 'dimension', 'infinity', 'dimension', 'solve', 'non', 'linear', 'problem', 'easily', 'con', 'may', 'overbite', 'learning', 'slow']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
557,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['center', 'hidden', 'neuron', 'synaptic', 'weight', 'connecting', 'neuron', 'ref', '1', 'hidden', 'layer', 'nonlinear', 'transformation', 'input', 'hidden', 'space', 'linear', 'transformation', 'hidden', 'space', 'output', 'space', 'pro', 'used', 'nonlinearly', 'separate', 'data']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
558,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['1', 'weighs', 'network', '2', 'center', 'cluster', '3', 'variation', 'cluster', 'sigma', 'difference', 'ref', 'always', 'three', 'layer', 'ref', 'also', 'trained', 'unsupervised', 'method', 'ref', 'also', 'approximate', 'continuous', 'function']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
559,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['centroid', 'radial', 'basis', 'function', 'weight', 'neuron', 'amount', 'needed', 'neuron', 'difference', 'neural', 'network', 'centroid', 'radial', 'basis', 'function', 'need']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
560,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['center', 'cluster', 'width', 'cluster', 'weight', 'contrast', 'nun', 'output', 'depends', 'radial', 'distance', 'center', 'cluster']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
561,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['weight', 'interpolation', 'matrix', 'learned', 'ref', 'map', 'input', 'space', 'higher', 'dimensional', 'feature', 'space', 'nonlinearly', 'feature', 'space', 'mapped', 'output', 'space', 'linearly', 'output', 'space', 'much', 'smaller', 'feature', 'space', 'pro', 'local', 'learning', 'con', 'feature', 'space', 'really', 'large', 'curse', 'dimensionality']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
562,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['cluster', 'width', 'basis', 'function', 'weight', 'cluster', 'width', 'learned', 'unsupervised', 'fashion', 'weight', 'learning', 'standard', 'supervised', 'steepest', 'descent', 'method', 'pro', 'ref', 'easily', 'trained', 'ref', 'achieve', 'better', 'result', 'le', 'complexity', 'con', 'easy', 'understand']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",2,2.0,neural_networks,neural_course,1.0
563,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['center', 'radial', 'basis', 'function', 'best', 'model', 'rbf', 'distance', 'input', 'pair', 'pro', 'nonlinear', 'function', 'application', 'ease', 'compute', 'using', 'cover', 'theorem', 'con', 'highdimensional']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
564,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['centroid', 'width', 'parameter', 'function', 'learning', 'run', 'splitter', 'unsupervised', 'supervised', 'part', 'one', 'layer', 'vanishing', 'gradient', 'pro', 'easy', 'learning', 'unsupervised', 'part', 'sensitive', 'con', 'difficult', 'approximate', 'constant']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",2,2.0,neural_networks,neural_course,1.0
565,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['1', 'input', 'layer', 'connecting', 'ref', 'environment', '2', 'hidden', 'layer', 'nonlinear', 'transformation', 'input', 'space', 'hidden', 'space', '3', 'output', 'layer', 'linear', 'transformation', 'hidden', 'space', 'output', 'space', 'different', 'nun', 'learning', 'pattern', 'nonlinear', 'transforms', 'input', 'space', 'higher', 'dimensional', 'space', 'nun', 'transform', 'input', 'transforms', 'input', 'pattern', 'high', 'dimensional', 'nonlinear', 'space', 'pattern', 'separate', 'lower', 'dimension', 'greater', 'chance', 'separated', 'select', 'basis', 'function', 'equal', 'datapoints', 'problem', 'illformulated', 'processing', 'computationallly', 'heavy', 'regulation', 'becomes', 'problem', 'specific', 'hence', 'unsupervised', 'learning', 'employed', 'cluster', 'data', 'initially']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
566,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['data', 'variance', 'feature', 'ref', 'us', 'support', 'vector', 'machine', 'classifier', 'us', 'different', 'kernel', 'doesnt', 'feedback', 'cycle', 'also', 'classifies', 'non', 'linear', 'classification', 'problem', 'mainly', 'work', '2', 'class', 'ca', 'c2', 'also', 'regression', 'feedback', 'rnn']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",0,2.0,neural_networks,neural_course,0.0
567,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['difference', 'ref', 'nun', '1', 'ref', 'one', 'hidden', 'layer', 'whereas', 'hard', 'limitation', 'number', 'hidden', 'layer', 'nun', '2', 'activation', 'function', 'used', 'ref', 'non', 'linear']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",1,2.0,neural_networks,neural_course,0.5
568,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"['ref', 'network', 'learns', 'radial', 'function', 'weight', 'hidden', 'output', 'neuron', 'centroid', 'cluster', 'difference', 'ref', 'composed', 'input', 'layer', '1', 'hidden', 'layer', 'output', 'layer', 'generally', 'use', 'many', 'hidden', 'layer', 'required', 'transformation', 'input', 'hidden', 'layer', 'ref', 'non', 'linear', 'hidden', 'output', 'linear', 'non', 'linear', 'proscons', 'simple', 'learner', 'many', 'variation', 'ref', 'available']","['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",2,2.0,neural_networks,neural_course,1.0
569,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,[],"['three', 'item', 'learned', 'center', 'weight', 'bias', 'run', 'consists', 'single', 'hidden', 'layer', 'linear', 'output', 'layer', 'multiple', 'hidden', 'layer', 'linear', 'nonlinear', 'output', 'layer', 'pro', 'run', 'universal', 'approximate', 'easy', 'add', 'center', 'con', 'bias', 'unique']",0,2.0,neural_networks,neural_course,0.0
570,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['nearest', 'neighbor', '1', 'take', 'input', 'data', 'classified', '2', 'find', 'first', 'nearest', 'neighbour', 'term', 'euclidean', 'distance', '3', 'push', 'class', 'nearest', 'neighbour', 'list', 'label', '4', 'repeat', 'step', '2', '3', 'need', 'odd', '5', 'nearest', 'label', 'collected', 'list', 'count', 'label', 'class', '6', 'assign', 'input', 'data', 'class', 'maximum', 'count', 'majority', 'vote']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
571,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['first', 'initialize', 'random', 'point', 'point', 'considered', 'centroid', 'cluster', 'ii', 'new', 'point', 'compute', 'euclidean', 'distance', 'point', 'closest', 'centroid', 'assigned', 'respective', 'cluster', 'iii', 'recalculate', 'centroid', 'cluster', 'ivy', 'repeat', '2', '3', 'convergence', 'achieved', 'making', 'sure', 'centroid', 'moving', 'cost', 'function', 'minimized']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
572,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['nearest', 'neighbor', 'want', 'determine', 'encoder', 'doc', 'assigns', 'input', 'cluster', 'based', 'rule', 'defined']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
573,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,[],"['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
574,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['1', 'get', 'input', '2', 'find', 'ke', 'nearest', 'neighbour', 'finding', 'distance', 'euclidean', 'input', 'node', 'selecting', 'closest', 'one', '3', 'class', 'input', 'frequent', 'class', 'kneighbnours', 'found', 'need', 'odd', 'number']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
575,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['number', 'cluster', 'given', 'sample', 'data', 'select', 'different', 'cluster', 'center', 'random', 'assign', 'sample', 'point', 'closest', 'cluster', 'repeat', 'change', 'recalculate', 'cluster', 'center', 'assign', 'sample', 'point', 'closest', 'cluster']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
576,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['given', 'fixed', 'sky', 'given', 'point', 'classify', 'new', 'given', 'empty', 'class', 'given', 'list', 'point', '1', 'find', 'nearest', 'point', 'ex', 'new', 'add', 'class', 'nearest', 'point', 'ex', 'list', 'class', 'new', 'list', 'without', 'nearest', 'neighbor', 'ex', 'class', 'new', 'class', 'class']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
577,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['define', 'centroid', 'random', 'initialized', 'assign', 'data', 'point', 'class', 'label', 'change', 'anymore', 'calculate', 'centroid', 'datapoint', 'belonging', 'label', 'datapoint', 'determine', 'nearest', 'centroid', 'assign', 'new', 'class', 'label', 'belongs', 'centroid']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
578,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['nearest', 'neighbor', 'seen', 'unsupervised', 'learning', 'method', 'defined', 'number', 'group', 'ke', 'nearest', 'neighbor', 'calculated', 'given', 'input', 'data', 'define', 'value', 'get', 'point', 'closer', 'given', 'point']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
579,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['randomly', 'define', 'redefined', 'number', 'cluster', 'centerscc', 'calculate', 'distance', 'datapoint', 'ca', 'data', 'point', 'belongs', 'cluster', 'least', 'distance', 'ca', 'calculate', 'new', 'ca', 'getting', 'average', 'point', 'inside', 'cluster', 'go', '2', 'repeat', 'process', 'reach', 'termination', 'condition']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
580,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['firstly', 'identify', 'nearest', 'neighbouring', 'weight', 'choose', 'amount', 'neighbor', 'adapt', 'weight']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
581,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['initialize', 'neighbor', 'every', 'neuron', 'find', 'nearest', 'neighbor', 'add', 'neighbor', 'return', 'nearest', 'neighbor']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",1,2.0,neural_networks,neural_course,0.5
582,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['pseudo', 'code', '1', 'initiate', 'weight', 'randomly', '2', 'assign', 'label', 'input', 'map', 'neuron', 'closest', '3', 'happened', 'input', 'map', 'neuron', 'using', '2', '4', 'find', 'centroid', 'cluster', 'move', 'map', 'neuron', 'centroid', '5', '4', 'convergence', 'criterion', 'reached', 'edge', 'maximum', 'iteration', 'reached', 'update', 'performed', 'net', 'distance', 'specified', 'distance']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
583,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['given', 'la', 'test', 'element', 'la', 'number', 'neighbor', 'taken', 'consideration', 'function', 'classof', 'set', 'x', 'l0l', 'classf', 'j1k', 'lj1', 'im', 'exclude', 'data', 'point', 'identified', 'nearest', 'neighbor', 'already', 'xfind', 'closest', 'neighbor', 'test', 'let', 'eg', 'compute', 'eucldea', 'distance', 'classofx', 'classfpushc', 'set', 'cxtest', 'frequently', 'value', 'class']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
584,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['train', 'inn', 'storing', 'data', 'labeled', 'point', 'present', 'test', 'point', 'compute', 'distance', 'test', 'point', 'training', 'data', 'point', 'sort', 'distance', 'choose', 'datapoints', 'smallest', 'distance', 'determine', 'class', 'test', 'point', 'majority', 'vote']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
585,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['la', 'data', 'set', 'x1x2x3xn', 'la', 'storing', 'dataset', 'based', 'number', 'neighbor', 'test', 'test', 'data', 'set', 'basically', 'value', 'odd', 'number', 'select', 'majority', 'value', 'based', 'number', 'la', 'xu', 'test', 'distance', 'neighboring', 'neuron', 'la', 'smallest', 'xu', 'based', 'number', 'test', 'maxl2', 'select', 'neuron', 'neighborhood', 'calculating', 'euclidean', 'distance', 'based', 'weight', '3', 'neuron', 'select', 'label', 'fixed', 'maximum', 'dataset', 'given', 'kfields']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
586,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['define', 'criterion', 'finding', 'nearest', 'neighbour', 'bra', 'find', 'nearest', 'neighbour', 'test', 'input', 'training', 'dataset', 'bra', 'find', 'class', 'neighbour', 'belong', 'bra', 'assign', 'class', 'test', 'input', 'bra']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
587,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['learning', 'based', 'nearest', 'neighbor', 'inputoutput', 'sample', 'training', 'set', 'stored', 'memory', 'test', 'input', 'find', 'nearest', 'neighbor', 'assign', 'test', 'vector', 'class', 'neighbour', 'neighborhood']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
588,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['parameter', 'number', 'cluster', 'datapoints', 'class', 'initialize', 'randomly', 'centroid', 'cluster', 'select', 'data', 'point', 'compute', 'set', 'nearest', 'neighbour', 'point', 'using', 'euclidean', 'distance', 'find', 'class', 'maximum', 'number', 'neighbour', 'belong', 'assign', 'class', 'datapoint', 'class', 'assigned', 'compute', 'centroid', 'cluster', 'class', 'considering', 'class', 'member', 'literate', 'datapoints', 'repeat', 'point', 'step', 'update', 'centroid', 'required']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
589,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,[],"['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
590,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['1', 'given', 'classified', 'data', 'ex', '2', 'new', 'sample', 'x', 'determine', 'sky', 'nearest', 'neighbour', 'output', 'majority', 'vote', 'class', 'nearest', 'neighbour']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
591,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['x1x2xn', 'al', 'let', 'ex', 'input', 'xd', 'test']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
592,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['1', 'identify', 'classified', 'pattern', 'lie', 'nearest', 'test', 'vector', '2', 'assign', 'test', 'vector', 'class', 'frequently', 'presented', 'nearest', 'neighbor']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
593,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['1', 'define', 'number', 'cluster', 'sky', '2', 'generate', 'random', 'weight', '3', 'find', 'center', 'mean', '4', 'cluster', 'output', 'determining', 'closest', 'neighbor', '5', 'update', 'weight']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
594,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['choose', 'value', 'represents', 'number', 'neighbor', 'get', 'sample', 'input', 'space', 'find', 'class', 'based', 'majority', 'vote', 'received', 'neighbor', 'example', 'value', 'let', 'say', '2', 'neighbor', 'class', 'one', '1', 'neighbor', 'class', 'two', 'new', 'input', 'sample', 'belongs', 'class', 'one']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
595,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['step', 'randomly', 'place', 'neuron', 'step', 'data', 'point', 'whichever', 'neuron', 'closer', 'datapoint', 'assigned', 'neuron', 'step', 'datapoints', 'assigned', 'mean', 'datapoints', 'attached', 'neuron', 'calculated', 'neuron', 'shifted', 'mean', 'value', 'step', 'step', '2', '3', 'done', 'shift', 'neuron', 'position', 'way', 'neuron', 'adjusted']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
596,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['step', 'randomly', 'select', 'center', 'step', 'cluster', 'datapoints', 'based', 'center', 'step', 'centroid', 'cluster', 'becomes', 'new', 'mean', 'step', 'repeat', 'step', '2', '3', 'evidential', 'change', 'network']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
597,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['input', 'labeled', 'data', 'set', 'one', 'unlabeled', 'data', 'point', 'number', 'find', 'labeled', 'point', 'closest', 'given', 'unlabeled', 'point', 'point', 'find', 'label', 'occurs', 'often', 'assign', 'label', 'unlabeled', 'data', 'point']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
598,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['1', 'get', 'nearest', 'neighbor', 'current', 'xu', '2', 'remove', '3', 'get', 'class', 'current', '4', 'classify', 'xu', 'class', 'occurs', 'often', 'neighbor', '1', 'ke', 'li', 'lex', 'inn', 'minxx', 'getclassofxnn', 'amountofclassesaddc', 'setclassofx', 'maxamountofclasses']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
599,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['input', 'data', 'distance', 'every', 'data', 'point', 'calculated', 'using', 'distance', 'measure', 'take', 'data', 'point', 'minimum', 'distance', 'xu', 'nearest', 'neighbour', 'frequent', 'class', 'neighbour', 'assigned', 'class', 'input', 'data']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
600,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['learning', 'based', 'memory', 'introduced', 'dataset', 'data', 'point', 'nearest', 'neighbour', 'found', 'via', 'distance', 'function', 'datapoint', 'neighbour', 'getknearestneighboursofd', 'class', 'getmostrepresentedclassneighbours']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
601,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['given', 'input', 'compute', 'distance', 'input', 'point', 'pick', 'nearest', 'neighbor', 'look', 'labeling', 'neighbor', 'decide', 'labeling', 'classification', 'highest', 'number', 'neighbor', 'one', 'class', 'german', 'mehrheitsentscheid']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
602,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['training', 'training', 'data', 'define', 'cluster', 'select', 'cluster', 'datapoints', 'centroid', 'randomly', 'datapoint', 'trainingset', 'calculate', 'distance', 'centroid', 'able', 'datapoint', 'according', 'closest', 'centroid', 'end', 'literate', 'cluster', 'calculate', 'centroid']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
603,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['knearest', 'neighbour', 'memory', 'based', 'learning', 'take', 'input', 'calculate', 'calculate', 'distance', 'training', 'point', 'select', 'training', 'point', 'minimum', 'distance', 'data', 'fetch', 'class', 'selected', 'nearest', 'point', 'calculate', 'number', 'point', 'per', 'class', 'nearest', 'point', 'determine', 'class', 'maximum', 'point', 'nearest', 'point', 'class', 'input', 'point', 'ca']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
604,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['nearest', 'neighbor', 'basically', 'work', 'follows', 'define', 'randomly', 'cluster', 'point', 'calculate', 'mean', 'equlidian', 'distance', 'data', 'point', 'point', 'previous', 'step', 'act', 'centrioids', 'check', 'variance', 'cluster', 'repeat', '123', 'till', 'get', 'proper', 'cluster']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
605,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['1', 'slept', 'random', 'number', 'neighbourhood', 'initially', '2', 'find', 'input', 'nearest', 'weight', 'vector', 'using', 'competitive', 'learning', '3', 'change', 'input', 'win', '4', 'decrease', 'size', 'neighbourhood', '5', 'repeat']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",0,2.0,neural_networks,neural_course,0.0
606,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['inputpoints', 'neighbour', 'findnearestkpointsx', 'neighbour', 'getvoteofn', 'updatevotescountforxv', 'max', 'getmaxvoteforx']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
607,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"['let', 'set', 'labeled', 'data', 'memory', 'x1x2xn', 'prime', 'nearest', 'point', 'test', 'point', 'term', 'euclidean', 'distance', 'let', 'class', 'function', 'return', 'class', 'type', 'certain', 'data', 'point', 'xu', 'let', 'constant', 'number', 'neighboring', 'point', 'conspired', 'algorithm', 'search', 'initialize', 'prime', 'la', 'la', 'listofclasses', 'je', 'jk', 'job', 'la', 'lj1xprime', 'prime', 'nearest', 'neighbor', 'test', 'form', 'la', 'data', 'classofxprime', 'listofclassesappendc', 'end', 'cxtest', 'frequent', 'class', 'listofclasses']","['add', 'new', 'data', 'member', 'colored', 'classified', 'old', 'data', 'construct', 'sphere', 'nearest', 'data', 'point', 'find', 'class', 'color', 'maximum', 'vote', 'assign', 'new', 'data', 'class', 'maximum', 'vote', 'unsupervised', 'manner']",2,2.0,neural_networks,neural_course,1.0
608,Explain the Bias Variance Dilemma!,238,"['machine', 'learning', 'choice', 'always', 'need', 'made', 'tradeoff', 'bias', 'variance', 'bias', 'determines', 'close', 'result', 'true', 'value', 'variance', 'determines', 'sensitivity', 'fluctuation', 'training', 'dataset', 'bias', 'reduced', 'variance', 'increase', 'vice', 'versa', 'optimum', 'tradeoff', 'need', 'chosen', 'present', 'dilemma']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",1,2.0,neural_networks,neural_course,0.5
609,Explain the Bias Variance Dilemma!,238,"['bias', 'variance', 'dilemma', 'used', 'analyse', 'generalization', 'error', 'algorithm', 'value', 'bias', 'high', 'network', 'learn', 'relation', 'feature', 'output', 'correctlyoverfitting', 'value', 'variance', 'high', 'network', 'may', 'model', 'random', 'noise', 'learn', 'intended', 'ouputsunderfitting', 'tradeoff', 'bias', 'variance', 'model', 'generalize', 'properly']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",1,2.0,neural_networks,neural_course,0.5
610,Explain the Bias Variance Dilemma!,238,[],"['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
611,Explain the Bias Variance Dilemma!,238,"['training', 'model', 'limited', 'training', 'data', 'set', 'must', 'decide', 'wether', 'accept', 'biased', 'model', 'make', 'assumption', 'test', 'data', 'better', 'performance', 'train', 'data', 'model', 'variance', 'might', 'model', 'entirety', 'data', 'better', 'prone', 'data', 'noise', 'usually', 'decide', 'trade', 'two', 'may', 'select', 'well', 'balanced', 'model', 'based', 'dimension', 'cross', 'validation', 'result']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",2,2.0,neural_networks,neural_course,1.0
612,Explain the Bias Variance Dilemma!,238,"['bias', 'variance', 'undesirable', 'learning', 'bias', 'defines', 'far', 'generated', 'output', 'differs', 'true', 'value', 'variance', 'defines', 'much', 'op', 'change', 'changing', 'input', 'dataset', 'however', 'case', 'possible', 'decrease', 'one', 'expense', 'thus', 'called', 'bias', 'variance', 'dilemma']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",1,2.0,neural_networks,neural_course,0.5
613,Explain the Bias Variance Dilemma!,238,[],"['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
614,Explain the Bias Variance Dilemma!,238,"['bias', 'error', 'make', 'assumption', 'creating', 'learning', 'machine', 'much', 'away', 'actual', 'truth', 'variance', 'much', 'learning', 'machine', 'change', 'different', 'training', 'data', 'set', 'high', 'bias', 'habe', 'low', 'variance', 'habe', 'low', 'variance', 'habe', 'high', 'bias']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",1,2.0,neural_networks,neural_course,0.5
615,Explain the Bias Variance Dilemma!,238,"['tradeoff', 'high', 'bias', 'high', 'variance', 'high', 'variance', 'mean', 'model', 'overfishing', 'data', 'therefore', 'variance', 'input', 'quit', 'hight', 'high', 'bias', 'mean', 'model', 'generalization', 'unspecified']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",1,2.0,neural_networks,neural_course,0.5
616,Explain the Bias Variance Dilemma!,238,"['bias', 'defined', 'grade', 'correctness', 'learning', 'algorithm', 'used', 'variance', 'defined', 'grade', 'flexibility', 'algorithm', 'given', 'model', 'learn', 'bias', 'high', 'variance', 'low', 'algorithm', 'flexible', 'data', 'discard', 'data', 'exactly', 'data', 'fit', 'model', 'hand', 'variance', 'high', 'bias', 'low', 'algorithm', 'flexible', 'data', 'accept', 'error', 'data', 'part', 'model', 'learn']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",2,2.0,neural_networks,neural_course,1.0
617,Explain the Bias Variance Dilemma!,238,"['bias', 'bias', 'difference', 'predicted', 'value', 'desired', 'value', 'generalization', 'run', 'variance', 'inadequate', 'produced', 'value', 'regression', 'desired', 'value', 'expect', 'network']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
618,Explain the Bias Variance Dilemma!,238,"['bias', 'variance', 'dilemma', 'coming', 'fact', 'time', 'network', 'equally', 'great', 'outpouring', 'extremely', 'high', 'accuracy', 'extremely', 'hight', 'amount', 'variable', 'therefore', 'need', 'find', 'balance', 'two', 'suit', 'need', 'neural', 'network']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
619,Explain the Bias Variance Dilemma!,238,"['refers', 'problem', 'trying', 'maintain', 'balance', 'two', 'cause', 'error', 'learning', 'algorithm', 'network', 'able', 'generalize', 'data', 'beyond', 'used', 'training', 'namely', 'bias', 'error', 'variance', 'error', 'high', 'bias', 'error', 'may', 'cause', 'network', 'miss', 'important', 'feature', 'training', 'data', 'lead', 'underfitting', 'high', 'variance', 'make', 'network', 'memorize', 'noise', 'present', 'training', 'data', 'rather', 'learning', 'feature', 'lead', 'overfitting']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",2,2.0,neural_networks,neural_course,1.0
620,Explain the Bias Variance Dilemma!,238,"['one', 'optimize', 'simultaneously', 'learning', 'algorithm', 'learning', 'maximum', 'variance', 'data', 'learning', 'localization', 'termed', 'bias']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
621,Explain the Bias Variance Dilemma!,238,[],"['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
622,Explain the Bias Variance Dilemma!,238,"['bias', 'variance', 'dilemma', 'tell', 'u', 'bias', 'difference', 'actual', 'desired', 'output', 'variance', 'output', 'difference', 'trial', 'decreased', 'time', 'complex', 'model', 'result', 'small', 'variance', 'larger', 'variance']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",1,2.0,neural_networks,neural_course,0.5
623,Explain the Bias Variance Dilemma!,238,"['machine', 'learning', 'problem', 'minimizing', 'two', 'main', 'source', 'error', 'simultaneously', 'allow', 'network', 'generalized', 'easy', 'bias', 'increase', 'variance', 'decrease', 'vice', 'versa', 'also', 'hold', '1', 'bias', 'tell', 'u', 'close', 'true', 'value', '2', 'variance', 'tell', 'u', 'vary', 'different', 'data', 'set', 'standard', 'problem']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",2,2.0,neural_networks,neural_course,1.0
624,Explain the Bias Variance Dilemma!,238,"['high', 'value', 'bias', 'mean', 'network', 'unable', 'learn', 'data', 'whereas', 'higher', 'variance', 'mean', 'difficult', 'learn', 'training', 'data', 'successfully']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
625,Explain the Bias Variance Dilemma!,238,[],"['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
626,Explain the Bias Variance Dilemma!,238,"['bias', 'variance', 'estimation', 'error', 'bias', 'corresponds', 'inability', 'learning', 'machine', 'appropriately', 'approximate', 'function', 'learnt', 'hence', 'induces', 'deviation', 'actual', 'function', 'variance', 'inadequacy', 'training', 'data', 'allow', 'learning', 'machine', 'successfully', 'learn', 'function', 'dilemma', 'completely', 'learn', 'actual', 'function', 'reduce', 'variancerelated', 'error', 'training', 'data', 'required', 'consist', 'infinite', 'sample', 'however', 'result', 'slower', 'convergence', 'intern', 'bias', 'error', 'increase', 'therefore', 'trade', 'error', 'need', 'made']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",2,2.0,neural_networks,neural_course,1.0
627,Explain the Bias Variance Dilemma!,238,[],"['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
628,Explain the Bias Variance Dilemma!,238,"['bias', 'difference', 'predicted', 'true', 'value', 'variance', 'range', 'several', 'predicted', 'value', 'datapoint', 'desirable', 'low', 'bias', 'low', 'variance', 'ensure', 'predicted', 'value', 'consistently', 'close', 'true', 'value', 'bias', 'variance', 'dilemma', 'achieve', 'low', 'bias', 'variance', 'becomes', 'high', 'vice', 'versa', 'hence', 'always', 'tradeoff', 'two']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",2,2.0,neural_networks,neural_course,1.0
629,Explain the Bias Variance Dilemma!,238,"['bias', 'variance', 'dilemma', 'refers', 'problem', 'minimizing', 'two', 'source', 'error', 'bias', 'error', 'variance', 'error', 'simultaneously', 'creates', 'problem', 'generalization', 'network', 'bias', 'error', 'error', 'occurs', 'setting', 'parameter', 'network', 'variance', 'errorit', 'refers', 'sensitive', 'network', 'fluctuation', 'dataset']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",2,2.0,neural_networks,neural_course,1.0
630,Explain the Bias Variance Dilemma!,238,[],"['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
631,Explain the Bias Variance Dilemma!,238,"['bias', 'variance', 'dilemma', 'process', 'simultaneously', 'decreasing', 'two', 'source', 'error', 'prevents', 'supervised', 'learning', 'algorithm', 'centralizing', 'beyond', 'trained', 'data']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
632,Explain the Bias Variance Dilemma!,238,"['bias', 'used', 'fine', 'transform', 'u', 'help', 'shift', 'classifier', 'line', 'vub']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
633,Explain the Bias Variance Dilemma!,238,"['bias', 'close', 'estimate', 'true', 'value', 'variance', 'much', 'estimate', 'vary', 'different', 'training', 'set', 'always', 'either', 'hugh', 'variance', 'low', 'bias', 'low', 'variance', 'high', 'bias']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",1,2.0,neural_networks,neural_course,0.5
634,Explain the Bias Variance Dilemma!,238,"['bias', 'difference', 'estimated', 'output', 'actual', 'output', 'variance', 'range', 'output', 'network', 'different', 'training', 'set', 'bias', 'variance', 'cant', 'decreased', 'time', 'many', 'network', 'one', 'time', 'decreased']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",1,2.0,neural_networks,neural_course,0.5
635,Explain the Bias Variance Dilemma!,238,[],"['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
636,Explain the Bias Variance Dilemma!,238,"['adapting', 'parameter', 'network', 'either', 'small', 'bias', 'small', 'variance', 'small', 'bias', 'approximation', 'network', 'close', 'real', 'one', 'variance', 'trial', 'high', 'low', 'variance', 'bias', 'cant', 'minimized', 'network', 'bigger', 'error', 'approximation', 'real', 'value']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",1,2.0,neural_networks,neural_course,0.5
637,Explain the Bias Variance Dilemma!,238,[],"['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
638,Explain the Bias Variance Dilemma!,238,"['ideally', 'bias', 'variance', 'would', '0', 'learning', 'machine', 'however', 'bias', 'variance', 'counteract', 'eachother', 'bias', 'decrease', 'variance', 'rise', 'respectively', 'direction', 'lead', 'dilemma', 'either', 'one', 'value', 'present']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",1,2.0,neural_networks,neural_course,0.5
639,Explain the Bias Variance Dilemma!,238,[],"['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
640,Explain the Bias Variance Dilemma!,238,"['usually', 'one', 'bias', 'variance', 'minimized', 'run', 'example', 'kernel', 'greater', 'width', 'lead', 'high', 'bias', 'low', 'variance', 'choose', 'many', 'kernel', 'smaller', 'width', 'bias', 'low', 'variance', 'high', 'higher', 'complexity', 'model', 'need', 'training', 'data']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",2,2.0,neural_networks,neural_course,1.0
641,Explain the Bias Variance Dilemma!,238,[],"['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
642,Explain the Bias Variance Dilemma!,238,"['bias', 'provides', 'fine', 'transformation', 'treated', 'extra', 'input', 'normal', 'taken', '1']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
643,Explain the Bias Variance Dilemma!,238,"['high', 'bias', 'variance', 'desirable', 'input', 'bias', 'variance', 'dilemma', 'property', 'input', 'data', 'bias', 'increased', 'variance', 'decrease', 'vice', 'versa', 'difficult', 'find', 'tradeoff']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",1,2.0,neural_networks,neural_course,0.5
644,Explain the Bias Variance Dilemma!,238,"['bias', 'bias', 'mean', 'much', 'prediction', 'differs', 'true', 'value', 'variance', 'variance', 'mean', 'much', 'prediction', 'varies', 'different', 'datasets', 'dilemma', 'generally', 'reduced', 'simultaneously', 'learning', 'machine', 'reduce', 'one', 'cost']","['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",1,2.0,neural_networks,neural_course,0.5
645,Explain the Bias Variance Dilemma!,238,[],"['biasvariance', 'dilemma', 'principle', 'supervised', 'learning', 'problem', 'dilemma', 'arises', 'due', 'variance', 'data', 'bias', 'model', 'high', 'bias', 'model', 'fit', 'training', 'data', 'perfectly', 'suffers', 'high', 'variance', 'bias', 'low', 'variance', 'reduces', 'model', 'doesnt', 'fit', 'data', 'well', 'dilemma', 'make', 'generalizability', 'difficult', 'achieve']",0,2.0,neural_networks,neural_course,0.0
