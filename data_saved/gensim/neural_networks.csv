row_id,question,question_id,student_answer,reference_answer,assigned_points,max_points,domain,dataset_name
0," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a massively parallel distributed processor with simple processing units that has the natural propensity to store experiential knowledge and make use of them an artificial neural network is similar to the human brain in two ways 1 the ann works by the process of learning from its environment 2 interferon connections called synaptic weights are used to store the knowledge gained,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
1," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network consists of largely parallel distributed processor simple processing units that has ability to store the experiential knowledge and making it available to use it resembles to human brain in two ways knowledge is acquired from the environment by the network as learning process synaptic strengths called weights are used to store the knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
2," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a massive distributed processor it consists of several information processing units which are able to acquire and store knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1.0,2.0,neural_networks,neural_course
3," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an ann is a layered graphical model containing neurons and weighted connections resembling the excitatory properties of the human brain weights of the ann are changed after presenting it training examples from an environment where weights are changed based on the training procedure used artificial neurons also are biased just like real ones adding a constant level of activation before being activated by a nonlinear activation function depending on the training procedure both weights topology or even activation functions may be learned,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
4," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural networks are large parallel processing units that have the natural ability to learn experiential knowledge they are composed of interconnected neurons as basic units which in turn consists of weights squashing functions and adder functions ann resembles brain in the manner that like in human brain it is composed of a network of neurons which help in learning by adjusting the synaptic weights of the connections between neurons this enables it to learn experiential knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
5," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network consists of neurons each neuron can have several weighted inputs an activation function and output usually several neurons are connected together often in layers the network then calculates the output given an input to the network the human brain works in a similar way it also consists of neurons that are connected in several ways,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1.0,2.0,neural_networks,neural_course
6," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an ann is a massively parallel distributed processor made up of simple processing units which have the capability of storing experimental knowledge and is made up for use an ann resembles the brain because 1 it gets its knowledge through a learning process from its environment 2 it stores its knowledge in its interferon connections synaptic weights,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
7," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,a ann is a massively distributed processor it has the propensity to store experimental knowledge and make it available for use the knowledge is gained throug a process of learning the knowledge is stored in the weights between the neurons this structure resembles the structure of the brain neurons are a the basic information unit in the ann and act similar to real neurons,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
8," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is defined as a learning machine which is divided by layers and each layer is composed by neurons the neurons from different layers can be connected between each other and give an output or multiple outputs by a given input this structure is very similar with the neurological structure of our brain where neurons are interconnected by synapses also important to mention if a feature is really important for a given task this wil have more connections and neurons participating like in the human brain the important human functions have more synapses,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
9," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a graph of small and identical processing units that these small units called neurons and they are connected to each other in different architecture and the whole network adapt and itself to the environment inputs by trying to decrease the error or the cost function and increase its preciseness by manipulating the free variables of the network which are the synaptic weights it is similar to human brain because similar to the human brain we have many small processing units that are connected together and they react to the environment and learn from the environment,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
10," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is highly parallel processing it has a mathematical model similar to human brain which it was inspired from as human brain does computation in an extremely parallel manner similarities also lay in terminology ann is using neurons that are smallest computing unit of a network similarly to human brain,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1.0,2.0,neural_networks,neural_course
11," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,it is a massive parallel distributed processor made up of smaller processing units that acquire knowledge through the environment through a learning process and makes it available for use it resembles the brain in two ways knowledge is acquired through a stimulating process in the environment the knowledge is embedded in the synaptic links weights of the neurons,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
12," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,ann is a learning machine which is composed of neurons as units of computation the ann learns via interacting with its environment the ann has building capacity to dynamically adapt upon input stimulus the ann is motivated from biological brain and resembles human brain in terms of its localized representation for the inputs in terms of motor cortex the sensory stimulus to different bodyparts activates local part of the brain similar to ann local representation of similar type of input,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
13," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,a neural network is a massively parallel distributed processor made up for simple processing units that has a natural propensity for storing experiential knowledge and making it available for use it resembles the brain in two respects knowledge is acquired by the network from its environment through the learning process interferon connection strengths known as synaptic weights are used to stor the acquired knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
14," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is a massively parallel distributed processor which consists of one or more processing unit called neuron it resembles the human brain for that it acquires knowledge from the environment through learning process and that the acquired knowledge is stored in the synapses,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
15," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,definition 1 artificial neural networks are massively distributed parallel processor 2 it is made up of small units 3 which has the propensity for storing the experiential knowledge 4 and making it available for use it resembles the brain in 2 aspects 1 similar to the brain artificial neural network does the process of learning from the environment 2 it as a pair of inter neuron links known as the synaptic weights which is used for storing the information,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
16," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is massive parallel distributed processor it comprises of small processing units called neurons it learns from experiential knowledge which is then stored and can be used for making predictions it resembles human brain in 2 ways it learns from experiential knowledge knowledge is stored in synaptic interferon connections,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
17," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,here artificial neural network is a massively distributed parallel processor which is composed of simple processing units called neurons which have the natural propensity for storing experiential information and making it available for use it resembles the human brain in the following aspects knowledge is acquired by the network from its environment through a learning process synaptic links are used to store the acquired knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
18," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,ann is a learning machine which can perform complex parallel computation it has the ability to learn through the interactions withthe environment and store the learned knowledge it resembles the human brain in performing complex learning tasks acquiring information adapting to the environment and exploiting the acquired information,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
19," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a massively distributed parallel processor made up of simple processing units that have the natural propensity for storing experimental knowledge and making it available for future use it resembles the brain in the following ways 1 artificial neural networks have the ability to acquire knowledge from the environment in which they are are embedded 2 interferon connection strengths called synaptic links activate each neuron during the learning process,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
20," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a massively parallel distributed processor which interacts with its surrounding environment with a propensity to store knowledge and make it available to use it resembles the brain in two aspects 1 it has the ability to learn from its environment 2 the knowledge is stored in synaptic weights,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
21," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is massively distributed parallel processor containing simple processing units and has natural propensity to store experiential knowledge and use tit resembles the human brain in two aspects it gains knowledge from the environment and adapts the synaptic weight to store the knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
22," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,it is a massively parallel distributed processor consisting of simple processing units which can store experiential knowledge and make it available for use it resembles the human brain in 2 ways 1 knowledge is acquired from environment through a learning process 2 interferon connections are used to store the experiential knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
23," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is a massively parallel distributed processor that is made up of simple processing units called neuron it can replicate human brain by storing information in their weights,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1.0,2.0,neural_networks,neural_course
24," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is a massively parallel distributed processor with synaptic links that can able to store experimental knowledge and make it available for use it resembles human brain in two ways knowledge is acquired by the neural network from its environment through learning process interferon connection called synaptic links stores the acquired knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
25," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network are the network of the units that learn data from the environment and store them using synaptic weights the structure of the artificial neural network is similar to human brain it has neurons ie the store units and the atoms called synapses which link the stored data,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1.0,2.0,neural_networks,neural_course
26," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is massive parallel processor made up of simple processing units called neurons they are capable of storing experiential knowledge and make it available for later use similarity to human brain 1 they learn from the environment 2 they store knowledge as synaptic weight in the interferon connection,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
27," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a highly distributed processor which consists of several simple processing units it resembles the human brain because the processing units are neurons which are connected with weights the human brain also consists of neurons,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1.0,2.0,neural_networks,neural_course
28," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,a massively distributed processor consisting of single processing units that have a natural propensity of storing experimental knowledge and making it available for use,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1.0,2.0,neural_networks,neural_course
29," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network consists of neurons which are small computation devicesand synapses the connections between the neurons this resembles the brain because it also has neurons and synapses also a artificial neural network has weights which are used to store learned features from the environment like the brain a neural network learns from the environment an artificial neural network also has an activation function which creates the output,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
30," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a highly parallel computation model with learning and memory capacities similar to the brain it learns from the environment by strengthening the synapses between neurons once a task is learned it can be quickly used by reactivating those learned synapses,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1.0,2.0,neural_networks,neural_course
31," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a highly parallel working machine which consists of simple processing units neurons with are connected to each other in layers they are function approximates the brain is resembled in the architecture the processing units and the weights and how the learning process takes place and the properties of the brain fault tolerance parallel computing,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1.0,2.0,neural_networks,neural_course
32," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an ann is a massively parallel distributed leaving machine made up of small computational units computational units are connected via synapses defined by a weight it resembles the human brain in two aspects,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1.0,2.0,neural_networks,neural_course
33," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is massively parallel distributed processor made up of simple computing units called neurons which acquires knowledge from environment through learning it resembles brainlike structure in two ways 1 it acquires knowledge through learning and experience 2 it stores knowledge in interferon connections called synapses,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
34," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,ann is huge parallel distributed processor consist of simple processing units and which has propensity of storing experiential knowledge and making it available for use,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1.0,2.0,neural_networks,neural_course
35," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is a massively parallel distributed processor made up of simple processing units which has a natural propensity to acquire knowledge from the environment and make it available for future use it resembles the human brain in following ways 1 both of them acquire knowledge from the environment 2 the neurons are connected by synapses characterized by their weights which can be adjusted,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
36," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a massively distributed parallel processor made of simple processing units it has natural propensity to store experiential knowledge and it makes the knowledge available for further use an artificial neural network uses inter neuron connections called synaptic weights to store the knowledge acquired knowledge which is very similar to how human brain works,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
37," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,ann is a massively distributed processor consisting of simple processing units called neurons these neurons in terms of ann are similar to neurons in human brain both neurons are characterized by synapsesconnection links they represent connections used for data flow between neurons in both ann and human brain the knowledge is represented by its very structure and activation state of neurons,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2.0,2.0,neural_networks,neural_course
38,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron is the simplest processing unit of a neural network which has 1 synaptic weights to store the knowledge gained 2 adder function linear combined which adds the weighted values of the input signals to produce the local field 3 an activation function which squashes the local field to a range of values phisumi0n wi dot xi,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
39,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,mathematical model of a neuron is given as y phil where activation function is applied to local field i summation wifi i local field is weighted sum of inputs plus bias,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
40,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron is an information processing unit it consists of inputs associated with weights sum of inputs and an activation function,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,1.0,2.0,neural_networks,neural_course
41,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,input vector i weight matrix i net input nets utw net output opine,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,1.0,2.0,neural_networks,neural_course
42,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron consists of three basic components synaptic weights the synaptic weights are connections between neurons and are adjusted through training squashingactivation functions the squashing functions may be non linear or linear functions that that are applied to the signals from the neurons adder functions the adder functions help in combining outputs from several neurons,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
43,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,i number inputs xi input i ve local field varphivj activation function ya output wi weight from node i to i ya varphivj ve sumi0nwjixi,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
44,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron is a simple processing unit of an ann that is made up of the synaptic links which are defines by a weights when a adder function that combines the weighted input wifi plus some bias i to the local field sumwiwi be a activation function phi that squashes the local field to the output privy,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
45,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,the neuron consists of synapsesconnecting link each characterised by a weight a linear combined sums up the weighted sum of inputs to a local field the local field is then passed through an activation function the result of the activation function is the output,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
46,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron is defined by the following elements a number of input values i a number of weights i a bias i an activation function phi the inputs i are multiplied with the weights and the result is summed with the bias also the bias can be used just as a weight value i and a single connection with an stable input equal to 1 for mathematical simplicity the resulting value known as local field i will be the input to the activation function the mathematical model can be summarized in the formula i sun 0 kiwi i y phil,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
47,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron consists of a set of inputs and a bias which these inputs and redefined bias will be multiplied by a weight and then we have sum the results of all the inputs and bias multiplied by the weights which called induced field and after that we send this to an activation function which can be a linear or nonlinear function and the output of this function is the final output of our neuron,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
48,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,neuron is a simplest computation unit of a neural network that consists of input variables weights bias summation term combined activation function and output variables,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,1.0,2.0,neural_networks,neural_course
49,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,the neuron is the basic processing unit of a neural network and is made of three main component weights we we in adder function it is the linear combination of the input and weights plus bias induced local field i sum wi xi i squashing function it is the activation function applied to the local field used to limit the output of the neuron phil,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
50,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron is a computational unit composed of synapses which are stored in the form of weights i these are the variables that can are dynamic summing function that computes the weighted sum of inputs i sum wifi activation function phi gives nonlinear nature to network determines and normalize the output produced by neuron eg sigmoid function bias another synaptic unable variable with input 1 therefore the net output of neuron y sum wifi i,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
51,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,the following equations describe a nonlinear model of a neuron labeled i fuk sum from je to i we xu my think be where xu are the input signals we are the weights of the neurons uk is the linear combined output due to the input signals be is the bias phi is the activation function and ya is the output signal of te neuron,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
52,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron is a processing unit that contains three main components a set of synaptic weights that connect the neuron with other neurons an adder that computes the induced local field or the weighted sum of the signals flowing through the neuron an activation function that constrains the magnitude of the output signal from the neuron,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
53,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a mathematical model of a neurons consists of a 1 a set of synaptic links which are classified based on weights we when 2 it consists of a adder function which performs the weighted sum of the inputs and the bias sigmai1n wax i 3 it consists of an activation function used to minimize the amplitude of the neuron output phisigmai1n wax i,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
54,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a mathematical model of neuron comprises of 2 main units adder functions it sums up all the product of all synaptic connections and inputs of neuron synaptic weights these are interferon connections in which the knowledge is stored activation function it is used for introducing nonlinearity,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
55,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,here the neuronal model consists of the following synaptic links characterized by their weights which connects the network to the environment it is embedded in an adder function which sums up the weighted inputs and outputs the induced local field of the neuron an activation function which takes the induced local field of the neuron as its input and limits the output of the neuron,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
56,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a mathematical model of neuron consists of 3 important parts a neuron is the smallest computational node with 1 input vectors set of vectors of a certain dimension to train the model 2 weights and biases each of the input vectors are weighted using weight vectors in accordance withthe output that is required bias is added when necessary 3 activation function the linear combination of weights and inputs are passed through the activation function which produces an output,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
57,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,the neuron is the fundamental processing unit of an artificial neural network that is characterised by the following features 1 a neuron has a set of nonlinear synaptic links an externally applied bias and possibly one or more linear activation links the bias is represented by a synaptic link from an input fixed at 1 2 the synaptic links of the neuron weight the respective inputs 3 an adder function linear combined computes the weighted sum of the inputs to the neurons 4 an activation function squashing function limits the amplitude of the neurons output,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
58,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,let xu xu in be the inputs to the neuron wi be the corresponding weights of connections i be the bias and valpi be the activation function then the induced field i is given by i sum in wi xi i the output y is given by y varphiv,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
59,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,the mathematical model of neuron has three parts a set of synapses or connecting links characterized by weight i an adder function that calculates the weighted sum of inputs plus some bias an activation function squashing function to minimize the amplitude,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
60,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,ok sumj1m we xu be ya think we is the synaptic weight connecting neuron i and input data i xu is input data be is bias ok is induced local field ya is output of neuron,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
61,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron consists of a synapse connecting link an adder function or linear combined and an activation function i sigma wi dot xi i where xi is the input wi is the weight and i is bias,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,1.0,2.0,neural_networks,neural_course
62,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron is a basic information processing unit that have a adder function to compute weighted sum of inputs plus bias and apply activation function on the result phil sumlimitsi1n omegaixi bias,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
63,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,each neuron has a set of inputs and their respective weights the local field is i summit xi the local field is passed through a activation function so the output of the neuron is y phil y phisumwij xi,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
64,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,the neurons are the basic processing units in neural network output of the neuron phi sum wi xi they consist of three parts synaptic weight the connections between the neurons characterised by weights adder function calculates the weighted sum of the inputs of the neuron activation function limits the amplitude of the output of the neuron phi,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
65,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,the model of a neuron consists of synaptic weights which are applied to the input signals the weighted inputs are then summed which gives the local field this local field is put into an activation function whose output will be the output of the neuron,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
66,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,y suit phiwxi a neuron consists of inputs i synaptic weights i an extra input we which is fixed to 1 for the bias an adder function that creates the local field i and a squashing function phi,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
67,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,y sum fix i where i are the weights which change the input according to the learned weights i is the input from the environment i is the bias which shifts the learned decision plane and i is the activation function which limits the output to a desired region of values,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
68,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron consists of one or multiple inputs which are gathered by a summation function the hereby induced local field of the neuron is processed by a squashing function and generates the output of the neuron,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,1.0,2.0,neural_networks,neural_course
69,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron consist of input connection links with a synaptic weight a bias an adder which adds the input signals and the bias and produces the local field the local field is processed by the activation function and produces the output of the neuron,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
70,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron consists of input nodes xu to in and weights we to in a linear combined i sum xi wi i where i is some bias the result i is called local field and is used as input for an activation function phil,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
71,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,neuron is consists of three units 1 synaptic links characterize by weights which nearly ways the input 2 adder which adds weighted inputs to generate local field 3 activation function which is nonlinear function smashing the output of the neuron,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
72,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,1 neuron is consist of synaptic links which measured in terms of weights neuron is given with inputs it has adder function or combined which adds all the inputs multiplied by the weights and bias is extra input to the neuron as well 3 it has a activation link which limit the amplitude of the output of the neuron,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,1.0,2.0,neural_networks,neural_course
73,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,neuron is the basic information processing unit which is the main component of a neural network a neuron is characterized by its input xi synaptic weight wi and activation function phil mathematically it can be modelled as phiwixi activation function bounds the input to a certain level,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
74,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron has three components synaptic weight i adder function it multiplies input i with the weight activation function it squashes the output of the adder function sigmoid hyperbolic tangent rectified linear unit etc,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
75,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron consist of set of inputs that takes data from environment each neuron contains synapsesconnection links that are characterized by weights all inputs are connected to the summing adder function that computes weighted sum of all input values this weighted sum is called local field of neuron the value of this local field i is limitedsquased by an activation function theta the result from this squashing function is output of a neuron y theta additionally a bias term i is added to the input and its value is always 0 but its associated weight is being changed over training period finally output of neuron is y theta where i sum we xu i,mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combined which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output,2.0,2.0,neural_networks,neural_course
76,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,1 label one class a positive with label 1 and the other class as negative with 1 2 augment the data with an additional value for the bias term 3 invert the sign of the data in the negative class 4 randomly initialize weights 5 if it dot i 0 update weight by and in eta in else leave the weight unchanged 6 continue step 5 7 terminate when there is no longer a change in any weight,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
77,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,1 initialization time step or iteration 1 and weights are small but randomly initialized 2 activation of perception apply training pattern to activate the perception 3 compute output apply activation function to the local fieldweighted sum of inputs plus bias 4 adjust weights adjust weight if current output desired output 5 continuation we continue by increasing i during each iteration and repeat from step 2 until all input pattern are applied to network and also error is minimized,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
78,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,here y denotes the actual result i denotes the desired result positive train error y 0 do new wold i negative train error y 1 i 0 new wold i,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,1.0,2.0,neural_networks,neural_course
79,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,initialize weights with zero or small values sample data point feed into network compute net output use the step activation function compute error edo where i is the true label o is the predicted label correct weights based on wt1wtalphadox where alpha is the training rate and i is the input pattern repeat for each pattern until convergence is reached,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
80,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,for this case the parameters that need to be learned are the slope of the line and the intercept these are the parameters for the weight vector 1 initialize random small values for weight vector 2 for inputdata xi in training data apply the input to the weight vector e the difference between the local field and the desired output didi update weight and in eta e xi,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,1.0,2.0,neural_networks,neural_course
81,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,varphiv tank single node network mu learning rate repeat as long as error is too high 1 present sample to network and collect output 2 compare actual output with desired output i 3 if not equal adapt weights win 1 win mudyxi,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
82,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,given i date points xiii and yiin11 given a learning rate for each point i add a bias 1 so that point i xiii for each point i there yi 1 point 1 point i nullvector i 0 convergence false whileconvergence false convergence true for each point i in the training set ifwe do i wlearningratepointi convergence false,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
83,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,weights a weight vector phi activation function eta learning rate for each datapoint xiii do weights weights eta xiiyiweightsi,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,1.0,2.0,neural_networks,neural_course
84,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,1 i i initweightsbias the weights can be initialized to 0 or random initialized 2 i 0 3 while stopcriteria do iteration until stop criteria is fulfilled 4 y in in i calculate output 5 if i is in ca e 1 if the i belongs to class ca error i 1 otherwise is 1 6 else if i is in ca e 1 7 i i e i update weights using the calculated error 8 i i 1 9 end the stop criteria can be if the number of misclassified input data is 0 then stop,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
85,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,the learning process consists of three main steps 1 positive error calculate the error of all the data sets in the learning set change the weight and positive error separate the data points based on the new i 2 negative error calculate the error of all the data sets in the learning set change the weight and negative error separate the data points based on the new i 3 no error when we have no error this is the end of the training,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,1.0,2.0,neural_networks,neural_course
86,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,define a bias in order to be able to trigger to which class data points will be classified to assign initial randomly chosen weights use a squashing function for example mccullon pits start training process and stop when error of output and desired output has reached desired percentage,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,0.0,2.0,neural_networks,neural_course
87,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,initialize the weight vector hate 0 do for every training sample ad i sum wi xi i y phil if i is not equal to y then e i y i i eta ei xi until convergence,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
88,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,pseudo code initiate weights and bias randomly compute output for the given input data y sum wifi i compute error between computed y and desired output y update weights and in eta my i stop when the error is below some specified threshold or becomes zero in case of data that is perfectly nearly separate,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
89,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,0.0,2.0,neural_networks,neural_course
90,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,initialize the perception with each weight equal to 0 we 0 present the labeled examples xi di to the perception for each example xi di compute actual output yi and error signal update weight based on the delta rule and in eta in yn in,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,1.0,2.0,neural_networks,neural_course
91,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,we use threshold function as activation function if we i 1 label class 1 else label class 0,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,0.0,2.0,neural_networks,neural_course
92,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,en current error be es convergence criteria be i learning rate be while change in en not less then es be calculate error en be and in i en in widow hoffman rule be,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
93,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,here perception learning algorithm initialize the network by assigning random weights to the synaptic links calculate error as the difference of the desired output with the actual output if the input is misclassified with positive error new current input if the input is misclassified with negative error new current input if the input is correctly classified no changes are made in the weights repeat from step 2 as long as the error is under some defined threshold value,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
94,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,the linear binary classifiable data consists of input vector i which when multiple with weights and added bias fall into class or class depending on the linear combination output of we i being above 0 or below class algo parameters desired output i i 1 weight vector i is initialized with small random values 2 input vector is chosen with a probability and output is computed using we i if the class y of vector i is and output is 0 or if the class of i is and output if 0 then the weights are updated accordingly otherwise weights are left unchanged 3 treated over other input vectors until convergence of output,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
95,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,1 initialization at time step no initialize weight vectors with random values we 2 activation apply the input example xindi to activate the perception with heavyside step function as the activation function 3 if output of the perception yn new in adjust the weight vector using the rule and in eta and yn 4 go to activation and repeat until no more change in weight vector is observed,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
96,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,1 inputs i xu xu in 2 desired outputs y ya ya yn 3 initialize weight vector i to random small values 4 for each data point in in i calculate hate from i and in calculate error en yn hate update i according to delta rule end,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
97,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,0.0,2.0,neural_networks,neural_course
98,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,apply input data to input layer and initialize small values weights minimize error according to difference between desired signal and output signal assign the test vector the class that has smallest error,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
99,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,1 compute the initial weights for all input vector 2 apply matrix multiplication from input to weight vector 3 apply linear combined 4 apply activation function to produce the output 5 compute the error 6 update weights,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,0.0,2.0,neural_networks,neural_course
100,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,randomly assign values to initial weights run the perception network and calculate the error e ya where e is error y is output and i is desired response update the weights based on the error if error is positive add the error with the input and update weight if error is negative subtract the error with the input and update weight if there is no error dont update the weights repeat the above process until the calculated error is approximately equal to zero,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
101,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,0.0,2.0,neural_networks,neural_course
102,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,i random number between 1 and 1 for every data in training set in the first layer calculate the weighted sum using adder function calculate the output of the activation function in the output layer calculate the output y calculate the error e i y i desired output change the weights using the formula delta i eta xu e continue till the error converges,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
103,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,initialize as many random weights as the dimension of the data points for each data point if the output matches the desired output do nothing else change the weights in the direction of the datapoint so that the datapoint is classified correctly end if end for if some weight was changed start again with the for loop end if,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
104,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,1 initialize the weights at random or as 0 2 activate the perception by giving an example 3 compute the actual output of the neuron 4 adjust the parameters of there perception 5 continue until convergence is achieved i rand y sumphiwx for wi in i wi dietary,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,1.0,2.0,neural_networks,neural_course
105,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,initialize the weights randomly y sum fix i compute the output of the perception using the input i the weight i the bias i and the activation function i e i y calculate the error by subtracting the actual output from the desired output new wold learningrate dot i dot e update the weights with this formula the learning rate is a parameter which changes how fast the perception learns,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
106,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,for i iterations for each datapoint i error desired output if error 0 weights weights error if error 0 weights weights error,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
107,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,pick random decision boundary while one of data points is in wrong class turn decision boundary by using vector of wrong data point negative rule or positive,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,1.0,2.0,neural_networks,neural_course
108,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,trainings set of labeled linear venerable data points i weight vector with dimension of input data i local field phil activationfunction threshold function y output e error y i where i is the desired output from labeled training data i learning rate 01 assign random values for i for i in trainings i sum wi y phil e y i i i ne delta rule end,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
109,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,initialize weights i and bias i set learning rate i set errorthreshold upper bound on error while error errorthreshold for every datapoint i in training dataset y i i i 1 bias is represented as weight of fixed input 1 if y is positive then i belongs to ca otherwise to ca store above predicted class find error in predicted output with respect to the labels store error e sum sum of all errors e for every data point i i i sum,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
110,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,for a binary classifier we can use threshold activation function 1 randomly initialize the weights 2 you calculate the output of the neuron 3 find out the error by subtracting expected output and current output 4 modify the weights related to that input with respect to the error repeat the process 24 till the you get minimal error,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
111,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,0.0,2.0,neural_networks,neural_course
112,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,continueprocess true i randomlyinitialize while continueprocess for i in list of points y we diff dy i is the desired output diff 0 i i i else i i i if all points are classified without error continueprocess false,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
113,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,i leaving rate repeat until the me is small enough tte for each point in training set do compute local field of perception i we apply linear activation function y theta i compute current error e dy apply delta rule to it nex end,label the data with positive and negative labels initialize the weights randomly apply simplified update rule do earn if we 0 repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separate,2.0,2.0,neural_networks,neural_course
114,Explain classification and regression; what is the difference?,225,classification in classification the output produced by the in is a discrete value which indicates which class the input belongs to regression in regression the output produced by the in is a continuous variable this could be used for instance to approximate a continuous function,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
115,Explain classification and regression; what is the difference?,225,in classification output values are always discrete in regression output values are continuous,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
116,Explain classification and regression; what is the difference?,225,a hydroplane is given by y we i regression wants to determine i classification wants to assign a class to a set of observations regression wants to determine separating hydroplane classification wants to label data points with a class,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
117,Explain classification and regression; what is the difference?,225,in classification tasks we assign discrete labels to data points of our training dataset either being assigned a specific label or not binary for supervised learning these datapoints are labeled with a label vector ground truth in regression we try to model a function which fits the data points of the training data and thus model a function with continuous values,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
118,Explain classification and regression; what is the difference?,225,classification it refers to classifying given data into discrete classes the output is discrete values use for activity like pattern recognition etc regression it refers to estimating the value of some continuous function given an input the output is continuous value used for activities like motor control etc,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
119,Explain classification and regression; what is the difference?,225,in classification we try to assign classes to input data regression we want the network to behave like a given systemformala this can also be a time series of input and output data,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
120,Explain classification and regression; what is the difference?,225,in classification the goal is to separates points into different classes the outcome is a class able regression try to fit a hyperplante to a point cloud best so that future data is represented by that hyperplane best les it try to minimize the distance to all data points the outcome is a countinius variable,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
121,Explain classification and regression; what is the difference?,225,both are learning tasks of a ann in classification the goal is to assign a class label to new datapoints in regression the goal is to estimate a unknown function the only difference between both is that classification uses discrete class labels while in regression a continuous output is used,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
122,Explain classification and regression; what is the difference?,225,the approach of classification is to classify sets of input data into their correct classes for example used in pattern recognition the approach of regression is to approximate to a defined function i by calculating the error between this function and the result of an algorithm the difference is that the classification approach is applied to a discreet data the samples are the different points of the input space and regression is an analogy approach where the whole function must be approximate for any input given,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
123,Explain classification and regression; what is the difference?,225,classification in classification problems we have different groups of data that have some common properties and after training we want that our model can detect the class of the new sample correctly regression in regression we have a series of values and we want to use the previous values in this series and predict the next value,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
124,Explain classification and regression; what is the difference?,225,classification is a problem of distinguishing to which discrete classes input variables are to be assigned to regression is estimation of the output by figuring out the continuous trend of the whole dataset,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
125,Explain classification and regression; what is the difference?,225,classification if to assign a class or category to the data while regression is when you fit the data to a function,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
126,Explain classification and regression; what is the difference?,225,regression learns modelfunction that can predict other unseen data well targetoutput is real spaced classification learns a model that classifiesmaps input to a discrete target label targetlabeloutput is binarydiscrete,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
127,Explain classification and regression; what is the difference?,225,classification describes the application in which a sample is assigned to one specific pattern of the problem in comparison to regression is the output deterministic an not continuously in regression the output is continuous describing,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
128,Explain classification and regression; what is the difference?,225,classification is the task of classifying the input signals into a finite number of groups so the output is a number that indicates a certain class regression is the task of approximating a function by estimating the values given the input signals so the output can be any real number,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
129,Explain classification and regression; what is the difference?,225,classification we need to predict the output data discretely that is the output space is a discrete space regression we need to predict the output data continuously that is the output space is continuous space the main difference is the discreteness and contionousness,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
130,Explain classification and regression; what is the difference?,225,classification is a problem of assigning a particular class to each data point in a given dataset be regression is a problem of fitting the given dataset on a particular hyperplane which can be used for representing the given data it finds the hyperplane which minimise the mean square error,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
131,Explain classification and regression; what is the difference?,225,here classification is a problem of assigning labels or classes to the input the output is a discrete variable regression is a problem of assigning a continuous variable to the input,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
132,Explain classification and regression; what is the difference?,225,classification is a problem of catergorization into discrete classes where as regression is a problem in a continuous space where the goal is to ether minimize or maximize a cost function classification is the process of dividing a set of discrete inputs into classes corresponding to similar patterns such as clustering regression could be finding a pattern of the distribution of the data such as fitting a line,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
133,Explain classification and regression; what is the difference?,225,classification in machine learning is used to find a decision surface in the form of a hyperplane that can separate a set of input examples or set of patterns into their respective classes regression on the other hand is used to find the parameters ie the weight vector i and the bias i for the function thatwas best fit the given data points xiii thus classification deals with predicting the class label for discrete data points whereas regression deals with fitting a continuous real valued function,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
134,Explain classification and regression; what is the difference?,225,classification is separating the data into classes and the output is a discontinuous variable regression is fitting a model and the output is a continuous variable,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
135,Explain classification and regression; what is the difference?,225,classification is about classifying the given data into different classes where as regression is about finding the localglobal minimal use perceptions to classify the data and we use constrained optimization techniques like newtons method to find regression,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
136,Explain classification and regression; what is the difference?,225,classification assign a test data to a class that is prescribed regression approximating an unknown function with minimization errors for inputoutput mapping,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
137,Explain classification and regression; what is the difference?,225,classification in classification the output variable takes class labels or identifying group membership regression in regression the output variable takes continuous values or predicting a response,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
138,Explain classification and regression; what is the difference?,225,classification problem is used to classify set of data points into specific groups regression is used to predict time series data classification works on discrete set of values and regression works on continuous values,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
139,Explain classification and regression; what is the difference?,225,classification classification is done between the classes the machine determines to what class the data belongs to regression regression is a expecting output for an input the machine learns from the given data and models a function and when new input is given it expects the output difference classification is discrete output where as regression is a continuous output,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
140,Explain classification and regression; what is the difference?,225,regression tries to fit a line are curve among the given points the have continuous output the output is a function classification tries to classify the given points into two or more classes they have a discrete output the output is a value representing the class,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
141,Explain classification and regression; what is the difference?,225,classification each datapoint is assigned with a class regression each datapoint is assigned with a value in classification we assign classes or labels to datapoints the error signal here can be only true or false in regression we try to learn a function the error for each prediction can be a number,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,2.0,2.0,neural_networks,neural_course
142,Explain classification and regression; what is the difference?,225,in classification a binary pattern has to be partitioned into the two classes in regression a line has to be fitted closest to some datapoints the difference is that in classification the output is a single class label while in regression the output is continuous,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
143,Explain classification and regression; what is the difference?,225,in classification the input data is split in 2 or more classes the goal of the neural network is to learn the input data and then be able to classify new input data into the classes based on the learned information the network then maps input data into one of the classes which is discrete space in regression the input data is learned swell but here the network tries to predict feature values which are in continuous space the network tries to predict close as possible to new input data only using the learned model,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
144,Explain classification and regression; what is the difference?,225,classification tries to label discrete data points with distinct classes while regression tries to approximate a continuous function from discrete data points results of these methods are respectively a labeled data set or a continuous function,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
145,Explain classification and regression; what is the difference?,225,in classification the task is to give an discrete output value to an input it assigned one of all defined classes to the current input regression try to approximate a function while minimizing error and produces a continuous output value,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
146,Explain classification and regression; what is the difference?,225,classification means mapping input data a class label for example 1 and 1 in regression on the other hand a continuous function is learned in way that fix fix is minimized where fix is the function learned by a learning machine and fix is the original function,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
147,Explain classification and regression; what is the difference?,225,classification is supervised learning where underlying function representing the training data is learn from training data to predict classes of datapoints or patterns drawn from similar distribution as of training data weights of the neural network are learned to minimize the error in classification regression is supervised learning algorithm where underlying function representing the training data is learn from training data to predict the value of label or output of some system for new datapoint or pattern of similar type weights of the neural network are learned to minimize the error in prediction of function differences 1 output of classification is discrete class 123 whereas output of regression is continuous 2 error in classification is number of wrong classifications whereas error in classification regression is distance between able value and predicted value,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,2.0,2.0,neural_networks,neural_course
148,Explain classification and regression; what is the difference?,225,classification is type of problem where algorithm needs to separate the one data class from the another data class if there is 2 classes ca ca algorithm classify the given data into these two classes it is discreet process regression is the predicting the next point depending on the previous points it is continuous process,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
149,Explain classification and regression; what is the difference?,225,classification is the problem where the input data has to be put in two or more classes distinctively different from each other for example in case of binary classification on class can be 1 and the other 1 regression on the other hand is data fitting the main aim is to find a hyperplane which can fit a given input pattern,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
150,Explain classification and regression; what is the difference?,225,classification is a task to partition the given input into one of several classes the classes are discrete values regression regression is the tasks of predicting output in a continuous range the prediction can be any value within a range,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
151,Explain classification and regression; what is the difference?,225,in classification task the aim to separate data in different classes such that output of in gives value of class index for each input point eg in the task is to classify binary data then the output of the in will 0 or 1 and each value represent on class in case of regression task the aim is to fit data namely a function that perform inputouput mapping output of in in this case will be error value such that we know how close is out function fitted to data points,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1.0,2.0,neural_networks,neural_course
152,Write down the SOM learning in pseudo code.,226,1 arrange the weights in the required topology according to the problem 2 initialize the weights randomly such that all the weights are different 3 sample the input from the input space 4 similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron 5 update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and reduce the learning rate and make sure learning rate is above zero 6 if ordering and convergence is complete stop else continue to step 3,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
153,Write down the SOM learning in pseudo code.,226,i first we initialize random weights for neurons ii then we choose random input from input space iii we compute distance between input vector and each weight vector iv neuron that have minimum euclidean distance with input vector is considered as winner neuron i then we find the neighborhood neurons of the winning neuron vi we adjust the weights of all neighborhood neurons via reduce the learning parameter and neighborhood size viii continue until it converges,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,1.0,2.0,neural_networks,neural_course
154,Write down the SOM learning in pseudo code.,226,i denote weights i denotes threshold i denotes the neighborhood function which decreases with distance i from winning neuron he win neighborhood function return exp2xxwin i rand initialize weights with random value while delta i proceed until there are no noticeable changes win are min xw2determine i which is closest to i competitive leaving update weights of winning neuron weights of losing neurons are not updated new wold the xwinxwupdate weights of neuron which a are in neighborhood of winning neuron,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
155,Write down the SOM learning in pseudo code.,226,initialize weights with small values such that all of the weight vectors are different sample a datapoint feed into network determine the winning neuron on the lattice picking the neuron with the least euclidean distance of its weight vector to the input vector determine the neighbourhood of the winning neuron through the neighbourhood function change weights of the neurons namely spatially pulling the weight vectors of the neighbourhood neurons towards the input vector depending on the trimester reduce learning rate and neighbourhood size based on wether we are in the organizing or finetuning step repeat until maximum number of steps,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
156,Write down the SOM learning in pseudo code.,226,1 randomly initialize weights 2 randomly select an input from the training data 3 find the nearest neighbour of this input in the weights this is done by finding the euclidean distance of the input from each weight and selecting the weight with least distance 4 update the weights of all the neurons within the neighbourhood in which is gaussian function with an exponentially decaying sigma of the winning neuron with some learning rate tan delta wijetanhnxixj where tan eta0ent1 and sigma sigma0ent1,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
157,Write down the SOM learning in pseudo code.,226,in som we start with randomized weights mu learning create di distance between i and i i neighbour function repeat as long as error is too highway iterations are not reached 1 take input sample 2 find closest nodeweight 3 find all it neighbours 4 move the weight and its neighbours closer to the given input use the neighbour function eg gaussian to reduce effect to far distance neighbours 5 optional adapt learning rate and neighbour function,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
158,Write down the SOM learning in pseudo code.,226,given a neighbourhood function hijo and a learning rate over time randomly asking different weights from the input layer to the neurons in the second layer for each training point xi do find the winnertakesall neuron i with min kiwi find the neighbours of i with the neighbourhood function compute the new weights for those neurons using the neighbourhood function and the learning rate update decrease the neighbourhood function and the learning rate end,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
159,Write down the SOM learning in pseudo code.,226,,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,0.0,2.0,neural_networks,neural_course
160,Write down the SOM learning in pseudo code.,226,1 i initweights equal to zero or random initialized 2 i 0 3 while stopcriteria 4 winnerneuron y i i find on the map layer which neuron is closer to the input euclidean distance 5 neighborhood defineneighboorwinnerneuron i define the neighborhood size first iterations big and being reduced 6 eta definelearningraten define the learning rate large value at the first iterations and being reduced 7 diff adaptweightsneighborhood eta adapt the weights just for the winner neuron and its neighborhood 8 i i diff update the weights 9 stopcritera muststopy i look if the distance between input and the winner neuron is 0 or really close to 0 9 end,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
161,Write down the SOM learning in pseudo code.,226,randomly define some values for the synaptic connections in the network send the first input to the network in the output layermap layer select the neuron that has lowest errorcompetition phase based on a redefined method define the neighborhood of the selected neuroncooparation phase change the weights of the selected neuron and the neurons located in its neighborhoodadaptation phase if the stop condition satisfied stop the process,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
162,Write down the SOM learning in pseudo code.,226,has three parts in it competition cooperation adaptation get input variable and choose amount of neurons to be more than amount of variables then run competition where from the input neurons will be competing to each other on choosing which fits the most after finding winning neuron change weight of neighbouring neuron only in cooperation weights of neighbouring neurons are adjusted to clusters in adaptation neurons are pulled to input variables to establish the classification,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,0.0,2.0,neural_networks,neural_course
163,Write down the SOM learning in pseudo code.,226,find the winning neuron find the neighbors of the winning neuron,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,0.0,2.0,neural_networks,neural_course
164,Write down the SOM learning in pseudo code.,226,pseudo code 1 initialize map neurons based on topology it could be a lattice on a circle etc 2 competition find map neuron that is closest to an input neuron by computing distances i 3 update the position of closest map neuron with update rule 4 do 2 and 3 until all input neurons are assigned a map neuron do 23 and 4 until specified iterations or the net cumulative distance goes below some specified value or becomes zero,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
165,Write down the SOM learning in pseudo code.,226,produce transom begin randomized weights for all neurons for i to iterationnumber do begin take random input pattern find the winning neuron find neighbors of the winner modify synaptic weights of these neurons reduce learning rate and lambda end end,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
166,Write down the SOM learning in pseudo code.,226,initialize the network with small and random weights sample the data set by picking an input randomly determine the winning neuron based on the output value determine the cooperating neurons based using the neighborhood function update the weights of the cooperating neurons adjust the learning rate stop if the network converges,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
167,Write down the SOM learning in pseudo code.,226,begin i range of data set initialise the weights we give a small random weights for the range of i select a input signal find the winning neuron based on the similarity between the weights update the weights of the neighboring neuron repeat until the convergence 1 initialising 2 sampling 3 similarity matching 4 updating the weights 5 continuation,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
168,Write down the SOM learning in pseudo code.,226,initialise weights be while significant change is observed in topographic pattern be take a random input sampling be find the winning output neuron competition be adjust the weights of the winning neuron and its neighbourhood neurons cooperation be continue be,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
169,Write down the SOM learning in pseudo code.,226,here som learning initialization with random small weights sampling picking a input pattern with certain probability similarity matching finding the most matching neuron ie the winning neuron synaptic updating updating the weights of the neuron and also the neurons in its neighbourhood continuation repeat steps 2 to 4 till there is no considerable change in the map,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
170,Write down the SOM learning in pseudo code.,226,parameters i data vectors i weights vectors in lattice tan learning rate sigma neighbourhood width hix neighbourhood function algo 1 initialize the weights to a small random nonrepeatible values 2 sample a data vector with a probability 3 compute the euclidean distance to weight vectors from the data points and find the winning neuron with minimum distance 4 update the weights of the winning neuron and its neighbourhood towards the input direction using neighbourhood function 5 reduce the learning rate and the neighbour hood width and literate from step 2 until no significant changes between weight vectors and inputs are seen,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
171,Write down the SOM learning in pseudo code.,226,1 initialization initialize the weight vectors with random values such that the we is different for all weights 2 sampling draw sample example i from input space 3 similarity matching find the best matching weight vector for the input vector wi arguing i win 4 adjust the weight vectors of neurons in the neighbourhood of the winning neuron 5 go to sampling step and repeat until no more changes are observed in the local neighbourhood of the winning neuron,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
172,Write down the SOM learning in pseudo code.,226,1 initialization initialize the weights of each neuron to small random values such that weight of each neuron is different 2 sampling sample an input from the input set 3 similarity matching determine the neuron nearest to the sampled input based on its distance 4 weight updating update the weights of the neighbouring neurons chosen by the neighbourhood function hijo 5 continuation continue from sampling until there is no more change in the weights,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
173,Write down the SOM learning in pseudo code.,226,som is referred to as self organized maps which is an unsupervised training algorithm for finding spatial pattern in data without using any external hearthe process in som is explained below initialization initialize random weights we for input patterns sampling take nah random sample from the input say i similarity matching for the input i find the best match in the weight vector ix arguing i update the next step is to update the weights and in etahjixix continuation continue from sampling until there is no significant change in the feature map,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
174,Write down the SOM learning in pseudo code.,226,initialization set random small values to weights we is different for each neuron sampling draw nah sample i from input space competition identify winning neuron i using are min wi which means weight vector of i is most similar to input cooperation identify neighbors of winning neuron i using neighborhood function hix i which shrinks with time weight adaptation adjustments made to synaptic weights of winning neuron and its neighbors go to sampling until no large changes in the feature map,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
175,Write down the SOM learning in pseudo code.,226,generate random weights for all neurons for i to maxiteration door take random input pattern find the winning neurons find the neighbors of the winning neurons compute weighs of these neurons reduce eta and lambda end for,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
176,Write down the SOM learning in pseudo code.,226,initialize the neuron weights randomly in a way that all neurons have different weights generate random samples i from the input space literate the samples and compare distance between current input and all neurons in the weight space find a winning neuron with shortest distance from current input distance is calculated using euclidean or manhattan distance find the neurons in the neighborhood boundary of winning neuron update the weights of neighborhood neurons using delta rule adapt the size of neighborhood lambda and learning rate eta at each iteration repeat the process until there is no neurons in the neighborhood boundary or all the inputs moved to some neuron,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
177,Write down the SOM learning in pseudo code.,226,step it selects a datapoint in random through sampling step finds the nearest neuron through competitive learning step updates the weight of the winner neuron and updates the weight of neighbouring neurons by a fraction step continues steps 1 2 3 until there is no change in the weights or some stopping criteria is met,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
178,Write down the SOM learning in pseudo code.,226,take a random point from the training data competitive phase find the winning neuron the neuron similar feature using the eucledian distance formula cooperative phase find the neighbors of the winning neuron based on the neighbor function eg gaussian function adoption phase change the weights of the all the neighboring neuron of the winning node using the formula del i eta xu we,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
179,Write down the SOM learning in pseudo code.,226,input distance function do y learning rate mu neighborhood distance i initialize the map layer with random weights for each input find the weight which is closest to the input minimum do y change the weight in the direction of the input depending on the learning rate change all weights which are within the neighborhood distance i depending on their distance and the learning rate reduce learning rate and neighborhood distance,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
180,Write down the SOM learning in pseudo code.,226,1 initialize small random weights 2 draw the nah sample from the input space 3 similarity matching determine the winning neuron 4 update the weights of the neuron an the topological neighborhood 5 repeat steps 24 i random i exampledraw wax getminwin in getneighborhoodwmax for wi in in wi dietary,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
181,Write down the SOM learning in pseudo code.,226,initialize the weights randomly create a term to and to which decrease the learningrate and neighbourhood function respectively calculate ix again i i the weight which is closest to the input data received ix is the neuron which wins the competitive process this neuron and its neighbours weights are updated using new wold learningrate dot he dot i i he is the neighbourhood function which determines which neurons are updated and how strong they are changed by the update it is defined using the distance between the neurons the learningrate is updated using learningrate to also is the neighbourhood function updated in the same way using to the learningrate cannot get lower than 001 while the neighbourhood function can get as low as only the winning neuron so in the beginning almost every neuron is updated and at the end only a small neighbourhood or the neuron itself is updated,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
182,Write down the SOM learning in pseudo code.,226,for i iterations winner competitionbetweenneurons neighbourhood cooperationwithneighbourhoodfunctionwinner updateweightsneighbourhood,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,1.0,2.0,neural_networks,neural_course
183,Write down the SOM learning in pseudo code.,226,given a map layer set random small values for weights from input to map layer repeat until not converged find best match of input value and weight of the neurons competitive process adapt increase weight of winning neuron and neighborhood with gauss function and neighborhood size cooperating process and weight adjustment decrease neighborhood size,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
184,Write down the SOM learning in pseudo code.,226,,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,0.0,2.0,neural_networks,neural_course
185,Write down the SOM learning in pseudo code.,226,initialize weight vectors of hidden neurons with same dimension as of data number of hidden neuron should be significantly greater than number of data points initialize learning rate i and neighbouring function i while rate of change in weights is significant for every datapoint calculate distance of each neuron from data select winner neuron i with minimum distance maximum similarity error distance of winner form datapoint adjust weights of neurons with the rule i i horror,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
186,Write down the SOM learning in pseudo code.,226,randomly minimize the weights draw sample of inputs increase the weights of the local neighborhood of winning neuron repeat the process above process till there is only one winning neuron,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,1.0,2.0,neural_networks,neural_course
187,Write down the SOM learning in pseudo code.,226,,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,0.0,2.0,neural_networks,neural_course
188,Write down the SOM learning in pseudo code.,226,for i in numofepochs for i in inputpoints find the winning neuron find the neighbours of the winning neuron within distance sigma update winning neuron and neighbours weight update sigma and learningrate so that both reduces over time,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2.0,2.0,neural_networks,neural_course
189,Write down the SOM learning in pseudo code.,226,,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neuron update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,0.0,2.0,neural_networks,neural_course
190,Give the basic idea of an SVM using the correct terminology!,227,a support vector machine is a maximum margin classifier in which the width of the boundary of separation is maximized a margin is defined as the width of the boundary before hitting a point this maximum margin intuitively feels safe and is experimentally good,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
191,Give the basic idea of an SVM using the correct terminology!,227,basic idea of sum is to best segregate the data into two classes with the help of decision boundary this decision boundary is margin we always try to maximize the margin to make sure data is classified correctly,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
192,Give the basic idea of an SVM using the correct terminology!,227,support vector machines goal is to maximize margin between closest data points of separating hyperplane separating hyperplane is given by 0 when i by maximizing margin probability of classification errors is reduced,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
193,Give the basic idea of an SVM using the correct terminology!,227,an sum is a binary linear classifier spanning a separating hyperplane between two classes of datapoints the hyperplane is spanned between both the positive and negative decision boundaries and supported by a number of support vectors support vectors are the outermost datapoints which span the hyperplane during training the distance of falsely classified data points to their correct side of the hyperplane is minimized utilizing a quadratic programming formulation,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
194,Give the basic idea of an SVM using the correct terminology!,227,a sum is a binary classifier with a maximum width boundary separating the two classes this uses support vectors vectors that pushes against the boundaries the equations of the lines in an sum are wxb1for class 1 wxb1for class 1 i is the width between these boundaries,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
195,Give the basic idea of an SVM using the correct terminology!,227,because sums are binary classifies we can use a border to operate the data the border is typically placed where it has the largest possible distance to both classes the vectors the border touches on both sides with its margin are the support vectors,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
196,Give the basic idea of an SVM using the correct terminology!,227,a sum is an ann for supervised learning which is able to separate two classes of datapoints by using a hyperlane found by quadratic programming by finding the biggest margin the goal is to classify future data in there two classes,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
197,Give the basic idea of an SVM using the correct terminology!,227,the sum is a maximum margin classifier it is used the binary classify datapoints in a dichotomy the idea is to find a line with nearly separates both classes there perfect position of this line is in right in the middle of these classes to find this linedescision boundary we define a positive and a negative boundary which are parallel to this line the boundary define the margin between both classes the idea of sum is that the datapoints which are next to the boundary can be used to define the margin they are called support vectors additional not every problem is nearly venerable so the idea was to transform the input into many higher dimensions using some kernel functions we discussed the kernel function of polynomial terms and found out that it easy to compute,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
198,Give the basic idea of an SVM using the correct terminology!,227,support vector machines are a type of learning machines that try to classify different classes of an input space for linear separate classes the sums try to calculate the line that separates this two classes with maximum margin the support vectors will be the points closer to this margin when the input data is noisy we have an optimization problem of two aspects maximum margin proper classification so a tradeoff i will be defined the tradeoff will be calculated by the sum of the distance of misclassified points for nonlinear separate classes a kernel will be defined that will transform the input data into a higher dimensional space,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
199,Give the basic idea of an SVM using the correct terminology!,227,in linear sum we have a linear border line classifier that separate two different classespositive and negative planes and we calculate the distance of the data points from this border line classifier also a margin will be defined and this margin will be maximized until it touches some data points in the plane the data points that the margin pushed against them will be our support vectors the error for the wrongly classified datapoints will be calculated by calculating the distance of the data point from its correct plane the sum tries to learn the classifier and the margin from the training data,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
200,Give the basic idea of an SVM using the correct terminology!,227,support vector machines are classifies that are using support vectors which are variables of the dataset these variable are chosen during learning algorithm main advantage of sums is that it will not be overfishing by choosing correct margin activation functions can be both linear and nonlinear output of sum is always true or false for given variable,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
201,Give the basic idea of an SVM using the correct terminology!,227,support vector machines are a type of neural network that build a decision boundary around classes such that the margin of separation between classes is maximized,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,0.0,2.0,neural_networks,neural_course
202,Give the basic idea of an SVM using the correct terminology!,227,sums are binary classifier they learn the classification by memorizing the marginal data points called support vectors that make up the decision boundaries 2 positive and negative,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
203,Give the basic idea of an SVM using the correct terminology!,227,the abbreviation sum stands for support vector machine sums represent a feedforward category of in sums are binary learning machines whose functionality can be summarized for classification problem as follows given a training sample the sum constructs a hyperplane as the decision surface in such a way that the margin of separation between positive and negative examples is maximized one key innovation associated with sums is the kernel trick the kernel trick consists of observing that many machine learning algorithms can be written exclusively in terms of dot products between examples it allows us to learn models that are nonlinear as a function of i using convex optimization techniques that are guaranteed to converge efficiently besides the kernel function i often admits an implementation that is significantly more computational efficient than naively constructing two vectors and explicitly taking their dot product,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
204,Give the basic idea of an SVM using the correct terminology!,227,an sum or support vector machine is a feedforward network with a hidden layer to learn a task in a supervised learning manner the network tries to construct a hyperplane that separates the data points of two different classes by maximizing the margin of separation which is the distance from the hyperplane to the closest data points called support vectors,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
205,Give the basic idea of an SVM using the correct terminology!,227,given a dataset support vector machines builds a hyperplane in a such a way that positive and negative samples are separated to the maximum distance width of the margin should be maximum the vectors to which the marginsmargin for positive and negative sample are pushed on to it are called support vectors,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
206,Give the basic idea of an SVM using the correct terminology!,227,sum stands for support vector machine it creates a hyperplane such that margin of separation between positive and negative classes is maximise,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
207,Give the basic idea of an SVM using the correct terminology!,227,here sum is a linear machine whose goal is to construct a optimal hyperplane such that the marginal separation is the maximum between the decision boundaries the decision boundaries are drawn parallel to the hyperplane which just push the datapoints closest to the hyperplane the datapoints closer to the hyperplane are called support vectors,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
208,Give the basic idea of an SVM using the correct terminology!,227,the idea of sum is to fit a supervised model onto the training data allowing maximum generalization ability this is done by computing maximum margin between different classes of data using the support vectors the margin can be computed using different kernels for a higher dimensional data,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
209,Give the basic idea of an SVM using the correct terminology!,227,a sum is a linear machine which is used in pattern classification problems to find a decision surface in the form of a hyperplane for nearly separate classes such that the margin of separation between the classes is as large as possible sums are an approximate implementation of the induction principle of structural risk minimization which is based on the fact that the error rate in testing is bounded by a term that is dependent upon the sum of training error rate and the ve dimension of i,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
210,Give the basic idea of an SVM using the correct terminology!,227,the basic idea of sum is to determine the best decision boundary ie the one which provides maximum margin so that the boundary can be widened most before it touches any datapoint it is done using support vectors which are the the datapoints the margin pushes against,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
211,Give the basic idea of an SVM using the correct terminology!,227,sum refers to support vector machines terms of a linear classification problem sum can be defined as creating a hyper plane which is a decision surface and to maximize the width of decision boundary cases where the problem is complex sum can be used as it classifies the data by projecting the data in higher dimension the data is to be separated in 3 classes they can use 3 sums for three different classes,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
212,Give the basic idea of an SVM using the correct terminology!,227,basic idea of sum is to construct a hyperplane as the decision surface in such a way that the margin of separation between negative examples and positive examples is maximized,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
213,Give the basic idea of an SVM using the correct terminology!,227,the idea of sum is to construct a hyperplane as a decision surface such that the margin separation between positive and negative examples is maximized,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
214,Give the basic idea of an SVM using the correct terminology!,227,sum tries to find a best hyperplane with widest margin with the help of support vectors such that all the data points are classified correctly,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
215,Give the basic idea of an SVM using the correct terminology!,227,sum is used for nearly separate data a hyperplane is used to separate the data but there could be so many hyperplanes that separate the data the best hyperplane is choose which separates data with a bigger margin so in sum we find the hyperplane which has a bigger margin between the hyperplane and both the positive and negative data lines,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
216,Give the basic idea of an SVM using the correct terminology!,227,given a training set for classification the basic idea of sum is to construct a hyperplane as decision boundary such a way that the margin between the positive and negative points is maximum support vector is a small subset of the of the training data against which the boundary is pushed,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
217,Give the basic idea of an SVM using the correct terminology!,227,a support vector machine classifies given data using a decision boundary the width of this decision boundary margin is maximized to ensure good results because a maximized width is as robust as possible the margin width is frac2sqrtw i to maximize it quadratic programming is used in order to handle noisy data slack variables are introduced to eliminate them duality is used,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
218,Give the basic idea of an SVM using the correct terminology!,227,an sum is a linear classifier that divides a binary pattern by a line that maximizes the margin between its line and the respective support vectors,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
219,Give the basic idea of an SVM using the correct terminology!,227,a sum learns a decision boundary from the input data additional it learns two margins which are parallel to the decision boundary and lie as close as possible at the data points the support vectors the decision boundary is chosen so that the margins are maximized using kernel functions higher dimensional data and non nearly separate data can be learned swell,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
220,Give the basic idea of an SVM using the correct terminology!,227,an sum is a learning machine that tries to learn the support vectors of a two class data set to get the maximum margin the optimal separating hyperplane between the two classes,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
221,Give the basic idea of an SVM using the correct terminology!,227,a sum uses a few of the data points as support vectors to build the maximum margin classifier it searches for the separating line which has the maximum margin to the datapoints in cases of noise the separating line is searched which minimizes the distance to the points in the wrong category the data is cast to a higher dimensional space to use covers theorem while using kernels the data is more likely nearly venerable in the higher dimensional feature space using structural risk minimization the dimensionality is reduced,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
222,Give the basic idea of an SVM using the correct terminology!,227,sums are used to nearly separate data points the decision boundary is line or hyperplane in higher dimensions that defines the able of a data point the decon boundary is choose in a way that the margin is maximized data points on the decon boundary are called support vectors and define the hyperplane in 2 dimensions if the data is liner venerable the margin is equal to 2sqrtww where i is the weight vector if the data is not linear venerable the input can be projected into higher dimension space this increases the chance of linear seperablity,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
223,Give the basic idea of an SVM using the correct terminology!,227,support vector machine is classifier which maximizes the margin between boundaries learned from two classes margin is minimum distance by boundaries can be increased before hitting datapoints support vectors are the datapoints against which main pushes up the boundary,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
224,Give the basic idea of an SVM using the correct terminology!,227,support vector machines are the finding classier draw the vision boundary which push against the support vectors,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
225,Give the basic idea of an SVM using the correct terminology!,227,the basic idea of support vector machine sum is to find the width of a line or hyperplane which which divides the input data into two classes the points lying on the edge of the defined width are called support vectors,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
226,Give the basic idea of an SVM using the correct terminology!,227,sum is a classifier that classifies a set of points in a way that maximizes the margin between the points of two classes the classification can be linear or non linear,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,1.0,2.0,neural_networks,neural_course
227,Give the basic idea of an SVM using the correct terminology!,227,the idea behing sum is to find a hyperplane which separate data into classes first it is required to find a data point which are closest to hyperplane and these data points are called support vectors next task is to find a maximum possible width of the hyperplain such that support vectors are on the edge of that hyperplane this problem is formulated as minimal constrained optimization problem in order to find a optimum width of hyperplane optimism of a function the idea is to use method of language multiplied additionally when i data is not nearly separate than an approach is to project data in higher dimension and then to find a hyperplane that separates data in that dimension,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate nonlinear separate data and the algorithm is solved by using quadratic programming,2.0,2.0,neural_networks,neural_course
228, What role does the method of steepest decent have when learning a network?,228,in steepest descent the gradient of the cost function is found by partially differentiating it with respect to the weights the weights are then updated in the opposite direction if the gradient this ensures that the weight moves in the steepest direction are reduced it can also be proven that the weights always reduce hence steepest descent can be used to minimize the cost function,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
229, What role does the method of steepest decent have when learning a network?,228,steepest descent is method of optimizing the algorithm by minimizing the error weights are adjusted in the direction of sleeping descent opposite to the direction of the gradient,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1.0,2.0,neural_networks,neural_course
230, What role does the method of steepest decent have when learning a network?,228,steepest descent moves the error within error surface a small step into the opposite direction of gradient by help of steepest descent we want to minimize error steepest descent stops when gradient 0,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
231, What role does the method of steepest decent have when learning a network?,228,when learning weights with a so method we try to reduce the error based on following the gradient of an error function in the opposite direction effectively trailing the error surface towards the minimum here the error function typically some form of mean squared error is differentiated art the individual weights expressing how much a weight contributes to the network error and must thus be corrected due to the gradient pointing in the direction of steepest ascent we must thus step in the negative direction,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
232, What role does the method of steepest decent have when learning a network?,228,steepest descent is used for error minimization when updating weights according to this we update the weights along a direction which minimizes the error which is calculated by finding the slope at the point,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1.0,2.0,neural_networks,neural_course
233, What role does the method of steepest decent have when learning a network?,228,steepest decent is used to minimize the training error of a network given sample inputs and desired outputs it uses the gradient of the error function to move the weights closer to an optimal weight with lowest output error using a learning rate we can influence the speed and stability of this algorithm,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
234, What role does the method of steepest decent have when learning a network?,228,the steepest decent is the direction the error function falls the most we want to change the weights in the direction of the steepest decent the opposite direction of the gradient to have a smaller error in the next iteration and to optimize the ann,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
235, What role does the method of steepest decent have when learning a network?,228,the idea of learning a network is to minimize a certain costfunction we can use steepest descent to minimize this cost function while there are other optimization techniques which can be used for optimization steepest decent is a widely used optimization technique to optimize a network we calculate the partial derivativesgradient and use it to update our weights it is also used in be,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
236, What role does the method of steepest decent have when learning a network?,228,the approach of the method of steepest descent is to find the direction for the minimization of the error in an approximation problem the cost function e dependent of the weights i will be dedicated partial derivative for all defined weights this gradient will be used for updating the weights for the next iteration the direction of the minimization of the error is the opposite direction of the gradient i,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
237, What role does the method of steepest decent have when learning a network?,228,when the inputs are being send into a network and we calculate the error we need a mechanism to learn and manipulate the free parameters of the network and the learning uses the error but we must know in which direction in the searchoptimization space we should move so that we can reach the global minimal of the error for this we use steepest decent this method tells us in which direction we need to move by getting the gradient from the error,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
238, What role does the method of steepest decent have when learning a network?,228,steepest descent is a method of weight adaptation it is using first order derivative to approximate the function therefore is rather slow,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1.0,2.0,neural_networks,neural_course
239, What role does the method of steepest decent have when learning a network?,228,the steepest descent is an constrained optimization method that seeks to minimize an error function this function is iteratively changed in direction opposite to the gradient vector,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1.0,2.0,neural_networks,neural_course
240, What role does the method of steepest decent have when learning a network?,228,method of steepest descent updates the weights in the direction where the error is minimum,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1.0,2.0,neural_networks,neural_course
241, What role does the method of steepest decent have when learning a network?,228,the steepest descent method is an algorithm for finding the nearest local minimum of a function which presupposes that the gradient of the function can be computed this property is used to determine the optimal weights of the in,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
242, What role does the method of steepest decent have when learning a network?,228,steepest descent is used to update the synaptic weights of a network based on a cost function expressed by the errors of the output the weights are adjusted in the direction opposite to the gradient of the cost function,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
243, What role does the method of steepest decent have when learning a network?,228,in steepest descent the adjustments done on the weight vector are in the direction of the steepest descent which is in the direction opposite to that of a gradient descent in a learning problem it basically used to reduce the cost based on the weight the main goal is to find an optimal weight,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
244, What role does the method of steepest decent have when learning a network?,228,method of steepest decent is an constrained optimization technique used for learning in a network it is used in operative manner to minimize the error in supervised learning it finds the direction of maximum gradient so we go in the opposite direction hoping to find the minimal convergence of the algorithm depends on the learning rate and also the condition that it doesn't get stuck in local minimal,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
245, What role does the method of steepest decent have when learning a network?,228,here in steepest descent method the network moves towards the direction of the maximum gradient the learning with steepest descent method can be slow to converge and can exhibit zigzag behavior,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
246, What role does the method of steepest decent have when learning a network?,228,steepest descent involves weight updating in the direction of maximum steep or maximum decrease in the cost function ot in the direction opposite to the gradient function the weight update is delta in eta in where eta is the learning rate which defines the magnitude of learning using the gradient in which is the gradient of the cost function of errors the nah iteration higher eta will result in rapid learning but with oscillations in responses,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
247, What role does the method of steepest decent have when learning a network?,228,the method of steepest descent is used to find the direction in which the error function viewed as a function of weights is decreasing most rapidly and then take a small step in that direction when learning a network steepest descent enables to iteratively adjust the weight vectors until the optimal weight vector that minimise the cost function ie the error function where error is computed as the difference between the desired and actual response of the network is found,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
248, What role does the method of steepest decent have when learning a network?,228,when learning a network the steepest descent algorithm updates the weights in such a way that the error decreases in every iteration,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1.0,2.0,neural_networks,neural_course
249, What role does the method of steepest decent have when learning a network?,228,the method of steepest descent moves in the direction opposite to the gradient to minimize the cost function,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
250, What role does the method of steepest decent have when learning a network?,228,steepest decent method is based on minimization of error cost function xi 05 even so synaptic weight of network is updated in a direction opposite to gradient vector of xi that is want win eta habla xi win eta en in eta is learning rateekn is neuron i error signal xin is input data,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
251, What role does the method of steepest decent have when learning a network?,228,the steepest is used to find a direction in which e is decreasing most rapidly the adjustments applied to the weights are in the direction of steepest descent,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
252, What role does the method of steepest decent have when learning a network?,228,steepest decent helps to minimize the value of error function e by finding the right direction to move the weight vector to reach global minimal the direction is always opposite to the direction of actual gradient vector,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
253, What role does the method of steepest decent have when learning a network?,228,method of steepest descent is used to reduce the error in backpropogation during backward pass we need to know how by how much amount the weights should be changed this can be known if we use steepest descent find the gradient of error and use it to reduce the error,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
254, What role does the method of steepest decent have when learning a network?,228,the steepest descent finds the direction of the error function and tries to reduce it by adding in the opposite direction del i eta in in gradient of the cost function,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
255, What role does the method of steepest decent have when learning a network?,228,the steepest descent is used to find the right direction in which the weights should be changed while learning a network the private of the error is used and weights are changed in that direction which makes the error smaller as fast as possible,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
256, What role does the method of steepest decent have when learning a network?,228,the steepest descent can be used to optimize the weights of a network in steepest descent the error function is a function of the weights so we determine the direction of the steepest descent on the error surface and go into that direction to minimize the error of the weights on optimize them,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1.0,2.0,neural_networks,neural_course
257, What role does the method of steepest decent have when learning a network?,228,the method of steepest descent is used to minimize the error function the error function is the gradient of the error delta e i y where i is the desired output and y is the actual output of the neuron,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
258, What role does the method of steepest decent have when learning a network?,228,steepest descent is the basic learning algorithm others are derived from the goal when learning a network is to minimize the error this is achieved by starting at a random position and going in the opposite direction of the gradient vector the steepest descent,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
259, What role does the method of steepest decent have when learning a network?,228,the error function is computer to adapt the weights learn the network the error function is followed in small steps in direction of steepest descent to decrease the error using iterations the error is decreased in each step and end in a local minimum used in backpropagation,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1.0,2.0,neural_networks,neural_course
260, What role does the method of steepest decent have when learning a network?,228,in error correction learning the weights of a network are learned in a way that ex is minimized where ex is some error function in order to minimize the error function the method of steepest defend is used the negative gradient of ex points in the direction of steepest defend doing steepest descend in a single layer feed forward network leads to the delta rule,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
261, What role does the method of steepest decent have when learning a network?,228,steepest descent adjust the parameters weights and bias of the in to minimize the error it does so by adjusting the weights in the direction of steepest descent of the error function,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1.0,2.0,neural_networks,neural_course
262, What role does the method of steepest decent have when learning a network?,228,steepest decent while move in the direction of the max improvement in terms of decreasing in the cost function or error if the learning rate is large then the it follows the zigzag motion if the learning rate is too low then it takes time for converging,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1.0,2.0,neural_networks,neural_course
263, What role does the method of steepest decent have when learning a network?,228,the method of steepest descent is responsible for weight adjustments in the network the weights are adjusted in the direction of the steepest descent that is equal to the negative grad of the error it ensures that the weights are decreased in every iteration step,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
264, What role does the method of steepest decent have when learning a network?,228,steepest decent method helps in making the adjustments of the weights in a neural network in a way that minimizes the average squared error in each step it gives the direction towards which the maximum decrease of the average squared error can be achieved,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1.0,2.0,neural_networks,neural_course
265, What role does the method of steepest decent have when learning a network?,228,the method of steepest decent is used for finding minimum of a posterior function the steepest decent operates over possible values of weight vector to optimize the function it is used for deriving error function in adalind adaptive linear element algorithm and it is used also in backpropagation method in training of multiplayer nuns,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2.0,2.0,neural_networks,neural_course
266,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a dataset a subset i with i datapoints has in binary maps if for any of these binary maps a hypothesis i in i splits the positive data from the negative data such that there is no training error then it is said that i shatters the dataset a,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
267,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0.0,2.0,neural_networks,neural_course
268,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a a hypothesis i in i shatters a dataset a subset i leftrightarrow lots if there exists a an alpha for every training set with zero training error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,1.0,2.0,neural_networks,neural_course
269,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,when our learned machine achieves zero training error on every classification problem of the dataset a since we got a selection of i points in the dataset a the number of problems in binary classification is 2 to the power of i i didn't find the each symbol on the english keyboard,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
270,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,considering a dataset a subset i where i is the instance space and a contains i elements now there are in binary maps or learning problems when we what to separate two classes if any of these problems can be separated completely by hypothesis i in i then i is said to shatter a ie a hypothesis shatters a dataset if it can completely separate the classes with zero error for all possible combination of labels in the dataset,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
271,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,when every possible combination of input and desired output can be classified using i,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,1.0,2.0,neural_networks,neural_course
272,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a hypothesis i in i shatters a dataset a subset i then for every point xi in a there is a label yi in 11 and the i can separate these two classes using i with no training error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
273,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,there exists an arrangement of these points in a such that for each possible combination of labels to these points the hypothesis i has zero training error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0.0,2.0,neural_networks,neural_course
274,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,an hypothesis i shatters a dataset a if for a given data set i is able to distinguish or separate the different classes of this data set,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
275,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,i shatters a if for any set of input data points in a there exist at least one training error of zero,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
276,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,i shatters a when for example in given dataset x1x2xr output are in a form xu y1x2y2xryr there has been found a 0 error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
277,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a machine i can shatter a set of points xu xu xu in if and only if for every training set there is a weight vector alpha that produces zero training error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
278,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a hypothesis i in i shatters a dataset a subset i leftrightarrow for each assignable configuration of xi yin a i perfectly classifies all elements of the set a,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
279,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0.0,2.0,neural_networks,neural_course
280,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a hypothesis i in i shatters a dataset a subset i leftrightarrow at least on possible combination of dataset a can be classified by the hypothesis i in i with zero training error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0.0,2.0,neural_networks,neural_course
281,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,given a dataset a subset i where i is the instant data space for a given problem with the dataset a if a learning machine is able to successfully split the positive and the negative data then we say that a is shattered by the learning machine,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
282,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,suppose i is a training dataset and a is the subset of training dataset then hypothesis i is said to shatter if can correctly classify all the points in a ie zero training error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
283,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,here a hypothesis i in i shatters a dataset a subset i leftrightarrow lots if the hypothesis can clearly distinguish the positive examples from the negative examples in a,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,1.0,2.0,neural_networks,neural_course
284,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a hypothesis i is model that separates a dataset consisting of xi yi samples into positive and negative samples i is said to shatter a given subset of a dataset if it can successfully separate at least one configuration of the subset of dataset,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0.0,2.0,neural_networks,neural_course
285,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a hypothesis i in i shatters a dataset a subset i if there exists an alpha for which there is zero training error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
286,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,for each of the in where i is the size of a combinations of input output mapping of the form xi yi i is able to classify the data correctly that is with zero error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
287,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0.0,2.0,neural_networks,neural_course
288,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,for all possible binary labeling of dataset a we can find a hypothesis i that can separate the positive examples from negative examples the i shatters a,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
289,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,the hypothesis i can shatter any points of xu xu in if and only if for every possible training set of the form xu ya xu ya in yn there exist some values of alpha that gets zero training error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
290,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a hypothesis space i shatters a dataset if and only if there is a possible alpha weight vector on hypothesis space that separates all the positive data from negative data,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,1.0,2.0,neural_networks,neural_course
291,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a hypothesis i in i shatters a subset i if and only if there exists a value of alpha for which the training error is zero,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,1.0,2.0,neural_networks,neural_course
292,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,i is the ve dimension of a learning machine that can shatter i points ve dimension of a learning machine is the maximum number of points that can be arranged so that the learning machine can shatter them shattering the learning machine is said to shatter points xu or if and only if all the possible training set of xy try can be classified with zero training error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
293,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a hypothesis shatters a dataset if it can correctly classify all combinations of labelling of the points in the dataset,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
294,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,if there exists a configuration of i so that i gets zero training error on any dichotomy of the datapoints,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0.0,2.0,neural_networks,neural_course
295,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,there exist i weights which produce a perfect classification,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0.0,2.0,neural_networks,neural_course
296,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,for all possible classified subsets of dataset a the hypothesis i can separate it,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
297,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,when all combinations of position and labeling of the data can be separated in the given classes by the hypothesis,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
298,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,i shatters a when and only when for all possibilities of a ya a ya an yn where y is the class able 1 or 1 there exists some alpha for a learning machine i that produces 0 training error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
299,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,if there exist atleast one configuration of a for which training error of i is zero ie it successfully classifies all points in a,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0.0,2.0,neural_networks,neural_course
300,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,and there exist a linear saperater which separates positive examples from the negative examples correctly then we say that a can be shatter at i,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
301,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,given a data set a if it is possible to find a hypothesis i which separates the data set into binary form without any error we can say that hypothesis i in i shatters dataaet a subset i leftrightarrow lots,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
302,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,it means that for all the points in a with input output pair xy for any combination of xiii there exist parameter alpha of i that enables i to classify the points with zero error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2.0,2.0,neural_networks,neural_course
303,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,we say that a hypothesis i shatters a dataset a iff the i produces a zero training error for certain data set a in other words we say that a hypothesis i shatters a dataset a when i separates data a in two classes without error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0.0,2.0,neural_networks,neural_course
304,Write down and explain the Widrow-Hoff learning rule!,230,delta i eta even where eta is the learning rate widrowhoff rule states that the change in weights is proportional to the product of the error and the input in the corresponding synapse,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
305,Write down and explain the Widrow-Hoff learning rule!,230,weights adjusted are proportional to the product of error signal and the input vector in 1 in etadyxn eta is learning rate i is desired output y is current output in in input vector,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
306,Write down and explain the Widrow-Hoff learning rule!,230,adoption of weight is proportional to product of input and error new wold xe,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1.0,2.0,neural_networks,neural_course
307,Write down and explain the Widrow-Hoff learning rule!,230,for neurons with a linear activation function adalind wt1wtalpha dye where i is the input pattern i is the true value and y is the net output notice that the delta rule looks similar to the perception learning rule but was derived from so whereas the perception works with a step function which is not fully differential,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
308,Write down and explain the Widrow-Hoff learning rule!,230,widrowhoff learning rule is also known as error correction rule is used to update the weights as delta i eta diyixi where i is the desired output and y is the output the network generates and i is the input,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1.0,2.0,neural_networks,neural_course
309,Write down and explain the Widrow-Hoff learning rule!,230,and in mu in yen the change of the weights is determined using the error in yn and the input that was given to the network the learning rate can improve leaving speed the new weights are dependent on the old ones and the change calculated,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1.0,2.0,neural_networks,neural_course
310,Write down and explain the Widrow-Hoff learning rule!,230,win win learningratedjyjxi we change the weights by computing the error e day for the input and multiply it by the learningrate and the xi and adding it to the old weight this minimise the squared error function our cost function and is the online variant of the steepest decent method,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
311,Write down and explain the Widrow-Hoff learning rule!,230,delta in eta even en ya the widow off learning rule is error correction learning it is used to train a network in a supervised manner the widow off learning rule can be derived from gradient decent the rule consists of the error en the neuron has and is multiplied with the weight so that the impact of the weight to the error is incorporated into the update a learning rule is use as a adjustment in how much we trust the weight change the error is calculate by the difference between the current and expected output,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
312,Write down and explain the Widrow-Hoff learning rule!,230,the widrowhoff learning rule is defined as in 1 in eta in en the widrowhoff learning rule is a rule for adjusting the weights of a in for a error correction learning task this learning rule is derived from the steepest descent method where the direction for the minimization of the error is the defined as the opposite direction of the cost functions gradient this gradient can be simplified as in en where en is defined as the difference between the desired response and the actual response of the learning machine in en in yn eta defines the learning rate used,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
313,Write down and explain the Widrow-Hoff learning rule!,230,,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,0.0,2.0,neural_networks,neural_course
314,Write down and explain the Widrow-Hoff learning rule!,230,windrowhoff rule is wnewxinputwolddoutputyoutputetaa where wnewnew weightwoldold weightdoutputdesired outputyoutputactual outputxinputinput etalearning rate learning constant,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,0.0,2.0,neural_networks,neural_course
315,Write down and explain the Widrow-Hoff learning rule!,230,the widrowholf or delta rule is a gradient descent learning rule used to adapt weight in a perception delta in stand yen delta in eta even,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1.0,2.0,neural_networks,neural_course
316,Write down and explain the Widrow-Hoff learning rule!,230,the widrowhoff delta learning rule is given by and in eta in en where en is the error vector eta is learning parameter in is input vector,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1.0,2.0,neural_networks,neural_course
317,Write down and explain the Widrow-Hoff learning rule!,230,the widrowhoff learning rule is also referred to as delta or least mean square les rule it is used to minimize the cost function and is defined as follows delta win eta partial xin partial win where eta is the learning rate parameter xin is the total instantaneous error energy and i are the weights,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1.0,2.0,neural_networks,neural_course
318,Write down and explain the Widrow-Hoff learning rule!,230,the widrowhoff learning rule also called delta rule is used for learning a network by adjusting the synaptic weights of the network with the error signals and in eta in yn in where i is the number of iteration eta is the learning rate in is the desired output signal yn is the actual output signal and in is the input signal in yn is the error signal,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
319,Write down and explain the Widrow-Hoff learning rule!,230,widow offs learning rule states that the adjustment of the weight of a synapses are promotional to the product of the error function and the input which is given by the synapses based on the problem,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1.0,2.0,neural_networks,neural_course
320,Write down and explain the Widrow-Hoff learning rule!,230,widow off rule is based minimising the mean square error using gradient descent algorithm weights are adjusted in following manner and in i gradient of mean square error be it takes the gradient of the mean square error 05 en en fracpartial partial i en in,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
321,Write down and explain the Widrow-Hoff learning rule!,230,here widow off rule delta i eta en in widrowhoff rule states that when an input in produces an error en then the change in the weight is directly proportional to the error signal and the input signal,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1.0,2.0,neural_networks,neural_course
322,Write down and explain the Widrow-Hoff learning rule!,230,widow off learning rule is also called as error correction learning rule the error is defined as the difference between the desired and the actual output of the learning machine assuming the desired sign is available the error is computed and weights of the neural network are updated in the direction of reduction of errors the error for each input sample for a neuron i is computed using ski ski ski weight change delta i we that is the dot product of error and the weights is computed,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
323,Write down and explain the Widrow-Hoff learning rule!,230,given a neuron i excited by an input signal xi if ski is the synaptic weight of the neuron then the widrowhoff learning rule gives the weight adjustment delta ski applied to the neuron i in mathematical terms as follows delta ski eta linen where en is the instantaneous value of the error signal thus the widrowhoff rule states that the synaptic adjustment applied to the weights of a neuron is proportional to the product of the input signal to the neuro and the instantaneous value of the error signal this rule assumes that the neuron has an external supply of desired response so that the error can be computed,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
324,Write down and explain the Widrow-Hoff learning rule!,230,the widrowhoff learning rule is given by in 1 in eta en in where in weight in iteration i en in yn error in desired output yn actual output in input eta learning rate,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1.0,2.0,neural_networks,neural_course
325,Write down and explain the Widrow-Hoff learning rule!,230,widow off learning rule states that the adaptation made to the synaptic weights is proportional to the product of input and the error function basically states that if the error is high then the product of input and error will also be high and thus the adjustment made to the weight would be more want win etaerrorinput,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
326,Write down and explain the Widrow-Hoff learning rule!,230,it is based on minimization of error cost function xi 05 even so synaptic weight from neuron i to input i is updated in a direction opposite to gradient vector of xi that is wkjn1 when eta habla xi when eta en xin eta is learning rateekn is neuron i error signal xin is input data,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
327,Write down and explain the Widrow-Hoff learning rule!,230,windrowhoff or error correction learning rule says that the adjustment of a weight is proportional to the product of the error signal and the input signal of the weight,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1.0,2.0,neural_networks,neural_course
328,Write down and explain the Widrow-Hoff learning rule!,230,bigtriangleup omega e xi omega omega eta bigtriangleup omega widow off learning rule says that the synaptic weight update is directly proportional to the product of error and the input,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
329,Write down and explain the Widrow-Hoff learning rule!,230,widrowhoff learning rule the rules states that the weight update is directly proportional to the product of the input to the neuron and the error delta win eta en sum xin,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1.0,2.0,neural_networks,neural_course
330,Write down and explain the Widrow-Hoff learning rule!,230,delta we eta ek xu widow off rules states that the change in synaptic weight is proportional to the product of the error signal and the input signal,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1.0,2.0,neural_networks,neural_course
331,Write down and explain the Widrow-Hoff learning rule!,230,delta in mu in en mu learning rate in input at trimester i en in yn in desired signal at trimester i yn output of the network at trimester i the widroffhoff or delta rule changes the weights depending on the input and the error which is the difference between the output of the network and the desired output this weight change can be scaled by a learning rate,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
332,Write down and explain the Widrow-Hoff learning rule!,230,the widrowhoff rule is used in errorcorrection learning and uses the current error and output of the system to determine the new weights and went dot en dot yn,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1.0,2.0,neural_networks,neural_course
333,Write down and explain the Widrow-Hoff learning rule!,230,delta in learningrate dot in dot en where i is the input data e i y is the error from the desired output and the actual output and the learningrate is a parameter chosen as necessary to change the speed of learning new wold learningrate dot i dot e this is the formula to update the weights and to learn the input data,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
334,Write down and explain the Widrow-Hoff learning rule!,230,weights weights learningrate desired output the widrowhoff rule also the delta rule is used to update the weights of neural networks in a learning algorithm it uses the previous weights result and compares it to the desired result this discrepancy is then applied to update the weights based on a learning rate,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
335,Write down and explain the Widrow-Hoff learning rule!,230,new wold learningparameter error input while error is desiredinput currentoutput the new value for the synaptic weight is computed of the old value plus a learning rate times the current error and the input the output error is decreased in each step until the change is to small or the generalization is sufficient,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
336,Write down and explain the Widrow-Hoff learning rule!,230,rule we i i i y i where i is the learning rate i is the input y is the output of the network i is the desired output the widrowhoff rule minimizes the error ya the weight change is proportional the input i and the error it can be derived from steepest descend,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
337,Write down and explain the Widrow-Hoff learning rule!,230,,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,0.0,2.0,neural_networks,neural_course
338,Write down and explain the Widrow-Hoff learning rule!,230,this the basically the calculating mean squared error me from the expected output and real output modifying the weights for minimizing me it,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,0.0,2.0,neural_networks,neural_course
339,Write down and explain the Widrow-Hoff learning rule!,230,widrowhoff rule states that the weight adjustment is proportional to the product of input and the error in the output it is also called the delta rule delta wi eta xie eta is the proportional constant also called as learning constant wiwi1delta wi,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
340,Write down and explain the Widrow-Hoff learning rule!,230,delta wi eta exit adjustment made to the weight of a neuron is proportional to the product of the error in that neuron and input applied to the neuron,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
341,Write down and explain the Widrow-Hoff learning rule!,230,widrowhoff learning rule is derived from les error method and it is defined as to it mu dot delta i where mu represent learning rate and delta i gradient of instantaneous error i ya here i represent desired signal while y represent output signal of a neuron i represent input of a neuron,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2.0,2.0,neural_networks,neural_course
342,"Explain back propagation, use the correct technical terms!",231,in backpropagation the gradient of the error produced at the output layer by partially differentiating the cost function with respect to the weights is propagated backwards one layer at a time back to the input layer this propagated gradient is used to update the weights in the corresponding layer backpropagation is necessary because the desired output at every layer is not known and it is only possible to formulate the cost function at the output layer,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
343,"Explain back propagation, use the correct technical terms!",231,in back propagation there are two phases 1 forward phase first we apply input to the network and compute the current output 2 backward phase we compute the error between current and desired output error is minimized by computing gradient of error with respect to weight in return weights are adjust after adjusting weights in backward phase we again go to forward phase and compute the current output check whether error is minimized or not,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
344,"Explain back propagation, use the correct technical terms!",231,back propagation wants to minimize the error function e e is given by frac12sum end the error function can be minimized by calculating the gradient starting from the output term for calculating the gradient differs it depends on whether the neuron for which the gradient to be calculated is an output neuron or a hidden neuron,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
345,"Explain back propagation, use the correct technical terms!",231,backpropagation is the general form of the delta rule formulated for networks with multiple hidden layers here we propagate the error of the network back to the input layer to determine the change of weights using the error signal in the output layer and subsequently the local gradients in the hidden layers in the forward pass we compute the net output forwards in the backward pass we propagate the error backwards the be rule was derived from the error gradient art the weights and application of the chain rule,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
346,"Explain back propagation, use the correct technical terms!",231,back propagation is propagation of error from the output layer to the hidden layer in network with multiple layers this is done by calculating the local gradient of each node and then using this along with the weight to determine how much of the error is to be propagated to the particular node,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
347,"Explain back propagation, use the correct technical terms!",231,back propagation is used in multi layer network it consists of two phases forward and backward in the forward phase we give and input to the network and calculate its outputs also memorize the local field of each node the local gradient delta is used to adapt the weights of the layers it is different for output and the remaining layers for node i in an output layer deltaivi varphiprimevidi yi for node i in other layers deltaivi varphiprimevisumjin i wi deltajvj where i are all the nodes that use node i output as an input repeat this process for all input data until error is small enough,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
348,"Explain back propagation, use the correct technical terms!",231,the back propagation algorithm is there to train a multiplayer feedforward ann we change the weights by computing the local radiant at each neuron by using the neurons in the layer befor the local gradient of the output neurons can be computed easily the activation function has to be differantable for the backpropagation algorithm in the forward pass we compute the output y at the output layer in the backyard pass we use the output y and our desired output i to compute the local gradients at the output layer then we go back layer by layer and use the local gradients from before to compute the new local gradients by that we minimize the average squared error function,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
349,"Explain back propagation, use the correct technical terms!",231,backpropagation is a learning algorithm for multiplayer of in it is supervised error correction learning the weights are initialized randomly the algorithm has to steps in the forward pass the the output is calculated by using the current weights in the backward pass the weight update for the outputlayer is as like in single layer of the error is used to update the weights be allows us to also calculate the error of hidden layers for each hidden layer we use a local gradient as the error the local gradient is the sum of weighted error of the following layer which is passed trough the private of the activation function so it is possible to backpropagate the error from the output layer to to first layer a common problem in be is the vanishing gradient problem depending on the activation function used the local gradient gets smaller in each layer until it is eventually less than the floating point precision used this limits the number of layers that can be stacked,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
350,"Explain back propagation, use the correct technical terms!",231,the back propagation algorithm is a learning algorithm for updating in the weights in a multiplayer neural network for updating the weights of all the layers the error of each neuron must be calculated in the back propagation algorithm two phases will be defined forward phase the output of the neural network will be calculated and also the error of the neurons in the output layer backward phase the gradient of each neuron will be calculated by using the calculated error on the output layer and the defined connections between the hidden layer and the output layer if multiple hidden layers are defined the error will be iteratevely will be given backwards and the weights at each neuron will be updated,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
351,"Explain back propagation, use the correct technical terms!",231,back propagation is a steepest decent method that uses the final produced error and the local gradient to define the amount of change needed for each synaptic weight in this method we have two phase forward phase in this phase we feed the input to the network and the network calculate the output backward phase in this phase we first calculate the error and then use the local gradient to propagate the error to the network from the last layer to the first and manipulate the synaptic weights,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
352,"Explain back propagation, use the correct technical terms!",231,back propagation consists of two steps 1 forward pass data is passed through the network and weights are adapted 2 backward pass by using local field of each neuron error signal is propagated backward by using local field of each neuron from end to beginning and stacking them up local field is partial derivative of the output signal of a a neuron for output neuron it is simplest to calculate as it has only desired output and actual output to deal with,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
353,"Explain back propagation, use the correct technical terms!",231,backpropagation is a learning algorithm in multi layer networks that consists of two phases a forward pass and a backward pass in the forward pass the output is calculated by passing activation layer through layer starting from the input then through hidden layer and finally output then the error is calculated in the output layer and propagated backward through the network in the forward pass the weight do not change in the backward pass the weights change in proportion to the local gradient,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
354,"Explain back propagation, use the correct technical terms!",231,backpropagation is a neural network based learning algorithm where the network learns by propagating the error through the network be consists of two stages forward pass where the error is computed by feeding the input to the network backward pass where error is propagated through the network for doing the weight updates locally since be has vanishing gradient problem it is useful to use activation functions which are infinitely differential such as sigmoid function,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
355,"Explain back propagation, use the correct technical terms!",231,the back propagation algorithm is used to calculate the error contribution of each neuron after a batch of data is processed required is a known desired output of each input value thus the back propagation algorithm is a supervised method the algorithm can be subdivided into two phases 1 propagation propagation forward through the network to generate the output values calculation of the cost error term propagation of the output activation back through the network using the training pattern target in order to generate the deltas differences between desired and actual output of all output and hidden neurons by recursevliy computing the local gradient of each neuron 2 weight update for each weight the following steps need to be applied the weights output delta and input activation are multiplied to find the gradient of the weight a ratio percentage of the weights gradient is subtracted from the weight this ration is also referred to as the learning rate and influences the speed and quality of the learning learning is repeated for every new batch until the network performs adequately,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
356,"Explain back propagation, use the correct technical terms!",231,backpropagation is an algorithm for training a neural network and it contains of two main stages the first stage is to compute the actual output given the input in this stage the signal flows forward from the input layer to the output layer and the synaptic weights are fixed the second stage is to update the synaptic weights by propagating the error signals backward from the output layer in a layerbylayer manner for each neuron the local gradient the partial derivative of cost function to the local field is computed,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
357,"Explain back propagation, use the correct technical terms!",231,back propagation usually occurs in a multi layer perception it uses a non linear activation function basic elements 1 functional signals these are the input signals which passes through the network from left to right as the name denotes it performs a useful function at the output of the neuron and another reason for the name is that the functional signals are calculated based on the parameters and the activation function 2 error signals error signals propagate usually in the reverse direction which contains the error based on the desired output it consists of 2 phases 1 forward phase in the forward phase the signals propagate from left to right weights are fixed and passes through all the layers of the network that is undergo all the activation 2 reverse phase in the reverse phase the local gradients are calculated and are propagated through in the backward direction here weights change,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
358,"Explain back propagation, use the correct technical terms!",231,backpropogation is used for training multi layer networks it constitutes of forward pass and backward pass in forward pass network computes the output based on this the errors are calculated based on difference between network output and desired output these errors are the backpropogated to network during backward pass and used for adjusting the synaptic weights,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
359,"Explain back propagation, use the correct technical terms!",231,here backpropagation is used for multiplayer perception network it consists of two passes forward pass the outputs are calculated at every computational node and passed till the output node where the error is calculated by difference of desired output and the actual output in this pass the weights of the synaptic links are not changed backward pass the error generated at the output neuron is passed in the backward direction ie against the direction of the synapses and the local gradient of the error is calculated at every neuron,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
360,"Explain back propagation, use the correct technical terms!",231,back prop is a way of training a neural network by adapting the weights using error produced it consists of two phases forward and backward forward phase computes the output along the network using the function signal in the backward phase the error of the output fromthe desired output is computed and a local gradient of the error is used to update the weights of the network the local gradient considers the credit or blame of the corresponding weights of neuron in producing the output,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
361,"Explain back propagation, use the correct technical terms!",231,the back propagation algorithm is based on the error correction learning rule and consists of two passes 1 forward pass the input signal applied to the source nodes of the network is propagated forwards through the different layers of the network and the output is computed at the output layer of the network 2 backward pass the error signal computed at the output is propagated backwards with a local gradient computed at each of the hidden layer neurons in order to adjust the synaptic weights the neuron in the network,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
362,"Explain back propagation, use the correct technical terms!",231,back propagation is moving the error backwards recursive through the network by calculating the local field of every neuron to update the weights it is based on the chaining rule of derivatives,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
363,"Explain back propagation, use the correct technical terms!",231,backpropagation is a neural network which has two stages forward pass in forward pass the error is calculated in the output layer with the help of the desired output and the given output e i y backward pass it begins in the output layer in this case the error is passed backwards with the calculation of gradients at each layer of the neural network so in back propagation the adjustment to weights is made based on the local gradients which is calculated at each layer,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
364,"Explain back propagation, use the correct technical terms!",231,it contains forward pass and backward pass in the forward pass input is applied to the network and propagate it forward through the network then compute the output of neurons in output layer and errors for output neurons in the backward pass compute local gradients and update the synaptic weights according to error correction rule for each neuron layer by layer in a backward direction,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
365,"Explain back propagation, use the correct technical terms!",231,backpropagation algorithm consists of two passes 1 forward pass the input vector is applied to the network layer by layer 2 backward pass the weight is adjusted based on error correction learning rule be be back propagation uses error correction learning rule and the objective is to minimize the average of squared error,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
366,"Explain back propagation, use the correct technical terms!",231,backpropagation is a steepest decent method that calculates the error at the output neurons and backpropagates those errors backwards to update the weights of each neuron the synaptic weight updated is directly proportional to partial derivatives local gradient is calculated at output neurons and hidden neurons local gradient at output neurons are calculated using the observed error but the error function is missing in the hidden neurons so the local gradient of hidden neuron i is calculated recursive from the local gradients of all neurons which are connected directly to the hidden neuron i,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
367,"Explain back propagation, use the correct technical terms!",231,backpropogation has 2 steps forward pass in forward pass the data is run through the network and the error is calculated backward pass in backward pass the weight is adjusted using local gradient of error such that the error is minimized there are many ways for weight adjustment like steepest descent newtons method gauss newton method,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
368,"Explain back propagation, use the correct technical terms!",231,the back propagation is a learning method in neural networks back propagation enables the feed forward network to represent for gate it has two phases forward pass the initial weights are used to calculate the value of the output neuron backward pass starts from the output layer and travels backward during this phase the weights are changed based on the local gradients of each neuron,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
369,"Explain back propagation, use the correct technical terms!",231,back propagation is used to learn weights in a multiplayer feed forward network it is divided into two steps forward and backward in the forward step one input is passed through the network to calculate the output of the network this output is used to calculate the error of each output neuron given the desired output after this forward step in the backward step the weights are changed beginning in the end of the network each weight is changed by taking the derivative of the activation function of the neuron times either the error if the following neuron is an output neuron or all local gradients of connected neurons times the corresponding weights the weight changes are the local fields,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
370,"Explain back propagation, use the correct technical terms!",231,backpropagation is used in multiplayer perceptions to give a method of adapting the weights first the forward phase is run like in a regular feedforward network then after the output and thus the error is determined the error is backpropagated from output layer through the network since we have multiple layers there is only a desired output of the network for the last layer to counteract this problem a gradient is calculated for every neuron during the backward pass the gradient is giving a measure of the contribution of this neuron to the final error the gradient is then used to update the neurons weights if the neuron is not part of the output layer the previous gradients are used to calculate the new gradient instead of using the error,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
371,"Explain back propagation, use the correct technical terms!",231,back propagation consists of two steps 1 step forward pass here the input data is fed into the network and the output is calculated at the output nodes the usual calculations of the induced local field are done by using this formula i sum we i the output is then calculated using this formula y fu where i is the activation function 2 step backward pass here the error is backpropagated through the network from the output layer to the input layer in the output layer the error is calculated using this formula delta i y using the desired output i and the actual output y in the layers before the output layer the local gradient is used to calculate the error using the error from the output layer delta delta i additionally the weights are updated using new wold learningrate dot delta i,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
372,"Explain back propagation, use the correct technical terms!",231,back propagation is a learning algorithm for multiplayer neural networks at first the input is propagated through the network until the end is reached here the error is calculated with the desired result then the error is used to update the weights from the back to the front for the output layer the weights can be updated directly with the calculated error the following layers have to use the local gradient of the previous error which is calculated with the derivative of the activation function and its error this is then used to update the weights and repeated until the front is reached,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
373,"Explain back propagation, use the correct technical terms!",231,back propagation is used in multiplayer feedforward networks first the forward pass is computed the given error at the output nodes is used to compute the weight changes using widrowhoff learning rule then the error is given back layer by layer in the backward pass to compute the error and weight changing for each layer recursive the learning can be done in sequential online or batch mode offline,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
374,"Explain back propagation, use the correct technical terms!",231,in multi layer of networks the error is only available in the last layer therefore the error is propagated back through the network using the backpropagtion algorithm in order to do so the local gradient has to be calculated update of the weight we i i i gradient where the put i is the output of the previous layer the local gradient is calculated differently depending if the neuron is in the output layer or in the hidden layer output layer gradient phil y i hidden layer gradient phil sum local gradient,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
375,"Explain back propagation, use the correct technical terms!",231,in steepest gradient weights are adjusted in decreasing direction of error function but for hidden neurons there is no labels available to calculate the error hence final output error is backpropogated through the layers inside the hidden layers of in this is possible with continuous activation function and chain rule on its derivatives final error is differentiated with respect to hidden weights chain rule is applied to find local error on hidden neurons,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
376,"Explain back propagation, use the correct technical terms!",231,the back propagation algorithm it consist of forward pass and backward pass computes the output of the neuron then it propagates in backward direction while recursive compute local gradient of the neuron weights are adjusted accordingly,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
377,"Explain back propagation, use the correct technical terms!",231,back propagation is the process of learning in multi layer perception in which the error from the output of the network is fed back into the network to adjust the weights in the hidden layer that is the error back propagates into the network to enable the network to learn by adjusting the synaptic weights based on it,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
378,"Explain back propagation, use the correct technical terms!",231,back propagation is a process to make adjustment to the weights of a neural network in a way that minimizes the average squared error of the training data it uses steepest decent method in each step it moves towards the direction that gives maximum decrease of the error in back propagation the error is prepared backward from the last layer towards the earlier layers the adjustments made to the weights is proportional to the partial derivative of the error with respect to the weight the partial derivative is calculated using repeated application of the chain rule,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1.0,2.0,neural_networks,neural_course
379,"Explain back propagation, use the correct technical terms!",231,the idea of back propagation method is to propagate error from output final layer backward to hidden layers and adjust the weighs of neurons in hidden layer based of this error this is required because we do not have error information for hidden layers only for output neurons the error from output layer is propagated to hidden layers using idea from steepest descent method namely local gradients are computed for each neuron in backpropagation and these local gradients define how error changes in terms of weights local gradients are derived from chain rule for each layer the fact that local gradient for each hidden layer is derived based on local gradient of a previous layer defines that as we propagate more and more in hidden layers of in the gradient of a error function vanishes which means that as we go deeply back in in the change in weights is becoming smaller and smaller this is a drawback of back propagation method,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2.0,2.0,neural_networks,neural_course
380,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate controls the speed of the descent when learning rate is low the weight updating is overlapped and convergence is slow when the learning rate is high the weight updating is underdamped and a zigzagging behaviour is exhibited in the weight space when the learning rate is too large learning becomes unstable,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
381,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,if learning rate is very smaller then transition are overlapping trajectory of weight vector follows the smooth path if learning rate is large then transition are underdamping trajectory of weight vector exhibits the zigzagging oscillator behavior if learning gets higher than some threshold then learning algorithm gets unstable or diverged,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,1.0,2.0,neural_networks,neural_course
382,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate i determines stride of delta of weight if learning rate is too large weights starts to ziggerate,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,1.0,2.0,neural_networks,neural_course
383,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,when training with so the learning rate determines the step size we take towards the negative gradient when the learning rate is too small the weights may be overlapped and reach the error function minimum slowly eventually getting stuck in local minimal when step size is too big the weights may be underdampened bouncing between ridges of the error surface and never find the minimum especially when the minimum is in a steep ravine of the error surface,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
384,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate is used to control how much the wright update is affected by the error correction or so on learning rate too low learning is slow and takes more time learning rate too high learning is fast but causes zigzagging behaviour in convergence if the learning rate is too high it may result in situations where the zigzagging behaviour will cause it to overshoot and may never finally converge,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
385,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate defines the speed of the weight change a learning rate too high can lead to oscillation around the optimal weight such that its never reached a learning rate to low results in very slow learning and slow convergence,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,1.0,2.0,neural_networks,neural_course
386,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate is needed to make the algorithm more stable a high learning rate makes the weightchanges zickzacking and the algorithm might not converge a low learning rate makes the path in the plane more smooth if the learning rate gets to a certain critical value the algorithm might not converge at all,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
387,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning create is a factor of how much we trust the datapoint normally it is in the range of 01 a high learning rate normally results in a faster convergence while a lower rate in a slower conversion if the rate is choose to high it is possible that the cost function diverged if the rate is to slow it is possible that the rate so conversion is so slow that we never reach a local minimum,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
388,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate is a parameter using on updating the weights in a given iteration this parameter represents the importance that is given to the adaptation of the weights so when setting the learning rate small the learning machine will learn slower but also in a more stable way on the other hand when setting the learning rate with a large value the learning machine will learn faster but in an unstable way the danger here is that depending on the learning rates value the algorithm may never come into the perfect value if the learning rate is too small it may land into a local minimum and never approach the global minimum of the function if the learning rate is too big the learning progression will have a zigzagging behaviour and never approach the ideal value,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
389,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate defines the size of steps that the method moves in the search space if the learning rate is too small the method needs to take huge number of steps and maybe it stuck in a local minimal if the learning rate is too big the method will converge very fast toward the global minimal but there is a probability that it oscillates around the global minimal and never reach it,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
390,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,if learning rate is to large then process will oscillate a lot and might not converge if learning rate is to small then convergence will happen very slowly,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,1.0,2.0,neural_networks,neural_course
391,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate tells us how confident we are of the error and it affect the convergence rate a low learning rate will slow the convergence making the system overlapped a high learning rate will speed the convergence but the value oscillates making the system underdamped the system can become unstable if the learning rate is above a threshold value,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
392,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,if the learning rate is too small then the system is overlapped and the algorithm takes a long time to converge if the learning rate is too large then the system is underdamped and the algorithm oscillates around and optimal solution or could potentially make the system unstable,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
393,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the steepest descent method is an algorithm for finding the nearest local minimum of a function which presupposes that the gradient of the function can be computed the method of steepest descent starts at a point pa and as many times needed moves from pi to pig by minimizing along the line extending from pi in the direction of gradient fbi the local downhill gradient the danger of the algorithm is that it can get stuck in a local minimal,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
394,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate determines the rate of learning the smaller the leaving rate is the slower the learning process is but the path of weight adjustment is smoother the larger the value is the faster the leaving process is but it can result in oscillation and instability,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
395,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate is eta so based on the learning rate it undergoes various oscillation we could see zigzagging behaviours 1 when the learning rate is large the system is said to be under dumped 2 when the learning rate is small the system is said to be over dumped here we can see a zigzagging behaviour towards the convergence phase 3 after the learning rate crosses a certain value it becomes unstable it may stuck in a local minimal which is considered to be another danger,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
396,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate in steepest descent can directly affect the convergence of the algorithm if the learning rate is very small then algorithm can take long time to converge ie response is ovderdamped but if the learning rate is made very high then we may observe zigzagging oscillator behaviour and sometimes algorithm may fail to converge underdamped response,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
397,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,here when the learning rate is small the learning is very slow when the learning rate is large the learning is unstable and can exhibit zigzag behavior when the learning rate is too large the learning never converges,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
398,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate defines the efficiency of learning machine if it is small the system response may be overlapped if large the response may be underdamped and if it exceeds a critical value the response may diverge the danger is the possibility of the system output to not converge this should be ensured by scaling the learning rate using the largest einen value of the correction matrix of the input,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
399,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the value of the learning rate parameter eta controls the speed of descent and convergence towards the optimal weight vector for small values of eta the transient response of the algorithm is overlapped and the weight trajectory follows a smooth path on the other hand if the value of eta is large the transient response of the algorithm is underdamped and the weight trajectory follows an oscillator path in the plane,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
400,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate eta has a profound impact on the learning in steepest descent 1 if eta is too small the system is underdamped and convergence is slow 2 for larger eta the system is overlapped and tends to oscillate 3 if eta exceeds a certain critical value steepest descent may even diverge,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
401,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate has huge impact on convergence of the network if the learning rate is low then the transient response of the algorithm is overlapped and the trajectory of in is smooth if the learning rate is high then the transient response of the algorithm is underdamped and trajectory of the in is zigzag if we choose the wrong learning rate then the network might not converge,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
402,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate controls the speed and convergence of steepest descent method 1 if it is small the trajectory of weight vector follows a smooth path in i plane 2 if it is large the trajectory of weight vector follows a zigzagging path 3 if it exceeds a critical value then the algorithm is unstable,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
403,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,1 large learning rate eta results in a zigzagging behavior but it can converge quickly 2 small learning rate eta results in a smooth behavior but it is slow to converge,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
404,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate tells the network that how much steps it should move towards direction opposite to the gradient vector if the learning rate is too large the weight updating will be high so the danger is learning may oscillate or the network overdid the data,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
405,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate is used to regulate the speed of learning if the learning rate is small then the learning is slow and if the learning rate is high then it oscillates if it exceeds the critical value then the algorithm is unstable,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
406,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate is used to decide how fast the network should converge during the training phase if the learning rate is too high the system oscillates and becomes overlapped too low the system becomes underdamped and learns very slow,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
407,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate tells how long one step in the method of steepest descent is if the learning rate is too high the learning will oscillate and may not converge if the learning rate is too small the convergence will take many iterations,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
408,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,if we use steepest descent we use the learning rate to adjust the speed of the convergence to a minimum error if the learning rate is too small the learning is going on rather slow if the rate is high the error is zigzagging on the error surface towards the minimum if the learning rate is to high it might not converge but diverge,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
409,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate is a value between 0 and 1 which determines how fast the network learns when using small values for the learning rate the network converges slowly and needs lot of processing when choosing big values the learning oscillates and becomes unstable the goal is to choose the learning rate in a way that it does not learn to slow which needs more input data for convergence and that it does not become unstable,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
410,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate defines the speed of the learning convergence high values lead to faster learning und low values to slower learning however high values can lead to oscillations in the learning space and may overshoot the desired result and never reach it,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
411,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate gives the speed of learning it defines the stepwidth in direction of steepest descent if the learning rate is small the learning is more stable but slower when it is high the learning is more unstable but faster the danger is to overcome a minimum and result in oscillating behaviour,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
412,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,a too small leaving rate can lead to a very slow convergence or to no convergence at all if the time learn becomes too long a high learning rate can lead to an oscillating behavior and prevent convergence,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
413,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate is a scalar multiplied with adjustment term to adjust the weights it ensures the rate of learning it is typical greater than 0 and less than equal to 1 it covers the rate of sliding along the curve towards the minimal 1 lower learning rate will result in slow learning but chances of finding optimal minimal are greater 2 higher learning will result in hopping on either side of minimal hence zigzag behaviour 3 very high learning may not converge,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
414,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,if the learning rate is large then the it follows the zigzag motion if the learning rate is too low then it takes time for converging if the learning rate is very large or critical then it becomes unstable while processing there is possibility that it will get stuck in local minimal,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
415,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,when using steepest descent the learning rareta determines the speed at which the weights are adjusted in the in there can be two possible danger related to learning rate depending on its magnitude 1 low learning rather eta 001 results in smooth variation of the weights but makes the process becomes slow 2 hight learning rate eg eta 001 results in faster weight adjustment but it leads to an oscillator nature in the learning which is unwanted,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
416,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,with a small learning rate the network will converge very slowly towards the optimal weight of the network but it will give better performance in generalization with a high learning rate there can be zigzag effect because of the large rate the network may miss a local minimal and jump to a higher point with a very high learning rate the network may become unstable,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
417,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate defines the speed of steepest descent search for min of a error function in other words it defines how strong the change in weights will be throughout optimization procedure higher learning rate faster learning but then learning is characterized by oscillations in search for min this is dangerous because if learning rate becomes bigger that a certain value it can make search with steepest descent unstable in this case steepest descent will start to diverge instead of converging to min in other case when leaving rate is small that learning is slower but safer and the learning path is not oscillator,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2.0,2.0,neural_networks,neural_course
418,How does a Reduced Boltzman Machine work (main idea)?,233,the reduced blotzman machine works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2.0,2.0,neural_networks,neural_course
419,How does a Reduced Boltzman Machine work (main idea)?,233,it is a recurrent network it operates by flipping it has two groups of neurons visible neurons and hidden neurons visible neurons provides interaction between environment and network hidden neurons are running freely it has two modes of operation clamped state states of the neurons are clamped free running state neurons are running in free condition,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2.0,2.0,neural_networks,neural_course
420,How does a Reduced Boltzman Machine work (main idea)?,233,,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0.0,2.0,neural_networks,neural_course
421,How does a Reduced Boltzman Machine work (main idea)?,233,rum implement a combination of graphical and probabilistic ideas using probabilities of activation inspired from energy based networks we present a training input to the rum and determine the hidden activation based on a probability of net input and edge weights then when clamping the training data from the network sample from the distribution of the hidden layer where the rum tries to rebuild the distribution of the input data rum may be used for data completion or devising where eg incomplete images are completed based on the learned probability distribution,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2.0,2.0,neural_networks,neural_course
422,How does a Reduced Boltzman Machine work (main idea)?,233,rum has two layers and are interconnected recurrent operates by flipping the internal states 1 unlike the boltzmann machine reduced boltzmann machine does not contain interconnection among the same layer the weight update is done by the difference in correlation in clamped and free running mode,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2.0,2.0,neural_networks,neural_course
423,How does a Reduced Boltzman Machine work (main idea)?,233,it consists of only two layers input and hidden layer during training data is presented to the input the hidden layer starts oscillating,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0.0,2.0,neural_networks,neural_course
424,How does a Reduced Boltzman Machine work (main idea)?,233,the reduced boatman machine is an stochastic recurrent ann that operates with two classes of neurons hidden and visible it operates by neuronflipping with a probability impacted by the neurons around so it uses the lesbian rule an reduced boatman machine can learn the classify data and can reproduce the learned patterns,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2.0,2.0,neural_networks,neural_course
425,How does a Reduced Boltzman Machine work (main idea)?,233,the strutted of rum is a bitpartied graph it uses lesbian learning for training and the neurons used are binary stochastic neurons which have a binary state which fire based on a probability the training is achieved by passing the information a many times between the hidden layer and the input layer there weightsare updated on the pass into the hidden layer weighs between input and activation in the hidden layer are increased weights between generated inputs of the rum and the hidden layer are decreased,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2.0,2.0,neural_networks,neural_course
426,How does a Reduced Boltzman Machine work (main idea)?,233,the main idea of an rum can be defined as follows two layers will be defined where each neuron will be connected to every neuron of the other layer the input will be passed from the first layer to the second one and the state of each neuron of the second layer will be calculated the neurons with active states will pass again its values to the input layer the values given from the second layer will be compared with the input values and with the two states the weights will be adjusted,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1.0,2.0,neural_networks,neural_course
427,How does a Reduced Boltzman Machine work (main idea)?,233,,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0.0,2.0,neural_networks,neural_course
428,How does a Reduced Boltzman Machine work (main idea)?,233,they are neural network with only one hidden layer neurons from input to hidden layer are fully connected neurons from hidden layer to output layer are fully connected as well,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0.0,2.0,neural_networks,neural_course
429,How does a Reduced Boltzman Machine work (main idea)?,233,the reduced boatman machine works by flipping neurons it can operate in clamped or free running state if two connected neurons are activated at the same time the weight is increased if any of the two neurons are fired asynchronously then the weight is reduced or removed,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1.0,2.0,neural_networks,neural_course
430,How does a Reduced Boltzman Machine work (main idea)?,233,reduced boatman machines reduced because inputs do not share information via synapses are one of the initial nuns which consists of input layer and hidden layer the system adapts its internal weights and tries to reproduce the inputs,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1.0,2.0,neural_networks,neural_course
431,How does a Reduced Boltzman Machine work (main idea)?,233,a rum is a shallow two layer network containing a visible and a hidden layer each node in the visible layer is connected to each node of the hidden layer it is considered as restricted because no two nodes of one layer share a connection a rum is the mathematical equivalent of a two way translator in the forward pass a rum takes the inputs and translates them to a set of numbers that encode the inputs in the backward pass it takes the set of numbers and translates them back to form the reconstructed inputs a well trained rum will be able to perform the backward translation with a higher degree of accuracy three steps are repeated over and over through the training process 1 forward pass 2 backward pass 3 evaluate quality of reconstruction as visible layer often solved with al divergence,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1.0,2.0,neural_networks,neural_course
432,How does a Reduced Boltzman Machine work (main idea)?,233,,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0.0,2.0,neural_networks,neural_course
433,How does a Reduced Boltzman Machine work (main idea)?,233,,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0.0,2.0,neural_networks,neural_course
434,How does a Reduced Boltzman Machine work (main idea)?,233,rum is an unsupervised learning technique it has visible neurons and hidden neurons neurons are in either 1 or 1 states it uses the idea of simulated appealing to flip the neuron states based on energy function and pseudo temperature it operates in 2 states clamped state and free flowing state in clamped state only hidden neurons are flipped and in free flowing state both visible and hidden neurons are flipped weights are adjusted based on average correlation difference between all the neurons in clamped and free flowing state,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2.0,2.0,neural_networks,neural_course
435,How does a Reduced Boltzman Machine work (main idea)?,233,,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0.0,2.0,neural_networks,neural_course
436,How does a Reduced Boltzman Machine work (main idea)?,233,rims work on the principle of binary states rerunning or clamped the weight update is done based on the botlzmanns formula using the pseudotemperature which gives the probability of error,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1.0,2.0,neural_networks,neural_course
437,How does a Reduced Boltzman Machine work (main idea)?,233,the reduced boatman machines function by using two types of neurons visible neurons that provide an interface between the environment and he network an hidden neurons that operate freely the learning can proceed under two conditions namely 1 clamped state where the visible neurons are clamped to a particular state of the environment 2 free running state where both visible and hidden neurons operate freely if choir indicates the probability of correlation between the states of neurons i and i in clamped state choir indicates the probability of correlation between the states of neurons i and i in free running state then the weight adjustment delta win eta choir choir,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2.0,2.0,neural_networks,neural_course
438,How does a Reduced Boltzman Machine work (main idea)?,233,a reduced boltzmann machine rum consists of two layers of neurons visible and hidden the neurons may only have two states ie activated or not and they flip according to a certain probability based on the weights and states of other neurons the rum has two modes 1 clamped the visible layer is clamped to a certain input while the hidden neurons are allowed to change state until the network settles the correlation in this state is given by choir 2 rerunning in this state the network is allowed to flip all neurons until it settles the correlation is choir the weight update rule is given by delta win eta choir choir,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2.0,2.0,neural_networks,neural_course
439,How does a Reduced Boltzman Machine work (main idea)?,233,boltzmann machines is a neural network having recurrent structure is in two states either on which is 1 or off which is the energy function is given by e 11expdelta temperature the state of the input i is turned from 1 to 1 based on the change of the energy delta and the pseudo temperature i,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1.0,2.0,neural_networks,neural_course
440,How does a Reduced Boltzman Machine work (main idea)?,233,the neurons operate in a binary states on or off in clamped condition all visible neurons are clamped into specific states by the environment in free running condition all neurons including visible and hidden neurons operate freely,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1.0,2.0,neural_networks,neural_course
441,How does a Reduced Boltzman Machine work (main idea)?,233,it uses an energy function to oversee the learning process,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0.0,2.0,neural_networks,neural_course
442,How does a Reduced Boltzman Machine work (main idea)?,233,reduced boatman machine work based on flipping operation and calculating the probability variances of clamped state and freely running state,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1.0,2.0,neural_networks,neural_course
443,How does a Reduced Boltzman Machine work (main idea)?,233,rims run on boltzmann learning rule the neurons have 2 modes of operation clipped and free running all the neurons are binary units their status can be changed by flipping all the neurons that are in on position are clipped together,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1.0,2.0,neural_networks,neural_course
444,How does a Reduced Boltzman Machine work (main idea)?,233,it has the structure of recurrent neural network it has two layers of neuron visible and hidden the neuron can store only binary values they work based on flipping there are modes free running and clamped the weights are changes based on the correlation of the neurons in the free running mode and clamped mode,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1.0,2.0,neural_networks,neural_course
445,How does a Reduced Boltzman Machine work (main idea)?,233,in a reduced boatman machine there are one visible and at least one hidden layer the visible layer is the input and acts as output at the same time for each input the neurons of the visible layer will be assigned with a value with their weights hidden neurons may either be activated or not once the input has been passed through the hidden layers the values are passed all the way back to the visible layer for this different weights are used since the values move in the opposite direction,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1.0,2.0,neural_networks,neural_course
446,How does a Reduced Boltzman Machine work (main idea)?,233,in rims there are two states the free running and the clamped state during the clamped state the input neurons are clamped to the output neurons while the network is clamped the probabilities of the hidden states to be in a certain state are calculated to determine a probability of the output to be correct,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1.0,2.0,neural_networks,neural_course
447,How does a Reduced Boltzman Machine work (main idea)?,233,the reduced boatman machine hast an input layer and a hidden layer each neuron has a state and a probability to turn on if the neuron turns on the data passes trough it and the weights are updated the probability of turning on is calculated by the network,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1.0,2.0,neural_networks,neural_course
448,How does a Reduced Boltzman Machine work (main idea)?,233,two fully connected layers one input and one hidden layer are used the input layer is the only connection to the environment the rum has a specified energy level which can not be changed however the distribution of this energy to the nodes can be changed based on the data input every node has a chance to flip based on its input connections,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1.0,2.0,neural_networks,neural_course
449,How does a Reduced Boltzman Machine work (main idea)?,233,the binary state of each neuron is flipped by a given probability stochastic learning,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0.0,2.0,neural_networks,neural_course
450,How does a Reduced Boltzman Machine work (main idea)?,233,neurons have to states eg on or off each neuron has a probability to flip from one state to another,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0.0,2.0,neural_networks,neural_course
451,How does a Reduced Boltzman Machine work (main idea)?,233,,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0.0,2.0,neural_networks,neural_course
452,How does a Reduced Boltzman Machine work (main idea)?,233,the main idea of the rum is compute the least mean square error of the difference between expected output and real output,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0.0,2.0,neural_networks,neural_course
453,How does a Reduced Boltzman Machine work (main idea)?,233,,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0.0,2.0,neural_networks,neural_course
454,How does a Reduced Boltzman Machine work (main idea)?,233,it is a recurrent neural network it uses two groups of neurons hidden and visible it process the training data by flipping the neurons,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1.0,2.0,neural_networks,neural_course
455,How does a Reduced Boltzman Machine work (main idea)?,233,reduced boatman machine is a departed two parts recurrent in that has two layers visible and hidden layers in reduced boatman machine neurons can have two states namely or 1 depending on current time step at each time step the states of neurons are flipped here the visible layer represent interface for connection between environment and hidden layer and it operates in clamped mode limited values by environment while hidden layer operates in free mode,the reduced boltzmann machine is a departed graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neuron neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2.0,2.0,neural_networks,neural_course
456,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state network is a type of recurrent neural network and has atleast one cyclic feedback connection en consists of a dynamic reservoir and a output layer with neurons the dynamic reservoir consists of randomly initialized neurons with random structure and connections with atleast one feedback connection the output layer combines the dynamic behaviours of the reservoir in a required fashion only the weights of the output neurons are updated while learning an en consists of feedback connections while a of in does not an en could have persisting activation even when there is no input which is not the case in of in an en can approximate dynamic systems while a of in cannot,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
457,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state network are recurrent neural network which means these networks have feedback while in feedforward neural networks there is no feedback in feedfoward training data or inputs are not dependent on each other they do not have any system memory in eons training inputs are dependent on each other and they have system memory in echo state network there are fixed random generate reservoir weights these weights are not trained while only output weights are trained,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
458,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,an en is a recurrent neural network with many layers and fixed weights there are several differences an en has a cycle that means within the network there are backwards connections with a of in there are only feedforwad connections within a of in all weights are trained within an en only output weights are trained an en can produce an output without any input a of in needs an input to produce an output,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
459,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en are different to finn in so far that they consist of a reservoir of hidden neurons which may be connected recurrent as opposed to having a feed forward architecture here the inputs are connected to the recurrent dynamic reservoir whereas the do is connected to the linear output layer the output layer may be again connected to the do whereas during training only weights of the last layer are learned weights of the do of the en are thus initialized and never learning although since have been extended to minimal complexity architecture,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
460,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en are recurrent neural networks with a large reservoir or echo chamber with many nodes recurrent the weights are learnt only for the connection between this reservoir and the output layer the weights are not learnt for the nodes inside the reservoir the main idea is that during training the input layer cases the states inside the reservoir to behave in certain way and the weights in the output layer is adjusted to match this and the labelled output finn are feed forward networks ie they do not have any recurrent connections which is the main difference with respect to en,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
461,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,eons are a special class of recurrent neural networks in contrast to of they also allow backward node connections and thus are able to memorize data they are defined by xi input i yi output i a dynamic behaviour and weights connecting all the components the dynamic behaviour is generated randomly and fixed its topology including weights is never changed only the weights between output layer and dynamic behaviour are changed during training because the dynamic behaviour allows all kinds of connections between its nodes it can contain memory that is able to remember data it also has a spectral radius,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
462,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,an en is a recurrent ann with random sparse and fixed interferon connections in the hidden layers just the output layer weights get trained because the network itself is so complex it can model very much if the training was not successful we can just create a new random en training an complete en would by very complex and would take very very very long a of in is not recurrent no feedback and all its weights get trained and most of the time the interferon connections are not sparkly,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
463,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,a echo state network is a run is has a dynamic reservoir of neurons which are connected with each other and itself the do typically consists of more that 100 neurons the outputlayer consists of linear readouts of the do so a neuron in the output layer sums up the weighted behaviours of the do neurons the do is randomly initialized and only the output layer is trained by supervised learning the main difference is that en is a run in contrast to finn it can resemble any dynamic system usually it is used for time series prediction,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
464,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state networks are a type of recurrent neural networks where the input layer is interconnected to a reservoir a random initialized group of neurons with also random interconnection and this reservoir is connected to the output the reservoir will not be adjusted but the output weights the output weights can also have recurrent connections with the reservoir the states on the reservoir neurons will be calculated and with these states and the output weights the output will be extracted the main difference with the feed forward neural networks of in is that in the funny theres no recurrence so the input values will be passed to the next layer,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
465,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,in the en we have a huge recurrent network which is called dynamic reservoir and we have an output layer connected to this do and we will train the network by adapting and manipulating the connection weights just to the output layer unlike a feedforward network in a en because of the do we have at least one loops that returns the output of a neuron with some time delay therefore we have memory in our network but in of nuns we dont have any memory,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
466,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state networks are recurrent neural network type meaning there are feedback in its structure it is usually only 1 connected main difference is that it has a reservoir as a hidden layer where neurons are very randomly connected with random weight etc during learning phase only weight outpouring neurons are changed it is required more that 100 neurons to be in a reservoir,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
467,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,the en is a type of neural network model that uses a recurrent neural network as a large random fixed dynamic reservoir that remains unchanged during training and only changes the weight of the reservoir to output layer,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1.0,2.0,neural_networks,neural_course
468,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,eons are a form of recurrent neural networks with a least one recurrent input the eons are reservoir computers which have memory and can be activated without the inputs in eons instead of training we evolve the network state by feeding it input sequence eons are different from of nuns because eons contains at least one recurrent connection feedback,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1.0,2.0,neural_networks,neural_course
469,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,the basic idea of eons is to use a large random fixed recurrent in referred to as dynamic reservoir and to train only connections from the reservoir to the output the main difference to of in lies in the recurrent part of the network where back passes are built in giving feedback previous layers it is not possible to maintain the reservoir beforehand so it suits the given problem there is a lack of investigation of reservoir construction,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
470,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,an echo state network en is a modified version of a recurrent network it has a reservoir which is a large number of hidden neurons with sparselyconnected random and fixed weights to train an en only the weights connecting the reservoir and the output layer are adjusted therefore the efficiency is better than a normal recurrent network,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1.0,2.0,neural_networks,neural_course
471,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state network provides structure and supervised learning for recurrent neural networks it mainly 1 directs the fixed large recurrent neural networks by providing an input stimuli and also fix a response signals to the neurons which are present inside the reservoirpool of neurons 2 it can be directed to get the desired response by the traceable linear combined of the response signals unlike of nuns eons have memory they can be also activated without an input stimuli whereas in case of of in they require a external stimuli so that they are activated also the neurons needs to connected in one full cycle,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
472,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state newtons are type of run it has dynamic reservoir units which exhibits different dynamics weights of these reservoir units are fixed and are not changed during the training phase only the reservoir to output weights are changed to learn the inputs these networks converge only if reservoir units exhibit echo state property ie its output depends only on the previous inputs this property is satisfied if spectral norm reservoir weights is less then 1,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
473,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,here echo state networks are recurrent neural networks that have a large reservoir of oscillator functions that are connected to the input layer in of nuns considerthe outputs at the hidden layers are also considered but in eons the outputs from the reservoir to the final output layer are only considered,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1.0,2.0,neural_networks,neural_course
474,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en are another implementation of runs where training method is completely different they comprise of a dynamic reservoir with fixed hidden to hidden connections which makes up an run with sparse connectivity only the output weights which connect the dynamic units and the output of the reservoir are trained using error unlike runs where the hidden weights are also trained eons are less computational expensive since they can be easily trained with experimentation however runs use much less hidden units compared to en for a similar task,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1.0,2.0,neural_networks,neural_course
475,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,an echo state network en is a neural network that uses a recurrent neural network run as dynamic reservoir which is not changed during training and trains only the connection from the dynamic reservoir to the output layer an echo state network is different from of nuns due to the presence of feedback connection with the dynamic reservoirs which enables it to maintain activation even without inputs each unit within the dynamic reservoir in eons are excited differently to different inputs,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
476,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,eons are recurrent neural networks with at least one cyclic connection and are based on the concept of reservoirs in contrast of nuns do not have any cyclic connections additionally in en the output weights are trained but the reservoir weights are not whereas in of nuns all weights are trained the en has memory while of nuns do not have memory,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
477,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en refers to echo state networks echo state networks are the recurrent neural networks where the hidden to hidden layer weights are selected randomly and are fixed and hidden to output layer weights are changed by the learning processsince en is recurrent neural network hence the output echoes through the network even when there is no input where as in of nets there is no feedback so there is no output if there is no input,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1.0,2.0,neural_networks,neural_course
478,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en is a kind of recurrent in which has a large random fixed run called dynamic reservoir and only the weights connecting the reservoir and output layer are trained so en combine the desired system function and inputoutput history echo function,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1.0,2.0,neural_networks,neural_course
479,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en provides an architecture of supervised learning principle for runs it is different from of nuns because it has a reservoir based on runs to find a non linear signal response and combine the desired output by a traceable linear combination of these response,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1.0,2.0,neural_networks,neural_course
480,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state networks are recurrent neural networks with dynamic reservoirs weights initialized in the dynamic reservoirs will not be updated during training only the weights in output layer readout states is updated after each iteration in of in all neurons are connected with other neurons in next layer and all the weights are updated in each iteration but in en the neurons are connected randomly with other neurons and it is recursive and the weights are not updated in the dynamic reservoir,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
481,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en is a type of run it has a dynamic reservoir all the neuron are connected to each other,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1.0,2.0,neural_networks,neural_course
482,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,the echo state network has a large number of recurrent neural network in them this set of run is called the dynamic reservoir they can approximate any dynamic model they train the model by changing only the weights of the connection of output of the dynamic reservoir and output of the network of they can approximate any continuous function they train by adapting all the weights in the network,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
483,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,an echo state network contains of an input layer which is connected to a reservoir which is a big recurrent network the output layer is connected to the neurons of the reservoir while learning in an en only the weights between the reservoir and the output layer are changed no changes within the reservoir differences to feed forward networks are that the reservoir is recurrent and that during the training not all weights are changed but only the ones between output layer and reservoir,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1.0,2.0,neural_networks,neural_course
484,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,in contrast to regular feedforward networks en belongs to the group of recurrent neural networks it has a regular input layer like the of then comes a dynamic reservoir which is a layer of neurons where at least one full cycle of connections between the neurons is given the connections inside this reservoir are not constrained and can thus be any possible connection this reservoir is randomly initialized and kept that way only the respective connections to the output layer are trained during the learning process,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1.0,2.0,neural_networks,neural_course
485,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en have an input layer connected to a reservoir which is a recurrent neural network the reservoir is connected to the output layer on the connections to the output layer are weights which are updated by the network the weights of the reservoir are chosen randomly and not updated at all,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1.0,2.0,neural_networks,neural_course
486,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,an en is a recurrent neural network that consists of an input layer a dynamic reservoir and an output layer in the dynamic reservoir feedback loops are possible in contrast to a feedforward network however this dynamic reservoir is only randomly initialed and not learned only the connections to the output from the reservoir are learned normally in of nuns all connections are trained,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1.0,2.0,neural_networks,neural_course
487,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state networks have dynamic reservoir as hidden layer the dynamic reservoir consists of recurrent nonlinear neurons only the linear connections from dynamic reservoir to the output layer are trained the difference to of in is that the en is a recurrent network,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1.0,2.0,neural_networks,neural_course
488,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,the core of an en is an arbitrary network with recurrence,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,0.0,2.0,neural_networks,neural_course
489,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state networks have dynamic reservoir with echo state property which is a randomly initialized run hence it can maintain its own internal state which is not possible in of in run have feedback connections which echoes back the state of reservoir as well as previously applied inputs hence it can model dynamic systems which not possible with finn,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1.0,2.0,neural_networks,neural_course
490,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en are the run recurrent neural network which has at least one feedback cycle of in are normally forward moving networks where the input from one layer is fed into next layer and generated the output but in en the out put is again fed back as input en is tend to have revoir where its randomly connected,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,0.0,2.0,neural_networks,neural_course
491,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state network is a type of neural network which has a recurrent network of 100 to 1000 neurons called dynamic reservoir as the hidden layer the weights are choose randomly the synaptic weights from the reservoir to the output layers are only adjusted during the learning process they are different from the of nuns in the following regards 1 en have atleast one loop whereas the of nuns dont 2 only the output weights are adjusted in en in of nuns both the input and output weights are adjusted 3 en i have a memory of nuns dont,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
492,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en uses a large set of recurrent neurons called reservoir the weight of reservoir neurons does not change after initialization the network only years the weight of reservoir to output it works very well for one dimensional time series data the feed forward networks works differently the input is feed through the network layer by layer and error is prepared backward to make the adjustments till the first layer in case of en the adjustment is made to the reservoir to output weight only,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2.0,2.0,neural_networks,neural_course
493,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,0.0,2.0,neural_networks,neural_course
494,Describe: the structure on an CNN.,235,in a convolutions neural network the layer order is 1 convolutions layer has kernels which involve over the input image incase of first layer or feature maps otherwise 2 activation layer rely activation 3 pooling layer max or average pooling these 3 layers can be repeated any number of times 4 finally one or more fully connected layers followed by softmax layer,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2.0,2.0,neural_networks,neural_course
495,Describe: the structure on an CNN.,235,in can there are mainly three layers i convolutions layer it is used to capture the lowlevel and high level features using kernel over the image ii pooling layer it is used for dimensionality reduction and for translation variance iii fully connected layer this layer is same as regular nuns where all the nodes are fully connected with each other there is mostly sigmoid activation function is used to compute the probabilities of each outputclass furthermore in cans we use rectified linear unitrelu activation function,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2.0,2.0,neural_networks,neural_course
496,Describe: the structure on an CNN.,235,a convolutions neural network has a kernel which is much smaller than the input this is why it can operate much more efficient than a normal neural network normal neural network on times i convolutions neural network o i times i i is much smaller than i a convolutions network operates no large images the input is repressed in many layers before it is given to a normal neural network reprocessing transforms input into a linear separate problem,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
497,Describe: the structure on an CNN.,235,can learn on grid data images ad volumes using filters instead of matrix multiplication here the filters are convoluted with the input in the convolutions layer per neuron where we slide the filter defined by filter size times i over the input with a stride step size and optional zero padding strictly speaking since for rob images we are working have three color channels we work with volumes of filters for example for rob images of size times times 3 a filter of window size so has the dimensions 5times5times3 instead of learning a volume of weights for each convolutions step we share weights considering that one feature detected in one part of the image may be of interest in another part then we apply a nonlinearity commonly the rely activation as to introduce nonlinearity into our model to reduce spatial size of our input we can either use higher striped convolutions layers or pooling layers for example the popular max pooling layer where the maximum value over a subvolume is picked these layers are then stacked while in the last layers fully connected neurons are typically used to reduce data to for example a classification vector,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2.0,2.0,neural_networks,neural_course
498,Describe: the structure on an CNN.,235,a can uses convolutions instead of matrix multiplication after this there is a non linearity which may be a function like rely there is also a pooling stage which is used to pool the important features cans are translation invartiant,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
499,Describe: the structure on an CNN.,235,a convolutions neural network consists of convolutions layers a convolutions layer applies one or multiple kernels matrix to an input vectormatrix typically image instead of connecting all single inputs of the input vector to the next layer with separate weights instead in training only the kernel is updated after a convolutions layer there is typical a pooling layer given a window size it reduce the dimensional size of the output of the convolutions layer by using eg max or ave pooling afterwards the activation layer applies an activation function to the output of the pooling layer in the end of a can there are typically some fully connected regular layers resulting in a softmax activation function which assigns the probabilities to the classes output,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2.0,2.0,neural_networks,neural_course
500,Describe: the structure on an CNN.,235,an convalutional neuron network assumes the input is an image because of that it has a architecture so that there are abwechselnt coalition and subsampling layers after the last subsampling layer there is a normal of in which classify the input,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
501,Describe: the structure on an CNN.,235,a can typically consists of multiple can layers and a few fully connected of network layers ill assume the fully connected part is not so relevant to this questions a can layer is typically a convolutions layer and a pooling layer in the convolutions layer a kernel is involved onto the input if zero padding is used the result is in the same dimensionality depending on the kernel the convolutions can be 1 2 or ad in the pooling layer the result of the convolutions is reduced to focus ont the important features it also helps on transnational variance,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2.0,2.0,neural_networks,neural_course
502,Describe: the structure on an CNN.,235,a convolutions neural networks has the following structure the input is defined in a grid so any image or video sequence will be used a several number of convolutions layers where also subsampling pooling can be used in the convolutions steps a filter will be used for each layer after applying multiple convolutions layers a normal feedforward networks can be applied where for example a back propagation algorithm can be used for updating the weights in the numerous iterations,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
503,Describe: the structure on an CNN.,235,a can network consists of input layer conclusion layer detection layer pooling layer next layerbecause can consists of many layers this will be another block of layers similar to what described,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
504,Describe: the structure on an CNN.,235,convolutions neural networks are so that first layer is not fully connected but in a way that neuron connections overlap leading to a grid type structure with overlapping circles another layer is connected only with nodes that are responsible for a particular feature convolutions then next layer is choosing with of those convolutions from each ensemble is the most appropriate after that next layer is fully connected to output neurons,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
505,Describe: the structure on an CNN.,235,the can has an input layer the input layer is connected to a convolutions layer consisting of three phases convolutions stage detector stage pooling stage the next layer can be a traditional finn,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
506,Describe: the structure on an CNN.,235,cans are feed forward neural networks which replaces matrix multiplication task with convolutions operation which is much sparse can contain following stages convolutions learns local features max pooling coarsegraining to learn better abstraction of input image,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
507,Describe: the structure on an CNN.,235,in comparison to other in in can matrix multiplication is replaced with convolutions everything else remains the same,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,0.0,2.0,neural_networks,neural_course
508,Describe: the structure on an CNN.,235,an can covolutional neural network contains a set of hidden layers for feature extraction convolutions layers pooling layers and fullyconnected layers that classifies the features the covolutional layers are used to carry out the revolution between the incoming signals with a set of filters resulting in a set of feature maps the pooling layers are used to reduce the dimensionality of the feature maps and make the features variant of rotation or displacement,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
509,Describe: the structure on an CNN.,235,a can 1 starts with a input where we perform the convolutions which provides a piece of activation 2 next it is being sent through the activation layer otherwise known as the detection layer 3 then the final stage is the pooling,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
510,Describe: the structure on an CNN.,235,in can we have different kernels which are used for extracting certain properties of the inputs these are called feature maps after this there is a detection phase which introduces nonlinearity further there is pooling which introduces transnational variance there can be many such layers of feature maps and pooling finally its reduced to single row input and trained using traditional methods like back propagation algorithms,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2.0,2.0,neural_networks,neural_course
511,Describe: the structure on an CNN.,235,here convolutions neural networks have 4 main layers where input layer is connected to convolutions and subsampling layers followed by another set of convolutions and subsampling layers connected to the output layer they are designed to specifically recognize ad shapes are variant to skewing rotation and the actual location of the object,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
512,Describe: the structure on an CNN.,235,can comprises of multiple layers of neurons which perform specific tasks the initial layer is the convolutions layer which performs convolutions of the input with the elements of a given kernel simpler tasks such as edge detection are performed detector layer forms a second layer here the output of convolutions layer if fed through an activation function such as rely further the data is pooled in the pooling layers where downsamping is done to reduce dimensionality these layers are repeated to perform more complex feature extraction operations,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
513,Describe: the structure on an CNN.,235,a can is a neural network that replaces matrix multiplication with a mathematical operation called convolutions in one or more layers the main idea behind the structure of a can is to replace the activation of neuron with a flipped filter convolutions layer and then apply another function called pooling to dust the output further,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
514,Describe: the structure on an CNN.,235,a can consists of several stacked convolutions layers which can be separated by other layers such as pooling activation zeropadding and dropout which is a form of regularization the output layer is generally dependent on the task but could be a softmax activation from a fully connected also called densely connected layer the number of outputs is usually the number of classes,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2.0,2.0,neural_networks,neural_course
515,Describe: the structure on an CNN.,235,the structure is as follows convolutions in this layer convolutions takes place instead of matrix multiplication deconvolution in this layer deconvolution takes place by matrix multiplication average weight layer this is a max pooling layer,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
516,Describe: the structure on an CNN.,235,1 first stage the layer performs several convolutions parallel to produce a set of linear activation 2 detector stage each linear activation is run through a nonlinear activation 3 third stage use a pooling function to modify the output of layer,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
517,Describe: the structure on an CNN.,235,1 convolutions or matrix multiplication it produces output to hidden layer 2 deconvolution matrix multiplication by transpose matrix apply back propagation error for output to input 3 weight update apply back propagation error from output to weight,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
518,Describe: the structure on an CNN.,235,input layer convoluted layer fine transformation filtering layer sampling learning layer output layer,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
519,Describe: the structure on an CNN.,235,can has basically four types of layers they are convolutions layer rely layer pooling layer and the fully connected layer we can arrange the convolutions layer and rely layer in different ways one of the ways is to have 1 convolutions layer 1 pooling layer 1 rely layer and repeat this 3 layers again and then finally a fully connected layer another way is to have 1 convolutions layer 1 pooling layer again repeat the convolutions and pooling layer and then 1 rely layer and finally fully connected layer convolutions layer is used to find the feature space,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2.0,2.0,neural_networks,neural_course
520,Describe: the structure on an CNN.,235,the can will have a input layer convolutions layer here the convolutions and sub sampling of the feature maps take place feed forward neural network layer output layer,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
521,Describe: the structure on an CNN.,235,a convolutions neural network uses the steps of convolutions and subsampling alternating in the beginning using different kernels during convolutions many feature maps are created the subsampling step merges the maps to reduce their amount after some of these steps a classical feed forward network is in the end to transform the different feature maps to one output layer,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
522,Describe: the structure on an CNN.,235,a concolutional neural network has alternating layers of convolutions and pooling the convolutions layer is applying a filter to the input while the pooling layer subsamples the input in some networks this is replaced by striped convolutions which combines these two steps into one the structure at the end of a can is equal to that of a regular feedforward network,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
523,Describe: the structure on an CNN.,235,,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,0.0,2.0,neural_networks,neural_course
524,Describe: the structure on an CNN.,235,a basic can can be structured into the three layers convolutions detector and pooling in the first layer the convolutions operation is performed on the inputs in the second layer the the activation function mostly rely is applied to the result of the convolutions the last layer can be used to reduce the size of the resulting convoluted images eg by max pooling,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2.0,2.0,neural_networks,neural_course
525,Describe: the structure on an CNN.,235,convolutions neural network it has often images or video sequences as input the input is computed by convolutions with different kernels and downsampling in many steps to smaller but many more input matrices in last step the matrices are connected to a classical of in,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
526,Describe: the structure on an CNN.,235,a can consists of one or more convolutions layers as well as subsampling or pooling layers followed by a fully connected standard fun in the convolutution layer kernels are used to create feature maps a kernel is smaller matrix that is applied to all possible positions on the input matrix in the pooling stage the dimension of the feature map is reduced for example by max pooling,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
527,Describe: the structure on an CNN.,235,can uses convolutions layers to extract primitive information from pattern first data is involved with the first layer to extract some features output of this layer is passed through rely function to rectify it then is downsampled by pulling layer it basically chooses only relevant outputs of convolutions layer for further processing rely is chosen instead of sigmoid because it doesn't allow gradient to vanish in backpropogation,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2.0,2.0,neural_networks,neural_course
528,Describe: the structure on an CNN.,235,can is has multiple layers and they dont use multiplication matrix,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,0.0,2.0,neural_networks,neural_course
529,Describe: the structure on an CNN.,235,convolutions neural networking has three main layers in them 1 convolutions layer 2 pooling or subsampling layer 3 output layer,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1.0,2.0,neural_networks,neural_course
530,Describe: the structure on an CNN.,235,can has three components input convolutions stage feed forward network in can the input pass through one or more convolutions stage befor it is feed into a feed forward network the convolutions stage uses a hierarchical set of filters rely and polling to extract low level as well as high level concepts from the input the feed forward network along uses the output of the convolutions stage and back propagation is used to make adjustment to the network weights as well the filters in the convolutions stage,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2.0,2.0,neural_networks,neural_course
531,Describe: the structure on an CNN.,235,,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,0.0,2.0,neural_networks,neural_course
532,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,three items to learn in a run 1 centroid of the input clusters 2 widths of the clusters 3 weights of the synapses connecting the hidden layer and the output layer the centroid and widths are learned in an unsupervised fashion while the weights in a supervised fashion so an run combines unsupervised and supervised learning while a regular in is completely supervised or completely unsupervised learning is fast and is not so sensitive to the unsupervised part,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2.0,2.0,neural_networks,neural_course
533,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,in ref network we need to learn centre and width of gaussian function we also learn output weights difference between ref and nuns i in ref there is only one hidden layer while in nuns there can be more than one hidden layer ii in ref activation function of hidden layer is gaussian so parameters are in euclidean norm while in nuns parameters for activation function are product of weights and inputs iii parameter computation is different in ref as compute to other nuns like we compute centre of cluster in ref with the help of means clustering,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2.0,2.0,neural_networks,neural_course
534,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,ref network need to learn center of activation function difference to other in is that there are as many activation functions as data points one con of radial basis function is that due to many activation function ref networks have a huge computational effort,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
535,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,in ref we learn the centers of the radial basis functions using unsupervised clustering methods the weights of the last output layer and the width of our radial basis functions as opposed to multi layer in we dont need expensive backpropagation as we only need to train the last layer while the unsupervised training algorithm does the work the ref centers a possible con would be that if the ref centers dont represent the training data point distribution well some data points may be hard to model,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2.0,2.0,neural_networks,neural_course
536,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,1 weights 2 centres or means of clusters 3 sigma which is the width of the clusters difference uses functions which are radically variant pros easy to learn nonlinearity only dependent on the radial distance cons data required is more overfishing,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2.0,2.0,neural_networks,neural_course
537,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,an ref network relies on a clustering algorithm this can be eg means clustering the three items to be learned 1 cluster center 2 cluster size 3 weights connecting the hidden nodes to the output layer difference to other nuns only three layers input hidden and output each node in the hidden layer uses a different activation function depended on the cluster assigned to it only output weights are trained,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2.0,2.0,neural_networks,neural_course
538,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,if a ref network used a gauss function as the activation function these thinks have to be learned centroid ci unsupervised sigma unsupervised weights of the output layer supervised the ref network is easy learning and not so sensitive to the unsupervised learning part,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2.0,2.0,neural_networks,neural_course
539,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,this question is really specific difference to other nuns centers widths weights the main difference is that the ref uses localized activation functions and it has only one hidden layer it apply a nonlinear transformation from the input space to the hidden space and a linear transformation from the hidden space into output space it is important to use regularization for ref ref work well for interpolation so it should work good for regression,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2.0,2.0,neural_networks,neural_course
540,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,a radial basis function network has the following structure an input layer a hidden layer where a nonlinear dimensional transformation will be used each neuron of the hidden layer will have a defined center extracted in previous steps a linear transformation will be used to the hidden data space and the output will be calculated so the three items that must be learning in the ref networks are the centers of each hidden neuron using for example means neighbours algorithm the radial function that will be used for the nonlinear transformation the weights applied into the output layer,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2.0,2.0,neural_networks,neural_course
541,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the three items that must be learned in refs are the center of the kernel the sizestandard deviation of the kernel,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0.0,2.0,neural_networks,neural_course
542,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0.0,2.0,neural_networks,neural_course
543,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,use distance to center as argument for computation of local fields use radial basis functions as activation ribs are only global approximates splitter learning instead of global learning,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
544,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,kernels only neighbourhoods are computed based on distances radius of neighbourhoods pros ref are simple and easy to compute cons they remember the data points,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
545,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,differences are run has a single hidden layer nonlinear hidden layer linear output layer argument of hidden units euclidean norm universal approximation property local approximates splitter learning,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
546,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the mean of the i clusters the,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0.0,2.0,neural_networks,neural_course
547,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the three items that needs to be learnt are the centers widths and depth compared to other in they have a standard 3 layer structure they can have just one hidden layer,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
548,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,in ref first inputs are transformed to higher dimension using non linear transformation this is based on unsupervised learning inputs are then learned using least square estimation which is an supervised learning ref is based on covers theorem which states that there is higher probability that data will be nearly separate in higher dimension,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0.0,2.0,neural_networks,neural_course
549,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,here refs are only dependent on the radial distance ie distance from the center to the input,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0.0,2.0,neural_networks,neural_course
550,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the three parameters to be learned generalized ref are 1 cluster centers of the basis functions 2 spread or the width of the basis functions sigma and 3 weights of connecting the input and the hidden layers ref are different from nuns in different ways 1 the kernels are localized functions where as nuns are globalized 2 they use euclidean distance in their activation functions where as nuns use inner products 3 they have a single hidden layer and output is a linear combination but nuns compulsorily are not the same,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
551,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0.0,2.0,neural_networks,neural_course
552,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the three open parameters of an ref network are 1 the centers ci 2 the widths sigma and 3 the weights wi the number of centers i has to be determined by trial and error,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
553,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,in ref the main advantage is that it follows covers theorem and the complex pattern classification problem can be solved,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0.0,2.0,neural_networks,neural_course
554,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,1 nonlinear transformation function from input space to feature space 2 centers of input data that is used for each hidden neuron 3 synaptic weights connecting hidden layer and output layer,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
555,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0.0,2.0,neural_networks,neural_course
556,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,three items to be learned origin center pros it can transform data from i dimension to infinity dimension it can solve non linear problems easily cons it may overdid learning is slow,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
557,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,center of the hidden neurons synaptic weights connecting the neurons and refs have only 1 hidden layer there is a nonlinear transformation between the inputs and the hidden space and a linear transformation between the hidden space and the output space pros it can be used for nonlinear separate data,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
558,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,1 weighs in the network 2 the center of the clusters 3 variation of the cluster sigma difference ref always have only three layers ref can also trained in an unsupervised method ref can also approximate any continuous function,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
559,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the centroid of the radial basis functions the weights of the neurons the amount of needed neurons a difference to other neural networks is that the centroid of the radial basis functions need to be there,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
560,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the centers of the clusters the widths of the clusters and the weights in contrast to other nuns the output only depends on the radial distance to the center of the clusters,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
561,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the weights the interpolation matrix have to be learned the ref maps the input space into a higher dimensional feature space nonlinear the feature space is mapped into the output space nearly the output space is much smaller than the feature space pros local learning cons feature space can be really large curse of dimensionality,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
562,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the clusters the width of the basis function and the weights the clusters and the width are learned in an unsupervised fashion while the weights are learning by a standard supervised steepest descent method pros refs can be very easily trained refs can achieve better results with less complexity cons not as easy to understand,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2.0,2.0,neural_networks,neural_course
563,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,centers of the radial basis functions best model ref distance of each input pair pros nonlinear functions application ease to compute using covers theorem cons highdimensional,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
564,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,centroid width and parameter of function the learning of an run is splitter in an unsupervised and a supervised part only one layer no vanishing gradient pros easy learning the unsupervised part is not very sensitive cons difficult to approximate constants,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2.0,2.0,neural_networks,neural_course
565,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,1 input layer connecting ref to environment 2 hidden layer nonlinear transformation of input space to hidden space 3 output layer linear transformation of hidden space to output space it is different than other nuns because for learning patterns it nonlinear transforms the input space to higher dimensional space other nuns do not transform input as it transforms input patterns to high dimensional nonlinear space patterns which are not separate in lower dimensions have greater chance to be separated but if we select basis functions equal to datapoints problem is illformulated processing is computationallly heavy regulation becomes problem specific hence unsupervised learning is employed to clusters data initially,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
566,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,data variance features ref uses support vector machine which is classifier it uses different kernels it doesn't have feedback cycle it also classifies non linear classification problem it mainly works with 2 classes ca ca other in is can also regression and there can be feedback run,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0.0,2.0,neural_networks,neural_course
567,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the difference of ref to other nuns are 1 ref has only one hidden layer whereas their is no hard limitation on number of hidden layers on other nuns 2 the activation function used in ref is non linear,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1.0,2.0,neural_networks,neural_course
568,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,a ref network learns the radial function weight of the hidden to output neuron centroid of a cluster difference a ref is composed of input layer 1 hidden layer and the output layer other in can generally use as many hidden layers as required the transformation from input to hidden layer in ref is non linear and hidden to output is linear in most other in both are non linear prisons this is a very simple learner there are many variations of ref available,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2.0,2.0,neural_networks,neural_course
569,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0.0,2.0,neural_networks,neural_course
570,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,nearest neighbors 1 take the input data to be classified 2 find the first nearest neighbour in terms of euclidean distance 3 push the class of this nearest neighbour into a list of labels 4 repeat step 2 and 3 for each i which needs to be odd 5 after all i nearest labels are collected in the list count the labels in each class 6 assign to the input data the class which as maximum count majority vote,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
571,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,i first we initialize the random points those points are considered as centroid of clusters ii then for each new points we compute euclidean distance and points closest to centroid are assigned their respective clusters iii we again recalculate the centroid of clusters iv repeat 2 and 3 until convergence is achieved by making sure no centroid are moving and cost function is minimized,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
572,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,nearest neighbor wants to determine encoder i which assigns i inputs to i clusters based on a rule to be defined,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
573,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
574,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,1 get the input 2 find the i nearest neighbours by finding the distance euclidean from the input to all the nodes and selecting the i closest ones 3 class of the input is the most frequent class in the neighbours found as such i needs to be odd number,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
575,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,i number of clusters given sample data select i different cluster centers by random assign all sample points to the closest cluster repeat until no further change recalculate the cluster centers assign all sample points to the closest cluster,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
576,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,given a fixed i given a point to classify new given an empty class given a list of all points i from 1 to i do find nearest point i to new in i add class of nearest point i in list class new list i i without nearest neighbor i class of new most class in class,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
577,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,define i centroid random initialized assign each data point a class label while the is no change anymore for each i calculate the centroid of the datapoint belonging to that label for each datapoint determine the nearest centroid assign a new class label which belongs to the centroid,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
578,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,nearest neighbors can be seen as an unsupervised learning method where for a defined number of groups i the nearest neighbors will be calculated 1 for a given input data 2 define value i 3 get the i points that are closer to the given points,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
579,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,1 randomly define a redefined number of cluster centers 2 calculate the distance of each datapoint from each ca 3 each data point belongs to the cluster that has the least distance from its ca 4 calculate a new ca by getting the average of all the points inside a cluster 5 go to 2 and repeat this process until we reach the termination condition,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
580,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,firstly identify nearest neighbouring weights then choose i amount of neighbors and adapt their weights,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
581,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,initialize neighbors for every neuron find the nearest neighbor and add it to neighbors return nearest neighbors,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,1.0,2.0,neural_networks,neural_course
582,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,pseudo code 1 initiate weights randomly 2 assign labels to inputs that are map neuron is closest to 3 happened all inputs to map neurons using 2 4 find centroid of the cluster and move the map neuron to the centroid 5 do 2 and 4 until some convergence criteria is reached eg maximum iterations is reached or no updates are performed or net distance is below some specified distance,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
583,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,given i test not element of i i number of neighbors that will taken into consideration function class set i lil class for jak do let i exclude all the data points which have been identified as nearest neighbors already find the closest neighbor of test in la eg compute eucldea distance i classify classfpushc set cutest most frequently value in class,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
584,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,train the inn by storing the data labeled points present a test point compute the distance between the test point and all the training data points sort the distance and choose the i datapoints with smallest distance determine the class of the test point by majority vote,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
585,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,la data set x1x2x3xn la storing the dataset based on the number of neighbors test test data set so we basically have the i value to be an odd number so that we can select a majority value for i based on the number of i i test distance from the neighboring neuron i la smallest i in this based on the number of i test male we select the neurons from the neighborhood by calculating the euclidean distance based on weights then if i is 3 we have 3 neurons so from that we select the label which is fixed maximum on the dataset given in the fields,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
586,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,define criteria for finding i nearest neighbours be find i nearest neighbours of test input in training dataset be find the class to which most of the neighbours belong be assign that class to the test input be,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
587,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,here learning based on nearest neighbors all the inputoutput samples from the training set are stored in the memory for a test input find the nearest neighbors assign the test vector with the class of the most of the neighbours in the neighborhood,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
588,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,parameters i number of clusters i datapoints i classes 1 initialize randomly i centroid of the clusters 2 select a data point and compute the set of nearest neighbours of the point using euclidean distances 3 find the class that maximum number of neighbours belong to and assign the class to the datapoint 4 once the class is assigned compute the centroid of each cluster or class considering all the class members 5 literate over all the datapoints and repeat over all points from step 2 until no update in centroid is required,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
589,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
590,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,1 given classified data i 2 for a new sample i determine the i nearest neighbours in i output y majority vote of the class of nearest neighbours,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
591,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,i x1x2xn i la i for the input ad do test,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
592,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,1 identify i classified patterns that lie nearest to the test vector 2 assign the test vector to the class that is most frequently presented to the i nearest neighbors,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
593,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,1 define the number of cluster i 2 generate random weights 3 find the center of each i mean 4 cluster the other outputs by determining the closest neighbor 5 update the weights,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
594,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,choose a value for i i represents the number of neighbors get a sample from the input space find the class based on the majority of votes received from the neighbors for example if the value of i is 3 then let say there are 2 neighbors from class one and 1 neighbor from class two then the new input sample belongs to class one,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
595,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,step we randomly place the i neurons step for each data point whichever neuron is closer to it the datapoint is assigned to that neuron step once all the datapoints are assigned the mean of the datapoints attached to each neuron is calculated and the neuron is shifted to the mean value step step 2 and 3 are done until there is no more shift in the neurons position in this way the neurons are adjusted,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
596,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,step randomly select the i centers step cluster the datapoints based on the centers step the centroid of the cluster becomes the new mean step repeat step 2 and 3 until there is no more evidential change in the network,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
597,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,input labeled data set one unlabeled data point number i find the i labeled points which are closest to the given unlabeled point from these points find the label which occurs most often assign this label to the unlabeled data point,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
598,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,1 get the nearest neighbor of the current i 2 remove it from i 3 get the class of the current i 4 classify i as the class that occurs the most often in the neighbors for 1 to i li la inn minx i getclassofxnn amountofclassesaddc setclassofx maxamountofclasses,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
599,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,for the input data i the distance to every other data point is calculated using a distance measure take the i data points which have the minimum distance to i these are the nearest neighbours the most frequent class from the neighbours is assigned as the class of the input data,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
600,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,this learning is based on the memory introduced into the dataset for each data point the nearest neighbours are found via a distance function for each datapoint i neighbours getknearestneighboursofd class getmostrepresentedclassneighbours,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
601,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,for a given input compute distances to other input points pick i nearest neighbors look at labeling of neighbors decide labeling classification by highest number of neighbors in one class german mehrheitsentscheid,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
602,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,trainings training data define clusters select clusters datapoints as centroid randomly for datapoint in trainings calculate distance to centroid able datapoint according to closest centroid end for literate over clusters calculate centroid,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
603,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,nearest neighbours is memory based learning take input i calculate calculate distance of i from each training point select i training points with minimum distance from the data fetch classes of selected i nearest points calculate number points per class in i nearest points determine the class i having maximum points in i nearest points the class of the input point is i,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
604,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,nearest neighbors basically works as follows 1 the they define randomly the cluster points 2 calculate the mean of the equlidian distance between the data points here the points from the previous step acts as centroid 3 check the variance of the clusters 4 repeat 123 till you get the proper clusters,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
605,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,1 slept random number of neighbourhood initially 2 find out the input which is nearest to the weight vector using competitive learning 3 change only the input which wins 4 decrease the size of neighbourhood 5 repeat,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0.0,2.0,neural_networks,neural_course
606,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,for i in inputpoints neighbours findnearestkpointsx for i in neighbours i getvoteofn updatevotescountforxv max getmaxvoteforx,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
607,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,let i be set of labeled data in memory i x1x2xn while prime is nearest point to the test point in term of euclidean distance let class be function that return class type if certain data point i and let i be constant number of neighboring points conspired in algorithm search initialize prime la i listofclasses for i 1 ok i do la lj1xprime prime nearest neighbor to test form la data i classofxprime listofclassesappendc end cutest most frequent class in listofclasses,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2.0,2.0,neural_networks,neural_course
608,Explain the Bias Variance Dilemma!,238,in machine learning a choice always needs to be made for the tradeoff between bias and variance bias determines how close the result is to the true value and variance determines the sensitivity to fluctuations in the training dataset if bias is reduced variance increases and vice versa so an optimum tradeoff needs to be chosen which presents a dilemma,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1.0,2.0,neural_networks,neural_course
609,Explain the Bias Variance Dilemma!,238,bias variance dilemma is used to analyse the generalization error of the algorithm if the value of bias is very high then network does not learn relations between features and outputs correctlyoverfitting if the value of variance is very high then network may model the random noise and it does not learn intended ouputsunderfitting we have to to tradeoff between bias and variance so that our model can generalize properly,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1.0,2.0,neural_networks,neural_course
610,Explain the Bias Variance Dilemma!,238,,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
611,Explain the Bias Variance Dilemma!,238,when training a model on a limited training data set we must decide wether we accept a biased model which makes assumptions about the test data but has a better performance on the train data or a model with more variance which might model the entirety of the data better but be prone to data noise usually we have to decide on a trade off between the two where we may select well balanced models based on ve dimensions or cross validation results,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2.0,2.0,neural_networks,neural_course
612,Explain the Bias Variance Dilemma!,238,bias and variance are both undesirable to the learning bias defines how far the generated output differs from the true value variance defines how much the op change on changing the input dataset however in most cases it is only possible to decrease one at the expense of other thus it is called bias variance dilemma,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1.0,2.0,neural_networks,neural_course
613,Explain the Bias Variance Dilemma!,238,,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
614,Explain the Bias Variance Dilemma!,238,the bias is the error we make in the assumption by creating the learning machine how much we we are away from the actual truth the variance is how much the learning machine changes with different training data sets if we have a high bias we habe a low variance and if we habe a low variance we habe a high bias,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1.0,2.0,neural_networks,neural_course
615,Explain the Bias Variance Dilemma!,238,you have to to a tradeoff between high bias or high variance you cannot have both high variance means the model is overfishing the data and therefore the variance on input can be quit hight high bias means the model is generalization is to specific,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1.0,2.0,neural_networks,neural_course
616,Explain the Bias Variance Dilemma!,238,the bias is defined as the grade of correctness that a learning algorithm will use the variance is defined as the grade of flexibility that the algorithm have given a model to learn when having the bias high but the variance low the algorithm will not be flexible into data and will discard any data is not exactly the data that fits into the model on the other hand when having the variance high but the bias low the algorithm will be very flexible into the data and will accept any error data as part of the model to learn,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2.0,2.0,neural_networks,neural_course
617,Explain the Bias Variance Dilemma!,238,bias the bias is the difference between the predicted value and the desired value in the generalization run variance is the inadequate in the produced value in the regression and the desired value that we expect from the network,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
618,Explain the Bias Variance Dilemma!,238,bias variance dilemma is coming from the fact that you can not have both at the same time your network can not be equally great at outpouring with extremely high accuracy extremely hight amount of variables therefore you need to find balance between the two that suits needs of your neural network,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
619,Explain the Bias Variance Dilemma!,238,it is refers to the problem of trying to maintain a balance between two causes of errors in learning algorithms such that the network is able to generalize data beyond that used for training namely the bias error and the variance error having a high bias error may cause the network to miss important features in the training data which leads to undercutting high variance will make the network to memorize noise present in the training data rather than learning features which lead to overfishing,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2.0,2.0,neural_networks,neural_course
620,Explain the Bias Variance Dilemma!,238,one cannot optimize simultaneously the learning algorithm both for learning maximum variance in the data and learning localization which can be termed as bias,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
621,Explain the Bias Variance Dilemma!,238,,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
622,Explain the Bias Variance Dilemma!,238,the bias variance dilemma tells us that the bias the difference between the actual and desired output and the variance output difference between each trial cannot be decreased at the same time a complex model results in small variance and larger variance,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1.0,2.0,neural_networks,neural_course
623,Explain the Bias Variance Dilemma!,238,so in machine learning problem minimizing the two main source of error simultaneously does not allow the networks to be generalized very easy if bias increase variance decrease and vice versa also holds 1 bias tells us how close we are to the true value 2 variance tells us how they vary for different data set so this is a standard problem in in,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2.0,2.0,neural_networks,neural_course
624,Explain the Bias Variance Dilemma!,238,high value of bias means network is unable to learn the data whereas higher variance means its difficult to learn the training data successfully,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
625,Explain the Bias Variance Dilemma!,238,,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
626,Explain the Bias Variance Dilemma!,238,bias and variances are the estimation errors bias corresponds to the inability of the learning machine to appropriately approximate the function to be learnt hence this induces a deviation from the actual function variance is the inadequacy of the training data to allow the a learning machine to successfully learn the function the dilemma is that to completely learn the actual function to reduce variancerelated error the training data required should consist of infinite samples however this results in slower convergence intern bias error increases therefore trade of between both the errors need to be made,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2.0,2.0,neural_networks,neural_course
627,Explain the Bias Variance Dilemma!,238,,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
628,Explain the Bias Variance Dilemma!,238,bias is the difference between the predicted and true value variance is the range of several predicted values of the same datapoint it is desirable to have low bias and low variance to ensure the predicted value is consistently close to the true value the bias variance dilemma is that to achieve low bias the variance becomes high and vice versa hence there is always a tradeoff between the two,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2.0,2.0,neural_networks,neural_course
629,Explain the Bias Variance Dilemma!,238,bias variance dilemma refers to the problem of minimizing the two sources of error bias error and variance error simultaneously which creates problem in generalization of the network bias error it is the error that occurs while setting the parameters of the network variance terrorist refers to how sensitive the network is to the fluctuations in the dataset,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2.0,2.0,neural_networks,neural_course
630,Explain the Bias Variance Dilemma!,238,,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
631,Explain the Bias Variance Dilemma!,238,bias variance dilemma is a process of simultaneously decreasing two sources of error that prevents supervised learning algorithm from centralizing beyond the trained data,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
632,Explain the Bias Variance Dilemma!,238,bias is used to fine transform of u it helps to shift the classifier line rub,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
633,Explain the Bias Variance Dilemma!,238,bias how close the estimate is to the true value variance how much does the estimate vary for different training sets we always have either hugh variance low bias or low variance high bias,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1.0,2.0,neural_networks,neural_course
634,Explain the Bias Variance Dilemma!,238,bias difference between the estimated output and the actual output variance the range of output of a network for different training set bias and variance cant be decreased at the same time for many networks only one at a time can be decreased,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1.0,2.0,neural_networks,neural_course
635,Explain the Bias Variance Dilemma!,238,,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
636,Explain the Bias Variance Dilemma!,238,when adapting the parameters of a network we can either have a small bias or a small variance if we have a small bias the approximation of the network is close to the real one but the variance between trials is very high if we have a low variance the bias cant be minimized and the network has a bigger error between the approximation and the real value,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1.0,2.0,neural_networks,neural_course
637,Explain the Bias Variance Dilemma!,238,,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
638,Explain the Bias Variance Dilemma!,238,ideally bias and variance would be 0 after learning a machine however bias and variance counteract eachother when bias decreases variance rises and respectively in the other direction this leads to the dilemma that either one of the values has to be present,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1.0,2.0,neural_networks,neural_course
639,Explain the Bias Variance Dilemma!,238,,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
640,Explain the Bias Variance Dilemma!,238,usually only one of bias and variance can be minimized in an run for example few kernels with greater width leads to a high bias but a low variance if you choose many kernels with smaller width the bias is low but the variance is high higher complexity models need more training data,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2.0,2.0,neural_networks,neural_course
641,Explain the Bias Variance Dilemma!,238,,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
642,Explain the Bias Variance Dilemma!,238,bias is an provides an fine transformation and it is treated a extra inputs which normal taken as 1,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
643,Explain the Bias Variance Dilemma!,238,high bias and variance is desirable in input bias variance dilemma is the property of input data where if the bias is increased the variance decreases and vice versa it is difficult to find a tradeoff between them,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1.0,2.0,neural_networks,neural_course
644,Explain the Bias Variance Dilemma!,238,bias bias means how much the prediction differs from the true value variance variance means how much the prediction varies for different datasets the dilemma is that both generally can not be reduced simultaneously a learning machine can reduce one at the cost of other,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1.0,2.0,neural_networks,neural_course
645,Explain the Bias Variance Dilemma!,238,,biasvariance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0.0,2.0,neural_networks,neural_course
