{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found neural_course with type .parquet in (data_saved/emebed_words_conceptnet) and converted it to df\n",
      "df found: True, name: emebed_words_conceptnet\n",
      "File neural_course not found in (data_saved/conceptnet_cosine_similarity)\n",
      "df found: False, name: conceptnet_cosine_similarity\n",
      "No need to run emebed_words_conceptnet for neural_course\n",
      "Running conceptnet_cosine_similarity for neural_course\n",
      "basic processing starting for neural_course\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/646 [00:00<?, ?it/s]/Users/olaf/opt/miniconda3/envs/torch/lib/python3.9/site-packages/scipy/spatial/distance.py:620: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "100%|██████████| 646/646 [00:00<00:00, 30564.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no saving needed because basic emebed_words_conceptnet already done on neural_course\n",
      "saving new conceptnet_cosine_similarity phase for: neural_course\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from classes.Dataset_Basic import Dataset_Basic\n",
    "from classes.Process_Stages import Process_Stages\n",
    "\n",
    "from classes.Dataset_Settings import Dataset_Settings\n",
    "\n",
    "from run_models.cosine_sililarity.classes.Dataset_Cosine import Dataset_Cosine\n",
    "from run_models.gensim.classes.Process_Stages_Gensim import Process_Stages_Gensim\n",
    "\n",
    "from run_models.embed_words.classes.Embed_Words import Embed_Words\n",
    "\n",
    "from run_models.gensim.services.gensim_services import gensim_download, gensim_save, gensim_load\n",
    "from word_embedding.models.classes.EmbeddingModel import EmbeddingModel\n",
    "\n",
    "name_dataset = \"conceptnet_cosine_similarity\"\n",
    "\n",
    "datasets = {}\n",
    "datasets[\"neural_course\"] = Dataset_Cosine(\n",
    "    df_name=\"neural_course\",\n",
    "    model_name=name_dataset, # used for dir name inside data_saved\n",
    "\n",
    "    language=\"english\",\n",
    "\n",
    "    datasets = {\n",
    "        \"emebed_words_conceptnet\": Dataset_Settings(\n",
    "            df=None,\n",
    "            may_run_now=False,\n",
    "            required=True,\n",
    "            parquet=True\n",
    "        ),\n",
    "        name_dataset: Dataset_Settings(\n",
    "            df=None,\n",
    "            may_run_now=True,\n",
    "            required=True,\n",
    "            parquet=True,\n",
    "            name_required_dataset=\"gensim\"\n",
    "        ),\n",
    "    },\n",
    "\n",
    "    columns_to_add = {name_dataset: {\"cosine_similarity\": []}},\n",
    "\n",
    ")\n",
    "\n",
    "# get dataset, process dataset, save dataset\n",
    "datasets[\"neural_course\"].get_dataset()\n",
    "datasets[\"neural_course\"].process_dataset()\n",
    "datasets[\"neural_course\"].add_columns()\n",
    "datasets[\"neural_course\"].save()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found texas with type parquet in (data_saved/cosine_similarity_glove) and converted it to df\n"
     ]
    }
   ],
   "source": [
    "# run regression\n",
    "from run_models.regressions.classses.Regression_Model import Regression_Model\n",
    "\n",
    "# dataset\n",
    "from experiements.classes.Dataset import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# # import datasets\n",
    "# data = pd.read_parquet(\"data_saved/cosine_similarity_glove/texas.parquet\")\n",
    "# data.head(1)\n",
    "\n",
    "# splitting data\n",
    "seed = 42\n",
    "\n",
    "dataset = Dataset(\n",
    "    dir=\"data_saved/cosine_similarity_glove\",\n",
    "    file_name=\"texas\",\n",
    "    seed=seed, \n",
    ")\n",
    "\n",
    "dataset.split_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data\u001b[39m.\u001b[39mhead(\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "# classes\n",
    "from performance_tracking.classes.Measurement_Settings import Measurement_Settings\n",
    "\n",
    "# constants\n",
    "from performance_tracking.constants import *\n",
    "\n",
    "isotonic_regression = Regression_Model(\n",
    "    \n",
    "    # id what is being tracked\n",
    "    embedding_seperated=True,\n",
    "    embedding_model_name=\"glove\",\n",
    "    classfication_model_name=\"ridge_regression\",\n",
    "    dataset_name=\"texas\",\n",
    "    seed_data_split=seed,\n",
    "\n",
    "    # duplicates handeling\n",
    "    settings_performance_tacking=REPLACE,\n",
    "    measurement_settings=Measurement_Settings(\n",
    "        print_regression=False, \n",
    "        print_classification=False, \n",
    "        save_performance=True\n",
    "    ),\n",
    "    \n",
    "    dataset=dataset,\n",
    "    classification_model=Ridge,\n",
    "    x_column=\"cosine_similarity\",\n",
    "    y_column=\"normalized_points\"\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File performance_tracking not found in (performance_tracking/tracking)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olaf/opt/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/olaf/opt/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/olaf/UvA/masterLocal/Thesis/Thesis/performance_tracking/classes/Performance_Row.py:142: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.past_performance = self.past_performance.append(row_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "isotonic_regression.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found performance_tracking with type csv in (performance_tracking/tracking) and converted it to df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olaf/opt/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/olaf/opt/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/olaf/UvA/masterLocal/Thesis/Thesis/performance_tracking/classes/Performance_Row.py:142: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.past_performance = self.past_performance.append(row_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "isotonic_regression.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olaf/opt/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/olaf/opt/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/olaf/UvA/masterLocal/Thesis/Thesis/performance_tracking/classes/Performance_Row.py:142: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.past_performance = self.past_performance.append(row_data, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found performance_tracking with type csv in (performance_tracking/tracking) and converted it to df\n"
     ]
    }
   ],
   "source": [
    "isotonic_regression.validation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3788546255506608\n",
      "\n",
      "Weighted-Averaged Precision: 0.5409047623756303\n",
      "Weighted-Averaged Recall: 0.3788546255506608\n",
      "Weighted-Averaged F1-score: 0.3478631014039235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olaf/opt/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/olaf/opt/miniconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "isotonic_regression.model_accuracy(True, \"test_df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0261598424294478"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isotonic_regression[\"performance\"][\"rmse\"]\n",
    "# isotonic_regression[\"dataset\"][\"test_df\"].head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>assigned_points</th>\n",
       "      <th>max_points</th>\n",
       "      <th>normalized_points</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>pred_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.0</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1123.222467</td>\n",
       "      <td>170.002203</td>\n",
       "      <td>4.145374</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.829075</td>\n",
       "      <td>0.707738</td>\n",
       "      <td>0.824312</td>\n",
       "      <td>4.061674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>659.512420</td>\n",
       "      <td>23.833353</td>\n",
       "      <td>1.145492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229098</td>\n",
       "      <td>0.197314</td>\n",
       "      <td>0.089210</td>\n",
       "      <td>0.510968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004992</td>\n",
       "      <td>0.502070</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>535.750000</td>\n",
       "      <td>148.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.616904</td>\n",
       "      <td>0.783244</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1162.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.757160</td>\n",
       "      <td>0.846657</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1705.250000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847797</td>\n",
       "      <td>0.887636</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2271.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956451</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  question_id  assigned_points  max_points  \\\n",
       "count   454.000000   454.000000       454.000000       454.0   \n",
       "mean   1123.222467   170.002203         4.145374         5.0   \n",
       "std     659.512420    23.833353         1.145492         0.0   \n",
       "min       8.000000   131.000000         0.000000         5.0   \n",
       "25%     535.750000   148.250000         4.000000         5.0   \n",
       "50%    1162.000000   171.000000         5.000000         5.0   \n",
       "75%    1705.250000   192.000000         5.000000         5.0   \n",
       "max    2271.000000   211.000000         5.000000         5.0   \n",
       "\n",
       "       normalized_points  cosine_similarity      y_pred  pred_points  \n",
       "count         454.000000         454.000000  454.000000   454.000000  \n",
       "mean            0.829075           0.707738    0.824312     4.061674  \n",
       "std             0.229098           0.197314    0.089210     0.510968  \n",
       "min             0.000000          -0.004992    0.502070     3.000000  \n",
       "25%             0.800000           0.616904    0.783244     4.000000  \n",
       "50%             1.000000           0.757160    0.846657     4.000000  \n",
       "75%             1.000000           0.847797    0.887636     4.000000  \n",
       "max             1.000000           1.000000    0.956451     5.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test_df\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.model.index_to_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.model[f\"/c/en/open\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.read_csv(\"performance_tracking/tracking/performance_tracking.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>embedding_seperated</th>\n",
       "      <th>embedding_model_name</th>\n",
       "      <th>classification_model_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>dataset_split</th>\n",
       "      <th>seed_data_split</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>rmse</th>\n",
       "      <th>pears_correlation</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>conceptnet</td>\n",
       "      <td>IsotonicRegression</td>\n",
       "      <td>neural_course</td>\n",
       "      <td>train_df</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-05-20 20:38:12</td>\n",
       "      <td>0.704841</td>\n",
       "      <td>0.250259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340708</td>\n",
       "      <td>0.349706</td>\n",
       "      <td>0.355987</td>\n",
       "      <td>0.211992</td>\n",
       "      <td>0.340708</td>\n",
       "      <td>0.340708</td>\n",
       "      <td>0.340708</td>\n",
       "      <td>0.216995</td>\n",
       "      <td>0.340708</td>\n",
       "      <td>0.186239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>conceptnet</td>\n",
       "      <td>IsotonicRegression</td>\n",
       "      <td>neural_course</td>\n",
       "      <td>test_df</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-05-20 20:38:12</td>\n",
       "      <td>0.710536</td>\n",
       "      <td>0.200110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.454068</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.240756</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.276445</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.217686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>conceptnet</td>\n",
       "      <td>IsotonicRegression</td>\n",
       "      <td>neural_course</td>\n",
       "      <td>validation_df</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-05-20 20:38:12</td>\n",
       "      <td>0.638813</td>\n",
       "      <td>0.467774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.117949</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.174242</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.125207</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.184965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>conceptnet</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>neural_course</td>\n",
       "      <td>train_df</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-05-20 20:38:12</td>\n",
       "      <td>0.728005</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331858</td>\n",
       "      <td>0.110619</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166113</td>\n",
       "      <td>0.331858</td>\n",
       "      <td>0.331858</td>\n",
       "      <td>0.331858</td>\n",
       "      <td>0.110130</td>\n",
       "      <td>0.331858</td>\n",
       "      <td>0.165378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>conceptnet</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>neural_course</td>\n",
       "      <td>test_df</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-05-20 20:38:12</td>\n",
       "      <td>0.722605</td>\n",
       "      <td>0.041860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356589</td>\n",
       "      <td>0.118863</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.175238</td>\n",
       "      <td>0.356589</td>\n",
       "      <td>0.356589</td>\n",
       "      <td>0.356589</td>\n",
       "      <td>0.127156</td>\n",
       "      <td>0.356589</td>\n",
       "      <td>0.187464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>319</td>\n",
       "      <td>True</td>\n",
       "      <td>glove</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>english_language_arts</td>\n",
       "      <td>test_df</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-05-20 20:38:20</td>\n",
       "      <td>0.712191</td>\n",
       "      <td>0.316553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438017</td>\n",
       "      <td>0.348313</td>\n",
       "      <td>0.357988</td>\n",
       "      <td>0.273262</td>\n",
       "      <td>0.438017</td>\n",
       "      <td>0.438017</td>\n",
       "      <td>0.438017</td>\n",
       "      <td>0.403102</td>\n",
       "      <td>0.438017</td>\n",
       "      <td>0.328197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>320</td>\n",
       "      <td>True</td>\n",
       "      <td>glove</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>english_language_arts</td>\n",
       "      <td>validation_df</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-05-20 20:38:20</td>\n",
       "      <td>0.705093</td>\n",
       "      <td>0.321891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.406911</td>\n",
       "      <td>0.379881</td>\n",
       "      <td>0.295952</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.496436</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.358007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>321</td>\n",
       "      <td>True</td>\n",
       "      <td>glove</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>english_language_arts</td>\n",
       "      <td>train_df</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-05-20 20:38:20</td>\n",
       "      <td>0.694461</td>\n",
       "      <td>0.322731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469685</td>\n",
       "      <td>0.291059</td>\n",
       "      <td>0.274893</td>\n",
       "      <td>0.213212</td>\n",
       "      <td>0.469685</td>\n",
       "      <td>0.469685</td>\n",
       "      <td>0.469685</td>\n",
       "      <td>0.453618</td>\n",
       "      <td>0.469685</td>\n",
       "      <td>0.354294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>322</td>\n",
       "      <td>True</td>\n",
       "      <td>glove</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>english_language_arts</td>\n",
       "      <td>test_df</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-05-20 20:38:20</td>\n",
       "      <td>0.712380</td>\n",
       "      <td>0.316553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>0.347220</td>\n",
       "      <td>0.353646</td>\n",
       "      <td>0.261984</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>0.401856</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>0.315882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>323</td>\n",
       "      <td>True</td>\n",
       "      <td>glove</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>english_language_arts</td>\n",
       "      <td>validation_df</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-05-20 20:38:20</td>\n",
       "      <td>0.705399</td>\n",
       "      <td>0.321891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443526</td>\n",
       "      <td>0.400213</td>\n",
       "      <td>0.368757</td>\n",
       "      <td>0.275918</td>\n",
       "      <td>0.443526</td>\n",
       "      <td>0.443526</td>\n",
       "      <td>0.443526</td>\n",
       "      <td>0.488252</td>\n",
       "      <td>0.443526</td>\n",
       "      <td>0.333385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id  embedding_seperated embedding_model_name  \\\n",
       "0         0                 True           conceptnet   \n",
       "1         1                 True           conceptnet   \n",
       "2         2                 True           conceptnet   \n",
       "3         3                 True           conceptnet   \n",
       "4         4                 True           conceptnet   \n",
       "..      ...                  ...                  ...   \n",
       "319     319                 True                glove   \n",
       "320     320                 True                glove   \n",
       "321     321                 True                glove   \n",
       "322     322                 True                glove   \n",
       "323     323                 True                glove   \n",
       "\n",
       "    classification_model_name           dataset_name  dataset_split  \\\n",
       "0          IsotonicRegression          neural_course       train_df   \n",
       "1          IsotonicRegression          neural_course        test_df   \n",
       "2          IsotonicRegression          neural_course  validation_df   \n",
       "3            LinearRegression          neural_course       train_df   \n",
       "4            LinearRegression          neural_course        test_df   \n",
       "..                        ...                    ...            ...   \n",
       "319          LinearRegression  english_language_arts        test_df   \n",
       "320          LinearRegression  english_language_arts  validation_df   \n",
       "321                     Ridge  english_language_arts       train_df   \n",
       "322                     Ridge  english_language_arts        test_df   \n",
       "323                     Ridge  english_language_arts  validation_df   \n",
       "\n",
       "     seed_data_split           time_stamp      rmse  pears_correlation  ...  \\\n",
       "0                 42  2023-05-20 20:38:12  0.704841           0.250259  ...   \n",
       "1                 42  2023-05-20 20:38:12  0.710536           0.200110  ...   \n",
       "2                 42  2023-05-20 20:38:12  0.638813           0.467774  ...   \n",
       "3                 42  2023-05-20 20:38:12  0.728005           0.002383  ...   \n",
       "4                 42  2023-05-20 20:38:12  0.722605           0.041860  ...   \n",
       "..               ...                  ...       ...                ...  ...   \n",
       "319               42  2023-05-20 20:38:20  0.712191           0.316553  ...   \n",
       "320               42  2023-05-20 20:38:20  0.705093           0.321891  ...   \n",
       "321               42  2023-05-20 20:38:20  0.694461           0.322731  ...   \n",
       "322               42  2023-05-20 20:38:20  0.712380           0.316553  ...   \n",
       "323               42  2023-05-20 20:38:20  0.705399           0.321891  ...   \n",
       "\n",
       "     accuracy  precision_macro  recall_macro  f1_macro  precision_micro  \\\n",
       "0    0.340708         0.349706      0.355987  0.211992         0.340708   \n",
       "1    0.372093         0.454068      0.368421  0.240756         0.372093   \n",
       "2    0.353846         0.117949      0.333333  0.174242         0.353846   \n",
       "3    0.331858         0.110619      0.333333  0.166113         0.331858   \n",
       "4    0.356589         0.118863      0.333333  0.175238         0.356589   \n",
       "..        ...              ...           ...       ...              ...   \n",
       "319  0.438017         0.348313      0.357988  0.273262         0.438017   \n",
       "320  0.457300         0.406911      0.379881  0.295952         0.457300   \n",
       "321  0.469685         0.291059      0.274893  0.213212         0.469685   \n",
       "322  0.433884         0.347220      0.353646  0.261984         0.433884   \n",
       "323  0.443526         0.400213      0.368757  0.275918         0.443526   \n",
       "\n",
       "     recall_micro  f1_micro  precision_weighted  recall_weighted  f1_weighted  \n",
       "0        0.340708  0.340708            0.216995         0.340708     0.186239  \n",
       "1        0.372093  0.372093            0.276445         0.372093     0.217686  \n",
       "2        0.353846  0.353846            0.125207         0.353846     0.184965  \n",
       "3        0.331858  0.331858            0.110130         0.331858     0.165378  \n",
       "4        0.356589  0.356589            0.127156         0.356589     0.187464  \n",
       "..            ...       ...                 ...              ...          ...  \n",
       "319      0.438017  0.438017            0.403102         0.438017     0.328197  \n",
       "320      0.457300  0.457300            0.496436         0.457300     0.358007  \n",
       "321      0.469685  0.469685            0.453618         0.469685     0.354294  \n",
       "322      0.433884  0.433884            0.401856         0.433884     0.315882  \n",
       "323      0.443526  0.443526            0.488252         0.443526     0.333385  \n",
       "\n",
       "[324 rows x 21 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/qyl6p0kj7_s9q0djmp51j2jw0000gn/T/ipykernel_1734/1745069190.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  average_by_group = performance.groupby(\"dataset_name\").mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>embedding_seperated</th>\n",
       "      <th>seed_data_split</th>\n",
       "      <th>rmse</th>\n",
       "      <th>pears_correlation</th>\n",
       "      <th>p_value</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASAP_sas</th>\n",
       "      <td>175.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.863364</td>\n",
       "      <td>0.418410</td>\n",
       "      <td>6.596626e-54</td>\n",
       "      <td>0.365874</td>\n",
       "      <td>0.291367</td>\n",
       "      <td>0.245831</td>\n",
       "      <td>0.204836</td>\n",
       "      <td>0.365874</td>\n",
       "      <td>0.365874</td>\n",
       "      <td>0.365874</td>\n",
       "      <td>0.524953</td>\n",
       "      <td>0.365874</td>\n",
       "      <td>0.324609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beetle</th>\n",
       "      <td>166.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.460405</td>\n",
       "      <td>0.357448</td>\n",
       "      <td>1.218215e-17</td>\n",
       "      <td>0.680395</td>\n",
       "      <td>0.672701</td>\n",
       "      <td>0.658107</td>\n",
       "      <td>0.659449</td>\n",
       "      <td>0.680395</td>\n",
       "      <td>0.680395</td>\n",
       "      <td>0.680395</td>\n",
       "      <td>0.677785</td>\n",
       "      <td>0.680395</td>\n",
       "      <td>0.673531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biology</th>\n",
       "      <td>184.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.604562</td>\n",
       "      <td>0.327217</td>\n",
       "      <td>4.161546e-09</td>\n",
       "      <td>0.762405</td>\n",
       "      <td>0.216773</td>\n",
       "      <td>0.245545</td>\n",
       "      <td>0.228583</td>\n",
       "      <td>0.762405</td>\n",
       "      <td>0.762405</td>\n",
       "      <td>0.762405</td>\n",
       "      <td>0.685957</td>\n",
       "      <td>0.762405</td>\n",
       "      <td>0.719873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenated_datasets</th>\n",
       "      <td>121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.802515</td>\n",
       "      <td>0.319615</td>\n",
       "      <td>4.381512e-66</td>\n",
       "      <td>0.460245</td>\n",
       "      <td>0.213327</td>\n",
       "      <td>0.213958</td>\n",
       "      <td>0.207916</td>\n",
       "      <td>0.460245</td>\n",
       "      <td>0.460245</td>\n",
       "      <td>0.460245</td>\n",
       "      <td>0.470975</td>\n",
       "      <td>0.460245</td>\n",
       "      <td>0.453474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenated_domains</th>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.018374</td>\n",
       "      <td>0.326888</td>\n",
       "      <td>9.140345e-41</td>\n",
       "      <td>0.295484</td>\n",
       "      <td>0.216126</td>\n",
       "      <td>0.176683</td>\n",
       "      <td>0.124481</td>\n",
       "      <td>0.295484</td>\n",
       "      <td>0.295484</td>\n",
       "      <td>0.295484</td>\n",
       "      <td>0.443385</td>\n",
       "      <td>0.295484</td>\n",
       "      <td>0.214672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english</th>\n",
       "      <td>148.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.776940</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>1.612942e-18</td>\n",
       "      <td>0.343306</td>\n",
       "      <td>0.411532</td>\n",
       "      <td>0.322082</td>\n",
       "      <td>0.242673</td>\n",
       "      <td>0.343306</td>\n",
       "      <td>0.343306</td>\n",
       "      <td>0.343306</td>\n",
       "      <td>0.527899</td>\n",
       "      <td>0.343306</td>\n",
       "      <td>0.277276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english_language_arts</th>\n",
       "      <td>211.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.706115</td>\n",
       "      <td>0.311977</td>\n",
       "      <td>1.451808e-08</td>\n",
       "      <td>0.454440</td>\n",
       "      <td>0.382090</td>\n",
       "      <td>0.348437</td>\n",
       "      <td>0.271562</td>\n",
       "      <td>0.454440</td>\n",
       "      <td>0.454440</td>\n",
       "      <td>0.454440</td>\n",
       "      <td>0.461247</td>\n",
       "      <td>0.454440</td>\n",
       "      <td>0.348004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_course</th>\n",
       "      <td>112.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.710242</td>\n",
       "      <td>-0.009228</td>\n",
       "      <td>3.811481e-01</td>\n",
       "      <td>0.348989</td>\n",
       "      <td>0.157770</td>\n",
       "      <td>0.335910</td>\n",
       "      <td>0.176955</td>\n",
       "      <td>0.348989</td>\n",
       "      <td>0.348989</td>\n",
       "      <td>0.348989</td>\n",
       "      <td>0.161945</td>\n",
       "      <td>0.348989</td>\n",
       "      <td>0.182552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_networks</th>\n",
       "      <td>202.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.710242</td>\n",
       "      <td>-0.009228</td>\n",
       "      <td>3.811481e-01</td>\n",
       "      <td>0.348989</td>\n",
       "      <td>0.157770</td>\n",
       "      <td>0.335910</td>\n",
       "      <td>0.176955</td>\n",
       "      <td>0.348989</td>\n",
       "      <td>0.348989</td>\n",
       "      <td>0.348989</td>\n",
       "      <td>0.161945</td>\n",
       "      <td>0.348989</td>\n",
       "      <td>0.182552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sciEntsBank</th>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.466097</td>\n",
       "      <td>0.324944</td>\n",
       "      <td>1.821104e-27</td>\n",
       "      <td>0.647403</td>\n",
       "      <td>0.637658</td>\n",
       "      <td>0.615045</td>\n",
       "      <td>0.611933</td>\n",
       "      <td>0.647403</td>\n",
       "      <td>0.647403</td>\n",
       "      <td>0.647403</td>\n",
       "      <td>0.641803</td>\n",
       "      <td>0.647403</td>\n",
       "      <td>0.631225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>157.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.160001</td>\n",
       "      <td>0.143944</td>\n",
       "      <td>8.325677e-02</td>\n",
       "      <td>0.296865</td>\n",
       "      <td>0.212304</td>\n",
       "      <td>0.224699</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>0.296865</td>\n",
       "      <td>0.296865</td>\n",
       "      <td>0.296865</td>\n",
       "      <td>0.261679</td>\n",
       "      <td>0.296865</td>\n",
       "      <td>0.248347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texas</th>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.995967</td>\n",
       "      <td>0.413863</td>\n",
       "      <td>4.161257e-07</td>\n",
       "      <td>0.400845</td>\n",
       "      <td>0.274043</td>\n",
       "      <td>0.212931</td>\n",
       "      <td>0.177227</td>\n",
       "      <td>0.400845</td>\n",
       "      <td>0.400845</td>\n",
       "      <td>0.400845</td>\n",
       "      <td>0.581965</td>\n",
       "      <td>0.400845</td>\n",
       "      <td>0.370788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       row_id  embedding_seperated  seed_data_split      rmse  \\\n",
       "dataset_name                                                                    \n",
       "ASAP_sas                175.0                  1.0             42.0  0.863364   \n",
       "beetle                  166.0                  1.0             42.0  0.460405   \n",
       "biology                 184.0                  1.0             42.0  0.604562   \n",
       "concatenated_datasets   121.0                  1.0             42.0  0.802515   \n",
       "concatenated_domains    130.0                  1.0             42.0  1.018374   \n",
       "english                 148.0                  1.0             42.0  0.776940   \n",
       "english_language_arts   211.0                  1.0             42.0  0.706115   \n",
       "neural_course           112.0                  1.0             42.0  0.710242   \n",
       "neural_networks         202.0                  1.0             42.0  0.710242   \n",
       "sciEntsBank             193.0                  1.0             42.0  0.466097   \n",
       "science                 157.0                  1.0             42.0  1.160001   \n",
       "texas                   139.0                  1.0             42.0  0.995967   \n",
       "\n",
       "                       pears_correlation       p_value  accuracy  \\\n",
       "dataset_name                                                       \n",
       "ASAP_sas                        0.418410  6.596626e-54  0.365874   \n",
       "beetle                          0.357448  1.218215e-17  0.680395   \n",
       "biology                         0.327217  4.161546e-09  0.762405   \n",
       "concatenated_datasets           0.319615  4.381512e-66  0.460245   \n",
       "concatenated_domains            0.326888  9.140345e-41  0.295484   \n",
       "english                         0.421214  1.612942e-18  0.343306   \n",
       "english_language_arts           0.311977  1.451808e-08  0.454440   \n",
       "neural_course                  -0.009228  3.811481e-01  0.348989   \n",
       "neural_networks                -0.009228  3.811481e-01  0.348989   \n",
       "sciEntsBank                     0.324944  1.821104e-27  0.647403   \n",
       "science                         0.143944  8.325677e-02  0.296865   \n",
       "texas                           0.413863  4.161257e-07  0.400845   \n",
       "\n",
       "                       precision_macro  recall_macro  f1_macro  \\\n",
       "dataset_name                                                     \n",
       "ASAP_sas                      0.291367      0.245831  0.204836   \n",
       "beetle                        0.672701      0.658107  0.659449   \n",
       "biology                       0.216773      0.245545  0.228583   \n",
       "concatenated_datasets         0.213327      0.213958  0.207916   \n",
       "concatenated_domains          0.216126      0.176683  0.124481   \n",
       "english                       0.411532      0.322082  0.242673   \n",
       "english_language_arts         0.382090      0.348437  0.271562   \n",
       "neural_course                 0.157770      0.335910  0.176955   \n",
       "neural_networks               0.157770      0.335910  0.176955   \n",
       "sciEntsBank                   0.637658      0.615045  0.611933   \n",
       "science                       0.212304      0.224699  0.186916   \n",
       "texas                         0.274043      0.212931  0.177227   \n",
       "\n",
       "                       precision_micro  recall_micro  f1_micro  \\\n",
       "dataset_name                                                     \n",
       "ASAP_sas                      0.365874      0.365874  0.365874   \n",
       "beetle                        0.680395      0.680395  0.680395   \n",
       "biology                       0.762405      0.762405  0.762405   \n",
       "concatenated_datasets         0.460245      0.460245  0.460245   \n",
       "concatenated_domains          0.295484      0.295484  0.295484   \n",
       "english                       0.343306      0.343306  0.343306   \n",
       "english_language_arts         0.454440      0.454440  0.454440   \n",
       "neural_course                 0.348989      0.348989  0.348989   \n",
       "neural_networks               0.348989      0.348989  0.348989   \n",
       "sciEntsBank                   0.647403      0.647403  0.647403   \n",
       "science                       0.296865      0.296865  0.296865   \n",
       "texas                         0.400845      0.400845  0.400845   \n",
       "\n",
       "                       precision_weighted  recall_weighted  f1_weighted  \n",
       "dataset_name                                                             \n",
       "ASAP_sas                         0.524953         0.365874     0.324609  \n",
       "beetle                           0.677785         0.680395     0.673531  \n",
       "biology                          0.685957         0.762405     0.719873  \n",
       "concatenated_datasets            0.470975         0.460245     0.453474  \n",
       "concatenated_domains             0.443385         0.295484     0.214672  \n",
       "english                          0.527899         0.343306     0.277276  \n",
       "english_language_arts            0.461247         0.454440     0.348004  \n",
       "neural_course                    0.161945         0.348989     0.182552  \n",
       "neural_networks                  0.161945         0.348989     0.182552  \n",
       "sciEntsBank                      0.641803         0.647403     0.631225  \n",
       "science                          0.261679         0.296865     0.248347  \n",
       "texas                            0.581965         0.400845     0.370788  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_by_group = performance.groupby(\"dataset_name\").mean()\n",
    "average_by_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User chose Yes.\n"
     ]
    }
   ],
   "source": [
    "def get_yes_no_input(prompt):\n",
    "    while True:\n",
    "        user_input = input(prompt).lower().strip()\n",
    "        if user_input in ('yes', 'y', 'no', 'n'):\n",
    "            return user_input in ('yes', 'y')\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 'Yes' or 'No'.\")\n",
    "\n",
    "# Get user input\n",
    "user_response = get_yes_no_input(\"Do you want to continue? (Yes/No): \")\n",
    "\n",
    "if user_response:\n",
    "    print(\"User chose Yes.\")\n",
    "else:\n",
    "    print(\"User chose No.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.read_csv(\"performance_tracking/tracking/performance_tracking.csv\")\n",
    "performance = performance.query(\"dataset_split == 'validation_df'\")\n",
    "performance = performance.query(\"dataset_name != 'concatenated_datasets'\")\n",
    "performance = performance.query(\"dataset_name != 'concatenated_domains'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>embedding_seperated</th>\n",
       "      <th>embedding_model_name</th>\n",
       "      <th>classification_model_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>dataset_split</th>\n",
       "      <th>seed_data_split</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>rmse</th>\n",
       "      <th>pears_correlation</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>conceptnet</td>\n",
       "      <td>IsotonicRegression</td>\n",
       "      <td>neural_course</td>\n",
       "      <td>validation_df</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-05-20 15:57:59</td>\n",
       "      <td>0.638813</td>\n",
       "      <td>0.467774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.117949</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.174242</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.125207</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.184965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>conceptnet</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>neural_course</td>\n",
       "      <td>validation_df</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-05-20 15:57:59</td>\n",
       "      <td>0.698580</td>\n",
       "      <td>-0.502717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.117949</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.174242</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.125207</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.184965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  embedding_seperated embedding_model_name classification_model_name  \\\n",
       "2       2                 True           conceptnet        IsotonicRegression   \n",
       "5       5                 True           conceptnet          LinearRegression   \n",
       "\n",
       "    dataset_name  dataset_split  seed_data_split           time_stamp  \\\n",
       "2  neural_course  validation_df               42  2023-05-20 15:57:59   \n",
       "5  neural_course  validation_df               42  2023-05-20 15:57:59   \n",
       "\n",
       "       rmse  pears_correlation  ...  accuracy  precision_macro  recall_macro  \\\n",
       "2  0.638813           0.467774  ...  0.353846         0.117949      0.333333   \n",
       "5  0.698580          -0.502717  ...  0.353846         0.117949      0.333333   \n",
       "\n",
       "   f1_macro  precision_micro  recall_micro  f1_micro  precision_weighted  \\\n",
       "2  0.174242         0.353846      0.353846  0.353846            0.125207   \n",
       "5  0.174242         0.353846      0.353846  0.353846            0.125207   \n",
       "\n",
       "   recall_weighted  f1_weighted  \n",
       "2         0.353846     0.184965  \n",
       "5         0.353846     0.184965  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/qyl6p0kj7_s9q0djmp51j2jw0000gn/T/ipykernel_1734/3116340303.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  performance_embed_avg = performance.groupby(grouped_column).mean().reset_index()\n",
      "/var/folders/wh/qyl6p0kj7_s9q0djmp51j2jw0000gn/T/ipykernel_1734/3116340303.py:11: FutureWarning: The default value of numeric_only in DataFrameGroupBy.std is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  performance_embed_std = performance.groupby(grouped_column).std().reset_index()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grouped_column = \"embedding_model_name\"\n",
    "\n",
    "# embedding_model_name classification_model_name\n",
    "performance_embed_avg = performance.groupby(grouped_column).mean().reset_index()\n",
    "performance_embed_avg_classification = performance_embed_avg.loc[:, [grouped_column, \"accuracy\", \"precision_weighted\", \"recall_weighted\", \"f1_weighted\"]]\n",
    "performance_embed_avg_classification = performance_embed_avg_classification.round(2)\n",
    "\n",
    "performance_embed_avg_cont = performance_embed_avg.loc[:, [grouped_column, \"rmse\", \"pears_correlation\", \"p_value\"]]\n",
    "performance_embed_avg_cont = performance_embed_avg_cont.round(2)\n",
    "\n",
    "performance_embed_std = performance.groupby(grouped_column).std().reset_index()\n",
    "performance_embed_std_classification = performance_embed_std.loc[:, [grouped_column, \"accuracy\", \"precision_weighted\", \"recall_weighted\", \"f1_weighted\"]]\n",
    "performance_embed_std_classification = performance_embed_std_classification.round(2)\n",
    "\n",
    "performance_embed_std_cont = performance_embed_std.loc[:, [grouped_column, \"rmse\", \"pears_correlation\", \"p_value\"]]\n",
    "performance_embed_std_cont = performance_embed_std_cont.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "embedding\\_model\\_name &  accuracy &  precision\\_weighted &  recall\\_weighted &  f1\\_weighted \\\\\n",
      "\\midrule\n",
      "          conceptnet &      0.46 &                0.48 &             0.46 &         0.41 \\\\\n",
      "            fasttext &      0.44 &                0.47 &             0.44 &         0.37 \\\\\n",
      "               glove &      0.45 &                0.46 &             0.45 &         0.38 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/qyl6p0kj7_s9q0djmp51j2jw0000gn/T/ipykernel_1734/1166460973.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(performance_embed_avg_classification.to_latex(index=False))\n"
     ]
    }
   ],
   "source": [
    "print(performance_embed_avg_classification.to_latex(index=False))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "embedding\\_model\\_name &  rmse &  pears\\_correlation &  p\\_value \\\\\n",
      "\\midrule\n",
      "          conceptnet &  0.76 &               0.31 &     0.06 \\\\\n",
      "            fasttext &  0.78 &               0.26 &     0.06 \\\\\n",
      "               glove &  0.78 &               0.27 &     0.09 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/qyl6p0kj7_s9q0djmp51j2jw0000gn/T/ipykernel_1734/3261326330.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(performance_embed_avg_cont.to_latex(index=False))\n"
     ]
    }
   ],
   "source": [
    "print(performance_embed_avg_cont.to_latex(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "embedding\\_model\\_name &  accuracy &  precision\\_weighted &  recall\\_weighted &  f1\\_weighted \\\\\n",
      "\\midrule\n",
      "          conceptnet &      0.15 &                0.19 &             0.15 &         0.18 \\\\\n",
      "            fasttext &      0.16 &                0.19 &             0.16 &         0.19 \\\\\n",
      "               glove &      0.15 &                0.19 &             0.15 &         0.19 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/qyl6p0kj7_s9q0djmp51j2jw0000gn/T/ipykernel_1734/1155407788.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(performance_embed_std_classification.to_latex(index=False))\n"
     ]
    }
   ],
   "source": [
    "print(performance_embed_std_classification.to_latex(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "embedding\\_model\\_name &  rmse &  pears\\_correlation &  p\\_value \\\\\n",
      "\\midrule\n",
      "          conceptnet &  0.20 &               0.20 &     0.21 \\\\\n",
      "            fasttext &  0.21 &               0.16 &     0.19 \\\\\n",
      "               glove &  0.21 &               0.18 &     0.28 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/qyl6p0kj7_s9q0djmp51j2jw0000gn/T/ipykernel_1734/594965855.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(performance_embed_std_cont.to_latex(index=False))\n"
     ]
    }
   ],
   "source": [
    "print(performance_embed_std_cont.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24baac98ea445c1a3207eab7abef97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff03a1c1d7444b09f070f97c1dee430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e77738242f4f8ba38a12a237ba39fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c65ba87ac546d5b2777b6a10a96873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0100, -0.4312, -0.5749,  ..., -1.0529, -0.0838,  0.1126],\n",
      "         [-0.4931, -0.1674, -0.3542,  ..., -0.6042,  0.2402,  0.3796],\n",
      "         [-0.1265, -0.0057, -0.3444,  ..., -0.0752,  0.5391,  0.1031],\n",
      "         ...,\n",
      "         [-0.1106, -0.5507, -0.4991,  ...,  0.1243, -0.1096,  0.4351],\n",
      "         [-0.2631, -0.8986, -0.3745,  ..., -0.3932, -0.4494, -0.6258],\n",
      "         [-0.3255, -0.8167, -0.4563,  ..., -0.4466,  0.2009,  0.3663]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Load pre-trained model tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "# Load pre-trained model\n",
    "model = BertModel.from_pretrained('bert-large-uncased')\n",
    "\n",
    "# Sentence for which we want to create embeddings\n",
    "sentence = \"This is a sample sentence.\"\n",
    "\n",
    "# Tokenize the sentence and convert to input IDs.\n",
    "inputs = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "# Run the sentence through the model to get the embeddings.\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# We get a tuple as output. The first element of the tuple is the embeddings.\n",
    "embeddings = outputs[0]\n",
    "\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 7099, 6251, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1400,  0.2273, -0.2721,  ..., -0.0171,  0.2993,  0.8581],\n",
      "         [-0.6647,  0.1726, -0.0928,  ..., -0.1377,  0.6326,  0.6879],\n",
      "         [-0.6669, -0.1006, -0.1085,  ..., -0.0977, -0.1692,  1.0540],\n",
      "         ...,\n",
      "         [ 0.7031, -0.7658,  0.5756,  ...,  0.3718,  0.5955, -0.1600],\n",
      "         [ 0.4393, -0.7209,  0.1950,  ...,  0.7028,  0.5261, -0.3388],\n",
      "         [ 1.1341,  0.0862, -0.5087,  ...,  0.1970, -0.8134, -0.1709]]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Load pre-trained model tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained model\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# A very long sentence\n",
    "sentence = \"This is a very long sentence...\" # Assume this is a very long sentence\n",
    "\n",
    "# Tokenize the sentence and get the tokens\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "\n",
    "# Define the maximum chunk size (max BERT length - 2 for [CLS] and [SEP])\n",
    "max_chunk_size = 510\n",
    "\n",
    "# Split the tokens into chunks\n",
    "chunks = [tokens[i:i + max_chunk_size] for i in range(0, len(tokens), max_chunk_size)]\n",
    "\n",
    "# For each chunk, add special tokens, convert to input IDs, feed to BERT, and get embeddings\n",
    "for chunk in chunks:\n",
    "    # Add special tokens\n",
    "    chunk = ['[CLS]'] + chunk + ['[SEP]']\n",
    "    # Convert to input IDs\n",
    "    inputs = tokenizer.convert_tokens_to_ids(chunk)\n",
    "    inputs = torch.tensor([inputs])  # Add batch dimension\n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    # The first element of outputs is the embeddings\n",
    "    embeddings = outputs[0]\n",
    "    print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.embed_words.services.string_array import str_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some text to embed\n",
    "df = pd.read_parquet(\"data_saved/embed_words_conceptnet/ASAP_sas.parquet\")\n",
    "text = df.iloc[2][\"student_answer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 300)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_to_array(text).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
