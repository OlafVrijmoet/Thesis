{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found neural_course with type .parquet in (data_saved/emebed_words_conceptnet) and converted it to df\n",
      "df found: True, name: emebed_words_conceptnet\n",
      "File neural_course not found in (data_saved/conceptnet_cosine_similarity)\n",
      "df found: False, name: conceptnet_cosine_similarity\n",
      "No need to run emebed_words_conceptnet for neural_course\n",
      "Running conceptnet_cosine_similarity for neural_course\n",
      "basic processing starting for neural_course\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/646 [00:00<?, ?it/s]/Users/olaf/opt/miniconda3/envs/torch/lib/python3.9/site-packages/scipy/spatial/distance.py:620: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "100%|██████████| 646/646 [00:00<00:00, 30564.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no saving needed because basic emebed_words_conceptnet already done on neural_course\n",
      "saving new conceptnet_cosine_similarity phase for: neural_course\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from classes.Dataset_Basic import Dataset_Basic\n",
    "from classes.Process_Stages import Process_Stages\n",
    "\n",
    "from classes.Dataset_Settings import Dataset_Settings\n",
    "\n",
    "from run_models.cosine_sililarity.classes.Dataset_Cosine import Dataset_Cosine\n",
    "from run_models.gensim.classes.Process_Stages_Gensim import Process_Stages_Gensim\n",
    "\n",
    "from run_models.embed_words.classes.Embed_Words import Embed_Words\n",
    "\n",
    "from run_models.gensim.services.gensim_services import gensim_download, gensim_save, gensim_load\n",
    "from word_embedding.models.classes.EmbeddingModel import EmbeddingModel\n",
    "\n",
    "name_dataset = \"conceptnet_cosine_similarity\"\n",
    "\n",
    "datasets = {}\n",
    "datasets[\"neural_course\"] = Dataset_Cosine(\n",
    "    df_name=\"neural_course\",\n",
    "    model_name=name_dataset, # used for dir name inside data_saved\n",
    "\n",
    "    language=\"english\",\n",
    "\n",
    "    datasets = {\n",
    "        \"emebed_words_conceptnet\": Dataset_Settings(\n",
    "            df=None,\n",
    "            may_run_now=False,\n",
    "            required=True,\n",
    "            parquet=True\n",
    "        ),\n",
    "        name_dataset: Dataset_Settings(\n",
    "            df=None,\n",
    "            may_run_now=True,\n",
    "            required=True,\n",
    "            parquet=True,\n",
    "            name_required_dataset=\"gensim\"\n",
    "        ),\n",
    "    },\n",
    "\n",
    "    columns_to_add = {name_dataset: {\"cosine_similarity\": []}},\n",
    "\n",
    ")\n",
    "\n",
    "# get dataset, process dataset, save dataset\n",
    "datasets[\"neural_course\"].get_dataset()\n",
    "datasets[\"neural_course\"].process_dataset()\n",
    "datasets[\"neural_course\"].add_columns()\n",
    "datasets[\"neural_course\"].save()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Initialize the tokenizer and the model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Your sentence\n",
    "sentence = \"This is a simple sentence.\"\n",
    "\n",
    "# Tokenize the sentence and encode it to IDs\n",
    "input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "\n",
    "# Create tensors\n",
    "input_ids = torch.tensor([input_ids])\n",
    "\n",
    "# Forward pass: compute the BERT embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "# Extract the last hidden states (the embeddings)\n",
    "last_hidden_states = outputs[0]\n",
    "\n",
    "# # Print the embeddings\n",
    "# for i, token_str in enumerate(tokenizer.convert_ids_to_tokens(input_ids[0])):\n",
    "#     print(token_str, last_hidden_states[0, i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(sentence):\n",
    "    # Tokenize the sentence and encode it to IDs\n",
    "    input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "\n",
    "    # Create tensors\n",
    "    input_ids = torch.tensor([input_ids])\n",
    "\n",
    "    # Forward pass: compute the BERT embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "\n",
    "    # Extract the last hidden states (the embeddings)\n",
    "    last_hidden_states = outputs[0]\n",
    "\n",
    "    return last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found neural_course with type parquet in (data/embed_words/data/BERT/data) and converted it to df\n",
      "df found: True, name: BERT\n",
      "No need to run standardized_splits for neural_course\n",
      "No need to run BERT for neural_course\n",
      "no saving needed because basic BERT already done on neural_course\n"
     ]
    }
   ],
   "source": [
    "# classes\n",
    "from data.embed_words.BERT_embedding.classes.BERT_Embedding import BERT_Embedding\n",
    "from classes.Dataset_Settings import Dataset_Settings\n",
    "\n",
    "BERT_embed = BERT_Embedding(\n",
    "    df_name=\"neural_course\",\n",
    "    model_name=\"BERT\", # used for dir name inside data_saved\n",
    "\n",
    "    language=\"english\",\n",
    "\n",
    "    datasets = {\n",
    "        \"standardized_splits\": Dataset_Settings(\n",
    "            df=None,\n",
    "            df_name=\"splits\",\n",
    "            base_dir=\"data\",\n",
    "\n",
    "            may_run_now=False,\n",
    "            required=True,\n",
    "        ),\n",
    "        \"BERT\": Dataset_Settings(\n",
    "            df=None,\n",
    "            df_name=\"BERT\",\n",
    "            base_dir=\"data/embed_words/data\",\n",
    "\n",
    "            may_run_now=True,\n",
    "            required=True,\n",
    "            parquet=True,\n",
    "            name_required_dataset=\"standardized_splits\",\n",
    "            force_run=False\n",
    "        ),\n",
    "    },\n",
    "\n",
    "    pre_trained_BERT_model_name=\"bert-base-uncased\"\n",
    "\n",
    ")\n",
    "\n",
    "BERT_embed.run_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Marly is lief\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed a sentence in BERT_tokenized\n",
    "import pandas as pd\n",
    "\n",
    "df_BERT = pd.read_parquet(\"data/embed_words/data/BERT/data/neural_course.parquet\")\n",
    "df_2 = pd.read_csv(\"data/splits/data/neural_course.csv\")\n",
    "fast_text = pd.read_parquet(\"data/embed_words/data/fasttext/data/neural_course.parquet\")\n",
    "\n",
    "basic = pd.read_csv(\"data/basic_processed/data/neural_course.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from services.string_array import str_to_array\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "1 - cosine(str_to_array(df_BERT.iloc[0][\"student_answer\"])[0], str_to_array(df_BERT.iloc[0][\"student_answer\"])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create sample dataset\n",
    "sample = pd.read_csv(\"data/splits/data/beetle.csv\")\n",
    "sample = sample.sample(n=100, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the DataFrame into train (70%) and the remaining data (30%)\n",
    "train, temp_df = train_test_split(sample, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the remaining data further into test (20% of the original dataset) and validation (10% of the original dataset) sets\n",
    "test, validation = train_test_split(temp_df, test_size=1/3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.iloc[0:].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.save import save\n",
    "\n",
    "save(\n",
    "    dir=\"testing/data\", \n",
    "    file_name=\"sample\", \n",
    "    df=sample\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found sample with type csv in (testing/data) and converted it to df\n"
     ]
    }
   ],
   "source": [
    "from performance_tracking.classes.Dataset_api import Dataset_api\n",
    "                \n",
    "dataset = Dataset_api(\n",
    "    dir=\"testing/data\",\n",
    "    file_name=\"sample\",\n",
    "    seed=42,\n",
    "    shots=3 # DO NOT CHANGE UNTILL FINISHED WITH RUN THROUGH ALL DATASETS!\n",
    ")\n",
    "\n",
    "dataset.split_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "      <th>student_answer</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>assigned_points</th>\n",
       "      <th>max_points</th>\n",
       "      <th>domain</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>normalized_points</th>\n",
       "      <th>student_answer_1</th>\n",
       "      <th>reference_answer_1</th>\n",
       "      <th>assigned_points_1</th>\n",
       "      <th>student_answer_2</th>\n",
       "      <th>reference_answer_2</th>\n",
       "      <th>assigned_points_2</th>\n",
       "      <th>student_answer_3</th>\n",
       "      <th>reference_answer_3</th>\n",
       "      <th>assigned_points_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1419</td>\n",
       "      <td>How does a damaged bulb compare to an open swi...</td>\n",
       "      <td>70</td>\n",
       "      <td>It is the same.</td>\n",
       "      <td>A damaged bulb and an open switch both create ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beetle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>It is the same.</td>\n",
       "      <td>A damaged bulb and an open switch both create ...</td>\n",
       "      <td>1</td>\n",
       "      <td>the have the same effect on the circuit</td>\n",
       "      <td>A damaged bulb and an open switch both create ...</td>\n",
       "      <td>1</td>\n",
       "      <td>It is the same.</td>\n",
       "      <td>A damaged bulb and an open switch both create ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1454</td>\n",
       "      <td>How does a damaged bulb compare to an open swi...</td>\n",
       "      <td>70</td>\n",
       "      <td>the have the same effect on the circuit</td>\n",
       "      <td>A damaged bulb and an open switch both create ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beetle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>It is the same.</td>\n",
       "      <td>A damaged bulb and an open switch both create ...</td>\n",
       "      <td>1</td>\n",
       "      <td>the have the same effect on the circuit</td>\n",
       "      <td>A damaged bulb and an open switch both create ...</td>\n",
       "      <td>1</td>\n",
       "      <td>It is the same.</td>\n",
       "      <td>A damaged bulb and an open switch both create ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id                                           question  question_id  \\\n",
       "6     1419  How does a damaged bulb compare to an open swi...           70   \n",
       "26    1454  How does a damaged bulb compare to an open swi...           70   \n",
       "\n",
       "                             student_answer  \\\n",
       "6                           It is the same.   \n",
       "26  the have the same effect on the circuit   \n",
       "\n",
       "                                     reference_answer  assigned_points  \\\n",
       "6   A damaged bulb and an open switch both create ...                1   \n",
       "26  A damaged bulb and an open switch both create ...                1   \n",
       "\n",
       "    max_points  domain dataset_name  normalized_points student_answer_1  \\\n",
       "6            1     NaN       beetle                1.0  It is the same.   \n",
       "26           1     NaN       beetle                1.0  It is the same.   \n",
       "\n",
       "                                   reference_answer_1  assigned_points_1  \\\n",
       "6   A damaged bulb and an open switch both create ...                  1   \n",
       "26  A damaged bulb and an open switch both create ...                  1   \n",
       "\n",
       "                           student_answer_2  \\\n",
       "6   the have the same effect on the circuit   \n",
       "26  the have the same effect on the circuit   \n",
       "\n",
       "                                   reference_answer_2  assigned_points_2  \\\n",
       "6   A damaged bulb and an open switch both create ...                  1   \n",
       "26  A damaged bulb and an open switch both create ...                  1   \n",
       "\n",
       "   student_answer_3                                 reference_answer_3  \\\n",
       "6   It is the same.  A damaged bulb and an open switch both create ...   \n",
       "26  It is the same.  A damaged bulb and an open switch both create ...   \n",
       "\n",
       "    assigned_points_3  \n",
       "6                   1  \n",
       "26                  1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].query(\"question_id == 70\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "      <th>student_answer</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>assigned_points</th>\n",
       "      <th>max_points</th>\n",
       "      <th>domain</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>normalized_points</th>\n",
       "      <th>student_answer_1</th>\n",
       "      <th>reference_answer_1</th>\n",
       "      <th>assigned_points_1</th>\n",
       "      <th>student_answer_2</th>\n",
       "      <th>reference_answer_2</th>\n",
       "      <th>assigned_points_2</th>\n",
       "      <th>student_answer_3</th>\n",
       "      <th>reference_answer_3</th>\n",
       "      <th>assigned_points_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1488</td>\n",
       "      <td>How does a damaged bulb compare to an open swi...</td>\n",
       "      <td>70</td>\n",
       "      <td>it creates the same effect</td>\n",
       "      <td>A damaged bulb and an open switch both create ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beetle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>It is the same.</td>\n",
       "      <td>A damaged bulb and an open switch both create ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>the have the same effect on the circuit</td>\n",
       "      <td>A damaged bulb and an open switch both create ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>It is the same.</td>\n",
       "      <td>A damaged bulb and an open switch both create ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1321</td>\n",
       "      <td>Explain why you got a voltage reading of 1.5 f...</td>\n",
       "      <td>68</td>\n",
       "      <td>The positive battery terminal is separted by a...</td>\n",
       "      <td>Terminal 2 and the positive terminal are separ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beetle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Terminal 2 was connected to the negative terminal</td>\n",
       "      <td>Terminal 2 and the positive terminal are separ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Terminal 2 was connected to the negative terminal</td>\n",
       "      <td>Terminal 2 and the positive terminal are separ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Terminal 2 was connected to the negative terminal</td>\n",
       "      <td>Terminal 2 and the positive terminal are separ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2927</td>\n",
       "      <td>When switch X was closed and switch Y was open...</td>\n",
       "      <td>86</td>\n",
       "      <td>It was still contained in a closed path with t...</td>\n",
       "      <td>Bulb A is still contained in a closed path wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beetle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>it was in a closed path with the battery</td>\n",
       "      <td>Bulb A is still contained in a closed path wit...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>it was in a closed path with the battery</td>\n",
       "      <td>Bulb A is still contained in a closed path wit...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>it was in a closed path with the battery</td>\n",
       "      <td>Bulb A is still contained in a closed path wit...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4516</td>\n",
       "      <td>Explain why circuit 2 is not a short circuit.</td>\n",
       "      <td>106</td>\n",
       "      <td>Because the battery is out of the closed path ...</td>\n",
       "      <td>The battery in 2 is not in a closed path</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beetle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>postive terminal of battery is not connected</td>\n",
       "      <td>The battery in 2 is not in a closed path</td>\n",
       "      <td>0.0</td>\n",
       "      <td>postive terminal of battery is not connected</td>\n",
       "      <td>The battery in 2 is not in a closed path</td>\n",
       "      <td>0.0</td>\n",
       "      <td>postive terminal of battery is not connected</td>\n",
       "      <td>The battery in 2 is not in a closed path</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3901</td>\n",
       "      <td>Explain why circuit 5 is a short circuit.</td>\n",
       "      <td>98</td>\n",
       "      <td>the bulb is not connected to the battery.</td>\n",
       "      <td>the battery is contained in a closed path in w...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beetle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the battery has a closed path and no bulbs</td>\n",
       "      <td>the battery is contained in a closed path in w...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>the battery alone is in a closed path</td>\n",
       "      <td>the battery is contained in a closed path in w...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>the batter is on a closed path without any oth...</td>\n",
       "      <td>the battery is contained in a closed path in w...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3090</td>\n",
       "      <td>Explain why you got a voltage reading of 1.5 f...</td>\n",
       "      <td>88</td>\n",
       "      <td>I get a 1.5 V reading because the negative ter...</td>\n",
       "      <td>Terminal 1 and the positive terminal are not c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beetle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the positive battery terminal and terminal 1 a...</td>\n",
       "      <td>Terminal 1 and the positive terminal are not c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no damaged bulb</td>\n",
       "      <td>Terminal 1 and the positive terminal are not c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the gap separates the positive battery termina...</td>\n",
       "      <td>Terminal 1 and the positive terminal are not c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1536</td>\n",
       "      <td>What role does the path play in determining wh...</td>\n",
       "      <td>71</td>\n",
       "      <td>The path must be closed and contain the battery</td>\n",
       "      <td>If a bulb and a switch are in the same path th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beetle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bulbs will be affected by switches that are in...</td>\n",
       "      <td>If a bulb and a switch are in the same path th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A switch affects a bulb when it is in a closed...</td>\n",
       "      <td>If a bulb and a switch are in the same path th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>If the switch is in front of the path of a lig...</td>\n",
       "      <td>If a bulb and a switch are in the same path th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4882</td>\n",
       "      <td>Explain why you got a voltage reading of 1.5 f...</td>\n",
       "      <td>109</td>\n",
       "      <td>the positive terminal is seperated by a gap fr...</td>\n",
       "      <td>Terminal 3 and the positive terminal are separ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beetle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Terminal 3 is not connected to the positive ba...</td>\n",
       "      <td>Terminal 3 and the positive terminal are separ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Terminal 3 is not connected to the positive ba...</td>\n",
       "      <td>Terminal 3 and the positive terminal are separ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Terminal 3 is not connected to the positive ba...</td>\n",
       "      <td>Terminal 3 and the positive terminal are separ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                                           question  question_id  \\\n",
       "0    1488  How does a damaged bulb compare to an open swi...           70   \n",
       "2    1321  Explain why you got a voltage reading of 1.5 f...           68   \n",
       "3    2927  When switch X was closed and switch Y was open...           86   \n",
       "4    4516      Explain why circuit 2 is not a short circuit.          106   \n",
       "5    3901          Explain why circuit 5 is a short circuit.           98   \n",
       "7    3090  Explain why you got a voltage reading of 1.5 f...           88   \n",
       "8    1536  What role does the path play in determining wh...           71   \n",
       "9    4882  Explain why you got a voltage reading of 1.5 f...          109   \n",
       "\n",
       "                                      student_answer  \\\n",
       "0                         it creates the same effect   \n",
       "2  The positive battery terminal is separted by a...   \n",
       "3  It was still contained in a closed path with t...   \n",
       "4  Because the battery is out of the closed path ...   \n",
       "5          the bulb is not connected to the battery.   \n",
       "7  I get a 1.5 V reading because the negative ter...   \n",
       "8    The path must be closed and contain the battery   \n",
       "9  the positive terminal is seperated by a gap fr...   \n",
       "\n",
       "                                    reference_answer  assigned_points  \\\n",
       "0  A damaged bulb and an open switch both create ...                1   \n",
       "2  Terminal 2 and the positive terminal are separ...                1   \n",
       "3  Bulb A is still contained in a closed path wit...                1   \n",
       "4           The battery in 2 is not in a closed path                1   \n",
       "5  the battery is contained in a closed path in w...                0   \n",
       "7  Terminal 1 and the positive terminal are not c...                0   \n",
       "8  If a bulb and a switch are in the same path th...                0   \n",
       "9  Terminal 3 and the positive terminal are separ...                1   \n",
       "\n",
       "   max_points  domain dataset_name  normalized_points  \\\n",
       "0           1     NaN       beetle                1.0   \n",
       "2           1     NaN       beetle                1.0   \n",
       "3           1     NaN       beetle                1.0   \n",
       "4           1     NaN       beetle                1.0   \n",
       "5           1     NaN       beetle                0.0   \n",
       "7           1     NaN       beetle                0.0   \n",
       "8           1     NaN       beetle                0.0   \n",
       "9           1     NaN       beetle                1.0   \n",
       "\n",
       "                                    student_answer_1  \\\n",
       "0                                    It is the same.   \n",
       "2  Terminal 2 was connected to the negative terminal   \n",
       "3           it was in a closed path with the battery   \n",
       "4       postive terminal of battery is not connected   \n",
       "5         the battery has a closed path and no bulbs   \n",
       "7  the positive battery terminal and terminal 1 a...   \n",
       "8  bulbs will be affected by switches that are in...   \n",
       "9  Terminal 3 is not connected to the positive ba...   \n",
       "\n",
       "                                  reference_answer_1  assigned_points_1  \\\n",
       "0  A damaged bulb and an open switch both create ...                1.0   \n",
       "2  Terminal 2 and the positive terminal are separ...                1.0   \n",
       "3  Bulb A is still contained in a closed path wit...                1.0   \n",
       "4           The battery in 2 is not in a closed path                0.0   \n",
       "5  the battery is contained in a closed path in w...                1.0   \n",
       "7  Terminal 1 and the positive terminal are not c...                1.0   \n",
       "8  If a bulb and a switch are in the same path th...                0.0   \n",
       "9  Terminal 3 and the positive terminal are separ...                1.0   \n",
       "\n",
       "                                    student_answer_2  \\\n",
       "0            the have the same effect on the circuit   \n",
       "2  Terminal 2 was connected to the negative terminal   \n",
       "3           it was in a closed path with the battery   \n",
       "4       postive terminal of battery is not connected   \n",
       "5              the battery alone is in a closed path   \n",
       "7                                    no damaged bulb   \n",
       "8  A switch affects a bulb when it is in a closed...   \n",
       "9  Terminal 3 is not connected to the positive ba...   \n",
       "\n",
       "                                  reference_answer_2  assigned_points_2  \\\n",
       "0  A damaged bulb and an open switch both create ...                1.0   \n",
       "2  Terminal 2 and the positive terminal are separ...                1.0   \n",
       "3  Bulb A is still contained in a closed path wit...                1.0   \n",
       "4           The battery in 2 is not in a closed path                0.0   \n",
       "5  the battery is contained in a closed path in w...                1.0   \n",
       "7  Terminal 1 and the positive terminal are not c...                0.0   \n",
       "8  If a bulb and a switch are in the same path th...                0.0   \n",
       "9  Terminal 3 and the positive terminal are separ...                1.0   \n",
       "\n",
       "                                    student_answer_3  \\\n",
       "0                                    It is the same.   \n",
       "2  Terminal 2 was connected to the negative terminal   \n",
       "3           it was in a closed path with the battery   \n",
       "4       postive terminal of battery is not connected   \n",
       "5  the batter is on a closed path without any oth...   \n",
       "7  the gap separates the positive battery termina...   \n",
       "8  If the switch is in front of the path of a lig...   \n",
       "9  Terminal 3 is not connected to the positive ba...   \n",
       "\n",
       "                                  reference_answer_3  assigned_points_3  \n",
       "0  A damaged bulb and an open switch both create ...                1.0  \n",
       "2  Terminal 2 and the positive terminal are separ...                1.0  \n",
       "3  Bulb A is still contained in a closed path wit...                1.0  \n",
       "4           The battery in 2 is not in a closed path                0.0  \n",
       "5  the battery is contained in a closed path in w...                1.0  \n",
       "7  Terminal 1 and the positive terminal are not c...                1.0  \n",
       "8  If a bulb and a switch are in the same path th...                0.0  \n",
       "9  Terminal 3 and the positive terminal are separ...                1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.read_csv(\"performance_tracking/tracking/performance_tracking.csv\")\n",
    "performance = performance.query(\"dataset_split == 'validation_df'\")\n",
    "performance = performance.query(\"dataset_name != 'concatenated_datasets'\")\n",
    "performance = performance.query(\"dataset_name != 'concatenated_domains'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>embedding_seperated</th>\n",
       "      <th>embedding_model_name</th>\n",
       "      <th>classification_model_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>dataset_split</th>\n",
       "      <th>seed_data_split</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>rmse</th>\n",
       "      <th>pears_correlation</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>conceptnet</td>\n",
       "      <td>IsotonicRegression</td>\n",
       "      <td>neural_course</td>\n",
       "      <td>validation_df</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-05-20 15:57:59</td>\n",
       "      <td>0.638813</td>\n",
       "      <td>0.467774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.117949</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.174242</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.125207</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.184965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>conceptnet</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>neural_course</td>\n",
       "      <td>validation_df</td>\n",
       "      <td>42</td>\n",
       "      <td>2023-05-20 15:57:59</td>\n",
       "      <td>0.698580</td>\n",
       "      <td>-0.502717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.117949</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.174242</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.125207</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.184965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  embedding_seperated embedding_model_name classification_model_name  \\\n",
       "2       2                 True           conceptnet        IsotonicRegression   \n",
       "5       5                 True           conceptnet          LinearRegression   \n",
       "\n",
       "    dataset_name  dataset_split  seed_data_split           time_stamp  \\\n",
       "2  neural_course  validation_df               42  2023-05-20 15:57:59   \n",
       "5  neural_course  validation_df               42  2023-05-20 15:57:59   \n",
       "\n",
       "       rmse  pears_correlation  ...  accuracy  precision_macro  recall_macro  \\\n",
       "2  0.638813           0.467774  ...  0.353846         0.117949      0.333333   \n",
       "5  0.698580          -0.502717  ...  0.353846         0.117949      0.333333   \n",
       "\n",
       "   f1_macro  precision_micro  recall_micro  f1_micro  precision_weighted  \\\n",
       "2  0.174242         0.353846      0.353846  0.353846            0.125207   \n",
       "5  0.174242         0.353846      0.353846  0.353846            0.125207   \n",
       "\n",
       "   recall_weighted  f1_weighted  \n",
       "2         0.353846     0.184965  \n",
       "5         0.353846     0.184965  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/qyl6p0kj7_s9q0djmp51j2jw0000gn/T/ipykernel_1734/3116340303.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  performance_embed_avg = performance.groupby(grouped_column).mean().reset_index()\n",
      "/var/folders/wh/qyl6p0kj7_s9q0djmp51j2jw0000gn/T/ipykernel_1734/3116340303.py:11: FutureWarning: The default value of numeric_only in DataFrameGroupBy.std is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  performance_embed_std = performance.groupby(grouped_column).std().reset_index()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grouped_column = \"embedding_model_name\"\n",
    "\n",
    "# embedding_model_name classification_model_name\n",
    "performance_embed_avg = performance.groupby(grouped_column).mean().reset_index()\n",
    "performance_embed_avg_classification = performance_embed_avg.loc[:, [grouped_column, \"accuracy\", \"precision_weighted\", \"recall_weighted\", \"f1_weighted\"]]\n",
    "performance_embed_avg_classification = performance_embed_avg_classification.round(2)\n",
    "\n",
    "performance_embed_avg_cont = performance_embed_avg.loc[:, [grouped_column, \"rmse\", \"pears_correlation\", \"p_value\"]]\n",
    "performance_embed_avg_cont = performance_embed_avg_cont.round(2)\n",
    "\n",
    "performance_embed_std = performance.groupby(grouped_column).std().reset_index()\n",
    "performance_embed_std_classification = performance_embed_std.loc[:, [grouped_column, \"accuracy\", \"precision_weighted\", \"recall_weighted\", \"f1_weighted\"]]\n",
    "performance_embed_std_classification = performance_embed_std_classification.round(2)\n",
    "\n",
    "performance_embed_std_cont = performance_embed_std.loc[:, [grouped_column, \"rmse\", \"pears_correlation\", \"p_value\"]]\n",
    "performance_embed_std_cont = performance_embed_std_cont.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "embedding\\_model\\_name &  accuracy &  precision\\_weighted &  recall\\_weighted &  f1\\_weighted \\\\\n",
      "\\midrule\n",
      "          conceptnet &      0.46 &                0.48 &             0.46 &         0.41 \\\\\n",
      "            fasttext &      0.44 &                0.47 &             0.44 &         0.37 \\\\\n",
      "               glove &      0.45 &                0.46 &             0.45 &         0.38 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/qyl6p0kj7_s9q0djmp51j2jw0000gn/T/ipykernel_1734/1166460973.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(performance_embed_avg_classification.to_latex(index=False))\n"
     ]
    }
   ],
   "source": [
    "print(performance_embed_avg_classification.to_latex(index=False))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "embedding\\_model\\_name &  rmse &  pears\\_correlation &  p\\_value \\\\\n",
      "\\midrule\n",
      "          conceptnet &  0.76 &               0.31 &     0.06 \\\\\n",
      "            fasttext &  0.78 &               0.26 &     0.06 \\\\\n",
      "               glove &  0.78 &               0.27 &     0.09 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/qyl6p0kj7_s9q0djmp51j2jw0000gn/T/ipykernel_1734/3261326330.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(performance_embed_avg_cont.to_latex(index=False))\n"
     ]
    }
   ],
   "source": [
    "print(performance_embed_avg_cont.to_latex(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "embedding\\_model\\_name &  accuracy &  precision\\_weighted &  recall\\_weighted &  f1\\_weighted \\\\\n",
      "\\midrule\n",
      "          conceptnet &      0.15 &                0.19 &             0.15 &         0.18 \\\\\n",
      "            fasttext &      0.16 &                0.19 &             0.16 &         0.19 \\\\\n",
      "               glove &      0.15 &                0.19 &             0.15 &         0.19 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/qyl6p0kj7_s9q0djmp51j2jw0000gn/T/ipykernel_1734/1155407788.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(performance_embed_std_classification.to_latex(index=False))\n"
     ]
    }
   ],
   "source": [
    "print(performance_embed_std_classification.to_latex(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "embedding\\_model\\_name &  rmse &  pears\\_correlation &  p\\_value \\\\\n",
      "\\midrule\n",
      "          conceptnet &  0.20 &               0.20 &     0.21 \\\\\n",
      "            fasttext &  0.21 &               0.16 &     0.19 \\\\\n",
      "               glove &  0.21 &               0.18 &     0.28 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/qyl6p0kj7_s9q0djmp51j2jw0000gn/T/ipykernel_1734/594965855.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(performance_embed_std_cont.to_latex(index=False))\n"
     ]
    }
   ],
   "source": [
    "print(performance_embed_std_cont.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24baac98ea445c1a3207eab7abef97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff03a1c1d7444b09f070f97c1dee430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e77738242f4f8ba38a12a237ba39fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c65ba87ac546d5b2777b6a10a96873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0100, -0.4312, -0.5749,  ..., -1.0529, -0.0838,  0.1126],\n",
      "         [-0.4931, -0.1674, -0.3542,  ..., -0.6042,  0.2402,  0.3796],\n",
      "         [-0.1265, -0.0057, -0.3444,  ..., -0.0752,  0.5391,  0.1031],\n",
      "         ...,\n",
      "         [-0.1106, -0.5507, -0.4991,  ...,  0.1243, -0.1096,  0.4351],\n",
      "         [-0.2631, -0.8986, -0.3745,  ..., -0.3932, -0.4494, -0.6258],\n",
      "         [-0.3255, -0.8167, -0.4563,  ..., -0.4466,  0.2009,  0.3663]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Load pre-trained model tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "# Load pre-trained model\n",
    "model = BertModel.from_pretrained('bert-large-uncased')\n",
    "\n",
    "# Sentence for which we want to create embeddings\n",
    "sentence = \"This is a sample sentence.\"\n",
    "\n",
    "# Tokenize the sentence and convert to input IDs.\n",
    "inputs = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "# Run the sentence through the model to get the embeddings.\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# We get a tuple as output. The first element of the tuple is the embeddings.\n",
    "embeddings = outputs[0]\n",
    "\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 7099, 6251, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1400,  0.2273, -0.2721,  ..., -0.0171,  0.2993,  0.8581],\n",
      "         [-0.6647,  0.1726, -0.0928,  ..., -0.1377,  0.6326,  0.6879],\n",
      "         [-0.6669, -0.1006, -0.1085,  ..., -0.0977, -0.1692,  1.0540],\n",
      "         ...,\n",
      "         [ 0.7031, -0.7658,  0.5756,  ...,  0.3718,  0.5955, -0.1600],\n",
      "         [ 0.4393, -0.7209,  0.1950,  ...,  0.7028,  0.5261, -0.3388],\n",
      "         [ 1.1341,  0.0862, -0.5087,  ...,  0.1970, -0.8134, -0.1709]]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Load pre-trained model tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained model\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# A very long sentence\n",
    "sentence = \"This is a very long sentence...\" # Assume this is a very long sentence\n",
    "\n",
    "# Tokenize the sentence and get the tokens\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "\n",
    "# Define the maximum chunk size (max BERT length - 2 for [CLS] and [SEP])\n",
    "max_chunk_size = 510\n",
    "\n",
    "# Split the tokens into chunks\n",
    "chunks = [tokens[i:i + max_chunk_size] for i in range(0, len(tokens), max_chunk_size)]\n",
    "\n",
    "# For each chunk, add special tokens, convert to input IDs, feed to BERT, and get embeddings\n",
    "for chunk in chunks:\n",
    "    # Add special tokens\n",
    "    chunk = ['[CLS]'] + chunk + ['[SEP]']\n",
    "    # Convert to input IDs\n",
    "    inputs = tokenizer.convert_tokens_to_ids(chunk)\n",
    "    inputs = torch.tensor([inputs])  # Add batch dimension\n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    # The first element of outputs is the embeddings\n",
    "    embeddings = outputs[0]\n",
    "    print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from performance_tracking.classes.Performance_Row import Performance_Row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m row \u001b[39m=\u001b[39m Performance_Row(\n\u001b[1;32m      2\u001b[0m     \u001b[39m# id what is being tracked\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39mmeasurement_settings\u001b[39m.\u001b[39mdataset_name,\n\u001b[1;32m      4\u001b[0m     embedding_seperated\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeasurement_settings\u001b[39m.\u001b[39membedding_seperated,\n\u001b[1;32m      5\u001b[0m     embedding_model_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeasurement_settings\u001b[39m.\u001b[39membedding_model_name,\n\u001b[1;32m      6\u001b[0m     sentence_embedding_method \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeasurement_settings\u001b[39m.\u001b[39msentence_embedding_method,\n\u001b[1;32m      7\u001b[0m     feature_engenearing_method \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeasurement_settings\u001b[39m.\u001b[39mfeature_engenearing_method,\n\u001b[1;32m      8\u001b[0m     grading_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeasurement_settings\u001b[39m.\u001b[39mgrading_model,\n\u001b[1;32m      9\u001b[0m     seed_data_split \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeasurement_settings\u001b[39m.\u001b[39mseed_data_split,\n\u001b[1;32m     10\u001b[0m     shots\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshots,\n\u001b[1;32m     11\u001b[0m     epochs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs,\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m     dataset_split\u001b[39m=\u001b[39mdataset_split,\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m     \u001b[39m# duplicates handeling\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     settings_performance_tracking\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeasurement_settings\u001b[39m.\u001b[39msettings_performance_tracking\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "row = Performance_Row(\n",
    "    # id what is being tracked\n",
    "    dataset_name=\"test\",\n",
    "    embedding_seperated=self.measurement_settings.embedding_seperated,\n",
    "    embedding_model_name = self.measurement_settings.embedding_model_name,\n",
    "    sentence_embedding_method = self.measurement_settings.sentence_embedding_method,\n",
    "    feature_engenearing_method = self.measurement_settings.feature_engenearing_method,\n",
    "    grading_model = self.measurement_settings.grading_model,\n",
    "    seed_data_split = self.measurement_settings.seed_data_split,\n",
    "    shots=self.shots,\n",
    "    epochs=self.epochs,\n",
    "\n",
    "    dataset_split=dataset_split,\n",
    "\n",
    "    # duplicates handeling\n",
    "    settings_performance_tracking=self.measurement_settings.settings_performance_tracking\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
