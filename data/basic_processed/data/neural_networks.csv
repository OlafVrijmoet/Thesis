row_id,question,question_id,student_answer,reference_answer,assigned_points,max_points,domain,dataset_name,normalized_points
0," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a massively parallel distributed processor with simple processing units that has the natural propensity to store experiential knowledge and make use of them an artificial neural network is similar to the human brain in two ways 1. the ann works by the process of learning from its environment 2. interferon connections called synaptic weights are used to store the knowledge gained,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
1," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network consists of . largely parallel distributed processor . simple processing units . that has ability to store the experiential knowledge and making it available to use it resembles to human brain in two ways . knowledge is acquired from the environment by the network as learning process . synaptic strengths called weights are used to store the knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
2," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a massive distributed processor it consists of several information processing units which are able to acquire and store knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1,2.0,neural_networks,neural_course,0.5
3," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an ann is a layered graphical model containing neurons and weighted connections resembling the excitatory properties of the human brain weights of the ann are changed after presenting it training examples from an environment where weights are changed based on the training procedure used artificial neurons also are biased just like real ones adding a constant level of activation before being activated by a nonlinear activation function depending on the training procedure both weights topology or even activation functions may be learned,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
4," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural networks are large parallel processing units that have the natural ability to learn experiential knowledge they are composed of interconnected neurons as basic units which in turn consists of weights squashing functions and adder functions ann resembles brain in the manner that like in human brain it is composed of a network of neurons which help in learning by adjusting the synaptic weights of the connections between neurons this enables it to learn experiential knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
5," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network consists of neurons each neuron can have several weighted inputs an activation function and output usually several neurons are connected together often in layers the network then calculates the output given an input to the network the human brain works in a similar way it also consists of neurons that are connected in several ways,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1,2.0,neural_networks,neural_course,0.5
6," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an ann is a - massively parallel distributed processor - made up of simple processing units - which have the capability of storing experimental knowledge - and is made up for used an ann resembles the brain because i it gets its knowledge through a learning process from its environment i it stores its knowledge in its interferon connections synaptic weights,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
7," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,a ann is a massively distributed processor it has the propensity to store experimental knowledge and make it available for used the knowledge is gained throug a process of learning the knowledge is stored in the weights between the neurons this structure resembles the structure of the brain neurons are a the basic information unit in the ann and act similar to real neurons,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
8," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is defined as a learning machine which is divided by layers and each layer is composed by neurons the neurons from different layers can be connected between each other and give an output or multiple outputs by a given input this structure is very similar with the neurological structure of our brain where neurons are interconnected by synapses also important to mention if a feature is really important for a given task this wil have more connections and neurons participating like in the human brain the important human functions have more synapses,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
9," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a graph of small and identical processing units that these small units called neurons and they are connected to each other in different architecture and the whole network adapt and itself to the environment inputs by trying to decrease the error or the cost function and increase its preciseness by manipulating the free variables of the network which are the synaptic weights it is similar to human brain because similar to the human brain we have many small processing units that are connected together and they react to the environment and learn from the environment,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
10," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is highly parallel processing it has a mathematical model similar to human brain which it was inspired from as human brain does computation in an extremely parallel manner similarities also lay in terminology ann is using neurons that are smallest computing unit of a network similarly to human brain,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1,2.0,neural_networks,neural_course,0.5
11," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,it is a massive parallel distributed processor made up of smaller processing units that acquire knowledge through the environment through a learning process and makes it available for used it resembles the brain in two ways - knowledge is acquired through a stimulating process in the environment - the knowledge is embedded in the synaptic links weights of the neurons,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
12," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,ann is a learning machine which is composed of neurons as units of computation the ann learns via interacting with its environment the ann has built-in capacity to dynamically adapt upon input stimulus the ann is motivated from biological brain and resembles human brain in terms of its localized representation for the inputs in terms of motor cortex the sensory stimulus to different body-parts activates local part of the brain similar to ann local representation of similar type of input,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
13," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,a neural network is a massively parallel distributed processor made up for simple processing units that has a natural propensity for storing experiential knowledge and making it available for used it resembles the brain in two respects * knowledge is acquired by the network from its environment through the learning process * interferon connection strengths known as synaptic weights are used to stor the acquired knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
14," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is a massively parallel distributed processor which consists of one or more processing unit called neurons it resembles the human brain for that it acquires knowledge from the environment through learning process and that the acquired knowledge is stored in the synapses,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
15," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,definition 1. artificial neural networks are massively distributed parallel processor 2. it is made up of small units 3. which has the propensity for storing the experiential knowledge 4. and making it available for used it resembles the brain in 2 aspects 1. similar to the brain artificial neural network does the process of learning from the environment 2. it as a pair of inter neuron links known as the synaptic weights which is used for storing the information,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
16," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is massive parallel distributed processor it comprises of small processing units called neurons it learns from experiential knowledge which is then stored and can be used for making predictions it resembles human brain in 2 ways * it learns from experiential knowledge * knowledge is stored in synaptic interferon connections,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
17," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,here artificial neural network is a massively distributed parallel processor which is composed of simple processing units called neurons which have the natural propensity for storing experiential information and making it available for used it resembles the human brain in the following aspects - knowledge is acquired by the network from its environment through a learning process - synaptic links are used to store the acquired knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
18," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,ann is a learning machine which can perform complex parallel computation it has the ability to learn through the interactions withthe environment and store the learned knowledge it resembles the human brain in performing complex learning tasks acquiring information adapting to the environment and exploiting the acquired information,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
19," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a massively distributed parallel processor made up of simple processing units that have the natural propensity for storing experimental knowledge and making it available for future used it resembles the brain in the following ways 1. artificial neural networks have the ability to acquire knowledge from the environment in which they are are embedded 2. inter-neuron connection strengths called synaptic links activate each neuron during the learning process,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
20," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a massively parallel distributed processor which interacts with its surrounding environment with a propensity to store knowledge and make it available to used it resembles the brain in two aspects 1. it has the ability to learn from its environment 2. the knowledge is stored in synaptic weights,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
21," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is massively distributed parallel processor containing simple processing units and has natural propensity to store experiential knowledge and use tit resembles the human brain in two aspects it gains knowledge from the environment and adapts the synaptic weight to store the knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
22," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,it is a massively parallel distributed processor consisting of simple processing units which can store experiential knowledge and make it available for used it resembles the human brain in 2 ways 1. knowledge is acquired from environment through a learning process 2. interferon connections are used to store the experiential knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
23," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is a massively parallel distributed processor that is made up of simple processing units called neurons it can replicate human brain by storing information in their weights,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1,2.0,neural_networks,neural_course,0.5
24," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is a massively parallel distributed processor with synaptic links that can able to store experimental knowledge and make it available for used it resembles human brain in two ways * knowledge is acquired by the neural network from its environment through learning process * interferon connection called synaptic links stores the acquired knowledge,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
25," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network are the network of the units that learn data from the environment and store them using synaptic weights the structure of the artificial neural network is similar to human brain it has neurons ieft the store units and the atoms called synapses which link the stored data,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1,2.0,neural_networks,neural_course,0.5
26," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is massive parallel processor made up of simple processing units called neurons they are capable of storing experiential knowledge and make it available for later used similarity to human brain 1. they learn from the environment 2. they store knowledge as synaptic weight in the interferon connection,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
27," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a highly distributed processor which consists of several simple processing units it resembles the human brain because the processing units are neurons which are connected with weights the human brain also consists of neurons,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1,2.0,neural_networks,neural_course,0.5
28," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,a massively distributed processor consisting of single processing units that have a natural propensity of storing experimental knowledge and making it available for used,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1,2.0,neural_networks,neural_course,0.5
29," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"an artificial neural network consists of neurons which are small computation devices,and synapses the connections between the neurons this resembles the brain because it also has neurons and synapses also a artificial neural network has weights which are used to store learned features from the environment like the brain a neural network learns from the environment an artificial neural network also has an activation function which creates the output",a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
30," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a highly parallel computation model with learning and memory capacities similar to the brain it learns from the environment by strengthening the synapses between neurons once a task is learned it can be quickly used by reactivating those learned synapses,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1,2.0,neural_networks,neural_course,0.5
31," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a highly parallel working machine which consists of simple processing units neurons with are connected to each other in layers they are function approximates the brain is resembled in the architecture the processing units and the weights and how the learning process takes place and the properties of the brain fault tolerance parallel computing ...,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1,2.0,neural_networks,neural_course,0.5
32," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an ann is a massively parallel distributed leaving machine made up of small computational units computational units are connected via synapses defined by a weight it resembles the human brain in two aspects,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1,2.0,neural_networks,neural_course,0.5
33," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is massively parallel distributed processor made up of simple computing units called neurons which acquires knowledge from environment through learning it resembles brainlike structure in two ways 1. it acquires knowledge through learning and experience 2. it stores knowledge in interferon connections called synapses,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
34," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,"ann is huge parallel distributed processor , consist of simple processing units and which has propensity of storing experiential knowledge and making it available for used",a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,1,2.0,neural_networks,neural_course,0.5
35," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,artificial neural network is a massively parallel distributed processor made up of simple processing units which has a natural propensity to acquire knowledge from the environment and make it available for future used it resembles the human brain in following ways 1. both of them acquire knowledge from the environment 2. the neurons are connected by synapses characterized by their weights which can be adjusted,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
36," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,an artificial neural network is a massively distributed parallel processor made of simple processing units it has natural propensity to store experiential knowledge and it makes the knowledge available for further used an artificial neural network uses inter neuron connections called synaptic weights to store the knowledge acquired knowledge which is very similar to how human brain works,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
37," Give a definition for the term ""artificial neural network"" and mention, how it resembles the human brain!",222,ann is a massively distributed processor consisting of simple processing units called neurons these neurons in terms of ann are similar to neurons in human brain both neurons are characterized by synapses(connection links they represent connections used for data flow between neurons in both ann and human brain the knowledge is represented by its very structure and activation state of neurons,a neural network is a massively parallel distributed processor which is made up of simple processing units it has a natural propensity for storing experiential knowledge neural networks resemble the brain in two aspects knowledge is acquired by the network from its environment through a learning process interferon connection strength known as synaptic weights are used to store the acquired knowledge,2,2.0,neural_networks,neural_course,1.0
38,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron is the simplest processing unit of a neural network which has 1. synaptic weights to store the knowledge gained 2. adder function linear combined which adds the weighted values of the input signals to produce the local field 3. an activation function which squashes the local field to a range of values $ \phi(\sum{i=0}^{n} wi dot xi $,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
39,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"mathematical model of a neuron is given as : y = $\phi(v)$ , where activation function is applied to local field(v) i = summation (w{i}x{i} + be . local field is weighted(w) sum of inputs(x) plus bias(b)","mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
40,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron is an information processing unit it consists of inputs associated with weights sum of inputs and an activation function,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",1,2.0,neural_networks,neural_course,0.5
41,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,input vector ex weight matrix we net input $net=\sum x^tw$ net output $o=\phi(net)$,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",1,2.0,neural_networks,neural_course,0.5
42,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron consists of three basic components - synaptic weights the synaptic weights are connections between neurons and are adjusted through training - *squashing/activation functions the squashing functions may be non linear or linear functions that that are applied to the signals from the neurons - ladder functions the adder functions help in combining outputs from several neurons,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
43,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,and number inputs exit input i $vj$ local field $\varphi(vj)$ activation function $yj$ output $w{ji}$ weight from node i to i my = \varphi(vj)$ ve = \sum{i=0}^{n}w{ji}xi$,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
44,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"a neuron is a simple processing unit of an anna that is made up of - the synaptic links which are defines by a weights $(w1,...,wn)$ - a adder function that combines the weighted input $(wi*xi)$ plus some bias $(b)$ to the local field $(\sum{wi*wi}) +b=v$ - a activation function phi that squashes the local field to the output $(phi(v)=y)$","mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
45,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,the neuron consists of synapses/connecting link each characterised by a weight a linear combined sums up the weighted sum of inputs to a local field the local field is then passed through an activation function the result of the activation function is the output,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
46,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"a neuron is defined by the following elements - a number of input values i - a number of weights i - a bias i - an activation function $/phi$. the inputs i are multiplied with the weights and the result is summed with the bias also the bias can be used just as a weight value i and a single connection with an stable input equal to i for mathematical simplicity the resulting value known as local field (v), will be the input to the activation function the mathematical model can be summarized in the formula iv = \sum^{n}{i = i x(i)*w(i) + be my = \phi(v)$","mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
47,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron consists of a set of inputs and a bias which these inputs and redefined bias will be multiplied by a weight and then we have sum the results of all the inputs and bias multiplied by the weights which called induced field and after that we send this to an activation function which can be a linear or nonlinear function and the output of this function is the final output of our neurons,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
48,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"neuron is a simplest computation unit of a neural network that consists of input variables weights bias summation term (combiner), activation function and output variables","mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",1,2.0,neural_networks,neural_course,0.5
49,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"the neuron is the basic processing unit of a neural network and is made of three main component - weights $w1, we ...,wn$ - adder function it is the linear combination of the input and weights plus bias induced local field iv = sum wi xi + be - squashing function it is the activation function applied to the local field used to limit the output of the neurons $\phi(v)$","mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
50,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron is a computational unit composed of + synapses which are stored in the form of weights $w$. these are the variables that can are dynamical. + summing function that computes the weighted sum of inputs iv = sum (wixi)$ + activation function $\phi$: gives nonlinear nature to network determines and normalize the output produced by neurons edge sigmoid function + bias another synaptic unable variable with input 1. therefore the net output of neurons $ y = sum (wixi) +b$.,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
51,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,the following equations describe a nonlinear model of a neurons labeled ke fuk = sum from job to i w{kj} x{j} 2)yk = phi(u{k} + b{k}) where x{j} are the input signals w{kj} are the weights of the neurons uk is the linear combined output due to the input signals bike is the bias phil is the activation function and ya is the output signal of te neurons,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
52,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron is a processing unit that contains three main components a set of synaptic weights that connect the neuron with other neurons an adder that computes the induced local field or the weighted sum of the signals flowing through the neurons an activation function that constrains the magnitude of the output signal from the neurons,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
53,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"a mathematical model of a neurons consists of a 1. a set of synaptic links which are classified based on weights(w1, we w3...wn) 2. it consists of a adder function which performs the weighted sum of the inputs and the bias $\sigma{i=1....n} wax + be 3. it consists of an activation function used to minimize the amplitude of the neuron output $\phi(\sigma{i=1....n} wax + be","mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
54,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a mathematical model of neuron comprises of 2 main units * adder functions it sums up all the product of all synaptic connections and inputs of neuron * synaptic weights these are interferon connections in which the knowledge is stored * activation function it is used for introducing non-linearity,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
55,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,here the neuronal model consists of the following - synaptic links characterized by their weights which connects the network to the environment it is embedded in - an adder function which sums up the weighted inputs and outputs the induced local field of the neurons - an activation function which takes the induced local field of the neuron as it's input and limits the output of the neurons,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
56,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a mathematical model of neuron consists of 3 important parts a neuron is the smallest computational node with i input vectors : set of vectors of a certain dimension to train the model i weights and biases each of the input vectors are weighted using weight vectors in accordance withthe output that is required bias is added when necessary i activation function : the linear combination of weights and inputs are passed through the activation function which produces an output,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
57,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,the neuron is the fundamental processing unit of an artificial neural network that is characterised by the following features 1. a neuron has a set of nonlinear synaptic links an externally applied bias and possibly one or more linear activation links the bias is represented by a synaptic link from an input fixed at +1. 2. the synaptic links of the neuron weight the respective inputs 3. an adder function linear combined computes the weighted sum of the inputs to the neurons 4. an activation function squashing function limits the amplitude of the neurons output,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
58,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"let $x1$, $x2$, ... , $xn$ be the inputs to the neurons win be the corresponding weights of connections be be the bias and $\varphi(.)$ be the activation function then the induced field ve is given by - rev = \sum{i = 1}^{n} wi xi + be the output my is given by - my = \varphi(v)$$","mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
59,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,the mathematical model of neuron has three parts - a set of synapses or connecting links characterized by weight ow . - an adder function that calculates the weighted sum of inputs plus some bias - an activation function squashing function to minimize the amplitude,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
60,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"ask = \sum{j=1}^{m} w{kj} xu + bk$, my = \phi(vk)$, $w{kj}$ is the synaptic weight connecting neuron i and input data je $xj$ is input data $bk$ is bias $vk$ is induced local field dyke is output of neurons","mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
61,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"a neuron consists of a synapse connecting link an adder function or linear combined and an activation function rev = sigma wi dot xi + b$$, where exit is the input win is the weight and be is bias","mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",1,2.0,neural_networks,neural_course,0.5
62,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron is a basic information processing unit that have a adder function to compute weighted sum of inputs plus bias and apply activation function on the results i \phi(v) = \sum\limits{i=1}^n \omega(i)x(i) + bias i,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
63,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,each neuron has a set of inputs and their respective weights the local field is iv = \sum(w{ij} * xiao the local field is passed through a activation function so the output of the neuron is my = \phi(v)$ my = \phi(\sum(w{ij} * xi))$,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
64,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,the neurons are the basic processing units in neural network output of the neuron = $ phi sum wait x{i})$ they consist of three parts synaptic weight the connections between the neurons characterised by weights adder function calculates the weighted sum of the inputs of the neuron activation function limits the amplitude of the output of the neurons ($\phi$),"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
65,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,the model of a neuron consists of synaptic weights which are applied to the input signals the weighted inputs are then summed which gives the local field this local field is put into an activation function whose output will be the output of the neurons,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
66,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"my = \sum{i=0} \phi(w*xi)$ a neuron consists of inputs $x$, synaptic weights $w$, an extra input $w0$ which is fixed to 1 for the bias an adder function that creates the local field ve and a squashing function $\phi$.","mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
67,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"my = sum few + b)$, where i are the weights which change the input according to the learned weights i is the input from the environment i is the bias which shifts the learned decision plane and for is the activation function which limits the output to a desired region of values","mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
68,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron consists of one or multiple inputs which are gathered by a summation function the hereby induced local field of the neuron is processed by a squashing function and generates the output of the neurons,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",1,2.0,neural_networks,neural_course,0.5
69,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron consist of input connection links with a synaptic weight a bias an adder which adds the input signals and the bias and produces the local field the local field is processed by the activation function and produces the output of the neurons,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
70,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron consists of input nodes xu to in and weights we to and a linear combined ve sum $ xi * wi i + be where i is some bias the result i is called local field and is used as input for an activation function $ phi(v) $,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
71,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,neuron is consists of three units 1. synaptic links characterize by weights which nearly ways the input 2. adder which adds weighted inputs to generate local field 3. activation function which is nonlinear function smashing the output of the neuron,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
72,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,i neuron is consist of synaptic links which measured in terms of weights neuron is given with inputs it has adder function or combined which adds all the inputs multiplied by the weights and bias is extra input to the neuron as well i it has a activation link which limit the amplitude of the output of the neurons,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",1,2.0,neural_networks,neural_course,0.5
73,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"neuron is the basic information processing unit which is the main component of a neural network a neuron is characterized by its input ($xi$), synaptic weight ($wi$) and activation function $\phi(v)$. mathematically it can be modelled as $\phi(wixi)$. activation function bounds the input to a certain level","mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
74,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,a neuron has three components * synaptic weight i * adder function it multiplies input i with the weight * activation function it squashes the output of the adder function sigmoid hyperbolic tangent rectified linear unit etc,"mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
75,"Define the mathematical model of a neuron, use the appropriate technical terms!",223,"a neuron consist of set of inputs that takes data from environment each neuron contains synapses(connection links that are characterized by weights all inputs are connected to the summing ladder function that computes weighted sum of all input values this weighted sum is called local field of neurons the value of this local field ve is limited(squased) by an activation function $\theta(v)$. the result from this squashing function is output of a neuron my = \theta(v)$). additionally a bias term $(b)$ is added to the input and its value is always i but its associated weight is being changed over training period finally output of neuron is my = \theta(v)$, where iv = sum we * xu + be","mathematical model of a neuron consists of a set of synapses or connecting links where each link is characterized by a weight an adder function linear combiner), which computes the weighted sum local field of the inputs plus some bias and an activation function squashing function for limiting the amplitude of a neurons output",2,2.0,neural_networks,neural_course,1.0
76,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"1. label one class a positive with label +1 and the other class as negative with -1. 2. augment the data with an additional value for the bias terms 3. invert the sign of the data in the negative class 4. randomly initialize weights 5. if wet dot i i 0$, update weight by $ w(n+1) = want + beta xena i else leave the weight unchanged 6. continue step 5. 7. terminate when there is no longer a change in any weight","label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
77,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,1. initialization time step or iteration = 1 and weights are small but randomly initialized 2. activation of perception apply training pattern to activate the perception 3. compute output apply activation function to the local field(weighted sum of inputs plus bias 4. adjust weights adjust weight if current output(y) i desired output(d) 5. continuation we continue by increasing i during each iteration and repeat from step 2 until all input pattern are applied to network and also error is minimized,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
78,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,here y denotes the actual results i denotes the desired result positive train error y = i do $w{new} = wold + i $ negative train error y = i i = 0 $w{new} = wold - xu,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",1,2.0,neural_networks,neural_course,0.5
79,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"initialize weights with zero or small values sample data point feed into network compute net output use the step activation function compute error $e=(d-o)$, where i is the true label o is the predicted label correct weights based on $w(t+1)=w(t)+\alpha(d-o)x$, where alpha is the training rate and i is the input pattern repeat for each pattern until convergence is reached","label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
80,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,for this case the parameters that need to be learned are the slope of the line and the intercept these are the parameters for the weight vector 1. initialize random small values for weight vector 2. for inputdata exit in training data - apply the input to the weight vector - e = the difference between the local field and the desired output $(di-yi)$ - update weight w(n+1) = want + beta e xi,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",1,2.0,neural_networks,neural_course,0.5
81,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"$\varphi(v) = \tanh(v)$, single node network $\mu$ learning rate repeat as long as error is too high 1. present sample to network and collect output 2. compare actual output with desired output (d). 3. if not equal adapt weights win + i = win + \mu(d-y)xi$","label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
82,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"given sky date points $(xi,yi)$ and $yi\in\{1,-1\}$ given a learning rate for each point i add a bias 1 so that point i i (1,xi,yi) ; for each point i there yi i -1 point = -1 * point we nullvector; i = i convergence = false while(convergence i false convergence = true for each point i in the training set if(w*x<=0) do i = w+learningrate*pointi; convergence = false","label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
83,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"weights # a weight vector phi = activation function eta = learning rate for each datapoint (xi,yi) do weights[i] = weights[i] + eta * (xi[i]-yi)*weights[i]","label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",1,2.0,neural_networks,neural_course,0.5
84,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,i we i = initweightsbias() i the weights can be initialized to 0 or random initialized i i = 0 i while !stopcriteria() do i iteration until stop criteria is fulfilled i y = want * xena + i i calculate output i if i is in can e = 1 i if the i belongs to class can error i i otherwise is -1 i else if i is in can e = -1 i i = i + e * i i update weights using the calculated error i i = i + 1 i end the stop criteria can be if the number of misclassified input data is i then stop,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
85,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,the learning process consists of three main steps i positive error - calculate the error of all the data sets in the learning set - change the w(weight): w(n+1) = w(n)+positive error - separate the data points based on the new i i negative error - calculate the error of all the data sets in the learning set - change the w(weight): w(n+1) = w(n)+negative error - separate the data points based on the new i i no error - when we have no error this is the end of the training,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",1,2.0,neural_networks,neural_course,0.5
86,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,define a bias in order to be able to trigger to which class data points will be classified to assign initial randomly chosen weights use a squashing function for example mccullon pits start training process and stop when error of output and desired output has reached desired percentage,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",0,2.0,neural_networks,neural_course,0.0
87,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,initialize the weight vector $\hat{w} = i - do - for every training sample and iv = sum wi xi + be my = \phi(v)$ if i is not equal to y then we = i - ya ow = i + beta evil xi - until convergence,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
88,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,pseudo code + initiate weights and bias randomly + compute output for the given input data $ ya = sum (wixi) +b$. + compute error between computed y's and desired output $y$. + update weights $w(n+1) = want + beta (y-y') xu + stop when the error is below some specified threshold or becomes zero in case of data that is perfectly nearly separable.,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
89,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",0,2.0,neural_networks,neural_course,0.0
90,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"initialize the perception with each weight equal to i $w(0) = 0$. present the labeled examples $(xi, did to the perception > for each example $(xi, did i compute actual output yi and error signal i update weight based on the delta rule $w(n+1) = want + beta (d(n) - y(n)) x(n)$","label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",1,2.0,neural_networks,neural_course,0.5
91,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,we use threshold function as activation function if wax + i i 1 label class 1. else label class 0.,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",0,2.0,neural_networks,neural_course,0.0
92,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,end = current error bra es = convergence criteria bra i = learning rate bra while change in end not less then else {<br> calculate error end bra w(n+1) = want + i end xena widow hoffman rule bra },"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
93,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,here perception learning algorithm - initialize the network by assigning random weights to the synaptic links - calculate error as the difference of the desired output with the actual output - if the input is misclassified with positive error $w(new)$ = $w(current) + input - if the input is misclassified with negative error $w(new)$ = $w(current) - input - if the input is correctly classified no changes are made in the weights - repeat from step 2 as long as the error is under some defined threshold value,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
94,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"the linear binary classifiable data consists of input vector ex which when multiple with weights and added bias fall into class or class depending on the linear combination output of we + be being above 0(+) or below class -). algo parameters : x,y(desired output we i i weight vector i is initialized with small random values i input vector is chosen with a probability and output is computed using we + be . if the class y of vector i is + and output is $<0$, or if the class of i is - and output if >0, then the weights are updated accordingly otherwise weights are left unchanged i treated over other input vectors until convergence of output","label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
95,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"1. initialization : at time step n(0), initialize weight vectors with random values $wj(0)$ 2. activation : apply the input example $(xi(n),di(n))$ to activate the perception with heavyside step function as the activation function 3. if output of the perception $y(n) one done i adjust the weight vector using the rule : $w(n+1) = want + beta x(n)(d(n) - y(n))$ 4. go to activation and repeat until no more change in weight vector is observed","label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
96,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"1. inputs xu $x1$, $x2$, ... , $xn$ 2. desired outputs ya $y1$, $y2$, ... , sync 3. initialize weight vector we to random small values 4. for each data point $xn$ in xu calculate $\hat{y}n$ from we and $xn$ calculate error men = yn - \hat{y}n$ update we according to delta rule end","label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
97,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",0,2.0,neural_networks,neural_course,0.0
98,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,apply input data to input layer and initialize small values weights minimize error according to difference between desired signal and output signal assign the test vector the class that has smallest error,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
99,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,1. compute the initial weights for all input vector 2. apply matrix multiplication from input to weight vector 3. apply linear combined 4. apply activation function to produce the output 5. compute the error 6. update weights,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",0,2.0,neural_networks,neural_course,0.0
100,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,* randomly assign values to initial weights * run the perception network and calculate the error we = yada where e is error y is output and i is desired response * update the weights based on the error * if error is positive add the error with the input and update weight * if error is negative subtract the error with the input and update weight * if there is no error don't update the weights * repeat the above process until the calculated error is approximately equal to zero,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
101,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",0,2.0,neural_networks,neural_course,0.0
102,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,i = random number between -1 and i for every data in training set { in the first layer calculate the weighted sum using adder function calculate the output of the activation function in the output layer calculate the output y calculate the error e = i - y ; do desired output change the weights using the formula $ delta i = beta xu end } continue till the error converges,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
103,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,initialize as many random weights as the dimension of the data points for each data point if the output matches the desired output do nothing else change the weights in the direction of the datapoint so that the datapoint is classified correctly end if end for if some weight was changed start again with the for loop end if,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
104,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,1. initialize the weights at random or as 0. 2. activate the perception by giving an example 3. compute the actual output of the neurons 4. adjust the parameters of there perception 5. continue until convergence is achieved i = rand y = sum($\phi$(w*x)) for wi in we wi = wi+$\eta$*e*y,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",1,2.0,neural_networks,neural_course,0.5
105,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,"initialize the weights randomly my = sum few + b)$, compute the output of the perception using the input xu the weight we the bias i and the activation function f(). we = i - you calculate the error by subtracting the actual output from the desired output $w{new} = wold + learning\rate dot i dot end update the weights with this formula the learning rate is a parameter which changes how fast the perception learns","label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
106,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,for i iterations for each datapoint i error = desired - output if error > 0 weights = weights - error if error < 0 weights = weights + error,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
107,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,pick random decision boundary while one of data points is in wrong class turn decision boundary by using vector of wrong data point negative rule or positive,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",1,2.0,neural_networks,neural_course,0.5
108,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,trainings i set of labeled linear venerable data points i i weight vector with dimension of input data i i local field phi(v): activationfunction threshold function you output e i error my - do where i is the desired output from labeled training data i i learning rate (0.1) assign random values for i for i in trainingset: i = sum(xi * win y = phi(v) e = y - i i = i + n*x*e i delta rule end,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
109,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,initialize weights i and bias i set learning rate i set errorthreshold upper bound on error while error < errorthreshold : for every datapoint i in training dataset : y = we be . ex i bias is represented as weight of fixed input i if y is positive then i belongs to ca otherwise to ca store above predicted class find error in predicted output with respect to the labels store error e sum = sum of all errors e for every data point i = i + i * sum,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
110,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,for a binary classifier we can use threshold activation function i randomly initialize the weights i you calculate the output of the neuron i find out the error by subtracting expected output and current output i modify the weights related to that input with respect to the error repeat the process 2-4 till the you get minimal error,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
111,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",0,2.0,neural_networks,neural_course,0.0
112,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,continueprocess = true i = randomlyinitialize() while continueprocess for i in list of points y = wax diff = day i i is the desired output if(diff i i i = i + i else i = i - i if all points are classified without error continueprocess = false,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
113,"Assume you want to binary classify linear separable data point using a perceptron. Write down the learning algorithm in pseudo code!
",224,not leaving rate repeat until the me is small enough t=t+1 for each point in training set do compute local field of percepron: i = wax apply linear activation function my = \theta(v) = ve compute current error e = (d-y) apply delta rule w(t+1) = with + nex end,"label the data with positive and negative (+/-) labels initialize the weights randomly apply simplified update rule do = eta*x(n) if <w,x> i i repeat on all epoch till the weights don't change much the algorithm will converge as the data is nearly separable.",2,2.0,neural_networks,neural_course,1.0
114,Explain classification and regression; what is the difference?,225,classification in classification the output produced by the in is a discrete value which indicates which class the input belongs to regression in regression the output produced by the in is a continuous variable this could be used for instance to approximate a continuous function,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
115,Explain classification and regression; what is the difference?,225,in classification output values are always discrete in regression output values are continuous,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
116,Explain classification and regression; what is the difference?,225,"a hydroplane is given by y = wax + i . regression wants to determine i classification wants to assign a class to a set of observations regression wants to determine separating hyerplane, classification wants to label data points with a class",classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
117,Explain classification and regression; what is the difference?,225,"in classification tasks we assign discrete labels to data points of our training dataset, either being assigned a specific label or not (binary). for supervised learning these datapoints are labeled with a label vector ground truth in regression we try to model a function which fits the data points of the training data and thus model a function with continuous values",classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
118,Explain classification and regression; what is the difference?,225,classification - it refers to classifying given data into discrete classes - the output is discrete values - use for activity like pattern recognition etc regression - it refers to estimating the value of some continuous function given an input - the output is continuous value - used for activities like motor control etc,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
119,Explain classification and regression; what is the difference?,225,in classification we try to assign classes to input data regression we want the network to behave like a given system/formala. this can also be a time series of input and output data,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
120,Explain classification and regression; what is the difference?,225,in classification the goal is to separates points into different classes the outcome is a class able regression try to fit a hyperplante to a point cloud best so that future data is represented by that hyperplane best (lms). it try to minimize the distance to all data points the outcome is a countinius variable,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
121,Explain classification and regression; what is the difference?,225,both are learning tasks of a anna in classification the goal is to assign a class label to new datapoints. in regression the goal is to estimate a unknown function the only difference between both is that classification uses discrete class labels while in regression a continuous output is used,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
122,Explain classification and regression; what is the difference?,225,the approach of classification is to classify sets of input data into their correct classes for example used in pattern recognition the approach of regression is to approximate to a defined function i by calculating the error between this function and the result of an algorithm the difference is that the classification approach is applied to a discreet data the samples are the different points of the input space and regression is an analogy approach where the whole function must be approximate for any input given,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
123,Explain classification and regression; what is the difference?,225,- classification in classification problems we have different groups of data that have some common properties and after training we want that our model can detect the class of the new sample correctly - regression in regression we have a series of values and we want to use the previous values in this series and predict the next value,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
124,Explain classification and regression; what is the difference?,225,classification is a problem of distinguishing to which discrete classes input variables are to be assigned to regression is estimation of the output by figuring out the continuous trend of the whole dataset.,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
125,Explain classification and regression; what is the difference?,225,classification if to assign a class or category to the data while regression is when you fit the data to a function,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
126,Explain classification and regression; what is the difference?,225,+ regression learns model/function that can predict other unseen data well target/output is real spaced + classification learns a model that classifies/maps input to a discrete target label targetlabel/output is binary/discrete.,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
127,Explain classification and regression; what is the difference?,225,classification describes the application in which a sample is assigned to one specific pattern of the problem in comparison to regression is the output deterministic an not continuously in regression the output is continuous describing,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
128,Explain classification and regression; what is the difference?,225,classification is the task of classifying the input signals into a finite number of groups so the output is a number that indicates a certain class regression is the task of approximating a function by estimating the values given the input signals so the output can be any real number,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
129,Explain classification and regression; what is the difference?,225,classification we need to predict the output data discretely that is the output space is a discrete space regression we need to predict the output data continuously that is the output space is continuous space the main difference is the discreteness and contionousness.,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
130,Explain classification and regression; what is the difference?,225,classification is a problem of assigning a particular class to each data point in a given dataset. bra regression is a problem of fitting the given dataset on a particular hyperplane which can be used for representing the given data it finds the hyperplane which minimise the mean square error,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
131,Explain classification and regression; what is the difference?,225,here - classification is a problem of assigning labels or classes to the input the output is a discrete variable - regression is a problem of assigning a continuous variable to the input,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
132,Explain classification and regression; what is the difference?,225,classification is a problem of catergorization into discrete classes where as regression is a problem in a continuous space where the goal is to ether minimize or maximize a cost function classification is the process of dividing a set of discrete inputs into classes corresponding to similar patterns such as clustering regression could be finding a pattern of the distribution of the data such as fitting a line,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
133,Explain classification and regression; what is the difference?,225,"classification in machine learning is used to find a decision surface in the form of a hyperplane that can separate a set of input examples for set of patterns into their respective classes regression on the other hand is used to find the parameters (i.e, the weight vector we and the bias be for the function thatwas best fit the given data points $\{xi,di\}$ . thus classification deals with predicting the class label for discrete data points whereas regression deals with fitting a continuous real valued function",classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
134,Explain classification and regression; what is the difference?,225,classification is separating the data into classes and the output is a discontinuous variable regression is fitting a model and the output is a continuous variable,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
135,Explain classification and regression; what is the difference?,225,classification is about classifying the given data into different classes where as regression is about finding the local/global minima.we use perceptions to classify the data and we use constrained optimization techniques like newton's method to find regression,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
136,Explain classification and regression; what is the difference?,225,classification assign a test data to a class that is prescribed regression approximating an unknown function with minimization errors for input-output mapping,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
137,Explain classification and regression; what is the difference?,225,classification in classification the output variable takes class labels or identifying group membership<br> regression in regression the output variable takes continuous values or predicting a response,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
138,Explain classification and regression; what is the difference?,225,classification problem is used to classify set of data points into specific groups regression is used to predict time series data classification works on discrete set of values and regression works on continuous values,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
139,Explain classification and regression; what is the difference?,225,classification classification is done between the classes the machine determines to what class the data belongs to regression regression is a expecting output for an input the machine learns from the given data and models a function and when new input is given it expects the output difference classification is discrete output where as regression is a continuous output,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
140,Explain classification and regression; what is the difference?,225,regression tries to fit a line are curve among the given points the have continuous output the output is a function classification tries to classify the given points into two or more classes they have a discrete output the output is a value representing the class,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
141,Explain classification and regression; what is the difference?,225,classification each datapoint is assigned with a class regression each datapoint is assigned with a value in classification we assign classes or labels to datapoints. the error signal here can be only true or false in regression we try to learn a function the error for each prediction can be a number,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,2,2.0,neural_networks,neural_course,1.0
142,Explain classification and regression; what is the difference?,225,in classification a binary pattern has to be partitioned into the two classes in regression a line has to be fitted closest to some datapoints. the difference is that in classification the output is a single class label while in regression the output is continuous,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
143,Explain classification and regression; what is the difference?,225,in classification the input data is split in 2 or more classes the goal of the neural network is to learn the input data and then be able to classify new input data into the classes based on the learned information the network then maps input data into one of the classes which is discrete space in regression the input data is learned swell but here the network tries to predict feature values which are in continuous space the network tries to predict close as possible to new input data only using the learned model,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
144,Explain classification and regression; what is the difference?,225,classification tries to label discrete data points with distinct classes while regression tries to approximate a continuous function from discrete data points results of these methods are respectively a labeled data set or a continuous function,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
145,Explain classification and regression; what is the difference?,225,in classification the task is to give an discrete output value to an input it assigned one of all defined classes to the current input regression try to approximate a function while minimizing error and produces a continuous output value,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
146,Explain classification and regression; what is the difference?,225,classification means mapping input data a class label for example 1 and -1. in regression on the other hand a continuous function is learned in way that fix - fix is minimized where fix is the function learned by a learning machine and fix is the original function,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
147,Explain classification and regression; what is the difference?,225,"classification is supervised learning where underlying function representing the training data is learn from training data to predict classes of datapoints or patterns drawn from similar distribution as of training data weights of the neural network are learned to minimize the error in classification regression is supervised learning algorithm where underlying function representing the training data is learn from training data to predict the value of label or output of some system for new datapoint or pattern of similar type weights of the neural network are learned to minimize the error in prediction of function differences : 1. output of classification is discrete ( class 1,2,3 ) whereas output of regression is continuous 2. error in classification is number of wrong classifications whereas error in classification regression is distance between able value and predicted value",classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,2,2.0,neural_networks,neural_course,1.0
148,Explain classification and regression; what is the difference?,225,"classification is type of problem where algorithm needs to separate the one data class from the another data class if there is 2 classes ca , ca . algorithm classify the given data into these two classes it is discreet process regression is the predicting the next point depending on the previous points it is continuous process",classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
149,Explain classification and regression; what is the difference?,225,classification is the problem where the input data has to be put in two or more classes distinctively different from each other for example in case of binary classification on class can be -1 and the other +1 regression on the other hand is data fitting the main aim is to find a hyperplane which can fit a given input pattern,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
150,Explain classification and regression; what is the difference?,225,classification is a task to partition the given input into one of several classes the classes are discrete values regression regression is the tasks of predicting output in a continuous range the prediction can be any value within a range,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
151,Explain classification and regression; what is the difference?,225,in classification task the aim to separate data in different classes such that output of in gives value of class index for each input point egg in the task is to classify binary data then the output of the in will 0 or i and each value represent on class in case of regression task the aim is to fit data namely a function that perform input-ouput mapping output of in in this case will be error value such that we know how close is out function fitted to data points,classification is a task of mapping data to discrete labels while regression is a task which maps data to a continuous function or real values error in classification is the number of misclassifications while in regression is the summed distance between the true and predicted values,1,2.0,neural_networks,neural_course,0.5
152,Write down the SOM learning in pseudo code.,226,1. arrange the weights in the required topology according to the problem 2. initialize the weights randomly such that all the weights are different 3. sample the input from the input space 4. similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons 5. update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and reduce the learning rate and make sure learning rate is above zero 6. if ordering and convergence is complete stop else continue to step 3.,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
153,Write down the SOM learning in pseudo code.,226,i first we initialize random weights for neurons ii then we choose random input from input space iii we compute distance between input vector and each weight vector ivy neuron that have minimum euclidean distance with input vector is considered as winner neuron ve then we find the neighborhood neurons of the winning neuron via we adjust the weights of all neighborhood neurons viii reduce the learning parameter and neighborhood size viii continue until it converges,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,1,2.0,neural_networks,neural_course,0.5
154,Write down the SOM learning in pseudo code.,226,"i denote weights i denotes threshold i denotes the neighborhood function which decreases with distance i from winning neuron hex x{win} neighborhood function return (exp(-2/||x-x{win}||) i = rand(); initialize weights with random value while (w{delta} > the proceed until there are no noticeable changes x{win} = are min ||x-w||^{2}//determine i which is closest to i competitive leaving i update weights of winning neuron i weights of losing neurons are not updated w{new} = wold + x*h(x, x{win})*(x-w)//update weights of neuron which a are in neighborhood of winning neuron }",arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
155,Write down the SOM learning in pseudo code.,226,"initialize weights with small values such that all of the weight vectors are different sample a datapoint, feed into network determine the winning neuron on the lattice picking the neuron with the least euclidean distance of its weight vector to the input vector determine the neighbourhood of the winning neuron through the neighbourhood function change weights of the neurons namely spatially pulling the weight vectors of the neighbourhood neurons towards the input vector depending on the timestep, reduce learning rate and neighbourhood size based on wether we are in the organizing or finetuning step repeat until maximum number of steps",arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
156,Write down the SOM learning in pseudo code.,226,1. randomly initialize weights 2. randomly select an input from the training data 3. find the nearest neighbour of this input in the weights this is done by finding the euclidean distance of the input from each weight and selecting the weight with least distance 4. update the weights of all the neurons within the neighbourhood $h(n)$ which is gaussian function with an exponentially decaying $\sigma(n)$) of the winning neuron with some learning rate $\eta(n)$. $$\delta w{ij}=\eta(n)h(n)(||xi-xj||)$$ where $$\eta(n)= \eta0e^{-n/t1}$$ and $$\sigma(n)= \sigma0e^{-n/t1}$$,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
157,Write down the SOM learning in pseudo code.,226,in som we start with randomized weights $\mu$ learning create $d{ji}$ distance between i and i the neighbour function repeat as long as error is too high/max iterations are not reached 1. take input sample 2. find closest node/weight 3. find all it neighbours 4. move the weight and its neighbours closer to the given input use the neighbour function (e.g. gaussian to reduce effect to far distance neighbours 5. optional adapt learning rate and neighbour function,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
158,Write down the SOM learning in pseudo code.,226,given a neighbourhood function $h{ij}(n)$ and a learning rate over time randomly asking different weights from the input layer to the neurons in the second layer for each training point xi do - find the winner-takes-all neuron sky with min ||xi-wi||$ - find the neighbours of sky with the neighbourhood function - compute the new weights for those neurons using the neighbourhood function and the learning rate - update decrease the neighbourhood function and the learning rate end,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
159,Write down the SOM learning in pseudo code.,226,,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,0,2.0,neural_networks,neural_course,0.0
160,Write down the SOM learning in pseudo code.,226,"i i = initweights() i equal to zero or random initialized i i = 0 i while !stopcriteria() i winnerneuron, y = ex we i find on the map layer which neuron is closer to the input (euclidean distance i neighborhood = defineneighboor(winnerneuron, no i define the neighborhood size first iterations big and being reduced i eta = definelearningrate(n) i define the learning rate large value at the first iterations and being reduced i diff = adaptweights(neighborhood, eta i adapt the weights just for the winner neuron and its neighborhood i i = i + diff i update the weights i stopcritera = muststop(y, xu i look if the distance between input and the winner neuron is 0 for really close to i i end",arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
161,Write down the SOM learning in pseudo code.,226,- randomly define some values for the synaptic connections in the network - send the first input to the network - in the output layer(map layer select the neuron that has lowest error(competition phase - based on a redefined method define the neighborhood of the selected neuron(cooparation phase - change the weights of the selected neuron and the neurons located in its neighborhood(adaptation phase - if the stop condition satisfied stop the process,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
162,Write down the SOM learning in pseudo code.,226,has three parts in it - competition cooperation adaptation get input variable and choose amount of neurons to be more than amount of variables then run competition where from the input neurons will be competing to each other on choosing which fits the most after finding winning neuron change weight of neighbouring neuron only in cooperation weights of neighbouring neurons are adjusted to clusters in adaptation neurons are pulled to input variables to establish the classification,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,0,2.0,neural_networks,neural_course,0.0
163,Write down the SOM learning in pseudo code.,226,- find the winning neuron - find the neighbors of the winning neurons,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,0,2.0,neural_networks,neural_course,0.0
164,Write down the SOM learning in pseudo code.,226,"pseudo code + 1. initialize map neurons based on topology it could be a lattice on a circle etc + 2. competition find map neuron that is closest to an input neuron by computing distances $d$. + 3. update the position of closest map neuron with update rule + 4. do 2 and 3 until all input neurons are assigned a map neurons + do 2,3 and 4 until specified iterations or the net cumulative distance goes below some specified value or becomes zero",arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
165,Write down the SOM learning in pseudo code.,226,produce transom begin randomized weights for all neurons for (i=1 to iterationnumber) do begin take random input pattern find the winning neurons find neighbors of the winner modify synaptic weights of these neurons reduce learning rate and lambda end end,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
166,Write down the SOM learning in pseudo code.,226,initialize the network with small and random weights sample the data set by picking an input randomly > determine the winning neuron based on the output value > determine the cooperating neurons based using the neighborhood function > update the weights of the cooperating neurons > adjust the learning rate > stop if the network converges,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
167,Write down the SOM learning in pseudo code.,226,begin i = range of data set initialise the weights we give a small random weights for the range of no select a input signal find the winning neuron based on the similarity between the weights update the weights of the neighboring neuron repeat until the convergence 1. initialising 2. sampling 3 similarity matching 4. updating the weights 5. continuation,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
168,Write down the SOM learning in pseudo code.,226,initialise weights bra while significant change is observed in topographic pattern {<br> take a random input sampling bra find the winning output neuron competition bra adjust the weights of the winning neuron and its neighbourhood neurons cooperation bra continue bra },arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
169,Write down the SOM learning in pseudo code.,226,"here som learning - initialization with random small weights - sampling picking a input pattern with certain probability - similarity matching finding the most matching neuron i.e., the winning neurons - synaptic updating updating the weights of the neuron and also the neurons in it's neighbourhood - continuation repeat steps 2 to 4 till there is no considerable change in the map",arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
170,Write down the SOM learning in pseudo code.,226,"parameters ex data vectors we weights vectors in lattice , $\eta(n)$ learning rate $\sigma(n)$ - neighbourhood width $h{ji(x)}$- neighbourhood function algo i initialize the weights to a small random , non-repeatible values i sample a data vector with a probability i compute the euclidean distance to weight vectors from the data points and find the winning neuron with minimum distance . i update the weights of the winning neuron and its neighbourhood towards the input direction using neighbourhood function i reduce the learning rate and the neighbour hood width and literate from step 2 until no significant changes between weight vectors and inputs are seen",arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
171,Write down the SOM learning in pseudo code.,226,1. initialization : initialize the weight vectors with random values such that the $wj(0)$ is different for all weights 2. sampling : draw sample example ex from input space 3. similarity matching : find the best matching weight vector for the input vector : wi = arguing ex - wi(n))$ 4. adjust the weight vectors of neurons in the neighbourhood of the winning neuron 5. go to sampling step and repeat until no more changes are observed in the local neighbourhood of the winning neurons,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
172,Write down the SOM learning in pseudo code.,226,1. initialization initialize the weights of each neuron to small random values such that weight of each neuron is different 2. sampling sample an input from the input set 3. similarity matching determine the neuron nearest to the sampled input based on its distance 4. weight updating update the weights of the neighbouring neurons chosen by the neighbourhood function $h{ij}(n)$ 5. continuation continue from sampling until there is no more change in the weights,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
173,Write down the SOM learning in pseudo code.,226,som is referred to as self organized maps which is an unsupervised training algorithm for finding spatial pattern in data without using any external help.the process in som is explained below initialization initialize random weights we for input patterns - sampling take nah random sample from the input say xu - similarity matching for the input xu find the best match in the weight vector $i(x) = argmin(x - we - update the next step is to update the weights $w(n+1) = want + eta*hji(x)*i(x)$ - continuation : continue from sampling until there is no significant change in the feature map,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
174,Write down the SOM learning in pseudo code.,226,"initialization set random small values to weights we is different for each neuron sampling draw not sample i from input space competition identify winning neuron i using are min $||x-wi||$ which means weight vector of i is most similar to input cooperation identify neighbors of winning neuron i using neighborhood function $h{j,i(x)} (n)$ which shrinks with time weight adaptation adjustments made to synaptic weights of winning neuron and its neighbors go to sampling until no large changes in the feature map",arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
175,Write down the SOM learning in pseudo code.,226,generate random weights for all neurons<br> for i to maxiteration do<br> ------take random input pattern<br> ------find the winning neuron<br> ------find the neighbors of the winning neuron<br> ------compute weighs of these neurons<br> ------reduce $\eta$ and $\lambda$<br> end for,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
176,Write down the SOM learning in pseudo code.,226,* initialize the neuron weights randomly in a way that all neurons have different weights * generate random samples i from the input space * literate the samples and compare distance between current input and all neurons in the weight space * find a winning neurons with shortest distance from current input * distance is calculated using **euclidean or manhattan distance**. * find the neurons in the neighborhood boundary of winning neurons * update the weights of neighborhood neurons using delta rule * adapt the size of neighborhood $(\lambda)$ and learning rate $(\eta)$ at each iteration * repeat the process until there is no neurons in the neighborhood boundary or all the inputs moved to some neurons,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
177,Write down the SOM learning in pseudo code.,226,step it selects a datapoint in random through sampling step finds the nearest neuron through competitive learning step updates the weight of the winner neuron and updates the weight of neighbouring neurons by a fraction step continues steps i i 3 until there is no change in the weights or some stopping criteria is met,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
178,Write down the SOM learning in pseudo code.,226,{ take a random point from the training data competitive phase find the winning neuron - the neuron similar feature using the eucledian distance formula cooperative phase find the neighbors of the winning neuron based on the neighbor function beg gaussian function adoption phase change the weights of the all the neighboring neuron of the winning node using the formula $ del i = beta xu - we $ },arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
179,Write down the SOM learning in pseudo code.,226,input distance function dex you learning rate mum neighborhood distance i initialize the map layer with random weights for each input find the weight which is closest to the input minimum dex you change the weight in the direction of the input depending on the learning rate change all weights which are within the neighborhood distance i depending on their distance and the learning rate reduce learning rate and neighborhood distance,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
180,Write down the SOM learning in pseudo code.,226,1. initialize small random weights 2. draw the nah sample from the input space 3. similarity matching determine the winning neurons 4. update the weights of the neuron an the topological neighborhood 5. repeat steps 2-4 i = random i = example.draw() wax = getmin(wi*n) in = getneighborhood(wmax) for wi in and wi = wi+$\eta$*h*y,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
181,Write down the SOM learning in pseudo code.,226,"initialize the weights randomly create a term to and the which decrease the learning\rate and neighbourhood function respectively calculate $i(x) = again | i - i |$, the weight which is closest to the input data received ix is the neurons which wins the competitive process this neuron and its neighbours weights are updated using $w{new} = wold - learning\rate dot hex dot ow - x)$. hex is the neighbourhood function which determines which neurons are updated and how strong they are changed by the update it is defined using the distance between the neurons the learning\rate is updated using $learning\rate / t1$, also is the neighbourhood function updated in the same way using the the learning\rate cannot get lower than 0.01, while the neighbourhood function can get as low as only the winning neurons so in the beginning almost every neuron is updated and at the end only a small neighbourhood or the neuron itself is updated",arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
182,Write down the SOM learning in pseudo code.,226,for i iterations winner = competitionbetweenneurons() neighbourhood = cooperationwithneighbourhoodfunction(winner) updateweights(neighbourhood),arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,1,2.0,neural_networks,neural_course,0.5
183,Write down the SOM learning in pseudo code.,226,given a map layer set random small values for weights from input to map layer repeat until not converged find best match of input value and weight of the neurons competitive process adapt increase weight of winning neuron and neighborhood with gauss function and neighborhood size cooperating process and weight adjustment decrease neighborhood size,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
184,Write down the SOM learning in pseudo code.,226,,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,0,2.0,neural_networks,neural_course,0.0
185,Write down the SOM learning in pseudo code.,226,initialize weight vectors of hidden neurons with same dimension as of data number of hidden neuron should be significantly greater than number of data points initialize learning rate i and neighbouring function i while rate of change in weights is significant for every datapoint: calculate distance of each neuron from data select winner neuron i with minimum distance maximum similarity error = distance of winner form datapoint adjust weights of neurons with the rule i = i + n*h*error,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
186,Write down the SOM learning in pseudo code.,226,randomly minimize the weights draw sample of inputs increase the weights of the local neighborhood of winning neuron repeat the process above process till there is only one winning neuron,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,1,2.0,neural_networks,neural_course,0.5
187,Write down the SOM learning in pseudo code.,226,,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,0,2.0,neural_networks,neural_course,0.0
188,Write down the SOM learning in pseudo code.,226,for i in numofepochs for i in inputpoints find the winning neuron find the neighbours of the winning neuron within distance sigma update winning neuron and neighbours weight update sigma and learningrate so that both reduces over time,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,2,2.0,neural_networks,neural_course,1.0
189,Write down the SOM learning in pseudo code.,226,,arrange the weights in the required topology according to the problem initialize the weights randomly such that all the weights are different sample the input from the input space similarity matching match the input to a neuron in the topological lattice which becomes the winning neurons update the weights of the winning neuron and its neighbours determined by the neighbourhood function reduce the neighbourhood and decay the learning rate and share radius if ordering and convergence are complete stop else continue sampling from the input space,0,2.0,neural_networks,neural_course,0.0
190,Give the basic idea of an SVM using the correct terminology!,227,a support vector machine is a maximum margin classifier in which the width of the boundary of separation is maximized a margin is defined as the width of the boundary before hitting a point this maximum margin intuitively feels safe and is experimentally good,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
191,Give the basic idea of an SVM using the correct terminology!,227,basic idea of sum is to best segregate the data into two classes with the help of decision boundary this decision boundary is margin we always try to maximize the margin to make sure data is classified correctly,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
192,Give the basic idea of an SVM using the correct terminology!,227,support vector machines goal is to maximize margin between closest data points of separating hyperplane. separating hyperplane is given by 0 = w(n)*x(n) + be by maximizing margin probability of classification errors is reduced,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
193,Give the basic idea of an SVM using the correct terminology!,227,an sum is a binary linear classifier spanning a separating hyperplane between two classes of datapoints. the hyperplane is spanned between both the positive and negative decision boundaries and supported by a number of support vectors support vectors are the outermost datapoints which span the hyperplane. during training the distance of falsely classified data points to their correct side of the hyperplane is minimized utilizing a quadratic programming formulation,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
194,Give the basic idea of an SVM using the correct terminology!,227,a sum is a binary classifier with a maximum width boundary separating the two classes this uses support vectors vectors that pushes against the boundaries the equations of the lines in an sum are - $wx+b>=1$:for class 1 - $wx+b<=-1$:for class -1 - i is the width between these boundaries,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
195,Give the basic idea of an SVM using the correct terminology!,227,because sums are binary classifies we can use a border to operate the data the border is typically placed where it has the largest possible distance to both classes the vectors the border touches on both sides with its margin are the support vectors,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
196,Give the basic idea of an SVM using the correct terminology!,227,a sum is an ann for supervised learning which is able to separate two classes of data-points by using a hyperlane found by quadratic programming by finding the biggest margin the goal is to classify future data in there two classes,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
197,Give the basic idea of an SVM using the correct terminology!,227,the sum is a maximum margin classifier it is used the binary classify datapoints in a dichotomy the idea is to find a line with nearly separates both classes there perfect position of this line is in right in the middle of these classes to find this line(descision boundary we define a positive and a negative boundary which are parallel to this line the boundary define the margin between both classes the idea of sum is that the datapoints which are next to the boundary can be used to define the margin they are called support vectors additional not every problem is nearly venerable so the idea was to transform the input into many higher dimensions using some kernel functions we discussed the kernel function of polynomial terms and found out that it easy to computer,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
198,Give the basic idea of an SVM using the correct terminology!,227,support vector machines are a type of learning machines that try to classify different classes of an input space for linear separate classes the sums try to calculate the line that separates this two classes with maximum margin the support vectors will be the points closer to this margin when the input data is noisy we have an optimization problem of two aspects maximum margin proper classification so a tradeoff act will be defined the tradeoff will be calculated by the sum of the distance of misclassified points for nonlinear separate classes a kernel will be defined that will transform the input data into a higher dimensional space,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
199,Give the basic idea of an SVM using the correct terminology!,227,in linear sum we have a linear border line classifier that separate two different classes(positive and negative planes and we calculate the distance of the data points from this border line classifier also a margin will be defined and this margin will be maximized until it touches some data points in the plane the data points that the margin pushed against them will be our support vectors the error for the wrongly classified datapoints will be calculated by calculating the distance of the data point from its correct plane the sum tries to learn the classifier and the margin from the training data,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
200,Give the basic idea of an SVM using the correct terminology!,227,support vector machines are classifies that are using support vectors which are variables of the dataset. these variable are chosen during learning algorithm main advantage of sums is that it will not be overfishing by choosing correct margin activation functions can be both linear and nonlinear output of sum is always true or false for given variable,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
201,Give the basic idea of an SVM using the correct terminology!,227,support vector machines are a type of neural network that build a decision boundary around classes such that the margin of separation between classes is maximized,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,0,2.0,neural_networks,neural_course,0.0
202,Give the basic idea of an SVM using the correct terminology!,227,sums are binary classifier they learn the classification by memorizing the marginal data points called support vectors that make up the decision boundaries i : positive and negative,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
203,Give the basic idea of an SVM using the correct terminology!,227,the abbreviation sum stands for support vector machine sums represent a feedforward category of nna sums are binary learning machines whose functionality can be summarized for classification problem as follows given a training sample the sum constructs a hyperplane as the decision surface in such a way that the margin of separation between positive and negative examples is maximized one key innovation associated with sums is the kernel trick the kernel trick consists of observing that many machine learning algorithms can be written exclusively in terms of dot products between examples it allows us to learn models that are nonlinear as a function of i using convex optimization techniques that are guaranteed to converge efficiently besides the kernel function i often admits an implementation that is significantly more computational efficient than naively constructing two vectors and explicitly taking their dot product,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
204,Give the basic idea of an SVM using the correct terminology!,227,an some or support vector machine is a feedforward network with a hidden layer to learn a task in a supervised learning manner the network tries to construct a hyperplane that separates the data points of two different classes by maximizing the margin of separation which is the distance from the hyperplane to the closest data points called support vectors,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
205,Give the basic idea of an SVM using the correct terminology!,227,"given a dataset, support vector machines builds a hyperplane in a such a way that positive and negative samples are separated to the maximum distance width of the margin should be maximum the vectors to which the margins(margin for positive and negative sample are pushed on to it are called support vectors",sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
206,Give the basic idea of an SVM using the correct terminology!,227,sum stands for support vector machine it creates a hyperplane such that margin of separation between positive and negative classes is maximise,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
207,Give the basic idea of an SVM using the correct terminology!,227,here sum is a linear machine whose goal is to construct a optimal hyperplane such that the marginal separation is the maximum between the decision boundaries the decision boundaries are drawn parallel to the hyperplane which just push the datapoints closest to the hyperplane. the datapoints closer to the hyperplane are called support vectors,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
208,Give the basic idea of an SVM using the correct terminology!,227,the idea of sum is to fit a supervised model onto the training data allowing maximum generalization ability this is done by computing maximum margin between different classes of data using the support vectors the margin can be computed using different kernels for a higher dimensional data,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
209,Give the basic idea of an SVM using the correct terminology!,227,a sum is a linear machine which is used in pattern classification problems to find a decision surface in the form of a hyperplane for nearly separate classes such that the margin of separation between the classes is as large as possible sam's are an approximate implementation of the induction principle of structural risk minimization which is based on the fact that the error rate in testing is bounded by a term that is dependent upon the sum of training error rate and the ve dimension of he,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
210,Give the basic idea of an SVM using the correct terminology!,227,the basic idea of sum is to determine the best decision boundary idea the one which provides maximum margin so that the boundary can be widened most before it touches any datapoint. it is done using support vectors which are the the datapoints the margin pushes against,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
211,Give the basic idea of an SVM using the correct terminology!,227,"sum refers to support vector machines.in terms of a linear classification problem sum can be defined as creating a hyper plane which is a decision surface and to maximize the width of decision boundary.in cases where the problem is complex sum can be used as it classifies the data by projecting the data in higher dimension.if the data is to be separated in 3 classes , they can use 3 sam's for three different classes",sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
212,Give the basic idea of an SVM using the correct terminology!,227,basic idea of sum is to construct a hyperplane as the decision surface in such a way that the margin of separation between negative examples and positive examples is maximized,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
213,Give the basic idea of an SVM using the correct terminology!,227,the idea of sum is to construct a hyperplane as a decision surface such that the margin separation between positive and negative examples is maximized,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
214,Give the basic idea of an SVM using the correct terminology!,227,sum tries to find a best hyperplane with widest margin with the help of support vectors such that all the data points are classified correctly,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
215,Give the basic idea of an SVM using the correct terminology!,227,sum is used for nearly separate data a hyperplane is used to separate the data but there could be so many hyperplanes that separate the data the best hyperplane is choose which separates data with a bigger margin so in sum we find the hyperplane which has a bigger margin between the hyperplane and both the positive and negative data lines,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
216,Give the basic idea of an SVM using the correct terminology!,227,given a training set for classification the basic idea of sum is to construct a hyperplane as decision boundary such a way that the margin between the positive and negative points is maximum support vector is a small subset of the of the training data against which the boundary is pushed,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
217,Give the basic idea of an SVM using the correct terminology!,227,a support vector machine classifies given data using a decision boundary the width of this decision boundary margin is maximized to ensure good results because a maximized width is as robust as possible the margin width is $\frac{2}{\sqrt{w * w}}$. to maximize it quadratic programming is used in order to handle noisy data slack variables are introduced to eliminate them duality is used,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
218,Give the basic idea of an SVM using the correct terminology!,227,an sum is a linear classifier that divides a binary pattern by a line that maximizes the margin between its line and the respective support vectors,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
219,Give the basic idea of an SVM using the correct terminology!,227,a sum learns a decision boundary from the input data additional it learns two margins which are parallel to the decision boundary and lie as close as possible at the data points the support vectors the decision boundary is chosen so that the margins are maximized using kernel functions higher dimensional data and non nearly separate data can be learned swell,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
220,Give the basic idea of an SVM using the correct terminology!,227,"an sum is a learning machine that tries to learn the support vectors of a two class data set to get the maximum margin the optimal separating hyperplane, between the two classes",sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
221,Give the basic idea of an SVM using the correct terminology!,227,a sum uses a few of the data points as support vectors to build the maximum margin classifier it searches for the separating line which has the maximum margin to the datapoints. in cases of noise the separating line is searched which minimizes the distance to the points in the wrong category the data is cast to a higher dimensional space to use covers theorem while using kernels the data is more likely nearly venerable in the higher dimensional feature space using structural risk minimization the dimensionality is reduced,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
222,Give the basic idea of an SVM using the correct terminology!,227,"sums are used to nearly separate data points the decision boundary is line or hyperplane in higher dimensions that defines the able of a data point the decon boundary is choose in a way that the margin is maximized data points on the decon boundary are called support vectors and define the hyperplane. in 2 dimensions if the data is liner venerable the margin is equal to 2/sqrt(w.w) where i is the weight vector if the data is not linear seperable, the input can be projected into higher dimension space this increases the chance of linear seperablity.",sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
223,Give the basic idea of an SVM using the correct terminology!,227,support vector machine is classifier which maximizes the margin between boundaries learned from two classes margin is minimum distance by boundaries can be increased before hitting datapoints. support vectors are the datapoints against which main pushes up the boundary,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
224,Give the basic idea of an SVM using the correct terminology!,227,"support vector machines are the finding classfiers, draw the vision boundary which push against the support vectors",sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
225,Give the basic idea of an SVM using the correct terminology!,227,the basic idea of support vector machine (svm) is to find the width of a line or hyperplane which which divides the input data into two classes the points lying on the edge of the defined width are called support vectors,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
226,Give the basic idea of an SVM using the correct terminology!,227,sum is a classifier that classifies a set of points in a way that maximizes the margin between the points of two classes the classification can be linear or non linear,sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,1,2.0,neural_networks,neural_course,0.5
227,Give the basic idea of an SVM using the correct terminology!,227,"the idea behing sum is to find a hyperplane which separate data into classes first it is required to find a data point which are closest to hyperplane, and these data points are called support vectors next task is to find a maximum possible width of the hyperplain such that support vectors are on the edge of that hyperplane. this problem is formulated as minimal constrained optimization problem in order to find a optimum width of hyperplane, (optimimum of a function the idea is to use method of language multiplied additionally when i data is not nearly separable, than an approach is to project data in higher dimension and then to find a hyperplane that separates data in that dimension",sums are linear bearable machines in the simplest case it uses a decision boundary with maximum margin to classify the data into different classes the data points which are near the decision boundary are called support vectors and the margin is determined based on these points kernels are used to separate non-linearly separate data and the algorithm is solved by using quadratic programming,2,2.0,neural_networks,neural_course,1.0
228, What role does the method of steepest decent have when learning a network?,228,in steepest descent the gradient of the cost function is found by partially differentiating it with respect to the weights the weights are then updated in the opposite direction if the gradient this ensures that the weight moves in the steepest direction are reduced it can also be proven that the weights always reduce hence steepest descent can be used to minimize the cost function,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
229, What role does the method of steepest decent have when learning a network?,228,steepest descent is method of optimizing the algorithm by minimizing the error weights are adjusted in the direction of sleeping descent opposite to the direction of the gradient,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1,2.0,neural_networks,neural_course,0.5
230, What role does the method of steepest decent have when learning a network?,228,steepest descent moves the error within error surface a small step into the opposite direction of gradient by help of steepest descent we want to minimize error steepest descent stops when gradient = 0.,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
231, What role does the method of steepest decent have when learning a network?,228,when learning weights with a so method we try to reduce the error based on following the gradient of an error function in the opposite direction effectively trailing the error surface towards the minimum here the error function typically some form of mean squared error is differentiated w.r.t. the individual weights expressing how much a weight contributes to the network error and must thus be corrected due to the gradient pointing in the direction of steepest ascent we must thus step in the negative direction,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
232, What role does the method of steepest decent have when learning a network?,228,- steepest descent is used for error minimization when updating weights - according to this we update the weights along a direction which minimizes the error which is calculated by finding the slope at the point,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1,2.0,neural_networks,neural_course,0.5
233, What role does the method of steepest decent have when learning a network?,228,steepest decent is used to minimize the training error of a network given sample inputs and desired outputs it uses the gradient of the error function to move the weights closer to an optimal weight with lowest output error using a learning rate we can influence the speed and stability of this algorithm,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
234, What role does the method of steepest decent have when learning a network?,228,the steepest decent is the direction the error function falls the most we want to change the weights in the direction of the steepest decent the opposite direction of the gradient to have a smaller error in the next iteration and to optimize the anna,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
235, What role does the method of steepest decent have when learning a network?,228,the idea of learning a network is to minimize a certain costfunction. we can use steepest descent to minimize this cost function while there are other optimization techniques which can be used for optimization steepest decent is a widely used optimization technique to optimize a network we calculate the partial derivatives(gradient) and use it to update our weights it is also used in be,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
236, What role does the method of steepest decent have when learning a network?,228,the approach of the method of steepest descent is to find the direction for the minimization of the error in an approximation problem the cost function e dependent of the weights we will be dedicated partial derivative for all defined weights this gradient will be used for updating the weights for the next iteration the direction of the minimization of the error is the opposite direction of the gradient - go,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
237, What role does the method of steepest decent have when learning a network?,228,when the inputs are being send into a network and we calculate the error we need a mechanism to learn and manipulate the free parameters of the network and the learning uses the error but we must know in which direction in the search(optimization) space we should move so that we can reach the global minimal of the error for this we use steepest decent this method tells us in which direction we need to move by getting the gradient from the error,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
238, What role does the method of steepest decent have when learning a network?,228,steepest descent is a method of weight adaptation it is using first order derivative to approximate the function therefore is rather slow,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1,2.0,neural_networks,neural_course,0.5
239, What role does the method of steepest decent have when learning a network?,228,the steepest descent is an constrained optimization method that seeks to minimize an error function this function is iteratively changed in direction opposite to the gradient vector,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1,2.0,neural_networks,neural_course,0.5
240, What role does the method of steepest decent have when learning a network?,228,method of steepest descent updates the weights in the direction where the error is minimum,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1,2.0,neural_networks,neural_course,0.5
241, What role does the method of steepest decent have when learning a network?,228,the steepest descent method is an algorithm for finding the nearest local minimum of a function which presupposes that the gradient of the function can be computed this property is used to determine the optimal weights of the nna,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
242, What role does the method of steepest decent have when learning a network?,228,steepest descent is used to update the synaptic weights of a network based on a cost function expressed by the errors of the output the weights are adjusted in the direction opposite to the gradient of the cost function,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
243, What role does the method of steepest decent have when learning a network?,228,in steepest descent the adjustments done on the weight vector are in the direction of the steepest descent which is in the direction opposite to that of a gradient descent in a learning problem it basically used to reduce the cost based on the weight the main goal is to find an optimal weight,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
244, What role does the method of steepest decent have when learning a network?,228,method of steepest decent is an constrained optimization technique used for learning in a network it is used in operative manner to minimize the error in supervised learning it finds the direction of maximum gradient so we go in the opposite direction hoping to find the minimal convergence of the algorithm depends on the learning rate and also the condition that it doesn't get stuck in local minimal,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
245, What role does the method of steepest decent have when learning a network?,228,here in steepest descent method the network moves towards the direction of the maximum gradient the learning with steepest descent method can be slow to converge and can exhibit zigzag behavior,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
246, What role does the method of steepest decent have when learning a network?,228,steepest descent involves weight updating in the direction of maximum steep or maximum decrease in the cost function ot in the direction opposite to the gradient function the weight update is delta want = - beta g(n)$ where $\eta$ is the learning rate which defines the magnitude of learning using the gradient gone which is the gradient of the cost function of errors the nah iteration higher $\eta$ will result in rapid learning but with oscillations in responses,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
247, What role does the method of steepest decent have when learning a network?,228,"the method of steepest descent is used to find the direction in which the error function viewed as a function of weights is decreasing most rapidly and then take a small step in that direction when learning a network steepest descent enables to iteratively adjust the weight vectors until the optimal weight vector that minimise the cost function (i.e, the error function where error is computed as the difference between the desired and actual response of the network is found",steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
248, What role does the method of steepest decent have when learning a network?,228,when learning a network the steepest descent algorithm updates the weights in such a way that the error decreases in every iteration,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1,2.0,neural_networks,neural_course,0.5
249, What role does the method of steepest decent have when learning a network?,228,the method of steepest descent moves in the direction opposite to the gradient to minimize the cost function .,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
250, What role does the method of steepest decent have when learning a network?,228,"steepest decent method is based on minimization of error cost function $\xi(w) = 0.5 e^2k(n)$, so synaptic weight of network is updated in a direction opposite to gradient vector of $\xi(w)$, that is $wk(n+1) = wk(n) - beta unable \xi(w) = wk(n) - beta eking x(n)$, beta is learning rate.$ek(n)$ is neuron i error signal $xj(n)$ is input data",steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
251, What role does the method of steepest decent have when learning a network?,228,the steepest is used to find a direction in which e is decreasing most rapidly the adjustments applied to the weights are in the direction of steepest descent,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
252, What role does the method of steepest decent have when learning a network?,228,steepest decent helps to minimize the value of error function $e$** by finding the right direction to move the weight vector to reach global minimal the direction is always opposite to the direction of actual gradient vector**.,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
253, What role does the method of steepest decent have when learning a network?,228,method of steepest descent is used to reduce the error in backpropogation during backward pass we need to know how by how much amount the weights should be changed this can be known if we use steepest descent find the gradient of error and use it to reduce the error,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
254, What role does the method of steepest decent have when learning a network?,228,the steepest descent finds the direction of the error function and tries to reduce it by adding in the opposite direction $ del i = - beta g(n)$ g(n)- gradient of the cost function,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
255, What role does the method of steepest decent have when learning a network?,228,the steepest descent is used to find the right direction in which the weights should be changed while learning a network the private of the error is used and weights are changed in that direction which makes the error smaller as fast as possible,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
256, What role does the method of steepest decent have when learning a network?,228,the steepest descent can be used to optimize the weights of a network in steepest descent the error function is a function of the weights so we determine the direction of the steepest descent on the error surface and go into that direction to minimize the error of the weights on optimize them,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1,2.0,neural_networks,neural_course,0.5
257, What role does the method of steepest decent have when learning a network?,228,the method of steepest descent is used to minimize the error function the error function is the gradient of the error delta e = i - you where i is the desired output and y is the actual output of the neurons,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
258, What role does the method of steepest decent have when learning a network?,228,steepest descent is the basic learning algorithm others are derived from the goal when learning a network is to minimize the error this is achieved by starting at a random position and going in the opposite direction of the gradient vector the steepest descent,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
259, What role does the method of steepest decent have when learning a network?,228,the error function is computer to adapt the weights learn the network the error function is followed in small steps in direction of steepest descent to decrease the error using iterations the error is decreased in each step and end in a local minimum used in back-propagation,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1,2.0,neural_networks,neural_course,0.5
260, What role does the method of steepest decent have when learning a network?,228,in error correction learning the weights of a network are learned in a way that ex is minimized where ex is some error function in order to minimize the error function the method of steepest defend is used the negative gradient of ex points in the direction of steepest defend doing steepest descend in a single layer feed forward network leads to the delta rule,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
261, What role does the method of steepest decent have when learning a network?,228,steepest descent adjust the parameters weights and bias of the in to minimize the error it does so by adjusting the weights in the direction of steepest descent of the error function,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1,2.0,neural_networks,neural_course,0.5
262, What role does the method of steepest decent have when learning a network?,228,steepest decent while move in the direction of the max improvement ( in terms of decreasing in the cost function or error if the learning rate is large then the it follows the zigzag motion if the learning rate is too low then it takes time for converging .,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1,2.0,neural_networks,neural_course,0.5
263, What role does the method of steepest decent have when learning a network?,228,the method of steepest descent is responsible for weight adjustments in the network the weights are adjusted in the direction of the steepest descent that is equal to the negative grad of the error it ensures that the weights are decreased in every iteration step,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
264, What role does the method of steepest decent have when learning a network?,228,steepest decent method helps in making the adjustments of the weights in a neural network in a way that minimizes the average squared error in each step it gives the direction towards which the maximum decrease of the average squared error can be achieved,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,1,2.0,neural_networks,neural_course,0.5
265, What role does the method of steepest decent have when learning a network?,228,the method of steepest decent is used for finding minimum of a cost(error) function the steepest decent operates over possible values of weight vector to optimize the function it is used for deriving error function in adalind adaptive linear elements algorithm and it is used also in backpropagation method in training of multiplayer nose,steepest descent is used to update the weights in a in during the learning phase it helps to navigate the cost function and find the parameters for which the cost is minimum the weights are updated in the direction of the steepest descent which is in a direction opposite to the gradient vector this method could suffer from local minimal and may become unstable,2,2.0,neural_networks,neural_course,1.0
266,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a dataset a \subseteq i $ with i datapoints has $2^n$ binary maps if for any of these binary maps a hypothesis oh in he splits the positive data from the negative data such that there is no training error then it is said that i shatters the dataset a,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
267,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0,2.0,neural_networks,neural_course,0.0
268,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a a hypothesis oh in he shatters a dataset a \subseteq i \leftrightarrow \ldots$ if there exists a an alpha for every training set with zero training error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,1,2.0,neural_networks,neural_course,0.5
269,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,... when our learned machine achieves zero training error on every classification problem of the dataset a since we got a selection of and points in the dataset a the number of problems in binary classification is 2 to the power of and i didn't find the dacha symbol on the english keyboard i ),for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
270,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"considering a dataset a \subseteq xu where i is the instance space and a contains i elements now there are $2^n$ binary maps or learning problems when we what to separate two classes if any of these problems can be separated completely by hypothesis oh in he then i is said to shatter a i.e., a hypothesis shatters a dataset, if it can completely separate the classes with zero error for all possible combination of labels in the dataset.",for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
271,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,when every possible combination of input and desired output can be classified using the,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,1,2.0,neural_networks,neural_course,0.5
272,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"a hypothesis oh in he shatters a dataset a \subseteq xu then for every point xi in a there is a label yi in \{1,-1\}$ and the the can separate these two classes using the with no training error",for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
273,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,there exists an arrangement of these points in a such that for each possible combination of labels to these points the hypothesis i has zero training error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0,2.0,neural_networks,neural_course,0.0
274,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,an hypothesis the shatters a dataset a if for a given data set i is able to distinguish for separate the different classes of this data set,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
275,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,the shatters a if for any set of input data points in a there exist at least one training error of zero,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
276,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"i shatters a when for example in given dataset (x1,x2...xr) output are in a form (x1, y1),(x2,y2)...(xr,yr) there has been found a 0 error",for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
277,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"a machine i can shatter a set of points $x1, xu x3,..., and if and only if for every training set there is a weight vector $\alpha$ that produces zero training error",for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
278,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"a hypothesis oh in he shatters a dataset a subset i \leftrightarrow$ for each assignable configuration of $(xi, yinlin a the perfectly classifies all elements of the set $a$.",for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
279,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0,2.0,neural_networks,neural_course,0.0
280,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a hypothesis oh in he shatters a dataset a \subseteq i \leftrightarrow$ at least on possible combination of dataset a can be classified by the hypothesis oh in he with zero training error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0,2.0,neural_networks,neural_course,0.0
281,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,given a dataset a \subseteq i $ where i is the instant data space for a given problem with the dataset a if a learning machine is able to successfully split the positive and the negative data then we say that a is shattered by the learning machine,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
282,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,suppose i is a training dataset and a is the subset of training dataset then hypothesis i is said to shatter if can correctly classify all the points in a ice zero training error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
283,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,here a hypothesis oh in he shatters a dataset a \subseteq i \leftrightarrow \ldots$ if the hypothesis can clearly distinguish the positive examples from the negative examples in a,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,1,2.0,neural_networks,neural_course,0.5
284,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"a hypothesis i is model that separates a dataset consisting of taxi , ying samples into positive and negative samples i is said to shatter a given subset of a dataset if it can successfully separate at least one configuration of the subset of dataset.",for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0,2.0,neural_networks,neural_course,0.0
285,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a hypothesis oh in he shatters a dataset a \subseteq i $ if there exists an $\alpha$ for which there is zero training error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
286,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"for each of the $2^n$ where i is the size of a combinations of input output mapping of the form $(xi, yi)$, i is able to classify the data correctly that is with zero error",for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
287,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0,2.0,neural_networks,neural_course,0.0
288,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,for all possible binary labeling of dataset a we can find a hypothesis i that can separate the positive examples from negative examples the i shatters a,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
289,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"the hypothesis the can shatter any points of $x1$, $x2$, ..., $xn$ if and only if for every possible training set of the form $(x1, y1), (x2, y2), ... (xn, yn there exist some values of $\alpha$ that gets zero training error",for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
290,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"a hypothesis space i shatters a dataset, if and only if there is a **possbile $\alpha$ weight vector)** on hypothesis space that **seperates all the positive data from negative data**.",for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,1,2.0,neural_networks,neural_course,0.5
291,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a hypothesis oh in he shatters a \subseteq xu if and only if there exists a value of $\alpha$ for which the training error is zero,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,1,2.0,neural_networks,neural_course,0.5
292,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"i is the ve dimension of a learning machine that can shatter i points ve dimension of a learning machine is the maximum number of points that can be arranged so that the learning machine can shatter them shattering the learning machine is said to shatter points $(x1 ... xray if and only if all the possible training set of $((x1,y1) ... (xr,yr))$ can be classified with zero training error",for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
293,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,a hypothesis shatters a dataset if it can correctly classify all combinations of labelling of the points in the dataset.,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
294,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,", if there exists a configuration of $x$, so that the gets zero training error on any dichotomy of the datapoints.",for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0,2.0,neural_networks,neural_course,0.0
295,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,there exist i weights which produce a perfect classification,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0,2.0,neural_networks,neural_course,0.0
296,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,for all possible classified subsets of dataset a the hypothesis i can separate it,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
297,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,when all combinations of position and labeling of the data can be separated in the given classes by the hypothesis,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
298,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"i shatters a when and only when for all possibilities of (a1, y1), (a2, y2), ... ,(an, yn where y is the class able i or -1) there exists some $ alpha $ for a learning machine i that produces 0 training error",for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
299,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,if there exist atleast one configuration of a for which training error of i is zero idea it successfully classifies all points in a,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0,2.0,neural_networks,neural_course,0.0
300,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,and there exist a linear saperater which separates positive examples from the negative examples correctly then we say that a can be shatter at he,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
301,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,given a data set a if it is possible to find a hypothesis i which separates the data set into binary form without any error we can say that hypothesis oh in he shatters dataaet a \subseteq i \leftrightarrow \ldots$.,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
302,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,"it means that for all the points in a with input output pair (x,y), for any combination of ($xi$,$yi$) there exist parameter $\alpha$ of i that enables i to classify the points with zero error",for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,2,2.0,neural_networks,neural_course,1.0
303,Define: a hypothesis $h \in H$ shatters a dataset $A \subseteq X \Leftrightarrow \ldots$,229,we say that a hypothesis i shatters a dataset a iff the i produces a zero training error for certain data set a in other words we say that a hypothesis i shatters a dataset a when i separates data a in two classes without error,for all in possible binary labeling of every data if a hypothesis i splits the positive data from the negative data with no error then it means that the hypothesis i shatters the dataset a,0,2.0,neural_networks,neural_course,0.0
304,Write down and explain the Widrow-Hoff learning rule!,230,$ delta i = beta e(n)x(n) i where $\eta$ is the learning rate widrow-hoff rule states that the change in weights is proportional to the product of the error and the input in the corresponding synapses,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
305,Write down and explain the Widrow-Hoff learning rule!,230,weights adjusted are proportional to the product of error signal and the input vector win + i = want + $\eta(d-y)x(n)$ $\eta$ is learning rate i is desired output y is current output xena in input vector,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
306,Write down and explain the Widrow-Hoff learning rule!,230,adoption of weight is proportional to product of input and error $w{new} = wold + xie,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1,2.0,neural_networks,neural_course,0.5
307,Write down and explain the Widrow-Hoff learning rule!,230,"for neurons with a linear activation function (adaline): $w(t+1)=w(t)+\alpha (d-y)x$, where i is the input pattern i is the true value and y is the net output notice that the delta rule looks similar to the perception learning rule but was derived from do whereas the perception works with a step function which is not fully differentiable.",the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
308,Write down and explain the Widrow-Hoff learning rule!,230,widrow-hoff learning rule is also known as error correction rule is used to update the weights as delta i = beta (di-yi)xi$ where i is the desired output and y is the output the network generates and i is the input,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1,2.0,neural_networks,neural_course,0.5
309,Write down and explain the Widrow-Hoff learning rule!,230,$w(n+1) = want + mu (d(n) - y(n))x(n)$ the change of the weights is determined using the error ($d(n) - y(n)$) and the input that was given to the network the learning rate can improve leaving speed the new weights are dependent on the old ones and the change calculated,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1,2.0,neural_networks,neural_course,0.5
310,Write down and explain the Widrow-Hoff learning rule!,230,$w{ij}(n)= w{ij}(n-1)+ learningrate*(dj-yj)*xi$ we change the weights by computing the error deja (dj-yj)$ for the input and multiply it by the learningrate and the exit and adding it to the old weight this minimise the squared error function your cost function and is the online variant of the steepest decent method,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
311,Write down and explain the Widrow-Hoff learning rule!,230,i delta want = beta * e(n)*w(n) i i end = (y-d) i the widow off learning rule is error correction learning it is used to train a network in a supervised manner the widow off learning rule can be derived from gradient decent the rule consists of the error end the neuron has and is multiplied with the weight so that the impact of the weight to the error is incorporated into the update a learning rule is use as a adjustment in how much we trust the weight change the error is calculate by the difference between the current and expected output,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
312,Write down and explain the Widrow-Hoff learning rule!,230,"the widrow-hoff learning rule is defined as own + i = want + beta * xena * e(n)$ the widrow-hoff learning rule is a rule for adjusting the weights of a in for a error correction learning task this learning rule is derived from the steepest descent method where the direction for the minimization of the error is the defined as the opposite direction of the cost function's gradient this gradient can be simplified as $x(n) * e(n)$, where end is defined as the difference between the desired response and the actual response of the learning machine (nn): $e(n) = done - y(n)$. $\eta$ defines the learning rate used",the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
313,Write down and explain the Widrow-Hoff learning rule!,230,,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,0,2.0,neural_networks,neural_course,0.0
314,Write down and explain the Widrow-Hoff learning rule!,230,"windrow-hoff rule is $$w{new}=x{input}*w{old}*(d{output}-y{output})*eta*a i where $w{new}=new weight,w{old}=old weight,d{output}=desired output,y{output}=actual output,x{input}=input, eta=learning rate learning constant",the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,0,2.0,neural_networks,neural_course,0.0
315,Write down and explain the Widrow-Hoff learning rule!,230,the widrow-holf or delta rule is a gradient descent learning rule used to adapt weight in a perception delta want = - \eta(d(n) - y(n))x(n) $ delta want = - beta e(n)x(n) $,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1,2.0,neural_networks,neural_course,0.5
316,Write down and explain the Widrow-Hoff learning rule!,230,the widrow-hoff delta learning rule is given by i w(n+1) = want - beta xena e(n)$$ where $e(n)$ is the error vector $\eta$ is learning parameters $x(n)$ is input vector,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1,2.0,neural_networks,neural_course,0.5
317,Write down and explain the Widrow-Hoff learning rule!,230,the widrow-hoff learning rule is also referred to as delta or least mean square alms rule it is used to minimize the cost function and is defined as follows delta wji(n) = eta partial xing / partial wji(n)) where eta is the learning rate parameters xing is the total instantaneous error energy and i are the weights,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1,2.0,neural_networks,neural_course,0.5
318,Write down and explain the Widrow-Hoff learning rule!,230,the widrow-hoff learning rule also called delta rule is used for learning a network by adjusting the synaptic weights of the network with the error signals i w(n+1) = want + beta (d(n) - y(n)) xena i where and is the number of iteration $\eta$ is the learning rate $d(n)$ is the desired output signal $y(n)$ is the actual output signal and $x(n)$ is the input signal $(d(n) - y(n))$ is the error signal,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
319,Write down and explain the Widrow-Hoff learning rule!,230,widow off's learning rule states that the adjustment of the weight of a synapses are promotional to the product of the error function and the input which is given by the synapses based on the problem,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1,2.0,neural_networks,neural_course,0.5
320,Write down and explain the Widrow-Hoff learning rule!,230,widow off rule is based minimising the mean square error using gradient descent alogirthm. weights are adjusted in following manner:<br> w(n+1) = want - i gradient of mean square error bra it takes the gradient of the mean square error $0.5 e^{2}(n) = end \frac{\partial e(n)}{\partial we = end x(n)$,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
321,Write down and explain the Widrow-Hoff learning rule!,230,"here widow off rule - delta we = beta end x(n)$ - widrow-hoff rule states that when an input xena produces an error e(n), then the change in the weight is directly proportional to the error signal and the input signal",the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1,2.0,neural_networks,neural_course,0.5
322,Write down and explain the Widrow-Hoff learning rule!,230,"widow off learning rule is also called as error correction learning rule the error is defined as the difference between the desired and the actual output of the learning machine assuming the desired sign is available the error is computed and weights of the neural network are updated in the direction of reduction of errors the error for each input sample for a neuron i is computed using $ek(i) = dk(i) - yk(i)$. weight change delta i = w*e$, that is the dot product of error and the weights is computed",the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
323,Write down and explain the Widrow-Hoff learning rule!,230,"given a neuron i excited by an input signal $xi$, if $w{ki}$ is the synaptic weight of the neurons then the widrow-hoff learning rule gives the weight adjustment delta w{ki}$ applied to the neuron i in mathematical terms as follows delta wiki = beta xi(n)e(n)$ where end is the instantaneous value of the error signal thus the widrow-hoff rule states that the synaptic adjustment applied to the weights of a neuron is proportional to the product of the input signal to the neuro and the instantaneous value of the error signal this rule assumes that the neuron has an external supply of desired response so that the error can be computed",the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
324,Write down and explain the Widrow-Hoff learning rule!,230,the widrow-hoff learning rule is given by $$w(n + i = want + beta end x(n)$$ where $w(n)$: weight in iteration i $e(n) = done - y(n)$: error $d(n)$: desired output $y(n)$: actual output $x(n$: input $\eta$: learning rate,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1,2.0,neural_networks,neural_course,0.5
325,Write down and explain the Widrow-Hoff learning rule!,230,"widow off learning rule states that the adaptation made to the synaptic weights is proportional to the product of input and the error function.it basically states that if the error is high then the product of input and error will also be high , and thus the adjustment made to the weight would be more $wj(n+1) = wj(n) + eta*(error)*input$",the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
326,Write down and explain the Widrow-Hoff learning rule!,230,"it is based on minimization of error cost function $\xi(w) = 0.5 e^2k(n)$, so synaptic weight from neuron i to input i is updated in a direction opposite to gradient vector of $\xi(w)$, that is $w{kj}(n+1) = w{kj}(n) - beta unable \xi(w) = w{kj}(n) - beta eking xj(n)$, beta $ is learning rate.$ek(n)$ is neuron i error signal $xj(n)$ is input data",the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
327,Write down and explain the Widrow-Hoff learning rule!,230,windrow-hoff or error correction learning rule says that the adjustment of a weight is proportional to the product of the error signal and the input signal of the weight,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1,2.0,neural_networks,neural_course,0.5
328,Write down and explain the Widrow-Hoff learning rule!,230,$$\bigtriangleup \omega{ji} = e * xiao $$\omega(n+1) = \omega(n) + beta \bigtriangleup \omega{ji}$$ widow off learning rule says that the synaptic weight update is directly proportional to the product of error and the input,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
329,Write down and explain the Widrow-Hoff learning rule!,230,widrow-hoff learning rule the rules states that the weight update is directly proportional to the product of the input to the neuron and the error delta w{ij} = beta end sum xi(n)$,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1,2.0,neural_networks,neural_course,0.5
330,Write down and explain the Widrow-Hoff learning rule!,230,delta $ w{kj} = beta ek . xu $ widow off rules states that the change in synaptic weight is proportional to the product of the error signal and the input signal,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1,2.0,neural_networks,neural_course,0.5
331,Write down and explain the Widrow-Hoff learning rule!,230,delta want = mu * xena * e(n)$ mu = $ learning rate $x(n) = $ input at trimester i $e(n) = done - y(n)$ $d(n) = $ desired signal at trimester i $y(n) = $ output of the network at trimester i the widroff-hoff for delta rule changes the weights depending on the input and the error which is the difference between the output of the network and the desired output this weight change can be scaled by a learning rate,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
332,Write down and explain the Widrow-Hoff learning rule!,230,the widrow-hoff rule is used in error-correction learning and uses the current error and output of the system to determine the new weights $w(n+1) = w(n)+\eta dot end dot yen $,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,1,2.0,neural_networks,neural_course,0.5
333,Write down and explain the Widrow-Hoff learning rule!,230,"delta want = learning\rate dot xena dot e(n)$, where i is the input data we = i - ya is the error from the desired output and the actual output and the learningrate is a parameter chosen as necessary to change the speed of learning $w{new} = wold + learning\rate dot i dot end this is the formula to update the weights and to learn the input data",the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
334,Write down and explain the Widrow-Hoff learning rule!,230,weights(t) = weights(t-1) * learningrate * (desired(t) - output(t)) the widrow-hoff rule also the delta rule is used to update the weights of neural networks in a learning algorithm it uses the previous weights result and compares it to the desired results this discrepancy is then applied to update the weights based on a learning rate,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
335,Write down and explain the Widrow-Hoff learning rule!,230,new = wold + learningparameter * error(n) * input(n) while error is desiredinput - currentoutput the new value for the synaptic weight is computed of the old value plus a learning rate times the current error and the input the output error is decreased in each step until the change is to small or the generalization is sufficient,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
336,Write down and explain the Widrow-Hoff learning rule!,230,rule we = i + i * i * ( y - do where i is the learning rate i is the input y is the output of the network i is the desired output the widrow-hoff rule minimizes the error (y-d). the weight change is proportional the input i and the error it can be derived from steepest descend,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
337,Write down and explain the Widrow-Hoff learning rule!,230,,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,0,2.0,neural_networks,neural_course,0.0
338,Write down and explain the Widrow-Hoff learning rule!,230,this the basically the calculating mean squared error (mse) from the expected output and real output modifying the weights for minimizing me it .,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,0,2.0,neural_networks,neural_course,0.0
339,Write down and explain the Widrow-Hoff learning rule!,230,widrow-hoff rule states that the weight adjustment is proportional to the product of input and the error in the output it is also called the delta rule $$\delta w{ji} = beta xie{ji}$$ $\eta$ is the proportional constant also called as learning constant $$w(i)=w(i-1)+\delta w{ji}$$,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
340,Write down and explain the Widrow-Hoff learning rule!,230,delta w{ji}$ = beta exit adjustment made to the weight of a neuron is proportional to the product of the error in that neuron and input applied to the neurons,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
341,Write down and explain the Widrow-Hoff learning rule!,230,widrow-hoff learning rule is derived from les error method and it is defined as $w{t+1} = with + mu dot delta we where $\mu$ represent learning rate and delta i = gradient \ of \ instantaneous \ error = and - you i here do represent desired signal while my represent output signal of a neurons ex represent input of a neuron,the adjustment made to a synaptic weight of a neuron is proportional to the product of the error signal and the input signal of the synapse in question the rule is derived from the steepest descent method,2,2.0,neural_networks,neural_course,1.0
342,"Explain back propagation, use the correct technical terms!",231,"in backpropagation, the gradient of the error produced at the output layer by partially differentiating the cost function with respect to the weights is propagated backwards one layer at a time back to the input layer this propagated gradient is used to update the weights in the corresponding layer backpropagation is necessary because the desired output at every layer is not known and it is only possible to formulate the cost function at the output layer",backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
343,"Explain back propagation, use the correct technical terms!",231,in back propagation there are two phases 1. forward phase first we apply input to the network and compute the current output 2. backward phase we compute the error between current and desired output error is minimized by computing gradient of error with respect to weight in return weights are adjust after adjusting weights in backward phase we again go to forward phase and compute the current output check whether error is minimized or not,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
344,"Explain back propagation, use the correct technical terms!",231,back propagation wants to minimize the error function e e is given by i $ \frac{1}{2}\sum e(n)^{2}$ \). the error function can be minimized by calculating the gradient starting from the output term for calculating the gradient differs it depends on whether the neuron for which the gradient to be calculated is an output neuron or a hidden neurons,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
345,"Explain back propagation, use the correct technical terms!",231,backpropagation is the general form of the delta rule formulated for networks with multiple hidden layers here we propagate the error of the network back to the input layer to determine the change of weights using the error signal in the output layer and subsequently the local gradients in the hidden layers in the forward pass we compute the net output forwards in the backward pass we propagate the error backwards the be rule was derived from the error gradient w.r.t. the weights and application of the chain rule,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
346,"Explain back propagation, use the correct technical terms!",231,back propagation is propagation of error from the output layer to the hidden layer in network with multiple layers this is done by calculating the local gradient of each node and then using this along with the weight to determine how much of the error is to be propagated to the particular node,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
347,"Explain back propagation, use the correct technical terms!",231,"back propagation is used in multi layer network it consists of two phases forward and backwards in the forward phase we give and input to the network and calculate its outputs also memorize the local field of each node the local gradient delta is used to adapt the weights of the layers it is different for output and the remaining layers for node i in an output layer $\deltai(vi) = \varphi^\prime(vi)(di - ying for node i in other layers $\deltai(vi) = \varphi^\prime(vi)\sum{j\in ca wi \deltaj(vj)$, where act are all the nodes that use node i output as an input repeat this process for all input data until error is small enough",backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
348,"Explain back propagation, use the correct technical terms!",231,the back propagation algorithm is there to train a multiplayer feedforward anna we change the weights by computing the local radiant at each neuron by using the neurons in the layer before the local gradient of the output neurons can be computed easily the activation function has to be differantable for the backpropagation algorithm in the forward pass we compute the output y at the output layer in the backyard pass we use the output y and our desired output i to compute the local gradients at the output layer then we go back layer by layer and use the local gradients from before to compute the new local gradients by that we minimize the average squared error function,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
349,"Explain back propagation, use the correct technical terms!",231,backpropagation is a learning algorithm for multiplayer of nna it is supervised error correction learning the weights are initialized randomly the algorithm has to steps in the forward pass the the output is calculated by using the current weights in the backward pass the weight update for the outputlayer is as like in single layer of the error is used to update the weights be allows us to also calculate the error of hidden layers for each hidden layer we use a local gradient as the error the local gradient is the sum of weighted error of the following layer which is passed trough the private of the activation function so it is possible to backpropagate the error from the output layer to to first layer a common problem in be is the vanishing gradient problem depending on the activation function used the local gradient gets smaller in each layer until it is eventually less than the floating point precision used this limits the number of layers that can be stacked,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
350,"Explain back propagation, use the correct technical terms!",231,the back propagation algorithm is a learning algorithm for updating in the weights in a multiplayer neural network for updating the weights of all the layers the error of each neuron must be calculated in the back propagation algorithm two phases will be defined - forward phase the output of the neural network will be calculated and also the error of the neurons in the output layer - backward phase the gradient of each neuron will be calculated by using the calculated error on the output layer and the defined connections between the hidden layer and the output layer if multiple hidden layers are defined the error will be iteratevely will be given backwards and the weights at each neuron will be updated,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
351,"Explain back propagation, use the correct technical terms!",231,back propagation is a steepest decent method that uses the final produced error and the local gradient to define the amount of change needed for each synaptic weight in this method we have two phase - forward phase in this phase we feed the input to the network and the network calculate the output - backward phase in this phase we first calculate the error and then use the local gradient to propagate the error to the network from the last layer to the first and manipulate the synaptic weights,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
352,"Explain back propagation, use the correct technical terms!",231,back propagation consists of two steps 1. forward pass - data is passed through the network and weights are adapted 2. backward pass - by using local field of each neuron error signal is propagated backward by using local field of each neuron from end to beginning and stacking them up local field is partial derivative of the output signal of a a neurons for output neuron it is simplest to calculate as it has only desired output and actual output to deal with,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
353,"Explain back propagation, use the correct technical terms!",231,backpropagation is a learning algorithm in multi layer networks that consists of two phases a forward pass and a backward pass in the forward pass the output is calculated by passing activation layer through layer starting from the input then through hidden layer and finally output then the error is calculated in the output layer and propagated backward through the network in the forward pass the weight do not change in the backward pass the weights change in proportion to the local gradient,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
354,"Explain back propagation, use the correct technical terms!",231,backpropagation is a neural network based learning algorithm where the network learns by propagating the error through the network be consists of two stages + forward pass where the error is computed by feeding the input to the network + backward pass where error is propagated through the network for doing the weight updates locally since be has vanishing gradient problem it is useful to use activation functions which are infinitely differential such as sigmoid function,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
355,"Explain back propagation, use the correct technical terms!",231,the back propagation algorithm is used to calculate the error contribution of each neuron after a batch of data is processed required is a known desired output of each input value thus the back propagation algorithm is a supervised method the algorithm can be subdivided into two phases i propagation * propagation forward through the network to generate the output value(s). * calculation of the cost error terms * propagation of the output activation back through the network using the training pattern target in order to generate the deltas differences between desired and actual output of all output and hidden neurons / by recursevliy computing the local gradient of each neurons i weight update for each weight the following steps need to be applied * the weight's output delta and input activation are multiplied to find the gradient of the weight * a ratio percentage of the weight's gradient is subtracted from the weight this ration is also referred to as the learning rate and influences the speed and quality of the learning learning is repeated for every new batch until the network performs adequately,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
356,"Explain back propagation, use the correct technical terms!",231,backpropagation is an algorithm for training a neural network and it contains of two main stages the first stage is to compute the actual output given the input in this stage the signal flows forward from the input layer to the output layer and the synaptic weights are fixed the second stage is to update the synaptic weights by propagating the error signals backward from the output layer in a layer-by-layer manner for each neurons the local gradient the partial derivative of cost function to the local field is computed,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
357,"Explain back propagation, use the correct technical terms!",231,back propagation usually occurs in a multi layer perception it uses a non linear activation function basic elements 1. functional signals these are the input signals which passes through the network from left to right as the name denotes it performs a useful function at the output of the neuron and another reason for the name is that the functional signals are calculated based on the parameters and the activation function 2. error signals error signals propagate usually in the reverse direction which contains the error based on the desired output it consists of 2 phases 1. forward phase in the forward phase the signals propagate from left to right weights are fixed and passes through all the layers of the network that is undergo all the activation 2. reverse phase in the reverse phase the local gradients are calculated and are propagated through in the backward direction here weights change,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
358,"Explain back propagation, use the correct technical terms!",231,backpropogation is used for training multi layer networks it constitutes of forward pass and backward pass in forward pass network computes the output based on this the errors are calculated based on difference between network output and desired output these errors are the backpropogated to network during backward pass and used for adjusting the synaptic weights,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
359,"Explain back propagation, use the correct technical terms!",231,"here backpropagation is used for multiplayer perception network it consists of two passes - forward pass the outputs are calculated at every computational node and passed till the output node where the error is calculated by difference of desired output and the actual output in this pass the weights of the synaptic links are not changed - backward pass the error generated at the output neuron is passed in the backward direction i.e., against the direction of the synapses and the local gradient of the error is calculated at every neurons",backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
360,"Explain back propagation, use the correct technical terms!",231,back prop is a way of training a neural network by adapting the weights using error produced it consists of two phases forward and backwards forward phase computes the output along the network using the function signal in the backward phase the error of the output fromthe desired output is computed and a local gradient of the error is used to update the weights of the network the local gradient considers the credit or blame of the corresponding weights of neuron in producing the output,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
361,"Explain back propagation, use the correct technical terms!",231,the back propagation algorithm is based on the error correction learning rule and consists of two passes 1. forward pass : the input signal applied to the source nodes of the network is propagated forwards through the different layers of the network and the output is computed at the output layer of the network 2. backward pass : the error signal computed at the output is propagated backwards with a local gradient computed at each of the hidden layer neurons in order to adjust the synaptic weights the neuron in the network,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
362,"Explain back propagation, use the correct technical terms!",231,back propagation is moving the error backwards recursive through the network by calculating the local field of every neuron to update the weights it is based on the chaining rule of derivatives,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
363,"Explain back propagation, use the correct technical terms!",231,"backpropagation is a neural network which has two stages forward pass in forward pass the error is calculated in the output layer with the help of the desired output and the given output e = i - y - backward pass it begins in the output layer , in this case the error is passed backwards with the calculation of gradients at each layer of the neural network so in back propagation the adjustment to weights is made based on the local gradients which is calculated at each layer",backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
364,"Explain back propagation, use the correct technical terms!",231,it contains forward pass and backward pass in the forward pass input is applied to the network and propagate it forward through the network then compute the output of neurons in output layer and errors for output neurons in the backward pass compute local gradients and update the synaptic weights according to error correction rule for each neuron layer by layer in a backward direction,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
365,"Explain back propagation, use the correct technical terms!",231,back-propagation algorithm consists of two passes:<br> 1. forward pass the input vector is applied to the network layer by layer 2. backward pass the weight is adjusted based on error correction learning rule bra bra back propagation uses error correction learning rule and the objective is to minimize the average of squared error,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
366,"Explain back propagation, use the correct technical terms!",231,* backpropagation is a steepest decent method that calculates the error at the output neurons and backpropagates those errors backwards to update the weights of each neurons * the synaptic weight updated is directly proportional to partial derivatives * local gradient is calculated at output neurons and hidden neurons * local gradient at output neurons are calculated using the observed error * but the error function is missing in the hidden neurons so the local gradient of hidden neuron i is calculated recursive from the local gradients of all neurons which are connected directly to the hidden neuron je,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
367,"Explain back propagation, use the correct technical terms!",231,backpropogation has 2 steps forward pass in forward pass the data is run through the network and the error is calculated backward pass in backward pass the weight is adjusted using local gradient of error such that the error is minimized there are many ways for weight adjustment like steepest descent newtons method gauss newton method,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
368,"Explain back propagation, use the correct technical terms!",231,the back propagation is a learning method in neural networks back propagation enables the feed forward network to represent for gate it has two phases forward pass the initial weights are used to calculate the value of the output neuron backward pass starts from the output layer and travels backwards during this phase the weights are changed based on the local gradients of each neurons,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
369,"Explain back propagation, use the correct technical terms!",231,back propagation is used to learn weights in a multiplayer feed forward network it is divided into two steps forward and backwards in the forward step one input is passed through the network to calculate the output of the network this output is used to calculate the error of each output neuron given the desired output after this forward step in the backward step the weights are changed beginning in the end of the network each weight is changed by taking the derivative of the activation function of the neuron times either the error if the following neuron is an output neurons or all local gradients of connected neurons times the corresponding weights the weight changes are the local fields,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
370,"Explain back propagation, use the correct technical terms!",231,backpropagation is used in multiplayer perceptions to give a method of adapting the weights first the forward phase is run like in a regular feedforward network then after the output and thus the error is determined the error is backpropagated from output layer through the network since we have multiple layers there is only a desired output of the network for the last layer to counteract this problem a gradient is calculated for every neuron during the backward pass the gradient is giving a measure of the contribution of this neuron to the final error the gradient is then used to update the neurons weights if the neuron is not part of the output layer the previous gradients are used to calculate the new gradient instead of using the error,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
371,"Explain back propagation, use the correct technical terms!",231,"back propagation consists of two steps 1. step - forward pass here the input data is fed into the network and the output is calculated at the output nodes the usual calculations of the induced local field are done by using this formula iv = sum we + be the output is then calculated using this formula my = f(v)$, where for is the activation function 2. step - backward pass here the error is backpropagated through the network from the output layer to the input layer in the output layer the error is calculated using this formula delta = i - you using the desired output i and the actual output ya in the layers before the output layer the local gradient is used to calculate the error using the error from the output layer delta = delta xu additionally the weights are updated using $w{new} = wold - learning\rate dot delta xu",backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
372,"Explain back propagation, use the correct technical terms!",231,back propagation is a learning algorithm for multiplayer neural networks at first the input is propagated through the network until the end is reached here the error is calculated with the desired results then the error is used to update the weights from the back to the front for the output layer the weights can be updated directly with the calculated error the following layers have to use the local gradient of the previous error which is calculated with the derivative of the activation function and its error this is then used to update the weights and repeated until the front is reached,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
373,"Explain back propagation, use the correct technical terms!",231,back propagation is used in multiplayer feedforward networks first the forward pass is computed the given error at the output nodes is used to compute the weight changes using widrow-hoff learning rule then the error is given back layer by layer in the backward pass to compute the error and weight changing for each layer recursivly. the learning can be done in sequential online or batch mode offline,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
374,"Explain back propagation, use the correct technical terms!",231,in multi layer of networks the error is only available in the last layer therefore the error is propagated back through the network using the backpropagtion algorithm in order to do so the local gradient has to be calculated update of the weight we = i + i * i * gradient where the put i is the output of the previous layer the local gradient is calculated differently depending if the neuron is in the output layer or in the hidden layer output layer $ gradient = phi`(x) * my do $ hidden layer $ gradient = phij`(x) * sum(wi * local gradient $,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
375,"Explain back propagation, use the correct technical terms!",231,in steepest gradient weights are adjusted in decreasing direction of error function but for hidden neurons there is no labels available to calculate the error hence final output error is backpropogated through the layers inside the hidden layers of nna this is possible with continuous activation function and chain rule on its derivatives final error is differentiated with respect to hidden weights chain rule is applied to find local error on hidden neurons,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
376,"Explain back propagation, use the correct technical terms!",231,the back propagation algorithm it consist of forward pass and backward pass computes the output of the neuron then it propagates in backward direction while recursive compute local gradient of the neuron weights are adjusted accordingly,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
377,"Explain back propagation, use the correct technical terms!",231,back propagation is the process of learning in multi layer perception in which the error from the output of the network is fed back into the network to adjust the weights in the hidden layer that is the error back propagates into the network to enable the network to learn by adjusting the synaptic weights based on it,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
378,"Explain back propagation, use the correct technical terms!",231,* back propagation is a process to make adjustment to the weights of a neural network in a way that minimizes the average squared error of the training data * it uses steepest decent method in each step it moves towards the direction that gives maximum decrease of the error * in back propagation the error is prepared backward from the last layer towards the earlier layers the adjustments made to the weights is proportional to the partial derivative of the error with respect to the weight * the partial derivative is calculated using repeated application of the chain rule,backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,1,2.0,neural_networks,neural_course,0.5
379,"Explain back propagation, use the correct technical terms!",231,"the idea of back propagation method is to propagate error from output final layer backward to hidden layers and adjust the weighs of neurons in hidden layer based of this error this is required because we do not have error information for hidden layers only for output neurons the error from output layer is propagated to hidden layers using idea from steepest descent method namely local gradients are computed for each neuron in backpropagation, and these local gradients define how error changes in terms of weights local gradients are derived from chain rule for each layer the fact that local gradient for each hidden layer is derived based on local gradient of a previous layer defines that as we propagate more and more in hidden layers of nna the gradient of a error function vanishes which means that as we go deeply back in nna the change in weights is becoming smaller and smaller this is a drawback of back propagation method",backpropagation lowers the error of a map level by level recursive backwards it back propagates an error from the last layer to the first layer by updating the weights the updates are determined by the local gradient at each level which is computed by partial derivatives of the error and chain rule,2,2.0,neural_networks,neural_course,1.0
380,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate controls the speed of the descent when learning rate is low the weight updating is overlapped and convergence is slow when the learning rate is high the weight updating is underdamped and a zigzagging behaviour is exhibited in the weight space when the learning rate is too large learning becomes unstable,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
381,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"if learning rate is very smaller then transition are over-damping, trajectory of weight vector follows the smooth path if learning rate is large then transition are under-damping, trajectory of weight vector exhibits the zigzagging(or oscillator behavior if learning gets higher than some threshold then learning algorithm gets unstable or diverged",learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,1,2.0,neural_networks,neural_course,0.5
382,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate i determines stride of delta of weight if learning rate is too large weights starts to ziggerate.,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,1,2.0,neural_networks,neural_course,0.5
383,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"when training with do the learning rate determines the step size we take towards the negative gradient when the learning rate is too small the weights may be overlapped and reach the error function minimum slowly eventually getting stuck in local minimal when step size is too big the weights may be underdampened, bouncing between ridges of the error surface and never find the minimum especially when the minimum is in a steep ravine of the error surface",learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
384,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,- learning rate is used to control how much the wright update is affected by the error correction or so on - learning rate too low learning is slow and takes more time - learning rate too high learning is fast but causes zigzagging behaviour in convergence - if the learning rate is too high it may result in situations where the zigzagging behaviour will cause it to overshoot and may never finally converge,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
385,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate defines the speed of the weight change a learning rate too high can lead to oscillation around the optimal weight such that its never reached a learning rate to low results in very slow learning and slow convergence,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,1,2.0,neural_networks,neural_course,0.5
386,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate is needed to make the algorithm more stable a high learning rate makes the weightchanges zickzacking and the algorithm might not converge a low learning rate makes the path in the plane more smooth if the learning rate gets to a certain critical value the algorithm might not converge at all,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
387,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"the learning create is a factor of how much we trust the datapoint. normally it is in the range of [0,1]. a high learning rate normally results in a faster convergence while a lower rate in a slower conversion if the rate is choose to high it is possible that the cost function divergent if the rate is to slow it is possible that the rate so conversion is so slow that we never reach a local minimum",learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
388,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate is a parameter using on updating the weights in a given iteration this parameter represents the importance that is given to the adaptation of the weights so when setting the learning rate small the learning machine will learn slower but also in a more stable way on the other hands when setting the learning rate with a large value the learning machine will learn faster but in an unstable way the danger here is that depending on the learning rate's value the algorithm may never come into the perfect value if the learning rate is too small it may land into a local minimum and never approach the global minimum of the function if the learning rate is too big the learning progression will have a zigzagging behaviour and never approach the ideal value,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
389,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,- the learning rate defines the size of steps that the method moves in the search space - if the learning rate is too small the method needs to take huge number of steps and maybe it stuck in a local minimal - if the learning rate is too big the method will converge very fast toward the global minimal but there is a probability that it oscillates around the global minimal and never reach it,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
390,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,if learning rate is to large then process will oscillate a lot and might not converge if learning rate is to small then convergence will happen very slowly,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,1,2.0,neural_networks,neural_course,0.5
391,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate tells us how confident we are of the error and it affect the convergence rate a low learning rate will slow the convergence making the system overdamped. a high learning rate will speed the convergence but the value oscillates making the system underdamped. the system can become unstable if the learning rate is above a threshold value,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
392,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,+ if the learning rate is too small then the system is overlapped and the algorithm takes a long time to converge + if the learning rate is too large then the system is underdamped and the algorithm oscillates around and optimal solution or could potentially make the system unstable,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
393,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the steepest descent method is an algorithm for finding the nearest local minimum of a function which presupposes that the gradient of the function can be computed the method of steepest descent starts at a point pa and as many times needed moves from pi to p(i+1) by minimizing along the line extending from pi in the direction of gradient f(pi) the local downhill gradient the danger of the algorithm is that it can get stuck in a local minimal,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
394,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate determines the rate of learning the smaller the leaving rate is the slower the learning process is but the path of weight adjustment is smoother the larger the value is the faster the leaving process is but it can result in oscillation and instability,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
395,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate is $\eta$ so based on the learning rate it undergoes various oscillation we could see zigzagging behaviours 1. when the learning rate is large the system is said to be under dumped 2. when the learning rate is small the system is said to be over dumped here we can see a zigzagging behaviour towards the convergence phase 3. after the learning rate crosses a certain value it becomes unstable it may stuck in a local minimal which is considered to be another danger,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
396,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate in steepest descent can directly affect the convergence of the algorithm if the learning rate is very small then algorithm can take long time to converge ice response is ovderdamped. but if the learning rate is made very high then we may observe zigzagging (oscillatory) behaviour and sometimes algorithm may fail to converge (underdamped response,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
397,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,here - when the learning rate is small the learning is very slow - when the learning rate is large the learning is unstable and can exhibit zigzag behavior - when the learning rate is too large the learning never converges,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
398,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"the learning rate defines the efficiency of learning machine if it is small the system response may be overdamped, if large , the response may be underdamped and if it exceeds a critical value the response may diverged the danger is the possibility of the system output to not converge this should be ensured by scaling the learning rate using the largest einen value of the correction matrix of the input",learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
399,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"the value of the learning rate parameter $\eta$ controls the speed of descent and convergence towards the optimal weight vector for small values of $\eta$, the transient response of the algorithm is overlapped and the weight trajectory follows a smooth path on the other hand if the value of $\eta$ is large the transient response of the algorithm is underdamped, and the weight trajectory follows an oscillator path in the w-plane.",learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
400,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"learning rate $\eta$ has a profound impact on the learning in steepest descent 1. if $\eta$ is too small the system is underdamped and convergence is slow 2. for larger $\eta$, the system is overlapped and tends to oscillates 3. if $\eta$ exceeds a certain critical value steepest descent may even diverged",learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
401,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate has huge impact on convergence of the network if the learning rate is low then the transient response of the algorithm is overlapped and the trajectory of want is smooth if the learning rate is high then the transient response of the algorithm is underdamped and trajectory of the want is zigzag if we choose the wrong learning rate then the network might not converge,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
402,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate controls the speed and convergence of steepest descent method 1. if it is small the trajectory of weight vector follows a smooth path in i plane 2. if it is large the trajectory of weight vector follows a zigzagging path 3. if it exceeds a critical value then the algorithm is unstable,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
403,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,1. large learning rate $\eta$ results in a zigzagging behavior but it can converge quickly 2. small learning rate $\eta$ results in a smooth behavior but it is slow to converge,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
404,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,* learning rate tells the network that how much steps it should move towards direction opposite to the gradient vector * if the learning rate is too large the weight updating will be high * so the danger is learning may oscillate or the network overdid the data,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
405,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate is used to regulate the speed of learning if the learning rate is small then the learning is slow and if the learning rate is high then it oscillates if it exceeds the critical value then the algorithm is unstable,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
406,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate is used to decide how fast the network should converge during the training phase if the learning rate is too high - the system oscillates and becomes overlapped too low - the system becomes underdamped and learns very slow,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
407,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate tells how long one step in the method of steepest descent is if the learning rate is too high the learning will oscillate and may not converge if the learning rate is too small the convergence will take many iterations,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
408,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,if we use steepest descent we use the learning rate to adjust the speed of the convergence to a minimum error if the learning rate is too small the learning is going on rather slow if the rate is high the error is zigzagging on the error surface towards the minimum if the learning rate is to high it might not converge but diverged,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
409,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate is a value between 0 and i which determines how fast the network learns when using small values for the learning rate the network converges slowly and needs lot of processing when choosing big values the learning oscillates and becomes unstable the goal is to choose the learning rate in a way that it does not learn to slow which needs more input data for convergence and that it does not become unstable,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
410,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate defines the speed of the learning convergence high values lead to faster learning und low values to slower learning however high values can lead to oscillations in the learning space and may overshoot the desired result and never reach it,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
411,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate gives the speed of learning it defines the stepwidth in direction of steepest descent if the learning rate is small the learning is more stable but slower when it is high the learning is more unstable but faster the danger is to overcome a minimum and result in oscillating behaviour,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
412,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,a too small leaving rate can lead to a very slow convergence or to no convergence at all if the time learn becomes too long a high learning rate can lead to an oscillating behavior and prevent convergence,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
413,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,learning rate is a scalar multiplied with adjustment term to adjust the weights it ensures the rate of learning it is typical greater than 0 and less than equal to 1. it covers the rate of sliding along the curve towards the minimal 1. lower learning rate will result in slow learning but chances of finding optimal minimal are greater 2. higher learning will result in hopping on either side of minimal hence zigzag behaviour 3. very high learning may not converge,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
414,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,if the learning rate is large then the it follows the zigzag motion if the learning rate is too low then it takes time for converging . if the learning rate is very large or critical then it becomes unstable while processing there is possibility that it will get stuck in local minimal,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
415,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,"when using steepest descent the learning rate($\eta$) determines the speed at which the weights are adjusted in the nna there can be two possible danger related to learning rate depending on its magnitude 1. low learning rate(eg, beta = 0.01$) results in smooth variation of the weights but makes the process becomes slow 2. hight learning rate beg beta = 0.01$) results in faster weight adjustment but it leads to an oscillator nature in the learning which is unwanted",learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
416,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,* with a small learning rate the network will converge very slowly towards the optimal weight of the network but it will give better performance in generalization * with a high learning rate there can be zigzag effect because of the large rate the network may miss a local minimal and jump to a higher point * with a very high learning rate the network may become unstable,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
417,"When learning using steepest descent, explain the role of the learning rate? What is a danger?",232,the learning rate defines the speed of steepest descent search for min of a error function in other words it defines how strong the change in weights will be throughout optimization procedure higher learning rate faster learning but then learning is characterized by oscillations in search for mind this is dangerous because if learning rate becomes bigger that a certain value it can make search with steepest descent unstable in this case steepest descent will start to diverged instead of converging to mind in other case when leaving rate is small that learning is slower but safer and the learning path is not oscilatory.,learning rate controls the speed of the convergence when the learning rate is low the convergence is overlapped and slow when the learning rate is high the convergence is underdamped and follows a zigzagging path when the learning rate exceeds a critical value learning becomes unstable,2,2.0,neural_networks,neural_course,1.0
418,How does a Reduced Boltzman Machine work (main idea)?,233,the reduced blotzman machine works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2,2.0,neural_networks,neural_course,1.0
419,How does a Reduced Boltzman Machine work (main idea)?,233,it is a recurrent network it operates by flipping it has two groups of neurons visible neurons and hidden neurons visible neurons provides interaction between environment and network hidden neurons are running freely it has two modes of operation . clamped state states of the neurons are clamped . free running state neurons are running in free condition,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2,2.0,neural_networks,neural_course,1.0
420,How does a Reduced Boltzman Machine work (main idea)?,233,,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0,2.0,neural_networks,neural_course,0.0
421,How does a Reduced Boltzman Machine work (main idea)?,233,"rum implement a combination of graphical and probabilistic ideas using probabilities of activation inspired from energy based networks we present a training input to the rum and determine the hidden activation based on a probability of net input and edge weights then when clamping the training data from the network sample from the distribution of the hidden layer where the rum tries to rebuild the distribution of the input data rum may be used for data completion or denoising, where edge incomplete images are completed based on the learned probability distribution",the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2,2.0,neural_networks,neural_course,1.0
422,How does a Reduced Boltzman Machine work (main idea)?,233,rum has two layers and are interconnected recurrent operates by flipping the internal states (+/- 1)> unlike the boltzmann machine reduced boltzmann machine does not contain interconnection among the same layer the weight update is done by the difference in correlation in clamped and free running model,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2,2.0,neural_networks,neural_course,1.0
423,How does a Reduced Boltzman Machine work (main idea)?,233,it consists of only two layers input and hidden layer during training data is presented to the input the hidden layer starts oscillating,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0,2.0,neural_networks,neural_course,0.0
424,How does a Reduced Boltzman Machine work (main idea)?,233,the reduced boatman machine is an stochastic recurrent anna that operates with two classes of neurons : hidden and visible it operates by neuron-flipping with a probability impacted by the neurons around so it uses the lesbian rule an reduced boatman machine can learn the classify data and can reproduce the learned patterns,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2,2.0,neural_networks,neural_course,1.0
425,How does a Reduced Boltzman Machine work (main idea)?,233,the strutted of rum is a bitpartied graph it uses lesbian learning for training and the neurons used are binary stochastic neurons which have a binary state which fire based on a probability the training is achieved by passing the information a many times between the hidden layer and the input layer there weightsare updated on the pass into the hidden layer weighs between input and activation in the hidden layer are increased weights between generated inputs of the rum and the hidden layer are decreased,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2,2.0,neural_networks,neural_course,1.0
426,How does a Reduced Boltzman Machine work (main idea)?,233,the main idea of an rum can be defined as follows - two layers will be defined where each neuron will be connected to every neuron of the other layer - the input will be passed from the first layer to the second one and the state of each neuron of the second layer will be calculated - the neurons with active states will pass again its values to the input layer - the values given from the second layer will be compared with the input values and with the two states the weights will be adjusted,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1,2.0,neural_networks,neural_course,0.5
427,How does a Reduced Boltzman Machine work (main idea)?,233,,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0,2.0,neural_networks,neural_course,0.0
428,How does a Reduced Boltzman Machine work (main idea)?,233,they are neural network with only one hidden layer neurons from input to hidden layer are fully connected neurons from hidden layer to output layer are fully connected as well,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0,2.0,neural_networks,neural_course,0.0
429,How does a Reduced Boltzman Machine work (main idea)?,233,"the reduced boatman machine works by flipping neurons it can operate in clamped or free running state - if two connected neurons are activated at the same time the weight is increased - if any of the two neurons are fired asynchronously, then the weight is reduced or removed",the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1,2.0,neural_networks,neural_course,0.5
430,How does a Reduced Boltzman Machine work (main idea)?,233,+ reduced boatman machines reduced because inputs do not share information via synapses are one of the initial nuns which consists of input layer and hidden layer the system adapts its internal weights and tries to reproduce the inputs,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1,2.0,neural_networks,neural_course,0.5
431,How does a Reduced Boltzman Machine work (main idea)?,233,a rum is a shallow two layer network containing a visible and a hidden layer each node in the visible layer is connected to each node of the hidden layer it is considered as restricted because no two nodes of one layer share a connection a rum is the mathematical equivalent of a two way translator in the forward pass a rum takes the inputs and translates them to a set of numbers that encode the inputs in the backward pass it takes the set of numbers and translates them back to form the reconstructed inputs a well trained rum will be able to perform the backward translation with a higher degree of accuracy three steps are repeated over and over through the training process i forward pass i backward pass i evaluate quality of reconstruction as visible layer often solved with al divergence,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1,2.0,neural_networks,neural_course,0.5
432,How does a Reduced Boltzman Machine work (main idea)?,233,,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0,2.0,neural_networks,neural_course,0.0
433,How does a Reduced Boltzman Machine work (main idea)?,233,,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0,2.0,neural_networks,neural_course,0.0
434,How does a Reduced Boltzman Machine work (main idea)?,233,rum is an unsupervised learning technique it has visible neurons and hidden neurons neurons are in either +1 or -1 states it uses the idea of simulated appealing to flip the neuron states based on energy function and pseudo temperature it operates in 2 states - clamped state and free flowing state in clamped state only hidden neurons are flipped and in free flowing state both visible and hidden neurons are flipped weights are adjusted based on average correlation difference between all the neurons in clamped and free flowing state,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2,2.0,neural_networks,neural_course,1.0
435,How does a Reduced Boltzman Machine work (main idea)?,233,,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0,2.0,neural_networks,neural_course,0.0
436,How does a Reduced Boltzman Machine work (main idea)?,233,"rims work on the principle of binary states free-running or clamped the weight update is done based on the botlzmann's formula using the pseudotemperature, which gives the probability of error",the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1,2.0,neural_networks,neural_course,0.5
437,How does a Reduced Boltzman Machine work (main idea)?,233,the reduced boatman machines function by using two types of neurons : visible neurons that provide an interface between the environment and he network an hidden neurons that operate freely the learning can proceed under two conditions namely 1. clamped state : where the visible neurons are clamped to a particular state of the environment 2. free running state : where both visible and hidden neurons operate freely if $\rho^+{ij}$ indicates the probability of correlation between the states of neurons i and i in clamped state $\rho^{-}{ij}$ indicates the probability of correlation between the states of neurons i and i in free running state then the weight adjustment delta w{ij} = beta (\rho^+{ij} - \rho^{-}{ij})$,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2,2.0,neural_networks,neural_course,1.0
438,How does a Reduced Boltzman Machine work (main idea)?,233,a reduced boltzmann machine (rbm) consists of two layers of neurons visible and hidden the neurons may only have two states idea activated or not and they flip according to a certain probability based on the weights and states of other neurons the rum has two modest 1. clamped the visible layer is clamped to a certain input while the hidden neurons are allowed to change state until the network settles the correlation in this state is given by $\rho{ij}^+$ 2. free-running: in this state the network is allowed to flip all neurons until it settles the correlation is $\rho{ij}^-$ the weight update rule is given by $$\delta w{ij} = beta (\rho{ij}^+ - \rho{ij}^-)$$,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2,2.0,neural_networks,neural_course,1.0
439,How does a Reduced Boltzman Machine work (main idea)?,233,boltzmann machines is a neural network having recurrent structure.it is in two states either on which is +1 or off which is -1.the energy function is given by we = 1/(1+exp(-delta e/temperature))$ the state of the input i is turned from +1 to -1 based on the change of the energy delta and the pseudo temperature to,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1,2.0,neural_networks,neural_course,0.5
440,How does a Reduced Boltzman Machine work (main idea)?,233,"the neurons operate in a binary states on or ""off"". in clamped condition all visible neurons are clamped into specific states by the environment in free running condition all neurons including visible and hidden neurons operate freely",the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1,2.0,neural_networks,neural_course,0.5
441,How does a Reduced Boltzman Machine work (main idea)?,233,it uses an energy function to oversee the learning process,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0,2.0,neural_networks,neural_course,0.0
442,How does a Reduced Boltzman Machine work (main idea)?,233,reduced boatman machine work based on flipping operation and calculating the probability variances of clamped state and freely running state,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1,2.0,neural_networks,neural_course,0.5
443,How does a Reduced Boltzman Machine work (main idea)?,233,rims run on boltzmann learning rule the neurons have 2 modes of operation clipped and free running all the neurons are binary units their status can be changed by flipping all the neurons that are in on position are clipped together,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1,2.0,neural_networks,neural_course,0.5
444,How does a Reduced Boltzman Machine work (main idea)?,233,it has the structure of recurrent neural network it has two layers of neuron visible and hidden the neuron can store only binary values they work based on flipping there are modes free running and clamped the weights are changes based on the correlation of the neurons in the free running mode and clamped mode,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1,2.0,neural_networks,neural_course,0.5
445,How does a Reduced Boltzman Machine work (main idea)?,233,in a reduced boatman machine there are one visible and at least one hidden layer the visible layer is the input and acts as output at the same time for each input the neurons of the visible layer will be assigned with a value with their weights hidden neurons may either be activated or not once the input has been passed through the hidden layers the values are passed all the way back to the visible layer for this different weights are used since the values move in the opposite direction,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1,2.0,neural_networks,neural_course,0.5
446,How does a Reduced Boltzman Machine work (main idea)?,233,in rims there are two states the free running and the clamped state during the clamped state the input neurons are clamped to the output neurons while the network is clamped the probabilities of the hidden states to be in a certain state are calculated to determine a probability of the output to be correct,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1,2.0,neural_networks,neural_course,0.5
447,How does a Reduced Boltzman Machine work (main idea)?,233,the reduced boatman machine hast an input layer and a hidden layer each neuron has a state and a probability to turn on if the neuron turns on the data passes trough it and the weights are updated the probability of turning on is calculated by the network,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1,2.0,neural_networks,neural_course,0.5
448,How does a Reduced Boltzman Machine work (main idea)?,233,two fully connected layers one input and one hidden layer are used the input layer is the only connection to the environment the rum has a specified energy level which can not be changed however the distribution of this energy to the nodes can be changed based on the data input every node has a chance to flip based on its input connections,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1,2.0,neural_networks,neural_course,0.5
449,How does a Reduced Boltzman Machine work (main idea)?,233,the binary state of each neuron is flipped by a given probability stochastic learning,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0,2.0,neural_networks,neural_course,0.0
450,How does a Reduced Boltzman Machine work (main idea)?,233,neurons have to states edge on or off each neuron has a probability to flip from one state to another,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0,2.0,neural_networks,neural_course,0.0
451,How does a Reduced Boltzman Machine work (main idea)?,233,,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0,2.0,neural_networks,neural_course,0.0
452,How does a Reduced Boltzman Machine work (main idea)?,233,the main idea of the rum is compute the least mean square error of the difference between expected output and real output,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0,2.0,neural_networks,neural_course,0.0
453,How does a Reduced Boltzman Machine work (main idea)?,233,,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,0,2.0,neural_networks,neural_course,0.0
454,How does a Reduced Boltzman Machine work (main idea)?,233,* it is a recurrent neural network * it uses two groups of neurons hidden and visible * it process the training data by flipping the neurons,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,1,2.0,neural_networks,neural_course,0.5
455,How does a Reduced Boltzman Machine work (main idea)?,233,reduced boatman machine is a departed two parts recurrent nna that has two layers visible and hidden layers in reduced boatman machine neurons can have two states namely + or - i depending on current time step at each time step the states of neurons are flipped here the visible layer represent interface for connection between environment and hidden layer and it operates in clamped mode limited values by environment while hidden layer operates in free model,the reduced boltzmann machine is a imparted graph which works by flipping the states of binary neurons based on a probability determined by the activation produced at the neurons neurons are arranged in a visible and a hidden layer in a recurrent fashion there are two states involved called the clamped state in which the visible neuron is connected to the input and a free running state in which both layers run free,2,2.0,neural_networks,neural_course,1.0
456,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state network is a type of recurrent neural network and has atleast one cyclic feedback connection en consists of a dynamic reservoir and a output layer with neurons the dynamic reservoir consists of randomly initialized neurons with random structure and connections with atleast one feedback connection the output layer combines the dynamic behaviours of the reservoir in a required fashion only the weights of the output neurons are updated while learning an en consists of feedback connections while a of in does not an en could have persisting activation even when there is no input which is not the case in of nna an en can approximate dynamic systems while a of in cannot,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
457,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"echo state network are recurrent neural network which means these networks have feedback while in feedforward neural networks there is no feedback in feedfoward, training data or inputs are not dependent on each other they do not have any system memory in sense training inputs are dependent on each other and they have system memory in echo state network there are fixed random generate reservoir weights these weights are not trained while only output weights are trained",echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
458,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,an en is a recurrent neural network with many layers and fixed weights there are several differences an en has a cycle that means within the network there are backwards connections with a of in there are only feedforwad connections within a of in all weights are trained within an en only output weights are trained an en can produce an output without any input a of in needs an input to produce an output,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
459,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en are different to finn in so far that they consist of a reservoir of hidden neurons which may be connected recurrent as opposed to having a feed forward architecture here the inputs are connected to the recurrent dynamic reservoir whereas the do is connected to the linear output layer the output layer may be again connected to the dry whereas during training only weights of the last layer are learned weights of the do of the en are thus initialized and never learning although since have been extended to minimal complexity architecture,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
460,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"en are recurrent neural networks with a large reservoir for echo chamber with many nodes (recurrent). the weights are learnt only for the connection between this reservoir and the output layer the weights are not learnt for the nodes inside the reservoir the main idea is that during training the input layer cases the states inside the reservoir to behave in certain way and the weights in the output layer is adjusted to match this and the labelled output finn are feed forward networks i.e., they do not have any recurrent connections which is the main difference with respect to en",echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
461,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"eons are a special class of recurrent neural networks in contrast to of they also allow backward node connections and thus are able to memorize data they are defined by exit input i yi output i a dynamic resaviour, and weights connecting all the components the dynamic behaviour is generated randomly and fixed its topology including weights is never changed only the weights between output layer and dynamic behaviour are changed during training because the dynamic behaviour allows all kinds of connections between its nodes it can contain memory that is able to remember data it also has a spectral radius",echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
462,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,an en is a recurrent ann with random sparse and fixed interferon connections in the hidden layers just the output layer weights get trained because the network itself is so complex it can model very much if the training was not successful we can just create a new random end training an complete en would by very complex and would take very very very long a of in is not recurrent no feedback and all its weights get trained and most of the time the interferon connections are not sparkly,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
463,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,a echo state network is a run is has a dynamic reservoir of neurons which are connected with each other and itself the do typically consists of more that 100 neurons the outputlayer consists of linear readouts of the dry so a neuron in the output layer sums up the weighted behaviours of the do neurons the do is randomly initialized and only the output layer is trained by supervised learning the main difference is that en is a run in contrast to finn it can resemble any dynamic system usually it is used for time series prediction,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
464,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"echo state networks are a type of recurrent neural networks where the input layer is interconnected to a reservoir a random initialized group of neurons with also random interconnections), and this reservoir is connected to the output the reservoir will not be adjusted but the output weights the output weights can also have recurrent connections with the reservoir the states on the reservoir neurons will be calculated and with these states and the output weights the output will be extracted the main difference with the feed forward neural networks off nna is that in the ff-nns there's no recurrence so the input values will be passed to the next layer",echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
465,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"- in the en we have a huge recurrent network which is called dynamic reservoir(dr)"" and we have an output layer connected to this do and we will train the network by adapting and manipulating the connection weights just to the output layer - unlike a feedforward network in a en because of the do we have at least one loops that returns the output of a neuron with some time delay therefore we have memory in our network but in of nuns we don't have any memory",echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
466,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state networks are recurrent neural network type meaning there are feedback in its structure it is usually only i connected main difference is that it has a reservoir as a hidden layer where neurons are very randomly connected with random weight etc during learning phase only weight outpouring neurons are changed it is required more that 100 neurons to be in a reservoir,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
467,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,the en is a type of neural network model that uses a recurrent neural network as a large random fixed dynamic reservoir that remains unchanged during training and only changes the weight of the reservoir to output layer,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1,2.0,neural_networks,neural_course,0.5
468,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,eons are a form of recurrent neural networks with a least one recurrent input the eons are reservoir computers which have memory and can be activated without the inputs in sense instead of training we evolve the network state by feeding it input sequence eons are different from of nuns because eons contains at least one recurrent connection (feedback).,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1,2.0,neural_networks,neural_course,0.5
469,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,the basic idea of eons is to use a large random fixed recurrent in preferred to as dynamic reservoir and to train only connections from the reservoir to the output the main difference to of in lies in the recurrent part of the network where back passes are built in giving feedback previous layers it is not possible to maintain the reservoir beforehand so it suits the given problem there is a lack of investigation of reservoir construction,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
470,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,an echo state network (esn) is a modified version of a recurrent network it has a reservoir which is a large number of hidden neurons with sparsely-connected random and fixed weights to train an end only the weights connecting the reservoir and the output layer are adjusted therefore the efficiency is better than a normal recurrent network,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1,2.0,neural_networks,neural_course,0.5
471,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state network provides structure and supervised learning for recurrent neural networks it mainly i directs the fixed large recurrent neural networks by providing an input stimuli and also fix a response signals to the neurons which are present inside the reservoir(pool of neurons i it can be directed to get the desired response by the traceable linear combined of the response signals unlike of nose isn't have memory they can be also activated without an input stimuli whereas in case of of nna they require a external stimuli so that they are activated also the neurons needs to connected in one full cycle,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
472,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state newtons are type of run it has dynamic reservoir units which exhibits different dynamics weights of these reservoir units are fixed and are not changed during the training phase only the reservoir to output weights are changed to learn the inputs these networks converge only if reservoir units exhibit echo state property ice its output depends only on the previous inputs this property is satisfied if spectral norm reservoir weights is less then 1.,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
473,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,here - echo state networks are recurrent neural networks that have a large reservoir of oscillator functions that are connected to the input layer - in of nose considerthe outputs at the hidden layers are also considered but in sense the outputs from the reservoir to the final output layer are only considered,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1,2.0,neural_networks,neural_course,0.5
474,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en are another implementation of runs where training method is completely different they comprise of a dynamic reservoir with fixed hidden to hidden connections which makes up an run with sparse connectivity only the output weights which connect the dynamic units and the output of the reservoir are trained using error unlike runs where the hidden weights are also trained eons are less computational expensive since they can be easily trained with experimentation however runs use much less hidden units compared to en for a similar task,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1,2.0,neural_networks,neural_course,0.5
475,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,an echo state network (esn) is a neural network that uses a recurrent neural network (rnn) as dynamic reservoir which is not changed during training and trains only the connection from the dynamic reservoir to the output layer an echo state network is different from of nuns due to the presence of feedback connection with the dynamic reservoirs which enables it to maintain activation even without inputs each unit within the dynamic reservoir in eons are excited differently to different inputs,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
476,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,eons are recurrent neural networks with at least one cyclic connection and are based on the concept of reservoirs in contrast of nuns do not have any cyclic connections additionally in en the output weights are trained but the reservoir weights are not whereas in of nuns all weights are trained the en has memory while of nuns do not have memory,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
477,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en refers to echo state networks echo state networks are the recurrent neural networks where the hidden to hidden layer weights are selected randomly and are fixed and hidden to output layer weights are changed by the learning process.since en is recurrent neural network hence the output echoes through the network even when there is no input where as in of nets there is no feedback so there is no output if there is no input,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1,2.0,neural_networks,neural_course,0.5
478,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"en is a kind of recurrent nna which has a large random , fixed run called dynamic reservoir and only the weights connecting the reservoir and output layer are trained so en combine the desired system function and input/output history echo function",echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1,2.0,neural_networks,neural_course,0.5
479,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en provides an architecture of supervised learning principle for runs it is different from of nose because it has a reservoir based on runs to find a non linear signal response and combine the desired output by a traceable linear combination of these response,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1,2.0,neural_networks,neural_course,0.5
480,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,* echo state networks are recurrent neural networks with dynamic reservoirs.** * weights initialized in the dynamic reservoirs will not be updated during training * only the weights in output layer readout states is updated after each iteration * in of nna all neurons are connected with other neurons in next layer and all the weights are updated in each iteration * but in end the neurons are connected randomly with other neurons and it is **recursive** and the weights are not updated in the dynamic reservoir,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
481,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en is a type of run it has a dynamic reservoir all the neuron are connected to each other,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1,2.0,neural_networks,neural_course,0.5
482,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,the echo state network has a large number of recurrent neural network in them this set of run is called the dynamic reservoir they can approximate any dynamic model they train the model by changing only the weights of the connection of output of the dynamic reservoir and output of the network of they can approximate any continuous function they train by adapting all the weights in the network,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
483,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,an echo state network contains of an input layer which is connected to a reservoir which is a big recurrent network the output layer is connected to the neurons of the reservoir while learning in an end only the weights between the reservoir and the output layer are changed no changes within the reservoir differences to feed forward networks are that the reservoir is recurrent and that during the training not all weights are changed but only the ones between output layer and reservoir,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1,2.0,neural_networks,neural_course,0.5
484,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,in contrast to regular feedforward networks en belongs to the group of recurrent neural networks it has a regular input layer like the of then comes a dynamic reservoir which is a layer of neurons where at least one full cycle of connections between the neurons is given the connections inside this reservoir are not constrained and can thus be any possible connection this reservoir is randomly initialized and kept that way only the respective connections to the output layer are trained during the learning process,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1,2.0,neural_networks,neural_course,0.5
485,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en have an input layer connected to a reservoir which is a recurrent neural network the reservoir is connected to the output layer on the connections to the output layer are weights which are updated by the network the weights of the reservoir are chosen randomly and not updated at all,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1,2.0,neural_networks,neural_course,0.5
486,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,an en is a recurrent neural network that consists of an input layer a dynamic reservoir and an output layer in the dynamic reservoir feedback loops are possible in contrast to a feedforward network however this dynamic reservoir is only randomly initialed and not learned only the connections to the output from the reservoir are learned normally in of nuns all connections are trained,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1,2.0,neural_networks,neural_course,0.5
487,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state networks have dynamic reservoir as hidden layer the dynamic reservoir consists of recurrent nonlinear neurons only the linear connections from dynamic reservoir to the output layer are trained the difference to of in is that the en is a recurrent network,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1,2.0,neural_networks,neural_course,0.5
488,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,the core of an en is an arbitrary network with recurrence,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,0,2.0,neural_networks,neural_course,0.0
489,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,echo state networks have dynamic reservoir with echo state property which is a randomly initialized run hence it can maintain its own internal state which is not possible in of nna run have feedback connections which echoes back the state of reservoir as well as previously applied inputs hence it can model dynamic systems which not possible with funny,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,1,2.0,neural_networks,neural_course,0.5
490,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,en are the run recurrent neural network which has at least one feedback cycle of in are normally forward moving networks where the input from one layer is fed into next layer and generated the output . but in en the out put is again fed back as input . en is tend to have revoir where its randomly connected,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,0,2.0,neural_networks,neural_course,0.0
491,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,"echo state network is a type of neural network which has a recurrent network of 100 to 1000 neurons called dynamic reservoir as the hidden layer the weights are choose randomly the synaptic weights from the reservoir to the output layers are only adjusted during the learning process they are different from the of nuns in the following regards 1. en have atleast one loop whereas the of nuns dont 2. only the output weights are adjusted in en , in of nuns both the input and output weights are adjusted 3. en i have a memory of nuns dont",echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
492,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,* en uses a large set of recurrent neurons called reservoir * the weight of reservoir neurons does not change after initialization * the network only years the weight of reservoir to output * it works very well for one dimensional time series data the feed forward networks works differently the input is feed through the network layer by layer and error is prepared backward to make the adjustments till the first layer in case of en the adjustment is made to the reservoir to output weight only,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,2,2.0,neural_networks,neural_course,1.0
493,"Define: Echo State Network (ESN), how are they different to FF NNs?",234,,echo state network is a type of recurrent neural network and has at least one cyclic feedback connection only the weights of the output layers are updated while learning en consists of feedback connections while a of in does not en can approximate dynamic systems while of in cannot,0,2.0,neural_networks,neural_course,0.0
494,Describe: the structure on an CNN.,235,in a convolutions neural network the layer order is 1. convolutions layer has kernels which involve over the input image incase of first layer or feature maps otherwise 2. activation layer rely activation 3. pooling layer max or average pooling these 3 layers can be repeated any number of times 4. finally one or more fully connected layers followed by softmax layer,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2,2.0,neural_networks,neural_course,1.0
495,Describe: the structure on an CNN.,235,in can there are mainly three layers i convolutions layer it is used to capture the low-level and high level features using kernel over the image ii pooling layer it is used for dimensionality reduction and for translation variance iii fully connected layer this layer is same as regular nose where all the nodes are fully connected with each other there is mostly sigmoid activation function is used to compute the probabilities of each output/class. furthermore in cans we use rectified linear unit(relu) activation function,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2,2.0,neural_networks,neural_course,1.0
496,Describe: the structure on an CNN.,235,a convolutions neural network has a kernel which is much smaller than the input this is why it can operate much more efficient than a normal neural network normal neural network on times my convolutions neural network o ( i $ times $ kid i is much smaller than my a convolutions network operates no large images the input is repressed in many layers before it is given to a normal neural network reprocessing transforms input into a linear separate problem,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
497,Describe: the structure on an CNN.,235,"can learn on grid data images ad volumes using filters instead of matrix multiplication here the filters are convoluted with the input in the convolutions layer per neurons where we slide the filter defined by filter size $s\times so over the input with a stride step size and optional zero padding strictly speaking since for rob images we are working have three color channels we work with volumes of filters for example for rob images of size $32\times 32\times 3$, a filter of window size $s=5$ has the dimensions $5\times5\times3$). instead of learning a volume of weights for each convolutions step we share weights considering that one feature detected in one part of the image may be of interest in another part then we apply a nonlinearity, commonly the rely activation as to introduce nonlinearity into our model to reduce spatial size of our input we can either use higher striped convolutions layers or pooling layers for example the popular max pooling layer where the maximum value over a subvolume is picked these layers are then stacked while in the last layers fully connected neurons are typically used to reduce data to for example a classification vector",convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2,2.0,neural_networks,neural_course,1.0
498,Describe: the structure on an CNN.,235,a can uses convolutions instead of matrix multiplication after this there is a non linearity which may be a function like relax there is also a pooling stage which is used to pool the important features cans are translation invartiant.,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
499,Describe: the structure on an CNN.,235,a convolutions neural network consists of convolutions layers a convolutions layer applies one or multiple kernels matrix to an input vector/matrix typically image instead of connecting all single inputs of the input vector to the next layer with separate weights instead in training only the kernel is updated after a convolutions layer there is typical a pooling layer given a window size it reduce the dimensional size of the output of the convolutions layer by using edge max or ave pooling afterwards the activation layer applies an activation function to the output of the pooling layer in the end of a can there are typically some fully connected regular layers resulting in a softmax activation function which assigns the probabilities to the classes output,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2,2.0,neural_networks,neural_course,1.0
500,Describe: the structure on an CNN.,235,an convalutional neuron network assumes the input is an image because of that it has a architecture so that there are (abwechselnt) coalition and subsampling layers after the last subsampling layer there is a normal of in which classify the input,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
501,Describe: the structure on an CNN.,235,a can typically consists of multiple can layers and a few fully connected of network layers i'll assume the fully connected part is not so relevant to this questions a can layer is typically a convolutions layer and a pooling layer in the convolutions layer a kernel is involved onto the input if zero padding is used the result is in the same dimensionality depending on the kernel the convolutions can be i 2 or do in the pooling layer the result of the convolutions is reduced to focus ont the important features it also helps on transnational invariance.,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2,2.0,neural_networks,neural_course,1.0
502,Describe: the structure on an CNN.,235,a convolutions neural networks has the following structure - the input is defined in a grid so any image or video sequence will be used - a several number of convolutions layers where also subsampling pooling can be used - in the convolutions steps a filter will be used for each layer - after applying multiple convolutions layers a normal feed-forward networks can be applied where for example a back propagation algorithm can be used for updating the weights in the numerous iterations,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
503,Describe: the structure on an CNN.,235,a can network consists of - input layer - conclusion layer - detection layer - pooling layer - next layer(because can consists of many layers this will be another block of layers similar to what described,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
504,Describe: the structure on an CNN.,235,"convolutions neural networks are so that first layer is not fully connected but in a way that neuron connections overlap leading to a grid type structure with overlapping circles another layer is connected only with nodes that are responsible for a particular feature (convolutions), then next layer is choosing with of those convolutions from each ensemble is the most appropriate after that next layer is fully connected to output neurons",convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
505,Describe: the structure on an CNN.,235,- the can has an input layer - the input layer is connected to a convolutions layer consisting of three phases - convolutions stage - detector stage - pooling stage - the next layer can be a traditional funny,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
506,Describe: the structure on an CNN.,235,cans are feed forward neural networks which replaces matrix multiplication task with convolutions operation which is much sparse can contain following stages + convolutions learns local features + max pooling (coarse-graining to learn better abstraction of input image,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
507,Describe: the structure on an CNN.,235,in comparison to other nna in can matrix multiplication is replaced with convolutions everything else remains the same,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,0,2.0,neural_networks,neural_course,0.0
508,Describe: the structure on an CNN.,235,an can (covolutional neural network contains a set of hidden layers for feature extraction (convolutional layers pooling layers and fully-connected layers that classifies the features the covolutional layers are used to carry out the revolution between the incoming signals with a set of filters resulting in a set of feature maps the pooling layers are used to reduce the dimensionality of the feature maps and make the features variant of rotation or displacement,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
509,Describe: the structure on an CNN.,235,a can 1. starts with a input where we perform the convolutions which provides a piece of activation 2. next it is being sent through the activation layer otherwise known as the detection layer 3. then the final stage is the pooling,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
510,Describe: the structure on an CNN.,235,in can we have different kernels which are used for extracting certain properties of the inputs these are called feature maps after this there is a detection phase which introduces non-linearity. further there is pooling which introduces transnational invariance. there can be many such layers of feature maps and pooling finally its reduced to single row input and trained using traditional methods like back propagation algorithms,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2,2.0,neural_networks,neural_course,1.0
511,Describe: the structure on an CNN.,235,here convolutions neural networks have 4 main layers where input layer is connected to convolutions and subsampling layers followed by another set of convolutions and subsampling layers connected to the output layer they are designed to specifically recognize and shapes are variant to skewing rotation and the actual location of the object,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
512,Describe: the structure on an CNN.,235,can comprises of multiple layers of neurons which perform specific tasks the initial layer is the convolutions layer which performs convolutions of the input with the elements of a given kernel simpler tasks such as edge detection are performed detector layer forms a second layer here the output of convolutions layer if fed through an activation function such as relax further the data is pooled in the pooling layers where downsamping is done to reduce dimensionality these layers are repeated to perform more complex feature extraction operations,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
513,Describe: the structure on an CNN.,235,a can is a neural network that replaces matrix multiplication with a mathematical operation called convolutions in one or more layers the main idea behind the structure of a can is to replace the activation of neuron with a flipped filter convolutions layer and then apply another function called pooling to dust the output further,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
514,Describe: the structure on an CNN.,235,a can consists of several stacked convolutions layers which can be separated by other layers such as pooling activation zero-padding and dropout which is a form of regularization the output layer is generally dependent on the task but could be a softmax activation from a fully connected also called densely connected layer the number of outputs is usually the number of classes,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2,2.0,neural_networks,neural_course,1.0
515,Describe: the structure on an CNN.,235,"the structure is as follows convolutions in this layer convolutions takes place instead of matrix multiplication -deconvolution: in this layer deconvolution takes place , by matrix multiplication average weight layer this is a max pooling layer",convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
516,Describe: the structure on an CNN.,235,1. first stage the layer performs several convolutions parallel to produce a set of linear activation 2. detector stage each linear activation is run through a nonlinear activation 3. third stage use a pooling function to modify the output of layer,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
517,Describe: the structure on an CNN.,235,1. convolutions or matrix multiplication it produces output to hidden layer 2. deconvolution matrix multiplication by transpose matrix apply back propagation error for output to input 3. weight update apply back propagation error from output to weight,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
518,Describe: the structure on an CNN.,235,* input layer * convoluted layer caffeine transformation * filtering layer sampling * learning layer * output layer,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
519,Describe: the structure on an CNN.,235,can has basically four types of layers they are convolutions layer rely layer pooling layer and the fully connected layer we can arrange the convolutions layer and rely layer in different ways one of the ways is to have 1 convolutions layer 1 pooling layer 1 rely layer and repeat this 3 layers again and then finally a fully connected layer another way is to have 1 convolutions layer 1 pooling layer again repeat the convolutions and pooling layer and then 1 rely layer and finally fully connected layer convolutions layer is used to find the feature space,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2,2.0,neural_networks,neural_course,1.0
520,Describe: the structure on an CNN.,235,the can will have a input layer convolutions layer - here the convolutions and sub sampling of the feature maps take place feed forward - neural network layer output layer,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
521,Describe: the structure on an CNN.,235,a convolutions neural network uses the steps of convolutions and subsampling alternating in the beginning using different kernels during convolutions many feature maps are created the subsampling step merges the maps to reduce their amount after some of these steps a classical feed forward network is in the end to transform the different feature maps to one output layer,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
522,Describe: the structure on an CNN.,235,a concolutional neural network has alternating layers of convolutions and pooling the convolutions layer is applying a filter to the input while the pooling layer sub-samples the input in some networks this is replaced by striped convolutions which combines these two steps into one the structure at the end of a can is equal to that of a regular feedforward network,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
523,Describe: the structure on an CNN.,235,,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,0,2.0,neural_networks,neural_course,0.0
524,Describe: the structure on an CNN.,235,a basic can can be structured into the three layers convolutions detector and pooling in the first layer the convolutions operation is performed on the inputs in the second layer the the activation function mostly relax is applied to the result of the convolutions the last layer can be used to reduce the size of the resulting convoluted images edge by max pooling,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2,2.0,neural_networks,neural_course,1.0
525,Describe: the structure on an CNN.,235,convolutions neural network it has often images or video sequences as input the input is computed by convolutions with different kernels and downsampling in many steps to smaller but many more input matrices in last step the matrices are connected to a classical of nna,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
526,Describe: the structure on an CNN.,235,a can consists of one or more convolutions layers as well as subsampling or pooling layers followed by a fully connected standard find in the convolutution layer kernels are used to create feature maps a kernel is smaller matrix that is applied to all possible positions on the input matrix in the pooling stage the dimension of the feature map is reduced for example by max pooling,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
527,Describe: the structure on an CNN.,235,can uses convolutions layers to extract primitive information from pattern first data is involved with the first layer to extract some features output of this layer is passed through rely function to rectify it then is downsampled by pulling layer it basically chooses only relevant outputs of convolutions layer for further processing rely is chosen instead of sigmoid because it doesn't allow gradient to vanish in backpropogation.,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2,2.0,neural_networks,neural_course,1.0
528,Describe: the structure on an CNN.,235,can is has multiple layers and they dont use multiplication matrix,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,0,2.0,neural_networks,neural_course,0.0
529,Describe: the structure on an CNN.,235,convolutions neural network(cnn) has three main layers in them 1. convolutions layer 2. pooling or subsampling layer 3. output layer,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,1,2.0,neural_networks,neural_course,0.5
530,Describe: the structure on an CNN.,235,can has three components * input * convolutions stage * feed forward network in can the input pass through one or more convolutions stage befor it is feed into a feed forward network the convolutions stage uses a hierarchical set of filters rely and polling to extract low level as well as high level concepts from the input the feed forward network along uses the output of the convolutions stage and back propagation is used to make adjustment to the network weights as well the filters in the convolutions stage,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,2,2.0,neural_networks,neural_course,1.0
531,Describe: the structure on an CNN.,235,,convolutions neural network consists of many layers such as a convolutions layer that has kernels which involve over the input image an activation layer rely activation pooling layer max or average pooling and one or more fully connected layers followed by softmax layer,0,2.0,neural_networks,neural_course,0.0
532,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,three items to learn in a rbfn: 1. centroid of the input clusters 2. widths of the clusters 3. weights of the synapses connecting the hidden layer and the output layer the centroid and widths are learned in an unsupervised fashion while the weights in a supervised fashion so an run combines unsupervised and supervised learning while a regular in is completely supervised or completely unsupervised learning is fast and is not so sensitive to the unsupervised part,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2,2.0,neural_networks,neural_course,1.0
533,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,in ref network we need to learn **centre** and **width** of gaussian function we also learn output weights difference between ref and nose i in raft there is only one hidden layer while in nose there can be more than one hidden layer ii in raft activation function of hidden layer is gaussian so parameters are in euclidean norm while in nose parameters for activation function are product of weights and inputs iii parameter computation is different in ref as compute to other nose like we compute centre of cluster in ref with the help of means clustering,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2,2.0,neural_networks,neural_course,1.0
534,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,ref network need to learn center of activation function difference to other in is that there are as many activation functions as data points one con of radial basis function is that due to many activation function ref networks have a huge computational effort,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
535,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,in raft we learn the centers of the radial basis functions using unsupervised clustering methods the weights of the last output layer and the width of our radial basis functions as opposed to multi layer nna we dont need expensive backpropagation as we only need to train the last layer while the unsupervised training algorithm does the work the ref centers a possible con would be that if the ref centers dont represent the training data point distribution well some data points may be hard to model,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2,2.0,neural_networks,neural_course,1.0
536,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,1. weights 2. centres for means of clusters 3. $\sigma$ which is the width of the clusters difference uses functions which are radically invariant. pros - easy to learn - non-linearity - only dependent on the radial distance cons - data required is more - overfishing,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2,2.0,neural_networks,neural_course,1.0
537,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,an ref network relies on a clustering algorithm this can be edge means clustering the three items to be learned 1. cluster center 2. cluster size 3. weights connecting the hidden nodes to the output layer difference to other nose - only three layers input hidden and output - each node in the hidden layer uses a different activation function depended on the cluster assigned to it - only output weights are trained,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2,2.0,neural_networks,neural_course,1.0
538,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,if a ref network used a gauss function as the activation function these thinks have to be learned - centroid acid unsupervised - sigma unsupervised - weights of the output layer supervised the ref network is easy learning and not so sensitive to the unsupervised learning part,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2,2.0,neural_networks,neural_course,1.0
539,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,this question is really unspecified difference to other nns... - centers - widths - weights the main difference is that the ref uses localized activation functions and it has only one hidden layer it apply a nonlinear transformation from the input space to the hidden space and a linear transformation from the hidden space into output space it is important to use regularization for ref ref work well for interpolation so it should work good for regression,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2,2.0,neural_networks,neural_course,1.0
540,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,a radial basis function network has the following structure - an input layer - a hidden layer where a nonlinear dimensional transformation will be used - each neuron of the hidden layer will have a defined center extracted in previous steps - a linear transformation will be used to the hidden data space and the output will be calculated so the three items that must be learning in the ref networks are - the centers of each hidden neuron using for example means neighbours algorithm - the radial function that will be used for the nonlinear transformation - the weights applied into the output layer,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2,2.0,neural_networks,neural_course,1.0
541,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the three items that must be learned in refs are - the center of the kernel - the size(standard deviation of the kernel,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0,2.0,neural_networks,neural_course,0.0
542,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0,2.0,neural_networks,neural_course,0.0
543,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"- use distance to center as argument for computation of local fields - use radial basis functions as activation - ribs are only global approximators, - splitter learning instead of global learning",three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
544,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,+ kernels + only neighbourhoods are computed based on distances + radius of neighbourhoods pros + ref are simple and easy to computer cons + they remember the data points,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
545,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,differences are * run has a single hidden layer nonlinear hidden layer * linear output layer * argument of hidden units euclidean norm * universal approximation property local approximators. * splitter learning,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
546,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the mean of the i clusters the,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0,2.0,neural_networks,neural_course,0.0
547,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the three items that needs to be learnt are the centers widths and depth compared to other in they have a standard 3 layer structure they can have just one hidden layer,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
548,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,in ref first inputs are transformed to higher dimension using non linear transformation this is based on unsupervised learning inputs are then learned using least square estimation which is an supervised learning ref is based on covers theorem which states that there is higher probability that data will be nearly separate in higher dimension,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0,2.0,neural_networks,neural_course,0.0
549,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"here - refs are only dependent on the radial distance i.e., distance from the center to the input",three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0,2.0,neural_networks,neural_course,0.0
550,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"the three parameters to be learned generalized ref are i cluster centers of the basis functions i spread or the width of the basis functions $\sigma$ , and i weights of connecting the input and the hidden layers ref are different from nuns in different ways i the kernels are localized functions where as nuns are globalized i they use euclidean distance in their activation functions where as nuns use inner products i they have a single hidden layer and output is a linear combination but nuns compulsorily are not the same",three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
551,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0,2.0,neural_networks,neural_course,0.0
552,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the three open parameters of an ref network are 1. the centers acid 2. the widths $\sigmai$ and 3. the weights win the number of centers sky has to be determined by trial and error,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
553,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,in ref the main advantage is that it follows cover's theorem and the complex pattern classification problem can be solved .,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0,2.0,neural_networks,neural_course,0.0
554,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,1. nonlinear transformation function from input space to feature space 2. centers of input data that is used for each hidden neuron 3. synaptic weights connecting hidden layer and output layer,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
555,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,-,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0,2.0,neural_networks,neural_course,0.0
556,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,three items to be learned * origin * center pros * it can transform data from i dimension to infinity dimension * it can solve non linear problems easily cons * it may overbite * learning is slow,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
557,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,center of the hidden neurons synaptic weights connecting the neurons and refs have only 1 hidden layer there is a nonlinear transformation between the inputs and the hidden space and a linear transformation between the hidden space and the output space pros it can be used for non-linearly separate data,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
558,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,1. weighs in the network 2. the center of the clusters 3. variation of the cluster ($\sigma$) difference ref always have only three layers ref can also trained in an unsupervised method ref can also approximate any continuous function,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
559,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,- the centroid of the radial basis functions - the weights of the neurons - the amount of needed neurons a difference to other neural networks is that the centroid of the radial basis functions need to be there,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
560,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the centers of the clusters the widths of the clusters and the weights in contrast to other nuns the output only depends on the radial distance to the center of the clusters,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
561,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the weights the interpolation matrix have to be learned the ref maps the input space into a higher dimensional feature space nonlinearly. the feature space is mapped into the output space linearly. the output space is much smaller than the feature space pros local learning cons feature space can be really large curse of dimensionality,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
562,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the clusters the width of the basis function and the weights the clusters and the width are learned in an unsupervised fashion while the weights are learning by a standard supervised steepest descent method pros refs can be very easily trained refs can achieve better results with less complexity cons not as easy to understand,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2,2.0,neural_networks,neural_course,1.0
563,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,centers of the radial basis functions best model (rbf) distance of each input pair pros nonlinear functions application ease to compute using covers theorem cons high-dimensional,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
564,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,centroid width and parameter of function the learning of an run is splitter in an unsupervised and a supervised part only one layer no vanishing gradient pros easy learning the unsupervised part is not very sensitive cons difficult to approximate constants,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2,2.0,neural_networks,neural_course,1.0
565,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"1. input layer connecting ref to environment 2. hidden layer nonlinear transformation of input space to hidden space 3. output layer linear transformation of hidden space to output space it is different than other nuns because for learning patterns it nonlinear transforms the input space to higher dimensional space other nuns do not transform input as it transforms input patterns to high dimensional nonlinear space patterns which are not separate in lower dimensions have greater chance to be separated but if we select basis functions equal to datapoints, problem is ill-formulated. processing is computationallly heavy regulation becomes problem specific hence unsupervised learning is employed to clusters data initially",three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
566,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,"data variance features ref uses support vector machine which is classifier it uses different kernels , it doesn't have feedback cycle it also classifies non linear classification problem it mainly works with 2 classes ca ,c2. other in is can also regression and there can be feedback (rnn)",three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0,2.0,neural_networks,neural_course,0.0
567,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,the difference of ref to other nuns are 1. ref has only one hidden layer whereas their is no hard limitation on number of hidden layers on other nuns 2. the activation function used in ref is non linear,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,1,2.0,neural_networks,neural_course,0.5
568,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,a ref network learns * the radial function * weight of the hidden to output neuron * centroid of a cluster difference * a ref is composed of input layer 1 hidden layer and the output layer other in can generally use as many hidden layers as required * the transformation from input to hidden layer in ref is non linear and hidden to output is linear in most other in both are non linear pros/cons: * this is a very simple learner * there are many variations of ref available,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,2,2.0,neural_networks,neural_course,1.0
569,"What are three items to be learned for an RBF network? Difference to other NNs, Pros/cons?",236,,three items to be learned are centers weights and biases run consists of a single hidden layer and a linear output layer in can have multiple hidden layers and a linear or nonlinear output layer pros run is a universal approximate and it is easy to add more centers con the bias is not unique,0,2.0,neural_networks,neural_course,0.0
570,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,nearest neighbors 1. take the input data to be classified 2. find the first nearest neighbour in terms of euclidean distance 3. push the class of this nearest neighbour into a list of labels 4. repeat step 2 and 3 for each i which needs to be odd 5. after all i nearest labels are collected in the list count the labels in each class 6. assign to the input data the class which as maximum count majority vote,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
571,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,i first we initialize the random points those points are considered as centroid of clusters ii then for each new points we compute euclidean distance and points closest to centroid are assigned their respective clusters iii we again recalculate the centroid of clusters ivy repeat 2 and 3 until convergence is achieved by making sure no centroid are moving and cost function is minimized,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
572,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,nearest neighbor wants to determine encoder doc which assigns i inputs to i clusters based on a rule to be defined,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
573,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
574,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,1. get the input 2. find the ke nearest neighbours by finding the distance (euclidean) from the input to all the nodes and selecting the i closest ones 3. class of the input is the most frequent class in the k-neighbnours found was such i needs to be odd number,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
575,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,and number of clusters given sample data select and different cluster centers by random assign all sample points to the closest cluster repeat until no further change - recalculate the cluster centers - assign all sample points to the closest cluster,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
576,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,given a fixed sky given a point to classify new given an empty class given a list of all points all from 1 to i do find nearest point ex to new in all add class of nearest point ex in list class new list i = i without nearest neighbor ex class of new = most class in class,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
577,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,define i centroid random initialized assign each data point a class label while the is no change anymore for each i calculate the centroid of the datapoint belonging to that label for each datapoint determine the nearest centroid assign a new class label which belongs to the centroid,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
578,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,nearest neighbors can be seen as an unsupervised learning method where for a defined number of groups ke the nearest neighbors will be calculated i for a given input data i define value i i get the i points that are closer to the given points,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
579,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,i randomly define a redefined number of cluster centers(cc) i calculate the distance of each datapoint from each ca i each data point belongs to the cluster that has the least distance from its ca i calculate a new ca by getting the average of all the points inside a cluster i go to 2 and repeat this process until we reach the termination condition,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
580,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,firstly identify nearest neighbouring weights then choose i amount of neighbors and adapt their weights,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
581,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"initialize neighbors = {}, for every neuron find the nearest neighbor and add it to neighbors return nearest neighbors",add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,1,2.0,neural_networks,neural_course,0.5
582,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,i pseudo code i 1. initiate weights randomly 2. assign labels to inputs that are map neuron is closest to 3. happened all inputs to map neurons using 2. 4. find centroid of the cluster and move the map neuron to the centroid 5. do i and 4 until some convergence criteria is reached edge maximum iterations is reached or no updates are performed or net distance is below some specified distance,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
583,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"given la test not element of la i = number of neighbors that will taken into consideration function classof() set x'={}, l0=l, classf={}; for j=1,...k do l{j-1} \ i'm exclude all the data points which have been identified as nearest neighbors already x'=find the closest neighbor of test in let //e.g. compute eucldea distance i = classof(x'); classf=push(c) set c(xtest)= most frequently value in class",add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
584,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,train the inn by storing the data labeled points present a test point > compute the distance between the test point and all the training data points > sort the distance and choose the i datapoints with smallest distance > determine the class of the test point by majority vote,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
585,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"la - data set (x1,x2,x3,xn) la - storing the dataset based on the number of neighbors test - test data set so we basically have the i value to be an odd number so that we can select a majority value for i based on the number of la xu = test - distance from the neighboring neuron i la = smallest xu in this based on the number of i test = max(l2) we select the neurons from the neighborhood by calculating the euclidean distance based on weights then if i is i we have 3 neurons so from that we select the label which is fixed maximum on the dataset given in the k-fields.",add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
586,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,define criteria for finding i nearest neighbours bra find i nearest neighbours of test input in training dataset bra find the class to which most of the neighbours belong bra assign that class to the test input bra,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
587,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,here learning based on nearest neighbors - all the input-output samples from the training set are stored in the memory - for a test input find the nearest neighbors - assign the test vector with the class of the most of the neighbours in the neighborhood,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
588,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"parameters i number of clusters i datapoints , i classes i initialize randomly i centroid of the clusters i select a data point and compute the set of nearest neighbours of the point using euclidean distances i find the class that maximum number of neighbours belong to and assign the class to the datapoint. i once the class is assigned compute the centroid of each cluster or class considering all the class members i literate over all the datapoints and repeat over all points from step i until no update in centroid is required",add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
589,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
590,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,1. given classified data ex 2. for a new sample $x$: determine the sky nearest neighbours in i output my i majority vote of the class of nearest neighbours,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
591,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"$ i = {x1,x2...xn} $ al = let ex = {}$ for the input (x,d) : do { test }",add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
592,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,1. identify i classified patterns that lie nearest to the test vector 2. assign the test vector to the class that is most frequently presented to the i nearest neighbors,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
593,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,1. define the number of cluster sky 2. generate random weights 3. find the center of each i mean 4. cluster the other outputs by determining the closest neighbor 5. update the weights,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
594,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,* choose a value for i * i represents the number of neighbors * get a sample from the input space * find the class based on the majority of votes received from the neighbors * for example if the value of i is i then let say there are 2 neighbors from class one and 1 neighbor from class two then the new input sample belongs to class one,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
595,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,step we randomly place the i neurons step for each data point whichever neuron is closer to it the datapoint is assigned to that neurons step once all the datapoints are assigned the mean of the datapoints attached to each neuron is calculated and the neuron is shifted to the mean value step step 2 and 3 are done until there is no more shift in the neurons position in this way the neurons are adjusted,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
596,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,step : randomly select the i centers step : cluster the datapoints based on the centers step : the centroid of the cluster becomes the new mean step : repeat step 2 and 3 until there is no more evidential change in the network,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
597,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,input labeled data set one unlabeled data point number i find the i labeled points which are closest to the given unlabeled point from these points find the label which occurs most often assign this label to the unlabeled data point,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
598,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,1. get the nearest neighbor of the current xu 2. remove it from i 3. get the class of the current i 4. classify xu as the class that occurs the most often in the neighbors for 1 to ke li = lex inn = min(|x-x'|) i = getclassof(xnn) amountofclasses.add(c) setclassof(x') = max(amountofclasses),add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
599,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,for the input data i the distance to every other data point is calculated using a distance measure take the i data points which have the minimum distance to xu these are the nearest neighbours the most frequent class from the neighbours is assigned as the class of the input data,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
600,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,this learning is based on the memory introduced into the dataset. for each data point the nearest neighbours are found via a distance function for each datapoint i neighbours = getknearestneighboursof(d) class = getmostrepresentedclass(neighbours),add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
601,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,for a given input compute distances to other input points pick i nearest neighbors look at labeling of neighbors decide labeling classification by highest number of neighbors in one class german mehrheitsentscheid),add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
602,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,trainings i training data define clusters select clusters datapoints as centroid randomly for datapoint in trainingset: calculate distance to centroid able datapoint according to closest centroid end for literate over clusters calculate centroid,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
603,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,(k-nearest neighbours is memory based learning take input i calculate calculate distance of i from each training point select i training points with minimum distance from the data fetch classes of selected i nearest points calculate number points per class in i nearest points determine the class i having maximum points in i nearest points the class of the input point is ca,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
604,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,nearest neighbors basically works as follows i the they define randomly the cluster points . i calculate the mean of the equlidian distance between the data points here the points from the previous step acts as centrioids. i check the variance of the clusters i repeat 1-2-3 till you get the proper clusters,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
605,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,1. slept random number of neighbourhood initially 2. find out the input which is nearest to the weight vector using competitive learning 3. change only the input which wins 4. decrease the size of neighbourhood 5. repeat,add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,0,2.0,neural_networks,neural_course,0.0
606,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"for i in inputpoints neighbours = findnearestkpoints(x) for i in neighbours i = getvoteof(n) updatevotescountfor(x,v) max = getmaxvotefor(x)",add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
607,"Describe how learning based on k-nearest neighbors works, use pseudo code!",237,"let i be set of labeled data in memory i ={x1,x2....xn}, while prime is nearest point to the test point in term of euclidean distance let class be function that return class type if certain data point xu and let i be constant number of neighboring points conspired in algorithm search initialize prime = {}, la = la listofclasses = i for je i j<=k; job do la = l(j-1)/xprime prime = nearest neighbor to test form la data i = classof(xprime) listofclasses.append(c) end c(xtest):= most frequent class in listofclasses",add the new data to the members of colored or classified old data construct a sphere with i nearest data points find the class or color which has the maximum vote and assign the new data to the class which has the maximum vote in an unsupervised manner,2,2.0,neural_networks,neural_course,1.0
608,Explain the Bias Variance Dilemma!,238,in machine learning a choice always needs to be made for the tradeoff between bias and variance bias determines how close the result is to the true value and variance determines the sensitivity to fluctuations in the training dataset. if bias is reduced variance increases and vice versa so an optimum tradeoff needs to be chosen which presents a dilemma,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1,2.0,neural_networks,neural_course,0.5
609,Explain the Bias Variance Dilemma!,238,bias variance dilemma is used to analyse the generalization error of the algorithm if the value of bias is very high then network does not learn relations between features and outputs correctly(overfitting) if the value of variance is very high then network may model the random noise and it does not learn intended ouputs(underfitting) we have to to tradeoff between bias and variance so that our model can generalize properly,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1,2.0,neural_networks,neural_course,0.5
610,Explain the Bias Variance Dilemma!,238,,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
611,Explain the Bias Variance Dilemma!,238,when training a model on a limited training data set we must decide wether we accept a biased model which makes assumptions about the test data but has a better performance on the train data or a model with more variance which might model the entirety of the data better but be prone to data noise usually we have to decide on a trade off between the two where we may select well balanced models based on ve dimensions or cross validation results,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2,2.0,neural_networks,neural_course,1.0
612,Explain the Bias Variance Dilemma!,238,bias and variance are both undesirable to the learning bias defines how far the generated output differs from the true value variance defines how much the op change on changing the input dataset. however in most cases it is only possible to decrease one at the expense of other thus it is called bias variance dilemma,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1,2.0,neural_networks,neural_course,0.5
613,Explain the Bias Variance Dilemma!,238,,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
614,Explain the Bias Variance Dilemma!,238,the bias is the error we make in the assumption by creating the learning machine how much we we are away from the actual truth the variance is how much the learning machine changes with different training data sets if we have a high bias we habe a low variance and if we habe a low variance we habe a high bias,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1,2.0,neural_networks,neural_course,0.5
615,Explain the Bias Variance Dilemma!,238,you have to to a tradeoff between high bias or high variance you cannot have both high variance means the model is overfishing the data and therefore the variance on input can be quit hight high bias means the model is generalization is to unspecified,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1,2.0,neural_networks,neural_course,0.5
616,Explain the Bias Variance Dilemma!,238,the bias is defined as the grade of correctness that a learning algorithm will used the variance is defined as the grade of flexibility that the algorithm have given a model to learn when having the bias high but the variance low the algorithm will not be flexible into data and will discard any data is not exactly the data that fits into the model on the other hands when having the variance high but the bias low the algorithm will be very flexible into the data and will accept any error data as part of the model to learn,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2,2.0,neural_networks,neural_course,1.0
617,Explain the Bias Variance Dilemma!,238,- bias the bias is the difference between the predicted value and the desired value in the generalization run - variance is the inadequate in the produced value in the regression and the desired value that we expect from the network,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
618,Explain the Bias Variance Dilemma!,238,bias variance dilemma is coming from the fact that you can not have both at the same time your network can not be equally great at outpouring with extremely high accuracy extremely hight amount of variables therefore you need to find balance between the two that suits needs of your neural network,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
619,Explain the Bias Variance Dilemma!,238,it is refers to the problem of trying to maintain a balance between two causes of errors in learning algorithms such that the network is able to generalize data beyond that used for training namely the bias error and the variance error having a high bias error may cause the network to miss important features in the training data which leads to underfitting. high variance will make the network to memorize noise present in the training data rather than learning features which lead to overfitting.,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2,2.0,neural_networks,neural_course,1.0
620,Explain the Bias Variance Dilemma!,238,+ one cannot optimize simultaneously the learning algorithm both for learning maximum variance in the data and learning localization which can be termed as bias,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
621,Explain the Bias Variance Dilemma!,238,,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
622,Explain the Bias Variance Dilemma!,238,the bias variance dilemma tells us that the bias the difference between the actual and desired output and the variance output difference between each trial cannot be decreased at the same time a complex model results in small variance and larger variance,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1,2.0,neural_networks,neural_course,0.5
623,Explain the Bias Variance Dilemma!,238,so in machine learning problem minimizing the two main source of error simultaneously does not allow the networks to be generalized very easy if bias increase variance decrease and vice versa also holds 1. bias tells us how close we are to the true value 2. variance tells us how they vary for different data set so this is a standard problem in in,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2,2.0,neural_networks,neural_course,1.0
624,Explain the Bias Variance Dilemma!,238,high value of bias means network is unable to learn the data whereas higher variance means its difficult to learn the training data successfully,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
625,Explain the Bias Variance Dilemma!,238,,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
626,Explain the Bias Variance Dilemma!,238,"bias and variances are the estimation errors bias corresponds to the inability of the learning machine to appropriately approximate the function to be learnt hence this induces a deviation from the actual function variance is the inadequacy of the training data to allow the a learning machine to successfully learn the function the dilemma is that , to completely learn the actual function to reduce variance-related error the training data required should consist of infinite samples however this results in slower convergence intern bias error increases therefore trade of between both the errors need to be made",bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2,2.0,neural_networks,neural_course,1.0
627,Explain the Bias Variance Dilemma!,238,,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
628,Explain the Bias Variance Dilemma!,238,bias is the difference between the predicted and true value variance is the range of several predicted values of the same datapoint. it is desirable to have low bias and low variance to ensure the predicted value is consistently close to the true value the bias variance dilemma is that to achieve low bias the variance becomes high and vice versa hence there is always a tradeoff between the two,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2,2.0,neural_networks,neural_course,1.0
629,Explain the Bias Variance Dilemma!,238,bias variance dilemma refers to the problem of minimizing the two sources of error bias error and variance error simultaneously which creates problem in generalization of the network bias error it is the error that occurs while setting the parameters of the network variance error:it refers to how sensitive the network is to the fluctuations in the dataset.,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2,2.0,neural_networks,neural_course,1.0
630,Explain the Bias Variance Dilemma!,238,,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
631,Explain the Bias Variance Dilemma!,238,bias variance dilemma is a process of simultaneously decreasing two sources of error that prevents supervised learning algorithm from centralizing beyond the trained data,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
632,Explain the Bias Variance Dilemma!,238,bias is used to fine transform of $u$. it helps to shift the classifier line $$v=u+b$$,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
633,Explain the Bias Variance Dilemma!,238,bias how close the estimate is to the true value variance how much does the estimate vary for different training sets we always have either hugh variance low bias or low variance high bias,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1,2.0,neural_networks,neural_course,0.5
634,Explain the Bias Variance Dilemma!,238,bias : difference between the estimated output and the actual output variance the range of output of a network for different training set bias and variance can't be decreased at the same time for many networks only one at a time can be decreased,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1,2.0,neural_networks,neural_course,0.5
635,Explain the Bias Variance Dilemma!,238,,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
636,Explain the Bias Variance Dilemma!,238,when adapting the parameters of a network we can either have a small bias or a small variance if we have a small bias the approximation of the network is close to the real one but the variance between trials is very high if we have a low variance the bias can't be minimized and the network has a bigger error between the approximation and the real value,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1,2.0,neural_networks,neural_course,0.5
637,Explain the Bias Variance Dilemma!,238,,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
638,Explain the Bias Variance Dilemma!,238,ideally bias and variance would be 0 after learning a machine however bias and variance counteract eachother when bias decreases variance rises and respectively in the other direction this leads to the dilemma that either one of the values has to be present,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1,2.0,neural_networks,neural_course,0.5
639,Explain the Bias Variance Dilemma!,238,,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
640,Explain the Bias Variance Dilemma!,238,usually only one of bias and variance can be minimized in an run for example few kernels with greater width leads to a high bias but a low variance if you choose many kernels with smaller width the bias is low but the variance is high higher complexity models need more training data,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,2,2.0,neural_networks,neural_course,1.0
641,Explain the Bias Variance Dilemma!,238,,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
642,Explain the Bias Variance Dilemma!,238,bias is an provides an fine transformation and it is treated a extra inputs which normal taken as +1,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
643,Explain the Bias Variance Dilemma!,238,high bias and variance is desirable in input bias variance dilemma is the property of input data where if the bias is increased the variance decreases and vice versa it is difficult to find a tradeoff between them,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1,2.0,neural_networks,neural_course,0.5
644,Explain the Bias Variance Dilemma!,238,bias bias means how much the prediction differs from the true value variance variance means how much the prediction varies for different datasets the dilemma is that both generally can not be reduced simultaneously a learning machine can reduce one at the cost of other,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,1,2.0,neural_networks,neural_course,0.5
645,Explain the Bias Variance Dilemma!,238,,bias-variance dilemma is a principle supervised learning problem the dilemma arises due to the variance of data and bias of model when there is high bias the model fits the training data perfectly but suffers from high variance when the bias is low the variance reduces but the model doesn't fit the data well this dilemma makes the generalizability difficult to achieve,0,2.0,neural_networks,neural_course,0.0
